<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>You can now fine-tune embedding models in our free Unsloth notebook! ü§ó</title><link>https://huggingface.co/posts/danielhanchen/579968620456275</link><description>You can now fine-tune embedding models in our free Unsloth notebook! ü§ó Fine-tuning embedding models improves retrieval &amp; RAG by aligning vectors to your domain-specific notion of similarity, improving search, clustering, and recommendations on your data. ‚≠ê Blog + Notebooks: https://unsloth.ai/docs/new/embedding-finetuning Unsloth trains embedding models 1.8-3.3x faster with 20% less VRAM, 2x longer context &amp; no accuracy loss vs. FA2 setups. We'd like to thank Hugging Face and Unsloth contributor: electroglyph for making this possible! See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/579968620456275</guid></item><item><title>Google published the paper. I shipped the code. üöÄ</title><link>https://huggingface.co/posts/hassenhamdi/338157395556750</link><description>Google published the paper. I shipped the code. üöÄ DeepMind just released PACEvolve (Progress-Aware Consistent Evolution), a massive overhaul of the AlphaEvolve framework. It solves the critical issues of "Context Pollution" and "Mode Collapse" that have historically crippled evolutionary coding agents. But there was no public implementation. So I built one. Introducing OpenPACEvolve: A fully open-source, production-grade implementation of the PACEvolve framework. üõ† I engineered this framework solo, but I wasn't working alone. I orchestrated a custom coding agents powered by Claude Opus 4.5 as Engineer and Gemini Pro 3 Preview ensuring fiedelity and quallty. By leveraging these SOTA models, I was able to translate complex theoretical research into functional, modular Python architecture in record time. This is what the future of AI engineering looks like: Human architectural oversight + AI velocity. üß† What OpenPACEvolve Solves: Unlike standard agents that get "stuck" in loops, this...</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hassenhamdi/338157395556750</guid></item><item><title>Our engineer Alan from</title><link>https://huggingface.co/posts/branikita/663180639810394</link><description>Our engineer Alan from https://robonine.com/ (Educational Robotics) integrated Feetech STS3250 and STS3215 servo motors into the prototype and completed the first test run of a 6-DOF semi-SCARA manipulator. During motion, the structure demonstrates high stiffness with no visible backlash or mechanical play. The kinematic chain remains stable throughout the test trajectory, confirming the rigidity of the mechanical design and joint assembly. The next stage includes full assembly with all actuators operating in backlash compensation mode, followed by quantitative measurement of positioning accuracy and repeatability. See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/663180639810394</guid></item><item><title>GLM-4.7-Flash is fast, good and cheap.</title><link>https://huggingface.co/posts/mitkox/833172754531021</link><description>GLM-4.7-Flash is fast, good and cheap. 3,074 tokens/sec peak at 200k tokens context window on my desktop PC. Works with Claude Code and opencode for hours. No errors, drop-in replacement of the Anthropic cloud AI. MIT licensed, open weights, free for commercial use and modifications. Supports speculative decoding using MTP, which is highly effective in mitigating latency. Great for on device AI coding as AWQ 4bit at 18.5 GB. Hybrid inference on a single consumer GPU + CPU RAM. See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mitkox/833172754531021</guid></item><item><title>Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI!</title><link>https://huggingface.co/posts/projectlosangeles/732365874551092</link><description>Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI! projectlosangeles/Orpheus-Karaoke See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/projectlosangeles/732365874551092</guid></item><item><title>Now Live: The</title><link>https://huggingface.co/posts/Reubencf/519964840142107</link><description>Now Live: The Reubencf/Nano_Banana_Editor now includes 10 free requests/day! üçå I'm personally sponsoring these credits to help make open AI accessible to all. (Note: Limits are subject to change based on funding). Enjoy ! See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reubencf/519964840142107</guid></item><item><title>Lacking vllm support  for Transformers v5, frustrating only me?</title><link>https://huggingface.co/posts/mahimairaja/981245341655161</link><description>Lacking vllm support for Transformers v5, frustrating only me? See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mahimairaja/981245341655161</guid></item><item><title>üéÆ Introducing: Paper Popularity Game</title><link>https://huggingface.co/posts/efecelik/696705775855438</link><description>üéÆ Introducing: Paper Popularity Game Think you know which AI papers go viral? Test your instincts! I built a little game where you try to guess the popularity of AI research papers from the Hugging Face Daily Papers feed. How it works: You'll see two papers side by side‚Äîread the titles, check the abstracts, and pick which one you think got more upvotes from the HF community. It's a great way to discover trending AI research while having fun. Tests your intuition about what the ML community finds interesting. Try it out: efecelik/paper-popularity-game Would love to hear your high scores and feedback! See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/efecelik/696705775855438</guid></item><item><title>üèõÔ∏è Google Code Archive Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/331224318760046</link><description>üèõÔ∏è Google Code Archive Dataset - nyuuzyou/google-code-archive Expanding beyond the modern code series, this release presents a massive historical snapshot from the Google Code Archive. This dataset captures the open-source landscape from 2006 to 2016, offering a unique time capsule of software development patterns during the era before GitHub's dominance. Key Stats: - 65,825,565 files from 488,618 repositories - 47 GB compressed Parquet storage - 454 programming languages (Heavily featuring Java, PHP, and C++) - Extensive quality filtering (excluding vendor code and build artifacts) - Rich historical metadata: original repo names, file paths, and era-specific licenses This is one of those releases that I'm most interested in getting feedback on. Would you like to see more old code datasets? See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/331224318760046</guid></item><item><title>DeepSeek R1 dropped one year ago üê≥ and a lot has changed.</title><link>https://huggingface.co/posts/AdinaY/119145219843817</link><description>DeepSeek R1 dropped one year ago üê≥ and a lot has changed. With @ irenesolaiman , we‚Äôre launching a blog series about how that moment reshaped AI + open source in 2025, starting with strategic shifts and the explosion of new open models in China! https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment See translation</description><pubDate>Fri, 23 Jan 2026 05:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/119145219843817</guid></item></channel></rss>