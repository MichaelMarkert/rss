<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Gini's AI Spaces: Everything You Need for Visual Content Creation!</title><link>https://huggingface.co/posts/ginipick/539440985640088</link><description>Gini's AI Spaces: Everything You Need for Visual Content Creation! Hello! ✨ Let me introduce Gini’s 5 AI Spaces that effortlessly generate various styles of visual content. Each Space leverages Diffusers and Gradio, so you can create stunning images in just a few clicks! 1) Flowchart Features: Hand-drawn style flowcharts for workflows or business processes Use Cases: Software release pipelines, data pipelines, corporate workflows Benefits: Clear stage-by-stage structure, simple icon usage ginigen/Flowchart 2) Infographic Features: Visually appealing infographics that communicate data or statistics Use Cases: Global energy charts, startup growth metrics, health tips and more Benefits: Eye-catching icons and layouts, perfect for storytelling at a glance ginigen/Infographic 3) Mockup Features: Sketch-style wireframes or UX mockups for apps/websites Use Cases: Mobile login flows, dashboards, e-commerce site layouts Benefits: Rapid prototyping of early design ideas, perfect for...</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/539440985640088</guid></item><item><title>🚀 FLUX Workflow Canvas</title><link>https://huggingface.co/posts/ginipick/141662077994282</link><description>🚀 FLUX Workflow Canvas Welcome to Workflow Canvas, your ultimate AI-driven platform for crafting stunning design concepts and intricate workflow diagrams that empower your business! 🤖✨ ginigen/Workflow-Canvas Features Product Design 🛠️ Transform your ideas into reality with sleek, industrial product designs that blend modern aesthetics with advanced technology. Mindmap 🧠 Generate vibrant, educational mind maps that outline your strategies and processes in a clear, visually engaging layout. Mockup 📱 Quickly prototype intuitive app interfaces and web designs using clean, hand-drawn wireframes that capture your vision. Infographic 📊 Build polished, data-rich infographics that communicate complex corporate metrics and trends with style and clarity. Diagram 📈 Illustrate comprehensive, end-to-end business workflows—from market analysis to implementation—with detailed and organized diagrams. Flowchart 🔄 Design easy-to-follow, hand-drawn style flowcharts that map out your operational...</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/141662077994282</guid></item><item><title>I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait</title><link>https://huggingface.co/posts/Reality123b/533143502736808</link><description>I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait See translation</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reality123b/533143502736808</guid></item><item><title>Finally here it is: a faster, custom, scalable GRPO trainer for smaller models with &lt; 500M params, can train on 8gb ram cpu,  also supports gpu for sanity sake (includes support for vllm + flash attention). Using smolLM2-135M/360M-instructs as ref &amp; base models. Experience your own “aha” moment 🐳 on 8gb ram.</title><link>https://huggingface.co/posts/Jaward/905904518817417</link><description>Finally here it is: a faster, custom, scalable GRPO trainer for smaller models with &lt; 500M params, can train on 8gb ram cpu, also supports gpu for sanity sake (includes support for vllm + flash attention). Using smolLM2-135M/360M-instructs as ref &amp; base models. Experience your own “aha” moment 🐳 on 8gb ram. Code: https://github.com/Jaykef/ai-algorithms/blob/main/smollm2_360M_135M_grpo_gsm8k.ipynb See translation</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/905904518817417</guid></item><item><title>The last week of Impression Craft Arts and sketches from strangerzonehf🎨🧑🏻‍🎨</title><link>https://huggingface.co/posts/prithivMLmods/804280933500371</link><description>The last week of Impression Craft Arts and sketches from strangerzonehf🎨🧑🏻‍🎨 - Collection : strangerzonehf/Flux-Ultimate-LoRA-Collection Adapters: + Ld-Art : strangerzonehf/Ld-Art + Animeopix-Flux : strangerzonehf/Animeopix-Flux + Flux-Super-Paint-LoRA : strangerzonehf/Flux-Super-Paint-LoRA + CinematicShot-Pics-Flux : strangerzonehf/cinematicShot-Pics-Flux + Oil-Wall-Art-Flux : strangerzonehf/Oil-Wall-Art-Flux + Pixelo-Flux : strangerzonehf/Pixelo-Flux + Abstract-Shattered : strangerzonehf/Abstract-Shattered + Neon-Impressionism-Flux : strangerzonehf/Neon-Impressionism-Flux + NewG-Art : strangerzonehf/NewG-Art 🪧Demo : prithivMLmods/FLUX-LoRA-DLC 🤗Page : https://huggingface.co/strangerzonehf See translation</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/804280933500371</guid></item><item><title>We crossed 1B+ tokens routed to inference providers partners on HF, that we released just a few days ago.</title><link>https://huggingface.co/posts/clem/679572962523651</link><description>We crossed 1B+ tokens routed to inference providers partners on HF, that we released just a few days ago. Just getting started of course but early users seem to like it &amp; always happy to be able to partner with cool startups in the ecosystem. Have you been using any integration and how can we make it better? https://huggingface.co/blog/inference-providers See translation</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/679572962523651</guid></item><item><title>🔮 GPT-3 implemented in pure Free Pascal!</title><link>https://huggingface.co/posts/schuler/523097349867184</link><description>🔮 GPT-3 implemented in pure Free Pascal! https://github.com/joaopauloschuler/gpt-3-for-pascal This implementation follows the GPT-3 Small architecture from the landmark paper "Language Models are Few-Shot Learners": ┌─────────────────────────┐ │ Input Layer │ ├─────────────────────────┤ │ Token &amp; Positional │ │ Embedding │ ├─────────────────────────┤ │ 12x Transformer │ │ Blocks │ │ - 12 heads │ │ - 768 hidden dims │ │ - 3072 intermediate │ ├─────────────────────────┤ │ Output Layer │ └─────────────────────────┘ Clean Pascal Implementation for CntLayer := 1 to {Layers=} 12 do begin Result .AddTransformerBlockCAI( {Heads=} 12 , {intermediate dimensions=} 4 * 768 , {NoForward=} true , {HasNorm=} true , false ) ; end ; See translation</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/schuler/523097349867184</guid></item><item><title>Introducing VLM-R1!</title><link>https://huggingface.co/posts/tianchez/384417618281589</link><description>Introducing VLM-R1! GRPO has helped DeepSeek R1 to learn reasoning. Can it also help VLMs perform stronger for general computer vision tasks? The answer is YES and it generalizes better than SFT. We trained Qwen 2.5 VL 3B on RefCOCO (a visual grounding task) and eval on RefCOCO Val and RefGTA (an OOD task). https://github.com/om-ai-lab/VLM-R1 See translation</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tianchez/384417618281589</guid></item><item><title>I am pleased to introduce my first project built upon Hugging Face’s smolagents framework, integrated with Alpaca for financial market analysis automation 🦙🤗</title><link>https://huggingface.co/posts/louisbrulenaudet/828105702758595</link><description>I am pleased to introduce my first project built upon Hugging Face’s smolagents framework, integrated with Alpaca for financial market analysis automation 🦙🤗 The project implements technical indicators such as the Relative Strength Index (RSI) and Bollinger Bands to provide momentum and volatility analysis. Market data is retrieved through the Alpaca API, enabling access to historical price information across various timeframes. AI-powered insights are generated using Hugging Face’s inference API, facilitating the analysis of market trends through natural language processing with DuckDuckGo search integration for real-time sentiment analysis based on financial news 🦆 Link to the GitHub project: https://github.com/louisbrulenaudet/agentic-market-tool See translation</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/louisbrulenaudet/828105702758595</guid></item><item><title>8 New Applications of Test-Time Scaling</title><link>https://huggingface.co/posts/Kseniase/134685305854108</link><description>8 New Applications of Test-Time Scaling We've noticed a huge interest in test-time scaling (TTS), so we decided to explore this concept further. Test-time compute (TTC) refers to the amount of computational power used by an AI model when generating a response. Many researchers are now focused on scaling TTC, as it enables slow, deep "thinking" and step-by-step reasoning, which improves overall models' performance. Here are 8 fresh studies on test-time scaling: 1. Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach (2502.05171) Introduces an LM that scales TTC by reasoning in latent space instead of generating more tokens with no special training. Here, a recurrent block to processes information iteratively. 2. Generating Symbolic World Models via Test-time Scaling of Large Language Models (2502.04728) Shows how TTS is applied to enhance model's Planning Domain Definition Language (PDDL) reasoning capabilities, which can be used to generate a symbolic world...</description><pubDate>Tue, 18 Feb 2025 09:21:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/134685305854108</guid></item></channel></rss>