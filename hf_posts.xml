<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>An assembly of 18 European companies, labs, and universities have banded together to launch 🇪🇺 EuroBERT! It's a state-of-the-art multilingual encoder for 15 European languages, designed to be finetuned for retrieval, classification, etc.</title><link>https://huggingface.co/posts/tomaarsen/782540332014764</link><description>An assembly of 18 European companies, labs, and universities have banded together to launch 🇪🇺 EuroBERT! It's a state-of-the-art multilingual encoder for 15 European languages, designed to be finetuned for retrieval, classification, etc. 🇪🇺 15 Languages: English, French, German, Spanish, Chinese, Italian, Russian, Polish, Portuguese, Japanese, Vietnamese, Dutch, Arabic, Turkish, Hindi 3️⃣ 3 model sizes: 210M, 610M, and 2.1B parameters - very very useful sizes in my opinion ➡️ Sequence length of 8192 tokens! Nice to see these higher sequence lengths for encoders becoming more common. ⚙️ Architecture based on Llama, but with bi-directional (non-causal) attention to turn it into an encoder. Flash Attention 2 is supported. 🔥 A new Pareto frontier (stronger *and* smaller) for multilingual encoder models 📊 Evaluated against mDeBERTa, mGTE, XLM-RoBERTa for Retrieval, Classification, and Regression (after finetuning for each task separately): EuroBERT punches way above its weight. 📝...</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tomaarsen/782540332014764</guid></item><item><title>Huggingface Space Leaderboard 🚀</title><link>https://huggingface.co/posts/openfree/729932908902684</link><description>Huggingface Space Leaderboard 🚀 Hello Huggingface Community! VIDraft/Space-Leaderboard We are excited to introduce the Huggingface Space Leaderboard, a service that lets you view the latest trending Spaces on the Huggingface platform at a glance. This service helps you quickly explore a wide range of creative projects and will spark new inspiration for your own ideas. 🎉 Detailed Feature Overview 1. Real-time Trend Reflection Automated Aggregation: Analyzes and ranks over 500 popular Spaces on Huggingface in real time. Accurate Ranking: Combines various metrics such as likes, engagement, and creation time to accurately reflect the latest trends. Instant Updates: Data is continuously updated, so you always see the most current popular Spaces. 2. Intuitive Preview 70% Scaled Preview: Each Space is displayed at 70% scale, providing a neat and clear preview at a glance. Easy Visual Comparison: View multiple Spaces side by side to easily compare their designs and functionalities. Error...</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/729932908902684</guid></item><item><title>LeRobot goes to driving school! 🚗🚗🚗</title><link>https://huggingface.co/posts/BrigitteTousi/467635548040677</link><description>LeRobot goes to driving school! 🚗🚗🚗 Hugging Face just announced a new collab with Yaak to bring the largest open-source self-driving dataset to LeRobot! Major kudos to HF's @ cadene , as well as @ sandhawalia , @ Shnissen and the Yaak team! Check out the blog post here: https://huggingface.co/blog/lerobot-goes-to-driving-school See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/BrigitteTousi/467635548040677</guid></item><item><title>Variable Demo for Two Image-to-Text-to-Text Multimodals 🌠</title><link>https://huggingface.co/posts/prithivMLmods/506493789164421</link><description>Variable Demo for Two Image-to-Text-to-Text Multimodals 🌠 📜Space: prithivMLmods/Multimodal-OCR By default, it will use: prithivMLmods/Qwen2-VL-OCR-2B-Instruct or prithivMLmods/Qwen2-VL-OCR2-2B-Instruct To trigger Aya-Vision's 8B by @ aya-vision , use the prompt: CohereForAI/aya-vision-8b See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/506493789164421</guid></item><item><title>Regardless of X being down or not, so glad I can rely on HF Posts for AI news ❤️🤗</title><link>https://huggingface.co/posts/BrigitteTousi/858963061028741</link><description>Regardless of X being down or not, so glad I can rely on HF Posts for AI news ❤️🤗 See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/BrigitteTousi/858963061028741</guid></item><item><title>Honored to be named among their 12 pioneers and power players in the news industry in the 2025 Tech Trends Report from Future Today Strategy Group.</title><link>https://huggingface.co/posts/fdaudens/473088205866195</link><description>Honored to be named among their 12 pioneers and power players in the news industry in the 2025 Tech Trends Report from Future Today Strategy Group. Incredible group to be part of - each person is doing groundbreaking work at the intersection of AI and journalism. Worth following them all: they're consistently sharing practical insights on building the future of news. Take the time to read this report, it's packed with insights as always. The news &amp; information section's #1 insight hits hard: "The most substantive economic impact of AI to date has been licensing payouts for a handful of big publishers. The competition will start shifting in the year ahead to separate AI 'haves' that have positioned themselves to grow from the 'have-nots.'" This AI-driven divide is something I've been really concerned about. Now is the time to build more than ever! 👉 Full report here: https://ftsg.com/wp-content/uploads/2025/03/FTSG_2025_TR_FINAL_LINKED.pdf See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/473088205866195</guid></item><item><title>I was chatting with</title><link>https://huggingface.co/posts/clem/381394695080482</link><description>I was chatting with @ peakji , one of the cofounders of Manu AI, who told me he was on Hugging Face (very cool!). He shared an interesting insight which is that agentic capabilities might be more of an alignment problem rather than a foundational capability issue. Similar to the difference between GPT-3 and InstructGPT, some open-source foundation models are simply trained to 'answer everything in one response regardless of the complexity of the question' - after all, that's the user preference in chatbot use cases. Just a bit of post-training on agentic trajectories can make an immediate and dramatic difference. As a thank you to the community, he shared 100 invite code first-come first serve, just use “HUGGINGFACE” to get access! See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/381394695080482</guid></item><item><title>We distill a more accurate and concise dataset from DeepSeek R1, and also provide a distillation pipeline code repository.🤗</title><link>https://huggingface.co/posts/JingzeShi/246281295432423</link><description>We distill a more accurate and concise dataset from DeepSeek R1, and also provide a distillation pipeline code repository.🤗 Dataset: SmallDoge/SmallThoughts Code: https://github.com/SmallDoges/small-thoughts See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JingzeShi/246281295432423</guid></item><item><title>Introducing OlympicCoder: a series of open reasoning models that can solve olympiad-level programming problems 🧑‍💻</title><link>https://huggingface.co/posts/lewtun/886287473065721</link><description>Introducing OlympicCoder: a series of open reasoning models that can solve olympiad-level programming problems 🧑‍💻 - 7B open-r1/OlympicCoder-7B - 32B open-r1/OlympicCoder-32B We find that OlympicCoder models outperform Claude 3.7 Sonnet, as well as others over 100x larger 💪 Together with the models, we are releasing: 📊CodeForces-CoTs: new dataset of code problems from the most popular competitive coding platform, with R1 traces in C++ and Python open-r1/codeforces-cots 🏆 IOI'2024: a new benchmark of VERY hard programming problems where even frontier models struggle to match human performance open-r1/ioi For links to the models and datasets, check out our latest progress report from Open R1: https://huggingface.co/blog/open-r1/update-3 See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/lewtun/886287473065721</guid></item><item><title>. World's largest open-source self driving dataset. Ready for end-to-end learning with LeRobot.</title><link>https://huggingface.co/posts/sandhawalia/828661994559435</link><description>LeRobot goes to driving school . World's largest open-source self driving dataset. Ready for end-to-end learning with LeRobot. 3 years, 30 German cities, 60 driving instructors and students. https://huggingface.co/blog/lerobot-goes-to-driving-school Coming this summer — LeRobot driver. See translation</description><pubDate>Wed, 12 Mar 2025 09:23:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sandhawalia/828661994559435</guid></item></channel></rss>