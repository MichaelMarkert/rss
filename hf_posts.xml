<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Samsung Hacking Incident: Samsung Electronics' Official Hugging Face Account Compromised</title><link>https://huggingface.co/posts/seawolf2357/424129432408590</link><description>Samsung Hacking Incident: Samsung Electronics' Official Hugging Face Account Compromised Samsung Electronics' official Hugging Face account has been hacked. Approximately 17 hours ago, two new language models (LLMs) were registered under Samsung Electronics' official Hugging Face account. These models are: https://huggingface.co/Samsung/MuTokenZero2-32B https://huggingface.co/Samsung/MythoMax-L2-13B The model descriptions contain absurd and false claims, such as being trained on "1 million W200 GPUs," hardware that doesn't even exist. Moreover, community participants on Hugging Face who have noticed this issue are continuously posting that Samsung Electronics' account has been compromised. There is concern about potential secondary and tertiary damage if users download these LLMs released under the Samsung Electronics account, trusting Samsung's reputation without knowing about the hack. Samsung Electronics appears to be unaware of this situation, as they have not taken any visible...</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/424129432408590</guid></item><item><title>ğŸš€ ZeroGPU</title><link>https://huggingface.co/posts/cbensimon/356529804559377</link><description>ğŸš€ ZeroGPU medium size is now available as a power-user feature Nothing too fancy for nowâ€”ZeroGPU Spaces still default to large (70GB VRAM)â€”but this paves the way for: - ğŸ’° size-based quotas / pricing ( medium will offer significantly more usage than large ) - ğŸ¦£ the upcoming xlarge size (141GB VRAM) You can as of now control GPU size via a Space variable. Accepted values: - auto (future default) - medium - large (current default) The auto mode checks total CUDA tensor size during startup: - More than 30GB â†’ large - Otherwise â†’ medium See translation</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/cbensimon/356529804559377</guid></item><item><title>Tried something new: an AI-generated podcast that breaks down the top research paper each day. Fully automated, now live on Spotify.</title><link>https://huggingface.co/posts/fdaudens/617387724043904</link><description>Tried something new: an AI-generated podcast that breaks down the top research paper each day. Fully automated, now live on Spotify. I built this prototype to help keep up with the rapid pace of AI developments and, hopefully, make cutting-edge research more accessible. I donâ€™t know about you, but just listening to a conversation about a paper really helps the content sink in for me. This build taught me a lot about full automation. If youâ€™re into the technical weeds: Qwen3 runs on Inference to handle the script, Kokoro does the voice, and the whole thing gets published automatically thanks to the Hugging Face Jobs API and Gradio deployment. Itâ€™s not perfect yet â€” Iâ€™ll be monitoring for hallucinations and incoherence. The voice model still needs polish, but itâ€™s a promising start. Would love to build this with the community â€” submit a PR or send feedback. Itâ€™s just a beta of an experimental idea! Big kudos to @ m-ric , whose Open NotebookLM this is based on, and to @ nielsr for his...</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/617387724043904</guid></item><item><title>ğŸŒŠ CycleNavigator: Visualizing Economic and Political Cycles Through AI at a Glance! ğŸ§ ğŸ’¹</title><link>https://huggingface.co/posts/openfree/905523908666849</link><description>ğŸŒŠ CycleNavigator: Visualizing Economic and Political Cycles Through AI at a Glance! ğŸ§ ğŸ’¹ ğŸ’« Strategic Intelligence Tool for Navigating Historical Waves and Forecasting the Future Hello there! ğŸ™Œ CycleNavigator brings you an innovative fusion of economic history, data visualization, and generative AI. This open-source project revolutionizes decision-making by displaying four major economic and political cycles through interactive visualizations! ğŸ“Š Experience Four Major Cycles in One View: Business Cycle (â‰ˆ9 years) â±ï¸ - The 'heartbeat' of investment and inventory Kondratiev Wave (â‰ˆ50 years) ğŸŒ - Long technological innovation waves Finance Cycle (â‰ˆ80 years) ğŸ’° - Rhythm of debt and financial crises Hegemony Cycle (â‰ˆ250 years) ğŸ›ï¸ - Transitions in global order âœ¨ Cutting-Edge Features: Interactive Wave Visualization ğŸ¯ - Intuitive graphs powered by Plotly AI-Powered Historical Similarity Mapping ğŸ§© - Connecting past events via SBERT embeddings Real-time News Integration ğŸ“° - Linking current issues...</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/905523908666849</guid></item><item><title>Lumier â€“ Run macOS &amp; Linux VMs in a Docker</title><link>https://huggingface.co/posts/dhruv3006/465197265329383</link><description>Lumier â€“ Run macOS &amp; Linux VMs in a Docker Lumier is an open-source tool for running macOS virtual machines in Docker containers on Apple Silicon Macs. When building virtualized environments for AI agents, we needed a reliable way to package and distribute macOS VMs. Inspired by projects like dockur/macos that made macOS running in Docker possible, we wanted to create something similar but optimized for Apple Silicon. The existing solutions either didn't support M-series chips or relied on KVM/Intel emulation, which was slow and cumbersome. We realized we could leverage Apple's Virtualization Framework to create a much better experience. Lumier takes a different approach: It uses Docker as a delivery mechanism (not for isolation) and connects to a lightweight virtualization service (lume) running on your Mac. Lumier is 100% open-source under MIT license and part of C/ua. Github : https://github.com/trycua/cua/tree/main/libs/lumier Join the discussion here :...</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/465197265329383</guid></item><item><title>We're thrilled to announce the launch of our comprehensive Model Context Protocol (MCP) Course! This free program is designed to take learners from foundational understanding to practical application of MCP in AI.</title><link>https://huggingface.co/posts/burtenshaw/628550559998121</link><description>We're thrilled to announce the launch of our comprehensive Model Context Protocol (MCP) Course! This free program is designed to take learners from foundational understanding to practical application of MCP in AI. Follow the course on the hub: mcp-course In this course, you will: ğŸ“– Study Model Context Protocol in theory, design, and practice. ğŸ§‘â€ğŸ’» Learn to use established MCP SDKs and frameworks. ğŸ’¾ Share your projects and explore applications created by the community. ğŸ† Participate in challenges and evaluate your MCP implementations. ğŸ“ Earn a certificate of completion. At the end of this course, you'll understand how MCP works and how to build your own AI applications that leverage external data and tools using the latest MCP standards. See translation</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/628550559998121</guid></item><item><title>60+ Generative AI projects for your resume. grind this GitHub repo if you want to level up:</title><link>https://huggingface.co/posts/hesamation/190820854172664</link><description>60+ Generative AI projects for your resume. grind this GitHub repo if you want to level up: &gt; LLM fine-tuning and applications &gt; advanced RAG apps &gt; Agentic AI projects &gt; MCP and A2A (new) GitHub: https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/resources/60_ai_projects.md See translation</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/190820854172664</guid></item><item><title>ğŸŒŸ Introducing IlÃºvatar: Creative Design &amp; Invention AI ğŸŒŸ</title><link>https://huggingface.co/posts/ginipick/340514834154581</link><description>ğŸŒŸ Introducing IlÃºvatar: Creative Design &amp; Invention AI ğŸŒŸ Link: ginipick/IDEA-DESIGN Hello, AI creators! ğŸ‘‹ Today I'm introducing IlÃºvatar, an amazing tool that automatically generates innovative design and invention ideas. âœ¨ Key Features ğŸ§  AI-Powered Idea Generation: Creates detailed design/invention ideas from simple prompts ğŸ” Web Search Integration: Incorporates real-time information to reflect latest trends ğŸ“Š Kaggle Dataset Analysis: Provides data-driven insights ğŸ–¼ï¸ Automatic Image Generation: Creates image prompts visualizing your ideas ğŸ“ File Upload Support: Analyzes reference materials (text, CSV, PDF) ğŸ“ˆ Business Frameworks: Includes SWOT, Porter's 5 Forces, BCG Matrix analyses ğŸŒ Multilingual Support: Available in both English and Korean ğŸ¯ Perfect For ğŸ’¼ Product Designers/Developers: When you need fresh product concepts ğŸ”¬ Researchers/Inventors: When you need innovative idea inspiration ğŸ“ Planners/Marketers: When you need differentiated business strategies ğŸ“ Students/Educators:...</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/340514834154581</guid></item><item><title>New in smolagents v1.16.0:</title><link>https://huggingface.co/posts/albertvillanova/859296817152556</link><description>New in smolagents v1.16.0: ğŸ” Bing support in WebSearchTool ğŸ Custom functions &amp; executor_kwargs in LocalPythonExecutor ğŸ”§ Streaming GradioUI fixes ğŸŒ Local web agents via api_base &amp; api_key ğŸ“š Better docs ğŸ‘‰ https://github.com/huggingface/smolagents/releases/tag/v1.16.0 See translation</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/albertvillanova/859296817152556</guid></item><item><title>Models for detecting images generated by diffusion models (Flux.1, SDXL, ..) are trained or fine-tuned using image classification models for content moderation. These models use datasets available on the Hub. For identifying AI-generated images or moderating visual content, the recommended model is OpenSDI-Flux.1-SigLIP2.ğŸ˜ºğŸ§¨</title><link>https://huggingface.co/posts/prithivMLmods/424330932729309</link><description>Models for detecting images generated by diffusion models (Flux.1, SDXL, ..) are trained or fine-tuned using image classification models for content moderation. These models use datasets available on the Hub. For identifying AI-generated images or moderating visual content, the recommended model is OpenSDI-Flux.1-SigLIP2.ğŸ˜ºğŸ§¨ Models : prithivMLmods/OpenSDI-Flux.1-SigLIP2 [Best approach for AI [Diffusion Generated] vs. real image classification] prithivMLmods/OpenSDI-SD2.1-SigLIP2 prithivMLmods/OpenSDI-SD3-SigLIP2 prithivMLmods/OpenSDI-SD1.5-SigLIP2 prithivMLmods/OpenSDI-SDXL-SigLIP2 Datasets : nebula/OpenSDI_test madebyollin/megalith-10m Collection : prithivMLmods/opensdi-diffusion-generated-image-classification-682488a3a3e5be7083db3383 Find a collections inside the collection.ğŸ‘† To know more about it, visit the model card of the respective model. See translation</description><pubDate>Sat, 17 May 2025 05:21:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/424330932729309</guid></item></channel></rss>