<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.</title><link>https://huggingface.co/posts/etemiz/710778843328598</link><description>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really "free": they are costing you your freedom if you know what i mean. See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/710778843328598</guid></item><item><title>Image-to-Promptâš¡</title><link>https://huggingface.co/posts/ovi054/657358125503535</link><description>Image-to-Promptâš¡ ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 ğŸ‘‰ Try it now: ovi054/image-to-prompt See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/657358125503535</guid></item><item><title>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:</title><link>https://huggingface.co/posts/fdaudens/770107969696647</link><description>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines &amp; specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup â€” just open-weight GPT-OSS models via Hugging Face If youâ€™ve been wanting to try agents but werenâ€™t sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/770107969696647</guid></item><item><title>Want to quickly try Gemma 3 270m? ğŸ’ğŸ’¬</title><link>https://huggingface.co/posts/anakin87/751707976654130</link><description>Want to quickly try Gemma 3 270m? ğŸ’ğŸ’¬ I made a simple Space to do that: anakin87/gemma-3-270m-it âš¡ Fast: Flash Attention, Zero GPU âš™ï¸ Configurable See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/anakin87/751707976654130</guid></item><item><title>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.ğŸ§ª</title><link>https://huggingface.co/posts/prithivMLmods/284574267701705</link><description>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.ğŸ§ª ğŸ¤— Space: prithivMLmods/Tiny-VLMs-Lab âœ¦ï¸ Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. âœ¦ï¸ Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 âœ¦ï¸ GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or the...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/284574267701705</guid></item><item><title>suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source?</title><link>https://huggingface.co/posts/appvoid/589674942896129</link><description>suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source? keep in mind everybody will have access to it: scientists, governments, terrorists, average people, etc... See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/appvoid/589674942896129</guid></item><item><title>âœ… New Article: *Memory as Structured Time*</title><link>https://huggingface.co/posts/kanaria007/576453037371058</link><description>âœ… New Article: *Memory as Structured Time* Title: ğŸ§  History: Memory Loops as Civilization Structure ğŸ”— https://huggingface.co/blog/kanaria007/memory-loops-as-civilization-structure --- Summary: Memory is often treated as *storage and retrieval*. Structured Intelligence reframes it as *timeâ€‘shaping architecture*: * *Loops that preserve context and continuity* * *Rollback paths that enable reflection and correction* * *Patterns that turn experience into adaptive structure* &gt; Memory isnâ€™t static â€” &gt; *itâ€™s how intelligence edits time.* --- Why It Matters: â€¢ Reveals *how memory enables learning, identity, and adaptation* â€¢ Supports *AI that can reflect, revise, and selfâ€‘align* â€¢ Connects *personal cognition and collective history* as structural processes --- Whatâ€™s Inside: â€¢ Memory as *recursive structural loop* â€¢ *Failure and recovery* as part of adaptive recall â€¢ How *history and recordâ€‘keeping mirror cognitive memory* â€¢ Implications for *resilient AI and social knowledge systems* --- ğŸ“–...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/576453037371058</guid></item><item><title>ğŸ”¥Check out new SOTA Orpheus Auto-Continuations GeneratorğŸ”¥</title><link>https://huggingface.co/posts/asigalov61/289707289100732</link><description>ğŸ”¥Check out new SOTA Orpheus Auto-Continuations GeneratorğŸ”¥ asigalov61/Orpheus-Music-Transformer Now you can generate good music with Orpheus without supervision!!! @ Timzoid @ John6666 @ alvanalrakib See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/asigalov61/289707289100732</guid></item><item><title>ğŸ§¬ DNA Diffusion Suite: AI-Powered Revolution in Life Science Research</title><link>https://huggingface.co/posts/openfree/904316268987326</link><description>ğŸ§¬ DNA Diffusion Suite: AI-Powered Revolution in Life Science Research ğŸš€ Transformative Innovation Through AI Technology DNA Diffusion Suite is a next-generation platform that leverages cutting-edge Diffusion models to generate biologically meaningful DNA sequences. By reducing sequence design time from weeks to mere seconds, we're revolutionizing research productivity and accelerating scientific discovery. VIDraft/DNA-Diffusion ğŸ’¡ Real-World Benefits of AI Technology ğŸ¯ Research Acceleration Instant Hypothesis Testing: Pre-validate experimental designs with AI-generated sequence variants Cost Reduction: Test hundreds of sequences virtually before expensive synthesis Time Efficiency: 1000x faster sequence generation compared to manual design ğŸ§  Intelligent Sequence Optimization Cell-Type Specific Learning: AI trained on real ChIP-seq data from K562, GM12878, and HepG2 cells Context-Aware Generation: Fine-tune biological context with precision Guidance Scale control Automated Pattern...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/904316268987326</guid></item><item><title>âœ¨ HairPick | Preview Your Perfect Hair Transformation in 360Â° âœ¨</title><link>https://huggingface.co/posts/ginipick/955296677233221</link><description>âœ¨ HairPick | Preview Your Perfect Hair Transformation in 360Â° âœ¨ ğŸŠ Free Trial for Hugging Face Launch! Hurry! â° Hello! Introducing an innovative AI service that helps you choose the perfect hairstyle without any regrets before visiting the salon! ğŸ¯ Try It Now ginigen/Hair-Pick ğŸ”„ What Makes HairPick Special? 360Â° Complete Preview! Other hair simulators only show the front view? ğŸ˜‘ HairPick is different! âœ… Front + 4 random angles = Total 5 multi-angle images generated âœ… Perfect check from side profile ğŸ‘¤ diagonal ğŸ“ back view ğŸ‘¥! âœ… 100+ trendy hairstyle library ğŸ’‡â€â™€ï¸ ğŸ’¡ Highly Recommended For: ğŸ¯ "I really don't want to fail this time!" â†’ Check side volume and back lines thoroughly ğŸ¯ "It's hard to explain exactly to my stylist" â†’ Perfect communication with 360Â° result images! ğŸ¯ "I have a profile photo/photoshoot coming up" â†’ Preview your best look from every angle ğŸš€ Super Simple Usage (Just 1 Minute!) 1ï¸âƒ£ One Selfie ğŸ“¸ Take a front-facing photo in bright light (show your forehead and face...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/955296677233221</guid></item></channel></rss>