<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Has anyone ever backed up a model to a sequential tape drive, or I'm the world first? :D</title><link>https://huggingface.co/posts/csabakecskemeti/762115035937109</link><description>Has anyone ever backed up a model to a sequential tape drive, or I'm the world first? :D Just played around with my retro PC that has got a tape drive‚Äîdid it just because I can. See translation</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/762115035937109</guid></item><item><title>üöÄ ZeroGPU now supports PyTorch native quantization via</title><link>https://huggingface.co/posts/cbensimon/565026286160860</link><description>üöÄ ZeroGPU now supports PyTorch native quantization via torchao While it hasn‚Äôt been battle-tested yet, Int8WeightOnlyConfig is already working flawlessly in our tests. Let us know if you run into any issues ‚Äî and we‚Äôre excited to see what the community will build! import spaces from diffusers import FluxPipeline from torchao.quantization.quant_api import Int8WeightOnlyConfig, quantize_ pipeline = FluxPipeline.from_pretrained(...).to( 'cuda' ) quantize_(pipeline.transformer, Int8WeightOnlyConfig()) # Or any other component(s) @spaces.GPU def generate ( prompt: str ): return pipeline(prompt).images[ 0 ] See translation</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/cbensimon/565026286160860</guid></item><item><title>ü§ó I'm leading 'Openfree AI', Korea's most prominent AI open-source community. First and foremost, I'd like to express my deepest gratitude for Hugging Face's continuous support and efforts. üíô</title><link>https://huggingface.co/posts/openfree/428786122279500</link><description>ü§ó I'm leading 'Openfree AI', Korea's most prominent AI open-source community. First and foremost, I'd like to express my deepest gratitude for Hugging Face's continuous support and efforts. üíô Our Openfree AI collaborates with various AI communities across Korea, contributing to knowledge sharing and ecosystem development. ü§ù I've been actively promoting the critical importance of Hugging Face as Korea's AI infrastructure backbone, engaging with senior government officials, National Assembly members, university leaders, and media executives to emphasize how Hugging Face represents Korea's AI future at a national policy level. I consider myself a 'voluntary Korean ambassador for Hugging Face'. üá∞üá∑‚ú® Let me share our community's achievements on the Hugging Face platform over the past year: üéØ üöÄ Published hundreds of models and spaces üë• Surpassed 10 million cumulative visitors üìà Achieved 1.7 million Monthly Active Users (MAU) üé® Generated over 1 million images/videos per month These...</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/428786122279500</guid></item><item><title>Imagine you could have an Image Arena score equivalent at each checkpoint during training. We released the first version of just that:</title><link>https://huggingface.co/posts/jasoncorkill/871941197791232</link><description>Imagine you could have an Image Arena score equivalent at each checkpoint during training. We released the first version of just that: Crowd-Eval Add one line of code to your training loop and you will have a new real human loss curve in your W&amp;B dashboard. Thousands of real humans from around the world rating your model in real time at the cost of a few dollars per checkpoint is a game changer. Check it out here: https://github.com/RapidataAI/crowd-eval First 5 people to put it in their loop get 100'000 human responses for free! (ping me) See translation</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jasoncorkill/871941197791232</guid></item><item><title>üó£Ô∏è üì¢  New article alert!</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/462704497331407</link><description>üó£Ô∏è üì¢ New article alert! "Integrity Threats in AI: When Data Poisoning Undermines Model Effectiveness" from Duality AI is now on HuggingFace here: https://huggingface.co/blog/DualityAI-RebekahBogdanoff/integrity-threats-in-ai Significant threats to AI model performance aren‚Äôt always loud or obvious. Integrity violations‚Äîlike subtle data poisoning attacks‚Äîcan quietly erode your model‚Äôs reliability, long before anyone notices. These attacks can be surprisingly effective with minimal changes to the dataset. At Duality, our work in high-stakes sectors like defense has driven us to tackle this threat head-on. In our latest blog from Duality's Director of Infrastructure and Security at Duality, David Strout, we unpack how data poisoning works, why it‚Äôs so dangerous, and how organizations can secure their AI pipelines with clear provenance, regular performance auditing, and a trusted synthetic data supply chain. Whether you're building AI models for finance, healthcare, manufacturing, or...</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/462704497331407</guid></item><item><title>Mistral releases Magistral, their new reasoning models! üî•</title><link>https://huggingface.co/posts/danielhanchen/426556210957370</link><description>Mistral releases Magistral, their new reasoning models! üî• GGUFs to run: unsloth/Magistral-Small-2506-GGUF Magistral-Small-2506 excels at mathematics and coding. You can run the 24B model locally with just 32GB RAM by using our Dynamic GGUFs. See translation</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/426556210957370</guid></item><item><title>this repo is gold! a collection of LLM apps with multi-agents, MCP, RAG and so much more.</title><link>https://huggingface.co/posts/hesamation/842061188959684</link><description>this repo is gold! a collection of LLM apps with multi-agents, MCP, RAG and so much more. the best way to learn is by building, and this repo provides the blueprint. Repo: https://github.com/Shubhamsaboo/awesome-llm-apps See translation</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/842061188959684</guid></item><item><title>Ultimate ComfyUI &amp; SwarmUI on RunPod Tutorial with Addition RTX 5000 Series GPUs &amp; 1-Click to Setup :</title><link>https://huggingface.co/posts/MonsterMMORPG/478306591921253</link><description>Ultimate ComfyUI &amp; SwarmUI on RunPod Tutorial with Addition RTX 5000 Series GPUs &amp; 1-Click to Setup : https://youtu.be/R02kPf9Y3_w Tutorial Video : https://youtu.be/R02kPf9Y3_w If you want to use ComfyUI or SwarmUI with ComfyUI backend on RunPod cloud platform, this is the ultimate tutorial that you will find to step by step install ComfyUI and SwarmUI on RunPod and use each one of them. RunPod is a great platform to scale your AI generation or if you are a GPU poor, rent the very best GPUs and leverage the AI in your profession. ComfyUI is the ultimate ecosystem right now for Image and Video generation models and with SwarmUI interface leveraging ComfyUI, you can become master for gen AI. So learn how to install ComfyUI on RunPod step by step and run it. Then learn how to install SwarmUI on RunPod step by step and learn how to use it. Then learn how to give installed ComfyUI backend to SwarmUI and leverage its features and ultimate performance and optimizations. Moreover, the...</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/478306591921253</guid></item><item><title>Recently, I've been focusing my learning on the following topics:</title><link>https://huggingface.co/posts/a-r-r-o-w/231008365980283</link><description>Recently, I've been focusing my learning on the following topics: - Pytorch internals, specifically the inductor system (roughly ~1 month of experience) - Triton internals (~8 moe) - CUDA (~3 moe) - Understanding fusion patterns in compilers and how to improve them (~1 moe) - Parallelism strategies for large scale inference optimization (~6-7 moe) I thought it would be nice to document it somewhere for no particular reason. Maybe someone will find it useful? It's also because I want to get into the habit of writing, but had no motivation to do so. Maybe writing short informal posts will help build the habit. Since I don't have a personal site, and don't plan to create one in the near future, I think HF posts are best suited for short and informal documentation to share my little discoveries and learnings. If you're interested, strap in! First post in this series will be on basic study of Pytorch's float32 matmuls and their Triton implementation (nothing much, just the tutorial...</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/a-r-r-o-w/231008365980283</guid></item><item><title>stop building parser pipelines üëãüèª</title><link>https://huggingface.co/posts/merve/905835083426002</link><description>stop building parser pipelines üëãüèª there's a new document parser that is small, fast, Apache 2.0 licensed and is better than all the other ones! üò± echo840/MonkeyOCR is a 3B model that can parse everything (charts, formules, tables etc) in a document ü§† &gt; the authors show in the paper that document parsing pipelines often have errors propagating back &gt; using singular e2e models are better but they're too heavy to use this model addresses both: it's lighter, faster, stronger üî• See translation</description><pubDate>Fri, 13 Jun 2025 05:23:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/905835083426002</guid></item></channel></rss>