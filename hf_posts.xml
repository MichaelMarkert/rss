<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Excited to bring the new models that are performing exceptionally well in document OCR, image captioning, and visual understanding tasks. Megalodon-OCR and Perseus-Doc-VL have both demonstrated significant improvements across key areas. You can explore live demos on Hugging Face Spaces to compare their performance with other top-tier models available on the hub. ü§óüìÑ</title><link>https://huggingface.co/posts/prithivMLmods/700925755780035</link><description>Excited to bring the new models that are performing exceptionally well in document OCR, image captioning, and visual understanding tasks. Megalodon-OCR and Perseus-Doc-VL have both demonstrated significant improvements across key areas. You can explore live demos on Hugging Face Spaces to compare their performance with other top-tier models available on the hub. ü§óüìÑ Spaces &amp; Models : &gt; Doc-VLMs-OCR : prithivMLmods/Doc-VLMs-OCR &gt; core-OCR : prithivMLmods/core-OCR &gt; Megalodon-OCR (3B) : prithivMLmods/Megalodon-OCR-Sync-0713 &gt; Perseus-Doc-vl (7B): prithivMLmods/Perseus-Doc-vl-0712 Datasets Caption Mix : &gt; Corvus-OCR-Caption-Mix : prithivMLmods/Corvus-OCR-Caption-Mix &gt; Corvus-OCR-Caption-Mini-Mix : prithivMLmods/Corvus-OCR-Caption-Mini-Mix Collections : &gt; Corvus OCR Caption Mix: prithivMLmods/corvus-ocr-caption-mix-687349bfaceffbd10976f0cc &gt; Captioning / OCR / DocTable : prithivMLmods/captioning-ocr-doctable-687382e1da822008bb5c06f2 GitHub : &gt; OCR-ReportLab :...</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/700925755780035</guid></item><item><title>13 New types of LoRA</title><link>https://huggingface.co/posts/Kseniase/384482543815919</link><description>13 New types of LoRA LoRA (Low-Rank Adaptation) is a popular lightweight method for fine-tuning AI models. It doesn't update the full model, it adds small trainable components, low-rank matrices, while keeping the original weights frozen. Only these adapters are trained. Recently, many interesting new LoRA variations came out, so it‚Äôs a great time to take a look at these 13 clever approaches: 1. T-LoRA ‚Üí T-LoRA: Single Image Diffusion Model Customization Without Overfitting (2507.05964) A timestep-dependent LoRA method for adapting diffusion models with a single image. It dynamically adjusts updates and uses orthogonal initialization to reduce overlap, achieving better fidelity‚Äìalignment balance than standard LoRA 2. SingLoRA ‚Üí SingLoRA: Low Rank Adaptation Using a Single Matrix (2507.05566) Simplifies LoRA by using only one small matrix instead of usual two, and multiplying it by its own transpose (like A √ó A·µÄ). It uses half the parameters of LoRA and avoids scale mismatch between...</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/384482543815919</guid></item><item><title>üôãüèª‚Äç‚ôÇÔ∏è Normalize adding compute &amp; runtime traces to your model cards</title><link>https://huggingface.co/posts/Tonic/414083244384754</link><description>üôãüèª‚Äç‚ôÇÔ∏è Normalize adding compute &amp; runtime traces to your model cards See translation</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Tonic/414083244384754</guid></item><item><title>"Why did the bee get married?"</title><link>https://huggingface.co/posts/jasoncorkill/847126227827487</link><description>"Why did the bee get married?" "Because he found his honey!" This was the "funniest" joke out of 10'000 jokes we generated with LLMs. With 68% of respondents rating it as "funny". Original jokes are particularly hard for LLMs, as jokes are very nuanced and a lot of context is needed to understand if something is "funny". Something that can only reliably be measured using humans. LLMs are not equally good at generating jokes in every language. Generated English jokes turned out to be way funnier than the Japanese ones. 46% of English-speaking voters on average found the generated joke funny. The same statistic for other languages: Vietnamese: 44% Portuguese: 40% Arabic: 37% Japanese: 28% There is not much variance in generation quality among models for any fixed language. But still Claude Sonnet 4 slightly outperforms others in Vietnamese, Arabic and Japanese and Gemini 2.5 Flash in Portuguese and English We have release the 1 Million (!) native speaker ratings and the 10'000 jokes...</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jasoncorkill/847126227827487</guid></item><item><title>üì¢ Generate your own data in simulation using two new free and customizable data-generating Scenarios on Duality's FalconCloud service.</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/377698831818015</link><description>üì¢ Generate your own data in simulation using two new free and customizable data-generating Scenarios on Duality's FalconCloud service. üôå These multi-class Scenarios are designed to target model weaknesses for our recent Kaggle competition, but they are free to anyone for non-commercial use! Just create a free account. üì∏ Control object and camera posing üëâ Select random variable ranges üñºÔ∏è Set post-processing effects ‚ûï and more to create a robust dataset for strong model training. Access the 2 Scenarios here: üí† https://falcon.duality.ai/secure/scenarios/edit/9e90e036-8af9-41e4-8af0-1343b8e8f467?utm_source=Kaggle&amp;utm_medium=post&amp;utm_campaign=competition_4 üí† https://falcon.duality.ai/secure/scenarios/edit/e3294c19-49d4-4f64-9ca8-8373876c2c94?utm_source=Kaggle&amp;utm_medium=post&amp;utm_campaign=competition_4 See translation</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/377698831818015</guid></item><item><title>Made some 245GB (80% size reduction) 1.8bit quants for Kimi K2!</title><link>https://huggingface.co/posts/danielhanchen/383539577783045</link><description>Made some 245GB (80% size reduction) 1.8bit quants for Kimi K2! unsloth/Kimi-K2-Instruct-GGUF See translation</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/383539577783045</guid></item><item><title>past week had huuuge releases üíó</title><link>https://huggingface.co/posts/merve/294233425076045</link><description>past week had huuuge releases üíó here's our picks üî• find more models, datasets, demos here merve/releases-july-11-68750452c358c98b0fa663f7 &gt; moonshotai/Kimi-K2-Instruct is the new sota LLM with 1T total 32B active parameters ü§Ø &gt; HuggingFaceTB/SmolLM3-3B is the new best LM for it's size, offers thinking mode üí≠ as well as the dataset HuggingFaceTB/smoltalk2 &gt; Alibaba-NLP/WebSailor-3B is the new agentic LLM for complex browsing &gt; Google DeepMind released medical vision LMs with an agentic doctor-patient app google/medgemma-release-680aade845f90bec6a3f60c4 &gt; fal released a LoRA to improve details on face images fal/Realism-Detailer-Kontext-Dev-LoRA See translation</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/294233425076045</guid></item><item><title>Hey fellow developers and AI enthusiasts,</title><link>https://huggingface.co/posts/SohanVichat/728099751320142</link><description>Hey fellow developers and AI enthusiasts, I am with the team at TeraVera, and we have just launched something we are really excited about ‚Äî the TeraVera Secure API for AI solutions. TeraVera API helps protect your data, prevents AI hallucinations, and ensures the integrity of your AI responses. It‚Äôs designed to work seamlessly across major platforms like OpenAI/Azure, Google/Gemini, and AWS/Anthropic. Don‚Äôt hesitate to request access to the TeraVera Secure API and ensure your data is never leaked into the AI model. Grab your API key here: üîó https://www.teravera.com/api-access-form/ You can also check out more about what we do on our site: üåê teravera.com Read: https://huggingface.co/blog/TeraVera/teravera We would love to hear your thoughts ‚Äî feedback, suggestions, or any questions are more than welcome! Cheers, Sohan See translation</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/SohanVichat/728099751320142</guid></item><item><title>MultiTalk Levelled Up - Way Better Animation Compared to Before with New Workflows - Image to Video &gt;</title><link>https://huggingface.co/posts/MonsterMMORPG/139363304280237</link><description>MultiTalk Levelled Up - Way Better Animation Compared to Before with New Workflows - Image to Video &gt; https://youtu.be/wgCtUeog41g MultiTalk is greatly upgraded. After doing more than 1 day more research with MultiTalk by using 8x A6000 48 GB GPUs, I have significantly improved the MultiTalk workflows and now I am sharing 4 different category workflows with you. VRAM usages and speeds are same but just better quality and animation. Moreover I am introducing a new app which is image and video comparison sliders. Ultra fast and lightweight. Runs as a html app and no GPU is required. https://youtu.be/wgCtUeog41g MultiTalk Full Tutorial With 1-Click Installer - Make Talking and Singing Videos From Static Images &gt; https://youtu.be/8cMIwS9qo4M By using MeiGen MultiTalk you can generate amazing fully animated real-like videos from given audio input. Not only talking but also animating the body movements is possible. In this video I will show you how to install ComfyUI on Windows and...</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/139363304280237</guid></item><item><title>Join us in Austin tomorrow for AI Camp‚Äôs monthly meetup.</title><link>https://huggingface.co/posts/GeorgiaArm/326406743119964</link><description>Join us in Austin tomorrow for AI Camp‚Äôs monthly meetup. Arm‚Äôs Zach Lasiuk and Geremy Cohen will dive into ‚ÄúFrom Model to Product: Right-Sizing Infrastructure for Real-World Use Cases.‚Äù RSVP here üëâ https://www.aicamp.ai/event/eventdetails/W2025071616 See translation</description><pubDate>Tue, 15 Jul 2025 17:22:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/GeorgiaArm/326406743119964</guid></item></channel></rss>