<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Liquid just released two 450M and 1.6B param VLMs!</title><link>https://huggingface.co/posts/mlabonne/575026837446793</link><description>Liquid just released two 450M and 1.6B param VLMs! They're super fast and leverage SigLIP2 NaFlex encoders to handle native resolutions without distortion. It's ideal for on-device deployment in constrained environments like phones. It's available today on Hugging Face, with an inference and a fine-tuning Colab notebooks. LiquidAI/LFM2-VL-450M LiquidAI/LFM2-VL-1.6B See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mlabonne/575026837446793</guid></item><item><title>No, I did not create those bots that just got banned today.</title><link>https://huggingface.co/posts/nroggendorff/812423234168314</link><description>No, I did not create those bots that just got banned today. See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/812423234168314</guid></item><item><title>Update on</title><link>https://huggingface.co/posts/ovi054/459497213356295</link><description>Update on ovi054/Qwen-Image-LORA âš¡ You can now load a Qwen LoRA in this space as follows: 1. Model ID: flymy-ai/qwen-image-realism-lora 2. Model link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora 3. Specific file link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /blob/m ain/flymy_realism.safetensors 4. Direct download link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /resolve/m ain/flymy_realism.safetensors You can also use an external .safetensors download link (if Hugging Face doesnâ€™t block it). It is useful if a model repository contains multiple weights and you want to load a specific one. ðŸ‘‰ Try it now: ovi054/Qwen-Image-LORA See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/459497213356295</guid></item><item><title>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:</title><link>https://huggingface.co/posts/fdaudens/770107969696647</link><description>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines &amp; specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup â€” just open-weight GPT-OSS models via Hugging Face If youâ€™ve been wanting to try agents but werenâ€™t sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/770107969696647</guid></item><item><title>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.</title><link>https://huggingface.co/posts/etemiz/710778843328598</link><description>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really "free": they are costing you your freedom if you know what i mean. See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/710778843328598</guid></item><item><title>Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B &amp; LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU!</title><link>https://huggingface.co/posts/prithivMLmods/730170022133992</link><description>Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B &amp; LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU! â†— LFM2-VL-1.6B-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-1.6B-LiquidAI/LFM2-VL-1.6B_ReportLab.ipynb â†— LFM2-VL-450M-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-450M-LiquidAI/LFM2-VL-450M_ReportLab.ipynb . . . To know more about it, visit the multimodal outpost notebooks !! See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/730170022133992</guid></item><item><title>Introducing the Computer Says No Dataset:</title><link>https://huggingface.co/posts/mrs83/441245217845502</link><description>Introducing the Computer Says No Dataset: ethicalabs/computer-says-no An LLM can do almost anything, but should it? This dataset provides clear examples of when LLMs should decline requests, such as: - Counting characters (e.g., "number of 'r's in 'raspberry'" â€“ seriously, youâ€™ve got this) - Solving basic equations (like *5.9 = x + 5.11* â€“ please, show that calculator some love) Inspired by Little Britain's iconic "Computer Says No" sketch, we address a critical issue in AI systems today: the waste of using a rocket launcher to swat flies (aka powerful models for trivial tasks). Goals: - Reduce waste by saving compute for tasks that actually need it - Guide users to better tools - Spark discussion about ethical AI This isnâ€™t a training set. Itâ€™s a provocation: if we donâ€™t define AI's limits, who will? See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mrs83/441245217845502</guid></item><item><title>We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so:</title><link>https://huggingface.co/posts/hba123/107730379524841</link><description>We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so: Check it out: https://huggingface.co/blog/hba123/ark See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hba123/107730379524841</guid></item><item><title>âœ… New Article: *Media as Cognitive Infrastructure*</title><link>https://huggingface.co/posts/kanaria007/811473012655185</link><description>âœ… New Article: *Media as Cognitive Infrastructure* Title: ðŸ“° Protocolic Media: Structured Intelligence and the Future of Cognitive Environments ðŸ”— https://huggingface.co/blog/kanaria007/protocolic-media --- Summary: Media doesnâ€™t just *deliver content* â€” it *shapes how collective thought moves*. Every feed, stream, and algorithm is *a scaffold for attention and reasoning*, determining *what we notice, connect, and forget*. Structured Intelligence reframes media as *cognitive infrastructure*: not passive transmission, but *active architecture for collective reasoning*. &gt; Media isnâ€™t flow â€” &gt; *itâ€™s the frame of shared cognition.* --- Why It Matters: â€¢ Modern media amplifies *bias, noise, and cognitive drift* â€¢ Traditional moderation reacts *after harm occurs* â€¢ Structured approaches support: * *Traceable content flows with coherence checks* * *Ethical filtering without blackâ€‘box censorship* * *Reflective scaffolds that encourage deliberate reasoning* --- Whatâ€™s Inside: â€¢ Media reframed...</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/811473012655185</guid></item><item><title>It's just a matter of time before all the data leakage and data scraping associated with building, training, and using AI results in some kind of major scandal.</title><link>https://huggingface.co/posts/ZennyKenny/202723059163333</link><description>It's just a matter of time before all the data leakage and data scraping associated with building, training, and using AI results in some kind of major scandal. That's why I think this paper by @ spintronic is so important: Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN (2508.06647) Glad to know that there are already researchers looking to mitigate and address this risk before the s**t hits the fan. See translation</description><pubDate>Fri, 15 Aug 2025 09:26:11 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/202723059163333</guid></item></channel></rss>