<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SceneWeaver â€” AI-Powered Background Generation &amp; Image Composition ğŸ¨âœ¨</title><link>https://huggingface.co/posts/DawnC/810522223628641</link><description>SceneWeaver â€” AI-Powered Background Generation &amp; Image Composition ğŸ¨âœ¨ Transform ordinary portraits into professional studio shots with just one click! What can SceneWeaver do? - ğŸ“¸ Upload any portrait photo and instantly generate stunning, professional-quality backgrounds - ğŸ­ Smart Subject Detection â€” Automatically identifies and extracts people, pets, or objects from your photos, even handling tricky cases like dark clothing and cartoon characters. - ğŸŒ„ Creative Scene Library â€” Choose from 24 professionally curated backgrounds spanning offices, nature landscapes, urban settings, artistic styles, and seasonal themes, or describe your own custom vision. - âš™ï¸ Professional Results â€” Delivers studio-quality compositions in seconds, saving hours of manual editing work while maintaining natural lighting and color harmony. What's next? ğŸ¬ Enhanced context-aware generation ğŸ¨ Batch processing for multiple style variations ğŸ”§ Higher resolution output support ğŸŒ Accessible cloud deployment Current...</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/810522223628641</guid></item><item><title>Just uploaded a detailed blog about my findings in optimizing NeuTTS to generate 200 seconds of audio in a single second. Also went in depth in NeuTTSâ€™s architecture. Will be happy to answer any questions.</title><link>https://huggingface.co/posts/YatharthS/933040846295981</link><description>Just uploaded a detailed blog about my findings in optimizing NeuTTS to generate 200 seconds of audio in a single second. Also went in depth in NeuTTSâ€™s architecture. Will be happy to answer any questions. https://huggingface.co/blog/YatharthS/making-neutts-200x-realtime See translation</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/933040846295981</guid></item><item><title>Introducing the advanced sketch-board editor "Nano-Banana-Pro-Sketch-Board" powered by the Gemini 2.5 Flash Image and Gemini 3 Pro Preview Image models through the Gemini API. This version includes more features than the Nano-Banana-AIO app for drawing and prompt-based concept transformation of freestyle sketches. ğŸ”¥ğŸŒ</title><link>https://huggingface.co/posts/prithivMLmods/585236174284354</link><description>Introducing the advanced sketch-board editor "Nano-Banana-Pro-Sketch-Board" powered by the Gemini 2.5 Flash Image and Gemini 3 Pro Preview Image models through the Gemini API. This version includes more features than the Nano-Banana-AIO app for drawing and prompt-based concept transformation of freestyle sketches. ğŸ”¥ğŸŒ âœ¨Nano-Banana-Pro-Sketch-Board: prithivMLmods/Nano-Banana-Pro-Sketch-Board âœ¨Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection âœ¨Github: https://github.com/PRITHIVSAKTHIUR/Nano-Banana-Pro-Sketch-Board âœ¨Model-Garden: https://tinyurl.com/4xxs9dvy Some Other Relevant Apps [OSS] â­Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast-Fusion â­Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast â­Photo-Mate-i2i: prithivMLmods/Photo-Mate-i2i â­Kontext-Photo-Mate-v2: prithivMLmods/Kontext-Photo-Mate-v2 Note: The Nano-Banana-Pro-Sketch-Board demo requires a Gemini API key for the...</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/585236174284354</guid></item><item><title>Both cat and  dog has RL, vision, hearing abilities like a human.  And they acted - run and jump - better than Optimus. Why can human own  cat and dog? Maybe we have better LLM model in brain than that of cat and dog?</title><link>https://huggingface.co/posts/John1604/431236892313740</link><description>Both cat and dog has RL, vision, hearing abilities like a human. And they acted - run and jump - better than Optimus. Why can human own cat and dog? Maybe we have better LLM model in brain than that of cat and dog? çŒ«å’Œç‹—éƒ½æ‹¥æœ‰åƒäººç±»ä¸€æ ·çš„å¼ºåŒ–å­¦ä¹ èƒ½åŠ›ã€è§†è§‰å’Œå¬è§‰ã€‚è€Œä¸”å®ƒä»¬è·‘è·³ç­‰æ–¹é¢çš„è¡¨ç°ç”šè‡³æ¯”æ“å¤©æŸ±è¿˜è¦å‡ºè‰²ã€‚ä¸ºä»€ä¹ˆäººç±»å¯ä»¥é¥²å…»çŒ«å’Œç‹—å‘¢ï¼Ÿæˆ–è®¸æˆ‘ä»¬çš„å¤§è„‘æ‹¥æœ‰æ¯”çŒ«ç‹—æ›´ä¼˜ç§€çš„å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ See translation</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/John1604/431236892313740</guid></item><item><title>No SOTA from gpt5 codex</title><link>https://huggingface.co/posts/onekq/122975793150084</link><description>No SOTA from gpt5 codex onekq-ai/WebApp1K-models-leaderboard See translation</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/122975793150084</guid></item><item><title>Try the demo of NVIDIA Nemotron Parse v1.1, NVIDIA's latest VLM for understanding document semantics and extracting text and table elements with spatial grounding. It is capable of comprehensive text understanding and document structure analysis in a given document, and can provide bounding boxes with coordinates.</title><link>https://huggingface.co/posts/prithivMLmods/294108395051728</link><description>Try the demo of NVIDIA Nemotron Parse v1.1, NVIDIA's latest VLM for understanding document semantics and extracting text and table elements with spatial grounding. It is capable of comprehensive text understanding and document structure analysis in a given document, and can provide bounding boxes with coordinates. â­Space[Demo]: prithivMLmods/NVIDIA-Nemotron-Parse-v1.1 â­Model: nvidia/NVIDIA-Nemotron-Parse-v1.1 â­Multimodal-Spaces: https://huggingface.co/collections/prithivMLmods/multimodal-implementations Some relevant Spaces â­DeepSeek-OCR-experimental [latest transformers]: prithivMLmods/DeepSeek-OCR-experimental â­Qwen3-VL-Outpost: prithivMLmods/Qwen3-VL-Outpost â­Multimodal-OCR3: prithivMLmods/Multimodal-OCR3 Check out the other spaces in the multimodal implementation collection. To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/294108395051728</guid></item><item><title>I run 20 AI coding agents locally on my desktop workstation at 400+ tokens/sec with MiniMax-M2. Itâ€™s a Sonnet drop-in replacement in my Cursor, Claude Code, Droid, Kilo and Cline peak at 11k tok/sec input and 433 tok/s output, can generate 1B+ tok/m.All with 196k context window. I'm running it for 6 days now with this config.</title><link>https://huggingface.co/posts/mitkox/488545088120873</link><description>I run 20 AI coding agents locally on my desktop workstation at 400+ tokens/sec with MiniMax-M2. Itâ€™s a Sonnet drop-in replacement in my Cursor, Claude Code, Droid, Kilo and Cline peak at 11k tok/sec input and 433 tok/s output, can generate 1B+ tok/m.All with 196k context window. I'm running it for 6 days now with this config. Today max performance was stable at 490.2 tokens/sec across 48 concurrent clients and MiniMax M2. Z8 Fury G5, Xeon 3455, 4xA6K. Aibrix 0.5.0, vLLM 0.11.2, See translation</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mitkox/488545088120873</guid></item><item><title>Need Help Getting arXiv Endorsement for My AI Research Paper</title><link>https://huggingface.co/posts/samerzaher80/574430859110807</link><description>Need Help Getting arXiv Endorsement for My AI Research Paper Hi everyone, I hope you're doing well. Iâ€™m trying to publish my new AI research paper on arXiv under the cs.AI category, but I currently need an endorser who is already authorized for cs.AI submissions. If anyone here is registered as a cs.AI endorser and is willing to help, I would truly appreciate it. Here is the official arXiv endorsement request link: ğŸ”— https://arxiv.org/auth/endorse?x=EZEMO7 (Backup: http://arxiv.org/auth/endorse.php â€” Code: EZEMO7) My research: Itâ€™s part of the AetherMind project â€” a self-reflective NLI reasoning system inspired by human cognitive consistency and used also in Alzheimerâ€™s research. If needed, I can share the abstract or full PDF. Thank you so much to anyone who can support. â€” Sameer S.Najm See translation</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/samerzaher80/574430859110807</guid></item><item><title>âœ… New Reference: *Atlas of Structured Intelligence*</title><link>https://huggingface.co/posts/kanaria007/443085216876424</link><description>âœ… New Reference: *Atlas of Structured Intelligence* Title: ğŸ—ºï¸ Atlas of Structured Intelligence ğŸ”— https://huggingface.co/blog/kanaria007/atlas-of-structured-intelligence --- Summary: Across 40+ articles, PoCs (education, computing, space), specs, and the Cosmic Intelligence Model, this *Atlas* is the navigation layer: it locates each piece, shows recurring protocols, and connects micro (cognition) â†’ meso (institutions) â†’ macro (civilization) â†’ cosmic (CIM). *Itâ€™s the map of the series itself, not a new theory.* &gt; From fragments to framework â€” &gt; *the Atlas turns a library into a system.* --- Why It Matters: â€¢ Gives newcomers a clear entry path; gives experts cross-links and dependencies â€¢ Reveals protocol reuse across domains (not just â€œthemes,â€ but shared machinery) â€¢ Bridges qualitative ideas with quantitative indices and evaluation --- Whatâ€™s Inside: â€¢ *Macro Map:* Core theory â†’ applied domains â†’ PoC suite â†’ cosmic series â€¢ *Protocol Matrix:* Where jump-generator, memory-loop,...</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/443085216876424</guid></item><item><title>@Reubencf</title><link>https://huggingface.co/posts/mybbnae/820891401991666</link><description>@ Reubencf made an WebOS check it out MCP-1st-Birthday/Reuben_OS See translation</description><pubDate>Mon, 24 Nov 2025 05:26:17 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mybbnae/820891401991666</guid></item></channel></rss>