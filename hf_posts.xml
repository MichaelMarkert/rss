<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Introducing the Qwen-Image-Edit-2511-LoRAs-Fast demo, featuring image property comparison and contrast, built on top of Gradio and the combined Rerun SDK. It supports single and multi-image edits with existing LoRAs that are lazily loaded. (Note: This is still an experimental Space for Qwen-Image-Edit-2511.)</title><link>https://huggingface.co/posts/prithivMLmods/163304413191334</link><description>Introducing the Qwen-Image-Edit-2511-LoRAs-Fast demo, featuring image property comparison and contrast, built on top of Gradio and the combined Rerun SDK. It supports single and multi-image edits with existing LoRAs that are lazily loaded. (Note: This is still an experimental Space for Qwen-Image-Edit-2511.) ‚≠ê Space Demo: prithivMLmods/Qwen-Image-Edit-2511-LoRAs-Fast ‚≠ê GitHub: https://github.com/PRITHIVSAKTHIUR/Qwen-Image-Edit-2511-LoRAs-Fast-Multi-Image-Rerun ‚≠ê Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/163304413191334</guid></item><item><title>Just sharing a result of a homelab infrastructure experiment:</title><link>https://huggingface.co/posts/csabakecskemeti/254891528281591</link><description>Just sharing a result of a homelab infrastructure experiment: I've managed to setup a distributed inference infra at home using a DGX Spark (128GB unified gddr6) and a linux workstation with an RTX 6000 Pro (96GB gddr7) connected via 100Gbps RoCEv2. The model I've used ( https://lnkd.in/gx6J7YuB ) is about 140GB so could not fit either of the GPU. Full setup and tutorial soon on devquasar.com Screen recording: https://lnkd.in/gKM9H5GJ See translation</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/254891528281591</guid></item><item><title>What if an AI agent could be tricked into stealing your data, just by reading a tool's description? A new paper reports it's possible.</title><link>https://huggingface.co/posts/MikeDoes/284489022074040</link><description>What if an AI agent could be tricked into stealing your data, just by reading a tool's description? A new paper reports it's possible. The "Attractive Metadata Attack" paper details this stealthy new threat. To measure the real-world impact of their attack, the researchers needed a source of sensitive data for the agent to leak. We're proud that the AI4Privacy corpus was used to create the synthetic user profiles containing standardized PII for their experiments. This is a perfect win-win. Our open-source data helped researchers Kanghua Mo, ÈæôÊò±‰∏û, Zhihao Li from Guangzhou University and The Hong Kong Polytechnic University to not just demonstrate a new attack, but also quantify its potential for harm. This data-driven evidence is what pushes the community to build better, execution-level defenses for AI agents. üîó Check out their paper to see how easily an agent's trust in tool metadata could be exploited: https://arxiv.org/pdf/2508.02110 #OpenSource #DataPrivacy #LLM #Anonymization...</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/284489022074040</guid></item><item><title>Update: TRELLIS.2 (Text to 3D, Image to 3D) Gradio with Rerun Embedded demo with improved visualization of the 3D model previewer is now available on Hugging Face. Generate assets and view them in the 3D viewer, powered and streamlined with Microsoft‚Äôs TRELLIS.2 and Tongyi-MAI‚Äôs Z-Image-Turbo models.</title><link>https://huggingface.co/posts/prithivMLmods/527859222205581</link><description>Update: TRELLIS.2 (Text to 3D, Image to 3D) Gradio with Rerun Embedded demo with improved visualization of the 3D model previewer is now available on Hugging Face. Generate assets and view them in the 3D viewer, powered and streamlined with Microsoft‚Äôs TRELLIS.2 and Tongyi-MAI‚Äôs Z-Image-Turbo models. ü§ó TRELLIS.2 (Demo): prithivMLmods/TRELLIS.2-Text-to-3D üïπÔ∏è GitHub: https://github.com/PRITHIVSAKTHIUR/TRELLIS.2-Text-to-3D-RERUN üïπÔ∏è Collection: https://huggingface.co/collections/prithivMLmods/multimodal-implementations To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/527859222205581</guid></item><item><title>I have update my</title><link>https://huggingface.co/posts/MohamedRashad/872380380430431</link><description>I have update my https://huggingface.co/collections/MohamedRashad/arabic-speech-datasets with new datasets, making the full audio data more than 3000 hours of good arabic speech. Feel Free to use it in your new innovations, And happy new year! See translation</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MohamedRashad/872380380430431</guid></item><item><title>Introducing Dhara-70M: A diffusion language model that achieves 3.8x higher throughput than autoregressive models!</title><link>https://huggingface.co/posts/codelion/602031524113549</link><description>Introducing Dhara-70M: A diffusion language model that achieves 3.8x higher throughput than autoregressive models! Key findings from our research on optimal architectures for small language models: ‚Üí Depth beats width: 32 layers outperforms 12 layers at the same parameter count ‚Üí Best-in-class factuality: 47.5% on TruthfulQA ‚Üí 10x training efficiency using WSD (Warmup-Stable-Decay) conversion ‚Üí Canon layers add only 0.13% parameters but improve reasoning We trained on 1B tokens using the optimal 50-30-20 dataset mix (PDFs + filtered web + educational content), then converted to diffusion with just 100M additional tokens. Blog: https://huggingface.co/blog/codelion/optimal-model-architecture Model: codelion/dhara-70m See translation</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/602031524113549</guid></item><item><title>Experimental global target bits‚Äëper‚Äëweight quantization of ServiceNow-AI/Apriel-1.6-15b-Thinker and zai-org/GLM-4.6V-Flash</title><link>https://huggingface.co/posts/eaddario/946715506605693</link><description>Experimental global target bits‚Äëper‚Äëweight quantization of ServiceNow-AI/Apriel-1.6-15b-Thinker and zai-org/GLM-4.6V-Flash Unlike standard llama.cpp quantizations that rely on fixed type heuristics (e.g., Q4_K_M), the Target BPW approach optimizes per-tensor precision where it matters the most, and produces high quality models that meet a precise global file size target. Key Advantages: - VRAM Maximization: Can generate high quality models sized exactly to fit hardware constraints (e.g., fitting the model into exactly 24GB VRAM). - Data-Driven Precision: Quantization mix is determined by actual weight error sensitivity rather than hardcoded rules, often yielding better PPL/KLD size trade-offs. Full benchmarks (PPL, KLD, ARC, MMLU, etc.) and methodology in the models' cards eaddario/Apriel-1.6-15b-Thinker-GGUF eaddario/GLM-4.6V-Flash-GGUF See translation</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eaddario/946715506605693</guid></item><item><title>‚úÖ New Article: *Pattern-Learning-Bridge (PLB)*</title><link>https://huggingface.co/posts/kanaria007/140378798774766</link><description>‚úÖ New Article: *Pattern-Learning-Bridge (PLB)* Title: üß© Pattern-Learning-Bridge: How SI-Core Actually Learns From Its Own Failures üîó https://huggingface.co/blog/kanaria007/learns-from-its-own-failures --- Summary: Most stacks ‚Äúlearn‚Äù by fine-tuning weights and redeploying ‚Äî powerful, but opaque. SI-Core already produces *structured evidence* (jump logs, ethics traces, effect ledgers, goal vectors, rollback traces), so learning can be *structural* instead: *Upgrade policies, compensators, SIL code, and goal structures ‚Äî using runtime evidence.* &gt; Learning isn‚Äôt a model tweak. &gt; *It‚Äôs upgrading the structures that shape behavior.* --- Why It Matters: ‚Ä¢ Makes improvement *localized and explainable* (what changed, where, and why) ‚Ä¢ Keeps ‚Äúself-improvement‚Äù *governable* (versioned deltas + review + CI/CD) ‚Ä¢ Turns incidents/metric drift into *actionable patches*, not postmortem PDFs ‚Ä¢ Scales to real ops: ethics policies, rollback plans, semantic compression, goal estimators --- What‚Äôs...</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/140378798774766</guid></item><item><title>I realized when I ask longer answers to my questions, the models sometimes produce completely opposite answer. What could be the reason?</title><link>https://huggingface.co/posts/etemiz/694510268767271</link><description>I realized when I ask longer answers to my questions, the models sometimes produce completely opposite answer. What could be the reason? I do mostly CPT. Should I convert my dataset to SFT and give longer reasonings too for it to have integrity? Example: Is the yolk of an egg more beneficial or the white? Answer in 100 words. Answer: Yolk is more beneficial because .......... Example: Is the yolk of an egg more beneficial or the white? Answer in 500 words. Answer: White is more beneficial because .......... Edit: These happen in temp = 0.0 See translation</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/694510268767271</guid></item><item><title>The tools we use to audit AI for privacy might be easier to fool than we think.</title><link>https://huggingface.co/posts/MikeDoes/799679518824958</link><description>The tools we use to audit AI for privacy might be easier to fool than we think. We're highlighting a critical paper that introduces "PoisonM," a novel attack that could make Membership Inference tests unreliable. The direct connection to our work is explicit: the researchers, Neal M., Atul Prakash, Amrita Roy Chowdhury, Ashish Hooda, Kassem Fawaz, Somesh Jha, Zhuohang Li, and Brad Malin used the AI4Privacy dataset as the "canary" dataset in their experiments to test the effectiveness of their attack on realistic, sensitive information. This is the power of a healthy open-source ecosystem. We provide the foundational data that helps researchers pressure-test our collective assumptions about AI safety. It's a win for everyone when this leads to a more honest conversation about what our tools can and can't do, pushing us all to create better solutions. üîó Read the full paper to understand the fundamental flaws in current MI testing: https://arxiv.org/pdf/2506.06003 #OpenSource...</description><pubDate>Mon, 29 Dec 2025 09:35:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/799679518824958</guid></item></channel></rss>