<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™</title><link>https://huggingface.co/posts/prithivMLmods/223082724733311</link><description>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™ ‚óè Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC ‚óè Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection ‚óè Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo ‚óè Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- ‚óè FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 ‚óè FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC ‚óè Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC ‚óè Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast ‚óè Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/223082724733311</guid></item><item><title>ü§Ø ü§Ø Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ü§Ø ü§Ø</title><link>https://huggingface.co/posts/YatharthS/190514854652270</link><description>ü§Ø ü§Ø Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ü§Ø ü§Ø Github link: https://github.com/ysharma3501/MiraTTS Model link: https://github.com/ysharma3501/MiraTTS Blog explaining llm tts models: https://huggingface.co/blog/YatharthS/llm-tts-models See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/190514854652270</guid></item><item><title>Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models üî•</title><link>https://huggingface.co/posts/victor/750233862472141</link><description>Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models üî• https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/victor/750233862472141</guid></item><item><title>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! üî•</title><link>https://huggingface.co/posts/danielhanchen/963278821580490</link><description>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! üî• Has 1M context window &amp; best in class performance for SWE-Bench, reasoning &amp; chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF üíö Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/963278821580490</guid></item><item><title>" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI ". r2r-protocol (Robot2Robot Protocol) is now officially open source! üîì</title><link>https://huggingface.co/posts/rajkumarrawal/519682431601479</link><description>" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI ". r2r-protocol (Robot2Robot Protocol) is now officially open source! üîì "pip install r2r-protocol" Whether you're a developer, researcher, or tech enthusiast, we invite you to explore, use, and contribute to the project. üîó Check it out here: [ https://github.com/Tech-Parivartan/r2r-protocol?tab=readme-ov-file ] Let‚Äôs build the future together! üí° AiParivartanResearchLab techparivartan Documentation of the r2r-protocal : [ https://techparivartanai.notion.site/Robot-to-Robot-r2r-Protocol-1f008f0fb18780439d70e8b9bbbdb869 ] The R2R Protocol enables seamless robot-to-robot interaction across industrial automation, swarm robotics, logistics, and multi-agent systems. It defines structured message formats, negotiation logic, discovery mechanisms, and extensible APIs. #r2r_protocol #robot2robot_protocol #ai...</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/rajkumarrawal/519682431601479</guid></item><item><title>Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on.</title><link>https://huggingface.co/posts/ronantakizawa/412513789590360</link><description>Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on. #github #developers ronantakizawa/github-top-developers See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/412513789590360</guid></item><item><title>Great News !</title><link>https://huggingface.co/posts/Reubencf/239576255947718</link><description>Great News ! Reubencf/Nano_Banana_Editor Now supports black-forest-labs/FLUX.1-Kontext-dev and Qwen/Qwen-Image-Edit-2509 Just log in with Huggingface and try it out See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reubencf/239576255947718</guid></item><item><title>Google releases FunctionGemma, a new 270M parameter model that runs on just 0.5 GB RAM.‚ú®</title><link>https://huggingface.co/posts/danielhanchen/264398594064230</link><description>Google releases FunctionGemma, a new 270M parameter model that runs on just 0.5 GB RAM.‚ú® Built for tool-calling, run locally on your phone at 50+ tokens/s, or fine-tune with Unsloth &amp; deploy to your phone. GGUF: unsloth/functiongemma-270m-it-GGUF Docs + Notebook: https://docs.unsloth.ai/models/functiongemma See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/264398594064230</guid></item><item><title>Update: Our engineer Alan has received a batch of components for the manipulator assemblies ‚Äî including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year.</title><link>https://huggingface.co/posts/branikita/654655990580208</link><description>Update: Our engineer Alan has received a batch of components for the manipulator assemblies ‚Äî including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year. See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/654655990580208</guid></item><item><title>Google DeepMind releases FunctionGemma, a 240M model specialized in üîß tool calling, built for fine-tuning</title><link>https://huggingface.co/posts/sergiopaniego/463044021249760</link><description>Google DeepMind releases FunctionGemma, a 240M model specialized in üîß tool calling, built for fine-tuning TRL has day-0 support. To celebrate, we‚Äôre sharing 2 new resources: &gt; Colab guide to fine-tune it for üåê browser control with BrowserGym OpenEnv &gt; Standalone training script &gt; Colab notebook: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_functiongemma_browsergym_openenv.ipynb &gt; Training script: https://github.com/huggingface/trl/blob/main/examples/scripts/openenv/browsergym_llm.py (command to run it inside the script) &gt; More notebooks in TRL: https://huggingface.co/docs/trl/example_overview#notebooks See translation</description><pubDate>Fri, 19 Dec 2025 05:27:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/463044021249760</guid></item></channel></rss>