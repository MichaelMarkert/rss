<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸ¦¥  Introducing Unsloth Dynamic v2.0 GGUFs!</title><link>https://huggingface.co/posts/danielhanchen/766411311755038</link><description>ğŸ¦¥ Introducing Unsloth Dynamic v2.0 GGUFs! Our v2.0 quants set new benchmarks on 5-shot MMLU and KL Divergence, meaning you can now run &amp; fine-tune quantized LLMs while preserving as much accuracy as possible. Llama 4: unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF DeepSeek-R1: unsloth/DeepSeek-R1-GGUF-UD Gemma 3: unsloth/gemma-3-27b-it-GGUF We made selective layer quantization much smarter. Instead of modifying only a subset of layers, we now dynamically quantize all layers so every layer has a different bit. Now, our dynamic method can be applied to all LLM architectures, not just MoE's. Blog with Details: https://docs.unsloth.ai/basics/dynamic-v2.0 All our future GGUF uploads will leverage Dynamic 2.0 and our hand curated 300Kâ€“1.5M token calibration dataset to improve conversational chat performance. For accurate benchmarking, we built an evaluation framework to match the reported 5-shot MMLU scores of Llama 4 and Gemma 3. This allowed apples-to-apples comparisons between full-...</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/766411311755038</guid></item><item><title>BOOOOM: Today I'm dropping TINY AGENTS</title><link>https://huggingface.co/posts/julien-c/991263782380176</link><description>BOOOOM: Today I'm dropping TINY AGENTS the 50 lines of code Agent in Javascript ğŸ”¥ I spent the last few weeks working on this, so I hope you will like it. I've been diving into MCP (Model Context Protocol) to understand what the hype was all about. It is fairly simple, but still quite powerful: MCP is a standard API to expose sets of Tools that can be hooked to LLMs. But while doing that, came my second realization: Once you have a MCP Client, an Agent is literally just a while loop on top of it. ğŸ¤¯ â¡ï¸ read it exclusively on the official HF blog: https://huggingface.co/blog/tiny-agents See translation</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/julien-c/991263782380176</guid></item><item><title>FlowReasoner is a new system that builds a custom set of small AI agents for every user question. Unlike search based methods it uses reasoning driven optimization with external execution feedback.</title><link>https://huggingface.co/posts/merterbak/740937534220692</link><description>FlowReasoner is a new system that builds a custom set of small AI agents for every user question. Unlike search based methods it uses reasoning driven optimization with external execution feedback. âœ… First, it distills reasoning data using DeepSeek R1-671B to build multi agent systems. ğŸ¤– âœ… Then, reasoning data used for DeepSeek-R1-Distill-Qwen-7B via supervised fine tuning for basic reasoning skills. ğŸ’¡ âœ… Finally, RL with GRPO (optimizes by comparing response groups from queries/tasks) to improve reasoning. FlowReasoner: Reinforcing Query-Level Meta-Agents (2504.15257) Code: https://github.com/sail-sg/flowreasoner See translation</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merterbak/740937534220692</guid></item><item><title>I'm excited to introduce VisionScout â€”an interactive vision tool that makes computer vision both accessible and powerful! ğŸ‘€ğŸ”</title><link>https://huggingface.co/posts/DawnC/336452242310313</link><description>I'm excited to introduce VisionScout â€”an interactive vision tool that makes computer vision both accessible and powerful! ğŸ‘€ğŸ” What can VisionScout do right now? ğŸ–¼ï¸ Upload any image and detect 80 different object types using YOLOv8. ğŸ”„ Instantly switch between Nano, Medium, and XLarge models depending on your speed vs. accuracy needs. ğŸ¯ Filter specific classes (people, vehicles, animals, etc.) to focus only on what matters to you. ğŸ“Š View detailed statistics about detected objects, confidence levels, and spatial distribution. ğŸ¨ Enjoy a clean, intuitive interface with responsive design and enhanced visualizations. What's next? I'm working on exciting updates: - Support for more models - Video processing and object tracking across frames - Faster real-time detection - Improved mobile responsiveness The goal is to build a complete but user-friendly vision toolkit for both beginners and advanced users. Try it yourself! ğŸš€ DawnC/VisionScout I'd love to hear your feedback , what features would...</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/336452242310313</guid></item><item><title>Ever dreamt of ingesting into a vector DB that pile of CSVs, Word documents and presentations laying in some remote folders on your PC?ğŸ—‚ï¸</title><link>https://huggingface.co/posts/as-cle-bert/792997014536541</link><description>Ever dreamt of ingesting into a vector DB that pile of CSVs, Word documents and presentations laying in some remote folders on your PC?ğŸ—‚ï¸ What if I told you that you can do it within three to six lines of code?ğŸ¤¯ Well, with my latest open-source project, ğ¢ğ§ğ ğğ¬ğ­-ğšğ§ğ²ğ­ğ¡ğ¢ğ§ğ  ( https://github.com/AstraBert/ingest-anything ), you can take all your non-PDF files, convert them to PDF, extract their text, chunk, embed and load them into a vector database, all in one go!ğŸš€ How? It's pretty simple! ğŸ“ The input files are converted into PDF by PdfItDown ( https://github.com/AstraBert/PdfItDown ) ğŸ“‘ The PDF text is extracted using LlamaIndex readers ğŸ¦› The text is chunked exploiting Chonkie ğŸ§® The chunks are embedded thanks to Sentence Transformers models ğŸ—„ï¸ The embeddings are loaded into a Qdrant vector database And you're done!âœ… Curious of trying it? Install it by running: ğ˜±ğ˜ªğ˜± ğ˜ªğ˜¯ğ˜´ğ˜µğ˜¢ğ˜­ğ˜­ ğ˜ªğ˜¯ğ˜¨ğ˜¦ğ˜´ğ˜µ-ğ˜¢ğ˜¯ğ˜ºğ˜µğ˜©ğ˜ªğ˜¯ğ˜¨ And you can start using it in your python scripts!ğŸ Don't forget to star it on GitHub and let me know...</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/792997014536541</guid></item><item><title>ComfyUI 1-click Installers updated for latest official Torch 2.7 with CUDA 12.8 (RTX 5000 series support + older GPUs) - Automatically installs xFormers, Flash Attention, Sage Attention, Triton, DeepSpeed, insightface, accelerate, onnxruntime-gpu for Windows</title><link>https://huggingface.co/posts/MonsterMMORPG/127802170120239</link><description>ComfyUI 1-click Installers updated for latest official Torch 2.7 with CUDA 12.8 (RTX 5000 series support + older GPUs) - Automatically installs xFormers, Flash Attention, Sage Attention, Triton, DeepSpeed, insightface, accelerate, onnxruntime-gpu for Windows 1-click Installers zip file is here : https://www.patreon.com/posts/105023709 xFormers compiled by me for Windows (Python 3.10, 3.11 and 3.12) and Linux (Python 3.10 only) Flash Attention compiled by me for Windows (Python 3.10, 3.11 and 3.12) and Linux (Python 3.10 only) Sage Attention compiled by me for Linux (Python 3.10 only) insightface compiled by me for Windows (Python 3.10, 3.11 and 3.12) Pre-compiled Triton + Sage Attention + DeepSpeed installed for Windows You must have pre-installed Python on your system manually Tutorial for Python + CUDA 12.8 installation : https://youtu.be/DrhUHnYfwC0 See translation</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/127802170120239</guid></item><item><title>Post of the Day</title><link>https://huggingface.co/posts/ProCreations/966463038154493</link><description>Post of the Day Iâ€™m fine-tuning Qwen 2.5-0.5B to be extremely good at math, using high-quality datasets and some smart training strategies. The logs are looking really promising so far! Expected release: Tomorrow morning? Iâ€™ll post as soon as itâ€™s ready â€” stay tuned. If you want faster updates or just wanna chat about it, come join my Discord: https://discord.gg/EXsug2Ux29 (Heads up: we might ask a couple quick questions when you join â€” just making sure we keep the server safe.) Also, check out one of the datasets weâ€™re using: ProCreations/SimpleMath This project is also helping shape the future of IntellIte. The insights and techniques weâ€™re developing here â€” better dataset curation, fine-tuning tricks, and evaluation methods â€” will directly contribute to making IntellIte even sharper, faster, and more reliable, especially for math and reasoning tasks. Big progress ahead. Canâ€™t wait to share it with you all! See translation</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ProCreations/966463038154493</guid></item><item><title>Bringing out style-intermixing adapters for Flux.Dev, including Aura Glow, Fallen Ink Art, Cardboard Paper Arts, Black &amp; White Expressions, and Glitter Gem Touch. For more details, visit the model card of the LoRA. ğŸ¥³</title><link>https://huggingface.co/posts/prithivMLmods/645344798909136</link><description>Bringing out style-intermixing adapters for Flux.Dev, including Aura Glow, Fallen Ink Art, Cardboard Paper Arts, Black &amp; White Expressions, and Glitter Gem Touch. For more details, visit the model card of the LoRA. ğŸ¥³ â•°â”ˆâ¤Demo : prithivMLmods/FLUX-LoRA-DLC2 &amp; prithivMLmods/FLUX-LoRA-DLC â•°â”ˆâ¤ Adapters : + Aura Glow : strangerzonehf/2DAura-Flux + Fallen Ink Art : strangerzonehf/FallenArt-Flux + Black &amp; White Expressions : strangerzonehf/BnW-Expressions-Flux + Glitter Gem Touch : strangerzonehf/Gem-Touch-LoRA-Flux + Cardboard Paper Arts v1 : strangerzonehf/Flux-Cardboard-Art-LoRA + Cardboard Paper Arts v2 : strangerzonehf/Cardboard-v2-Flux â•°â”ˆâ¤ Pages : - Repository Page : strangerzonehf - Collection : strangerzonehf/mixer-adp-042025-68095c365d9d1072c8d860be - Flux Ultimate LoRA Collection : strangerzonehf/Flux-Ultimate-LoRA-Collection - By prithivMLmods : @ prithivMLmods The best dimensions and inference settings for optimal results are as follows: A resolution of 1280 x 832 with a 3:2...</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/645344798909136</guid></item><item><title>6 Free resources on Reinforcement Learning (RL)</title><link>https://huggingface.co/posts/Kseniase/484268922176188</link><description>6 Free resources on Reinforcement Learning (RL) RL now is where the real action is, it's the engine behind autonomous tech, robots, and the next wave of AI that thinks, moves and solves problems on its own. To stay up to date with whatâ€™s happening in RL, we offer some fresh materials on it: 1. "Reinforcement Learning from Human Feedback" by Nathan Lambert -&gt; https://rlhfbook.com/ It's a short introduction to RLHF, explaining instruction tuning, reward modeling, alignment methods, synthetic data, evaluation, and more 2. "A Course in Reinforcement Learning (2nd Edition)" by Dimitri P. Bertsekas -&gt; https://www.mit.edu/~dimitrib/RLbook.html Explains dynamic programming (DP) and RL, diving into rollout algorithms, neural networks, policy learning, etc. Itâ€™s packed with solved exercises and real-world examples 3. "Mathematical Foundations of Reinforcement Learning" video course by Shiyu Zhao -&gt; https://www.youtube.com/playlist?list=PLEhdbSEZZbDaFWPX4gehhwB9vJZJ1DNm8 Offers a mathematical...</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/484268922176188</guid></item><item><title>ğŸ–¼ï¸ SVGRepo Icons Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/755157995506877</link><description>ğŸ–¼ï¸ SVGRepo Icons Dataset - nyuuzyou/svgrepo Collection of 217,510 Scalable Vector Graphics (SVG) icons featuring: - Sourced from SVGRepo.com across diverse categories &amp; styles - Includes metadata: title, tags, source collection, and specific license - Contains minified SVG markup for direct use or processing - Organized into splits based on individual icon license (e.g., MIT, CC0, Apache) See translation</description><pubDate>Sun, 27 Apr 2025 17:18:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/755157995506877</guid></item></channel></rss>