<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>A few months ago, I shared that I was building with</title><link>https://huggingface.co/posts/blaise-tk/599826348587266</link><description>A few months ago, I shared that I was building with @ deeivihh something like "the Steam for open source apps"... üöÄ Today, I‚Äôm excited to announce that Dione is now open source and live in public beta! Our mission is simple: make it easier to discover, use, and contribute to open source applications. üîó GitHub: https://github.com/dioneapp/dioneapp üí¨ Join the community: https://discord.gg/JDFJp33vrM Want to give it a try? I‚Äôd love your feedback! üëÄ See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/blaise-tk/599826348587266</guid></item><item><title>üéâ Dhanishtha 2.0 Preview is Now Open Source!</title><link>https://huggingface.co/posts/Abhaykoul/404767027882987</link><description>üéâ Dhanishtha 2.0 Preview is Now Open Source! The world's first Intermediate Thinking Model is now available to everyone! Dhanishtha 2.0 Preview brings revolutionary intermediate thinking capabilities to the open-source community. Unlike traditional reasoning models that think once, Dhanishtha can think, answer, rethink, answer again, and continue rethinking as needed using multiple blocks between responses. üöÄ Key Features - Intermediate thinking: Think ‚Üí Answer ‚Üí Rethink ‚Üí Answer ‚Üí Rethink if needed... - Token efficient: Uses up to 79% fewer tokens than DeepSeek R1 on similar queries - Transparent thinking: See the model's reasoning process in real-time - Open source: Freely available for research and development HelpingAI/Dhanishtha-2.0-preview https://helpingai.co/chat See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Abhaykoul/404767027882987</guid></item><item><title>Inference for generative ai models looks like a mine field, but there‚Äôs a simple protocol for picking the best inference:</title><link>https://huggingface.co/posts/burtenshaw/697123415535373</link><description>Inference for generative ai models looks like a mine field, but there‚Äôs a simple protocol for picking the best inference: üåç 95% of users &gt;&gt; If you‚Äôre using open (large) models and need fast online inference, then use Inference providers on auto mode, and let it choose the best provider for the model. https://huggingface.co/docs/inference-providers/index üë∑ fine-tuners/ bespoke &gt;&gt; If you‚Äôve got custom setups, use Inference Endpoints to define a configuration from AWS, Azure, GCP. https://endpoints.huggingface.co/ ü¶´ Locals &gt;&gt; If you‚Äôre trying to stretch everything you can out of a server or local machine, use Llama.cpp, Jan, LMStudio or vLLM. https://huggingface.co/settings/local-apps#local-apps ü™ü Browsers &gt;&gt; If you need open models running right here in the browser, use transformers.js. https://github.com/huggingface/transformers.js Let me know what you‚Äôre using, and if you think it‚Äôs more complex than this. See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/697123415535373</guid></item><item><title>so many multimodal releases these days ü§†</title><link>https://huggingface.co/posts/merve/587280854326828</link><description>so many multimodal releases these days ü§† &gt; ERNIE-4.5-VL: new vision language MoE models by Baidu https://huggingface.co/models?search=ernie-4.5-vl &gt; new visual document retrievers by NVIDIA (sota on ViDoRe!) nvidia/llama-nemoretriever-colembed-3b-v1 nvidia/llama-nemoretriever-colembed-1b-v1 &gt; Ovis-3b: new image-text in image-text out models by Alibaba ‚§µÔ∏è https://huggingface.co/spaces/AIDC-AI/Ovis-U1- See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/587280854326828</guid></item><item><title>The full Celestia 3 science-reasoning dataset is here!</title><link>https://huggingface.co/posts/sequelbox/523631078445392</link><description>The full Celestia 3 science-reasoning dataset is here! - 91k high-quality synthetic science prompts answered by DeepSeek-R1-0528 - subjects include physics, biology, chemistry, computer science, Earth science, astronomy, and information theory - one of the reasoning datasets powering the upcoming Shining Valiant 3 :) coming soon! GET IT NOW, FOR EVERYONE: sequelbox/Celestia3-DeepSeek-R1-0528 SUPPORT OUR RELEASES: sequelbox/SupportOpenSource with love, allegra See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sequelbox/523631078445392</guid></item><item><title>Check out new symbolic music AI front end and CLI training app</title><link>https://huggingface.co/posts/asigalov61/301808424415801</link><description>Check out new symbolic music AI front end and CLI training app https://webchatappai.github.io/midi-gen/ https://github.com/WebChatAppAi/Orpheus-Midi-Model-Maker @ Timzoid @ Csplk @ not-lain @ victor @ bartowski @ John6666 See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/asigalov61/301808424415801</guid></item><item><title>I'm auto-generating Docker Images to smoke-test new research repos üî•</title><link>https://huggingface.co/posts/salma-remyx/520178128759841</link><description>I'm auto-generating Docker Images to smoke-test new research repos üî• Shared to Docker Hub daily! üê≥ Today's featured paper+Image: LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs https://hub.docker.com/repository/docker/remyxai/2506.21862v1/general See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/520178128759841</guid></item><item><title>üé¨ How to Use Seedance, the #1 Video Generation Model, for Free</title><link>https://huggingface.co/posts/fantos/713394258829998</link><description>üé¨ How to Use Seedance, the #1 Video Generation Model, for Free üìå A Hidden Gem I Stumbled Upon While browsing Hugging Face, I discovered an amazing project. I found ByteDance's Seedance video generation service - which knocked Google's VEO3 down to 2nd place on the video generation leaderboard - available for free on Hugging Face! ginigen/Seedance-Free Leaderboard standings: ü•á 1st: ByteDance Seedance ü•à 2nd: Google VEO3 It's called "Bytedance Seedance Video Free" and is provided by Ginigen. üí° My Experience Using It Key Features Natural Physics Engine -Realistic object movements -Sophisticated light and shadow rendering Fast Generation Speed -Average 30 seconds to 1 minute completion -No waiting - instant access üõ†Ô∏è Available Features Text to Video -Generate 5-second videos from text descriptions -Multiple aspect ratio support (16:9, 9:16, 1:1, etc.) Image to Video -Convert static images to videos -Supports URL input or direct upload AI Prompt Enhancement -AI-based prompt optimization...</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fantos/713394258829998</guid></item><item><title>In case you missed it, Hugging Face expanded its collaboration with Azure a few weeks ago with a curated catalog of 10,000 models, accessible from Azure AI Foundry and Azure ML!</title><link>https://huggingface.co/posts/pagezyhf/189638803943526</link><description>In case you missed it, Hugging Face expanded its collaboration with Azure a few weeks ago with a curated catalog of 10,000 models, accessible from Azure AI Foundry and Azure ML! @ alvarobartt cooked during these last days to prepare the one and only documentation you need, if you wanted to deploy Hugging Face models on Azure. It comes with an FAQ, great guides and examples on how to deploy VLMs, LLMs, smolagents and more to come very soon. We need your feedback: come help us and let us know what else you want to see, which model we should add to the collection, which model task we should prioritize adding, what else we should build a tutorial for. You‚Äôre just an issue away on our GitHub repo! https://huggingface.co/docs/microsoft-azure/index See translation</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/pagezyhf/189638803943526</guid></item><item><title>üß∞ Free up space on the Hub with</title><link>https://huggingface.co/posts/anakin87/460502915743038</link><description>üß∞ Free up space on the Hub with super_squash_history üßπ As you may know, Hugging Face Hub has storage limits on private repos (100 GB for free users, 1 TB for PROs). This weekend I did some cleanup on my private repos I went 1.58 TB down to 1 GB. üòÖ Besides deleting old, unused models, the main tool I used was a lesser-known command: super_squash_history . When you train a model, you often push multiple checkpoints to the Hub. Each checkpoint = a commit. A 2.6B model in BF16 is ~5 GB. So 10 checkpoints = 50 GB. That adds up fast. While full commit history can be useful for rollbacks, it's often unnecessary for older experiments where only the final model matters. In these cases, you can use super_squash_history : it reduces your entire repo history to a single commit. https://huggingface.co/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfApi.super_squash_history ‚ö†Ô∏è super_squash_history is a non-revertible operation. Once squashed, the commit history cannot be...</description><pubDate>Wed, 02 Jul 2025 05:26:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/anakin87/460502915743038</guid></item></channel></rss>