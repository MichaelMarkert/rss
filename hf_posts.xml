<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>12 Foundational AI Model Types</title><link>https://huggingface.co/posts/Kseniase/795992300839975</link><description>12 Foundational AI Model Types Let‚Äôs refresh some fundamentals today to stay fluent in the what we all work with. Here are some of the most popular model types that shape the vast world of AI (with examples in the brackets): 1. LLM - Large Language Model (GPT, LLaMA) -&gt; Large Language Models: A Survey (2402.06196) + history of LLMs: https://www.turingpost.com/t/The%20History%20of%20LLMs It's trained on massive text datasets to understand and generate human language. They are mostly build on Transformer architecture, predicting the next token. LLMs scale by increasing overall parameter count across all components (layers, attention heads, MLPs, etc.) 2. SLM - Small Language Model (TinyLLaMA, Phi models, SmolLM) A Survey of Small Language Models (2410.20011) Lightweight LM optimized for efficiency, low memory use, fast inference, and edge use. SLMs work using the same principles as LLMs 3. VLM - Vision-Language Model (CLIP, Flamingo) -&gt; An Introduction to Vision-Language Modeling...</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/795992300839975</guid></item><item><title>Having an insanely good medical LLM is pointless if it won‚Äôt answer your questions!</title><link>https://huggingface.co/posts/drwlf/878228510592624</link><description>Having an insanely good medical LLM is pointless if it won‚Äôt answer your questions! So we‚Äôve made 2 notebook for abliterating any model in order to achieve a good model that will actually help you! The notebooks are made using @ mlabonne ‚Äòs abliteration logic and datasets! Feel free to use them and happy training üòä https://github.com/dralexlup/LLM-Abliteration See translation</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/drwlf/878228510592624</guid></item><item><title>The past year I have been trying to get diffusion models to work for language generation, without having to retrain a LLM from scratch. And recently, we finally succeeded:</title><link>https://huggingface.co/posts/Ruurd/491522052497480</link><description>The past year I have been trying to get diffusion models to work for language generation, without having to retrain a LLM from scratch. And recently, we finally succeeded: We introduce "LAD: LoRA-Adapted Denoiser", a method to convert a LLaMA model into a text diffusion model using LoRA finetuning and structured input corruption. üéØ Try the demo and read the write-up here! https://ruurdkuiper.github.io/tini-lad/ Unlike autoregressive (word-for-word) models like ChatGPT, diffusion models iteratively refine a noised sequence. However, most current diffusion approaches rely on all-parameter retraining and repeatedly remasking tokens, which is costly and slow during both training and inference! üß† With LAD: - We can finetune an autoregressive model for diffusive generation in just 10 hours on a single GPU. - Test-time compute is fully adjustable: fewer steps means faster outputs while more steps improve output quality. - Due to our unique noising schedule, remasking is not always needed...</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Ruurd/491522052497480</guid></item><item><title>C/ua Cloud Containers  - Docker for Computer-Use Agents. Zero local setup. Same Computer and Agent interfaces. Scale 1-100 agents instantly.</title><link>https://huggingface.co/posts/dhruv3006/635329388692480</link><description>C/ua Cloud Containers - Docker for Computer-Use Agents. Zero local setup. Same Computer and Agent interfaces. Scale 1-100 agents instantly. Github : https://github.com/trycua/cua Website : https://www.trycua.com See translation</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/635329388692480</guid></item><item><title>üöÄ Videoxity is live on Hugging Face! üéûÔ∏è</title><link>https://huggingface.co/posts/zamal/148346638153657</link><description>üöÄ Videoxity is live on Hugging Face! üéûÔ∏è A powerful, modular toolkit for intelligent video manipulation and scene editing. With Videoxity, you can: üñºÔ∏è Auto-caption keyframes with BLIP üß† Filter scenes using natural language (e.g. ‚Äúremove dog scenes‚Äù) ‚úÇÔ∏è Seamlessly trim videos with FFmpeg üìä Generate frame-based summaries Powered by Groq LLM + LangChain, OpenCV, BLIP, and SentenceTransformers, Videoxity bridges vision and language to give developers full control over video content. üîß Built for developers. Feedback welcome! üëâ Try it out here fau/videoxity See translation</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/zamal/148346638153657</guid></item><item><title>RoboBrain 2.0üî• OPEN embedded brain model by BAAIBeijing</title><link>https://huggingface.co/posts/AdinaY/444223242188874</link><description>RoboBrain 2.0üî• OPEN embedded brain model by BAAIBeijing BAAI/RoboBrain2.0-7B ‚ú® 7B - Apache 2.0 / 32B coming soon ‚ú® Supports multiple images, long videos, and high-resolution visuals ‚ú® Spatial + temporal reasoning ‚ú® Real-time memory &amp; scene graphs See translation</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/444223242188874</guid></item><item><title>New models from Qwen üî•</title><link>https://huggingface.co/posts/AdinaY/473255162200609</link><description>New models from Qwen üî• Qwen3-Embedding and Qwen3-Reranker Series just released on the hub by Alibaba Qwen team. ‚ú® 0.6B/ 4B/ 8B with Apache2.0 ‚ú® Supports 119 languages ü§Ø ‚ú® Top-tier performance: Leading the MTEB multilingual leaderboardÔºÅ Reranker: Qwen/qwen3-reranker-6841b22d0192d7ade9cdefea Embedding: Qwen/qwen3-embedding-6841b2055b99c44d9a4c371f See translation</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/473255162200609</guid></item><item><title>As part of Duality AI‚Äôs recent Kaggle competition, we‚Äôve released a free, fully customizable cloud scenario designed to help you create targeted datasets with YOLO-compatible labels.</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/946731855039439</link><description>As part of Duality AI‚Äôs recent Kaggle competition, we‚Äôve released a free, fully customizable cloud scenario designed to help you create targeted datasets with YOLO-compatible labels. The cloud simulation lets you customize the: üì∏ camera distance üéûÔ∏è film grain variation üñºÔ∏èbackground objects, ‚ûï and more! Create the dataset that you need by following this link: https://falcon.duality.ai/secure/scenarios/edit/cca0bc47-265a-4f67-843f-a434b63271b3?utm_source=huggingface&amp;utm_medium=social&amp;utm_campaign=general I‚Äôve attached an instructional video we used for the competition, but this feature is free for anyone who has an account. https://vimeo.com/1091271731?share=copy See translation</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/946731855039439</guid></item><item><title># Machine Learning and societal impact: The Next Frontier</title><link>https://huggingface.co/posts/ghostai1/343694476131326</link><description># Machine Learning and societal impact: The Next Frontier The societal impact of AI-driven Machine Learning is truly life-changing. It‚Äôs hard to imagine life without the innovations that AI has brought upon us. From personalized recommendations on our favorite streaming platforms to self-driving cars that take us to our destinations with ease. AI is also helping to revolutionize the medical field, with breakthroughs in disease detection and treatment. But it‚Äôs not just about the personal stuff ‚Äì AI is revolutionizing the workplace too. With the help of AI, companies are able to make data-driven decisions, automate mundane tasks, and optimize their operations. This is leading to increased productivity and efficiency, resulting in a better bottom line for businesses. In conclusion, AI-driven Machine Learning is transforming our world in ways we never imagined possible. It‚Äôs hard to think about life without it, and we can only wonder what amazing things the future holds for us when it...</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ghostai1/343694476131326</guid></item><item><title>Agents &amp; MCP Hackathon Day 5</title><link>https://huggingface.co/posts/azettl/146227040245541</link><description>Agents &amp; MCP Hackathon Day 5 I submitted my projects yesterday at lunch. Check the submissions and let me know what you think! There's also demo videos. #1: Consilium: Multi-AI Expert Consensus Platform Agents-MCP-Hackathon/consilium_mcp UI Video: https://www.youtube.com/watch?v=ciYLqI-Nawc MCP Video: https://www.youtube.com/watch?v=r92vFUXNg74 #2: Consilium Roundtable - Custom Gradio Component (used in #1) Agents-MCP-Hackathon/gradio_consilium_roundtable Video: https://www.youtube.com/watch?v=oyYlf1BfuU8 If you find this cool, please like the spaces and videos ‚ù§Ô∏è. Now that they extended the time by 2 days, I will polish the custom component a little more and update the submission. See translation</description><pubDate>Tue, 10 Jun 2025 05:23:46 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/azettl/146227040245541</guid></item></channel></rss>