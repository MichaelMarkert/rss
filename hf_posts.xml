<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13:</title><link>https://huggingface.co/posts/mike-ravkine/324105560308241</link><description>Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13: aquif-ai/aquif-3.5-8B-Think Built on top of the solid Qwen3-8B foundation, aquif-3.5-8B-Think successfully preserves the high performance of the original model while consuming 30-50% less reasoning tokens. The most notable regression vs the base model here is in arithmetic - if your workload is math heavy this model demonstrates an unfortunate collapse with performance under growing complexity. The interesting combination of awesome overall performance on SVG simple shapes identification coupled with a total inability to recognize more complex shapes like 'House' or 'Arrow' is a behavior directly inherited from the base model (but with a ~20% improvement in token utilization). If you like your reasoning models token-efficient, Aquif-3.5-8B-Think is well worth a spin. Higher resolution, more detailed, interactive plots are available at the m12X explorer: https://reasonscape.com/m12x/explorer/...</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mike-ravkine/324105560308241</guid></item><item><title>Just tried to create an educational assistant for younger people who can struggle with visualsation of 'what is this sorcery all about'.</title><link>https://huggingface.co/posts/s3nh/172255383269757</link><description>Just tried to create an educational assistant for younger people who can struggle with visualsation of 'what is this sorcery all about'. Its first step of my spare time projects, sft on Qwen3-8B, EduHelper is a child-friendly tutoring assistant fine-tuned from the Qwen3-8B base model using parameter-efficient fine-tuning (PEFT) with LoRA on the ajibawa-2023/Education-Young-Children dataset. s3nh/EduHelp-8B Glad to share my work, have a wonderful day! See translation</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/s3nh/172255383269757</guid></item><item><title>Released an AWQ quantized version of BosonAI‚Äôs Higgs-Llama-3-70B model! üéâ</title><link>https://huggingface.co/posts/ronantakizawa/301388923540512</link><description>Released an AWQ quantized version of BosonAI‚Äôs Higgs-Llama-3-70B model! üéâ The Higgs-Llama-3-70B is an LLM specialized in role-playing, useful for game characters. Using an NVIDIA B200 GPU, I was able to compress the huge 140GB model into 37GB while keeping minimal perplexity üëç ronantakizawa/higgs-llama-3-70b-awq See translation</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/301388923540512</guid></item><item><title>‚úÖ New Article: *Humor as Structured Protocol*</title><link>https://huggingface.co/posts/kanaria007/662291776092926</link><description>‚úÖ New Article: *Humor as Structured Protocol* Title: üé≠ Humor as Structured Protocol: Joke-Protocols as Emotion Regulation and AGI Design Resource üîó https://huggingface.co/blog/kanaria007/humor-as-structured-protocol --- Summary: Humor isn‚Äôt a distraction ‚Äî it‚Äôs a *protocol*. By framing paradox as *benign*, humor vents overload, resets attention, and enables safe re-entry to difficult topics. In Structured Intelligence terms, jokes are *bounded anomalies* that discharge tension without breaking identity or trust. &gt; Laughter is relief. &gt; *Humor is the design that makes relief safe.* --- Why It Matters: ‚Ä¢ Turns ‚Äúcomic timing‚Äù into *recoverable state transitions* (no denial, no collapse) ‚Ä¢ Gives teams and products a *de-escalation primitive* that preserves dignity ‚Ä¢ Informs *AI/UX safety*: sandboxed incongruity, ethical gates, clear exit paths --- What‚Äôs Inside: ‚Ä¢ The Humor Protocol: trigger ‚Üí incongruity ‚Üí benign boundary ‚Üí release ‚Üí re-entry ‚Ä¢ Patterns: irony, self-deprecation,...</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/662291776092926</guid></item><item><title>üì¢ Product Update: SalesPilot 1.2 Released!</title><link>https://huggingface.co/posts/andywu-kby/521155221047550</link><description>üì¢ Product Update: SalesPilot 1.2 Released! üîß What‚Äôs New: - Sales Forecasting, Sales Analysis using Excel - No technical skills required - Dashboard and Delete Functionality - Chatbot Application https://miragic.ai/products/sales-pilot Looking forward to your feedback! See translation</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/andywu-kby/521155221047550</guid></item><item><title>I've made some improvements to my custom Deep_Research tool in the</title><link>https://huggingface.co/posts/Nymbo/670905099951674</link><description>I've made some improvements to my custom Deep_Research tool in the Nymbo/Tools MCP server. I've added a second LLM process and it still takes less than 1 minute to complete! The original version of my Deep_Research tool would basically dump up to 50 fetched webpages onto the Researcher model ( Qwen3-235B ), with only a little bit of context shown from each page. # New "Filterer" Process The new process includes another LLM call before the researcher process. The Filterer (also Qwen3-235B ) gets the query summary and the original 50 pages with low context, and decides which pages are most relevant to the research topic. The Filterer then outputs the URLs to the relevant pages, which are then re-fetched (with more context) and sent to the Researcher. # Researcher Context The Researcher now gets only the relevant webpages, then begins writing the report. When testing with 50 initial results, the researcher would often end up with 10-20 results of relevant context. It still takes less...</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Nymbo/670905099951674</guid></item><item><title>We have trained a LBM-Eraser with RORD-Dataset in the open üî•</title><link>https://huggingface.co/posts/piercus/778833977889788</link><description>We have trained a LBM-Eraser with RORD-Dataset in the open üî• üöÄ 1-step only inference, no distillation ü™∂ Light backbone :SD1.5 üß† Light training : converge in 6k steps Now let's improve this, especially the inpainting capabilities. Stay tuned for more :-) LBM paper : LBM: Latent Bridge Matching for Fast Image-to-Image Translation (2503.07535) Our LBM fork : https://github.com/finegrain-ai/LBM See translation</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/piercus/778833977889788</guid></item><item><title>Introducing Image-Guard-2.0, an experimental, lightweight vision-language encoder model with a size of 0.1B (&lt;100M parameters), trained on SigLIP2 (siglip2-base-patch16-224). Designed for multi-label image classification tasks, this model functions as an image safety system, serving as an image guard or moderator across a wide range of categories, from anime to realistic imagery.</title><link>https://huggingface.co/posts/prithivMLmods/280533880488225</link><description>Introducing Image-Guard-2.0, an experimental, lightweight vision-language encoder model with a size of 0.1B (&lt;100M parameters), trained on SigLIP2 (siglip2-base-patch16-224). Designed for multi-label image classification tasks, this model functions as an image safety system, serving as an image guard or moderator across a wide range of categories, from anime to realistic imagery. ‚ö°blog-article: https://huggingface.co/blog/prithivMLmods/image-guard-models It also performs strict moderation and filtering of artificially synthesized content, demonstrating strong detection and handling of explicit images. Image-Guard-2.0 delivers robust performance in streamlined scenarios, ensuring reliable and effective classification across diverse visual inputs. See translation</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/280533880488225</guid></item><item><title>Stop Designing Workflows, Design Capabilities, and Let Models Plan at Runtime</title><link>https://huggingface.co/posts/mrmanna/327383930726574</link><description>Stop Designing Workflows, Design Capabilities, and Let Models Plan at Runtime &gt; Start Governing Capabilities in Enterprise Agent Development with Agentic Contract Model (ACM) https://cloudoffice.io/stop-designing-workflows-design-capabilities-and-let-models-plan-at-runtime-f49265496196 See translation</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mrmanna/327383930726574</guid></item><item><title>Just posted</title><link>https://huggingface.co/posts/jlopez-dl/435039183324892</link><description>Just posted https://huggingface.co/blog/jlopez-dl/hybrid-attention-game-changer , for those interested in Hybrid Attention See translation</description><pubDate>Thu, 16 Oct 2025 09:26:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jlopez-dl/435039183324892</guid></item></channel></rss>