<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸŒŸ 3D Llama Studio - AI 3D Generation Platform</title><link>https://huggingface.co/posts/ginipick/845644282975973</link><description>ğŸŒŸ 3D Llama Studio - AI 3D Generation Platform ğŸ“ Project Overview 3D Llama Studio is an all-in-one AI platform that generates high-quality 3D models and stylized images from text or image inputs. âœ¨ Key Features Text/Image to 3D Conversion ğŸ¯ Generate 3D models from detailed text descriptions or reference images Intuitive user interface Text to Styled Image Generation ğŸ¨ Customizable image generation settings Adjustable resolution, generation steps, and guidance scale Supports both English and Korean prompts ğŸ› ï¸ Technical Features Gradio-based web interface Dark theme UI/UX Real-time image generation and 3D modeling ğŸ’« Highlights User-friendly interface Real-time preview Random seed generation High-resolution output support (up to 2048x2048) ğŸ¯ Applications Product design Game asset creation Architectural visualization Educational 3D content ğŸ”— Try It Now! Experience 3D Llama Studio: ginigen/3D-LLAMA #AI #3DGeneration #MachineLearning #ComputerVision #DeepLearning See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/845644282975973</guid></item><item><title>8 New Types of RAG</title><link>https://huggingface.co/posts/Kseniase/113319295427497</link><description>8 New Types of RAG RAG techniques continuously evolve to enhance LLM response accuracy by retrieving relevant external data during generation. To keep up with current AI trends, new RAG types incorporate deep step-by-step reasoning, tree search, citations, multimodality and other effective techniques. Here's a list of 8 latest RAG advancements: 1. DeepRAG -&gt; DeepRAG: Thinking to Retrieval Step by Step for Large Language Models (2502.01142) Models retrieval-augmented reasoning as a Markov Decision Process, enabling strategic retrieval. It dynamically decides when to retrieve external knowledge and when rely on parametric reasoning. 2. RealRAG -&gt; RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning (2502.00848) Enhances novel object generation by retrieving real-world images and using self-reflective contrastive learning to fill knowledge gap, improve realism and reduce distortions. 3. Chain-of-Retrieval Augmented Generation (CoRAG) -&gt;...</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/113319295427497</guid></item><item><title>We did it. Kokoro TTS (v1.0) can now run 100% locally in your browser w/ WebGPU acceleration. Real-time text-to-speech without a server. âš¡ï¸</title><link>https://huggingface.co/posts/Xenova/620657830533509</link><description>We did it. Kokoro TTS (v1.0) can now run 100% locally in your browser w/ WebGPU acceleration. Real-time text-to-speech without a server. âš¡ï¸ Generate 10 seconds of speech in ~1 second for $0. What will you build? ğŸ”¥ webml-community/kokoro-webgpu The most difficult part was getting the model running in the first place, but the next steps are simple: âœ‚ï¸ Implement sentence splitting, allowing for streamed responses ğŸŒ Multilingual support (only phonemization left) Who wants to help? See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Xenova/620657830533509</guid></item><item><title>QwQ Edge Gets a Small Update..! ğŸ’¬</title><link>https://huggingface.co/posts/prithivMLmods/964278651693422</link><description>QwQ Edge Gets a Small Update..! ğŸ’¬ try now: prithivMLmods/QwQ-Edge ğŸš€Now, you can use the following commands for different tasks: ğŸ–¼ï¸ @ image 'prompt...' â†’ Generates an image ğŸ”‰@tts1 'prompt...' â†’ Generates speech in a female voice ğŸ”‰ @ tts2 'prompt...' â†’ Generates speech in a male voice ğŸ…°ï¸@text 'prompt...' â†’ Enables textual conversation (If not specified, text-to-text generation is the default mode) ğŸ’¬Multimodality Support : prithivMLmods/Qwen2-VL-OCR-2B-Instruct ğŸ’¬For text generation, the FastThink-0.5B model ensures quick and efficient responses, prithivMLmods/FastThink-0.5B-Tiny ğŸ’¬Image Generation: sdxl lightning model, SG161222/RealVisXL_V4.0_Lightning Github: https://github.com/PRITHIVSAKTHIUR/QwQ-Edge graph TD A[User Interface] --&gt; B[Chat Logic] B --&gt; C{Command Type } C --&gt;| Text | D [FastThink -0.5 B] C --&gt;| Image | E [Qwen2-VL-OCR -2 B] C --&gt;| @image | F [Stable Diffusion XL] C --&gt;| @tts | G [Edge TTS] D --&gt; H[Response] E --&gt; H F --&gt; H G --&gt; H See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/964278651693422</guid></item><item><title>Wanted: Peak Data. I'm collecting audio data to train another TTS model:</title><link>https://huggingface.co/posts/hexgrad/846477530846098</link><description>Wanted: Peak Data. I'm collecting audio data to train another TTS model: + AVM data: ChatGPT Advanced Voice Mode audio &amp; text from source + Professional audio: Permissive (CC0, Apache, MIT, CC-BY) This audio should *impress* most native speakers, not just barely pass their audio Turing tests. Professional-caliber means S or A-tier, not your average bloke off the street. Traditional TTS may not make the cut. Absolutely no low-fi microphone recordings like Common Voice. The bar is much higher than last time, so there are no timelines yet and I expect it may take longer to collect such mythical data. Raising the bar means evicting quite a bit of old data, and voice/language availability may decrease. The theme is *quality* over quantity. I would rather have 1 hour of A/S-tier than 100 hours of mid data. I have nothing to offer but the north star of a future Apache 2.0 TTS model, so prefer data that you *already have* and costs you *nothing extra* to send. Additionally, *all* the new...</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hexgrad/846477530846098</guid></item><item><title>VectorFlow âš¡: Transform Images into Professional Vector Graphics</title><link>https://huggingface.co/posts/openfree/664271513735189</link><description>VectorFlow âš¡: Transform Images into Professional Vector Graphics Convert your raster images (JPG, PNG, WEBP) into high-quality vector graphics (SVG, AI) with our easy-to-use tool! Perfect for designers, artists, and anyone needing vector conversions. ğŸ¯ Key Features: Dual format support: SVG and AI output Real-time preview for both formats Advanced customization options Clean, user-friendly interface Batch processing ready ğŸ› ï¸ Advanced Controls: Color/B&amp;W mode selection Speckle filtering Color precision adjustment Layer management Curve fitting options ğŸ’« Why VectorFlow? No installation needed Free to use Professional-grade output Simple yet powerful ğŸ”§ Technical Details: Built with Gradio Powered by VTracer Optimized SVG generation AI format support ğŸ‘‰ Try it now: openfree/VectorFlow #computervision #vectorgraphics #imageprocessing #svg #design #ai See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/664271513735189</guid></item><item><title>ğŸª„ LayerDiffuse - Flux Version (Demo) ğŸª„</title><link>https://huggingface.co/posts/eienmojiki/879034302218585</link><description>ğŸª„ LayerDiffuse - Flux Version (Demo) ğŸª„ LayerDiffuse - Transparent Image Layer Diffusion using Latent Transparency Demo: eienmojiki/Flux-LayerDiffuse See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eienmojiki/879034302218585</guid></item><item><title>Tutorial ğŸ’¥ Training a non-English reasoning model with GRPO and Unsloth</title><link>https://huggingface.co/posts/s-emanuilov/736266652835078</link><description>Tutorial ğŸ’¥ Training a non-English reasoning model with GRPO and Unsloth I wanted to share my experiment with training reasoning models in languages other than English/Chinese. Using Llama 3.1 8B as base, GRPO trainer from trl, and Unsloth optimizations, I got a working prototype in Bulgarian after ~5 hours on an L40S GPU. The approach should work for any language where the base model has some pre-training coverage. Full code and tutorial here: https://unfoldai.com/reasoning-in-a-non-english-language/ The model itself: s-emanuilov/LLMBG-Llama-3.1-8B-BG-Reasoning-v0.1 I hope this helps anyone looking to build reasoning models in their language. See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/s-emanuilov/736266652835078</guid></item><item><title>Just been starting to port my articles over that mattered most to me from Civitai.</title><link>https://huggingface.co/posts/Duskfallcrew/848384638750258</link><description>Just been starting to port my articles over that mattered most to me from Civitai. Look, i'm not going to sit here and whine, complain and moan entirely - they know why i've left, they're going to thrive without me. I'm a mere spec compared to their future, and that's amazing. But the journey continues, i've posted my Design 101 for Ai - the first one up -- i BELEIVE it's the first one, as it delves back to how Arts and Crafts connect to AI. I'm still looking for a model hub in future for my insane 800+ models i'd published - considering that that's half of what i've got sitting in my repos on HF. See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Duskfallcrew/848384638750258</guid></item><item><title>Blurred-Thoughts Supervised-Finetuning ğŸ™ˆ</title><link>https://huggingface.co/posts/mkurman/739948560091317</link><description>Blurred-Thoughts Supervised-Finetuning ğŸ™ˆ After hours of working with GitHub Copilot to organize the code, I'm keen to announce the release of Blurred Thoughts Supervised-Finetuning (BT-SFT), a new method for fine-tuning LLMs to produce more diverse and creative responses. BT-SFT introduces: âœ… Smart tokenization method randomly masks tokens within &lt;think&gt; ... &lt;/think&gt; tags, promoting the model to generate diverse responses that align better with its probability distribution instead of memorizing the thought process from distilled data. âœ… Reward function that ensures responses are well-structured. Explore and contribute to the project available in my GitHub repository: https://github.com/mkurman/blurred-thoughts-SFT Keep me updated on your experiments with BT-SFT! ğŸ See translation</description><pubDate>Mon, 10 Feb 2025 05:08:06 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mkurman/739948560091317</guid></item></channel></rss>