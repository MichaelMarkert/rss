<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Introducing Dhara-70M: A diffusion language model that achieves 3.8x higher throughput than autoregressive models!</title><link>https://huggingface.co/posts/codelion/602031524113549</link><description>Introducing Dhara-70M: A diffusion language model that achieves 3.8x higher throughput than autoregressive models! Key findings from our research on optimal architectures for small language models: ‚Üí Depth beats width: 32 layers outperforms 12 layers at the same parameter count ‚Üí Best-in-class factuality: 47.5% on TruthfulQA ‚Üí 10x training efficiency using WSD (Warmup-Stable-Decay) conversion ‚Üí Canon layers add only 0.13% parameters but improve reasoning We trained on 1B tokens using the optimal 50-30-20 dataset mix (PDFs + filtered web + educational content), then converted to diffusion with just 100M additional tokens. Blog: https://huggingface.co/blog/codelion/optimal-model-architecture Model: codelion/dhara-70m See translation</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/602031524113549</guid></item><item><title>What if an AI agent could be tricked into stealing your data, just by reading a tool's description? A new paper reports it's possible.</title><link>https://huggingface.co/posts/MikeDoes/284489022074040</link><description>What if an AI agent could be tricked into stealing your data, just by reading a tool's description? A new paper reports it's possible. The "Attractive Metadata Attack" paper details this stealthy new threat. To measure the real-world impact of their attack, the researchers needed a source of sensitive data for the agent to leak. We're proud that the AI4Privacy corpus was used to create the synthetic user profiles containing standardized PII for their experiments. This is a perfect win-win. Our open-source data helped researchers Kanghua Mo, ÈæôÊò±‰∏û, Zhihao Li from Guangzhou University and The Hong Kong Polytechnic University to not just demonstrate a new attack, but also quantify its potential for harm. This data-driven evidence is what pushes the community to build better, execution-level defenses for AI agents. üîó Check out their paper to see how easily an agent's trust in tool metadata could be exploited: https://arxiv.org/pdf/2508.02110 #OpenSource #DataPrivacy #LLM #Anonymization...</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/284489022074040</guid></item><item><title>Just sharing a result of a homelab infrastructure experiment:</title><link>https://huggingface.co/posts/csabakecskemeti/254891528281591</link><description>Just sharing a result of a homelab infrastructure experiment: I've managed to setup a distributed inference infra at home using a DGX Spark (128GB unified gddr6) and a linux workstation with an RTX 6000 Pro (96GB gddr7) connected via 100Gbps RoCEv2. The model I've used ( https://lnkd.in/gx6J7YuB ) is about 140GB so could not fit either of the GPU. Full setup and tutorial soon on devquasar.com Screen recording: https://lnkd.in/gKM9H5GJ See translation</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/254891528281591</guid></item><item><title>Qwen Image Edit 2511 Free and Open Source Crushes Qwen Image Edit 2509 and Challenges Nano Banana Pro :</title><link>https://huggingface.co/posts/MonsterMMORPG/548414281502732</link><description>Qwen Image Edit 2511 Free and Open Source Crushes Qwen Image Edit 2509 and Challenges Nano Banana Pro : https://www.youtube.com/watch?v=YfuQuOk2sB0 Full tutorial link &gt; https://www.youtube.com/watch?v=YfuQuOk2sB0 Full HF article here : https://huggingface.co/blog/MonsterMMORPG/qwen-image-edit-2511-free-and-open-source-crushes Qwen Image Edit 2511 model just published and it is literally competing against Nano Banana Pro at image editing tasks. With native whopping 2560x2560 pixels image output capability and with only 12 steps it is next level. With our installers and specially made Quant FP8 Scaled model, you can run this amazing beast even as low as 6 GB GPUs. In this tutorial, I have compared Qwen Image Edit 2511 with previous successor model Qwen Image 2509 with 12 different unique and hard prompts and cases. Everything is step by step explained and provided. Here check some comparison images See translation</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/548414281502732</guid></item><item><title>Hey folks üëã</title><link>https://huggingface.co/posts/dhruv3006/122199389172183</link><description>Hey folks üëã We‚Äôre experimenting with a new response panel layout and would love your feedback.We‚Äôre testing a more focused experience: - Only one response section open at a time (instead of multiple) - The response body now takes up most of the vertical space, making it easier to read and inspect The goal is simple: reduce clutter and keep the response as the main focus. That said, we know many developers are comfortable with the classic layout (Postman / Bruno-style), where multiple sections can stay open at once.What would you prefer? - A new, focused single-section layout - The classic multi-section layout - A toggle that lets you choose between both? Download Voiden here :https://voiden.md/download See translation</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/122199389172183</guid></item><item><title>Hey everyone!</title><link>https://huggingface.co/posts/Parveshiiii/283996096084237</link><description>Hey everyone! We‚Äôre excited to introduce our new Telegram group: https://t.me/XenArcAI This space is built for **model builders, tech enthusiasts, and developers** who want to learn, share, and grow together. Whether you‚Äôre just starting out or already deep into AI/ML, you‚Äôll find a supportive community ready to help with knowledge, ideas, and collaboration. üí° Join us to: - Connect with fellow developers and AI enthusiasts - Share your projects, insights, and questions - Learn from others and contribute to a growing knowledge base üëâ If you‚Äôre interested, hop in and be part of the conversation: https://t.me/XenArcAI See translation</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Parveshiiii/283996096084237</guid></item><item><title>Experimental global target bits‚Äëper‚Äëweight quantization of ServiceNow-AI/Apriel-1.6-15b-Thinker and zai-org/GLM-4.6V-Flash</title><link>https://huggingface.co/posts/eaddario/946715506605693</link><description>Experimental global target bits‚Äëper‚Äëweight quantization of ServiceNow-AI/Apriel-1.6-15b-Thinker and zai-org/GLM-4.6V-Flash The method to produce these experimental versions involves using a custom version of llama-imatrix to generate an imatrix including the mean activations, and a custom version of llama-quantize, which computes a per-tensor weighted mean squared quantization error and a bias/projection term (if the imatrix includes activations), to automatically select the lowest error quantization recipe that achieves a global target bits‚Äëper‚Äëweight (bpw). More information in the models' cards eaddario/Apriel-1.6-15b-Thinker-GGUF eaddario/GLM-4.6V-Flash-GGUF See translation</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eaddario/946715506605693</guid></item><item><title>Introducing the Qwen-Image-Edit-2511-LoRAs-Fast demo, featuring image property comparison and contrast, built on top of Gradio and the combined Rerun SDK. It supports single and multi-image edits with existing LoRAs that are lazily loaded. (Note: This is still an experimental Space for Qwen-Image-Edit-2511.)</title><link>https://huggingface.co/posts/prithivMLmods/163304413191334</link><description>Introducing the Qwen-Image-Edit-2511-LoRAs-Fast demo, featuring image property comparison and contrast, built on top of Gradio and the combined Rerun SDK. It supports single and multi-image edits with existing LoRAs that are lazily loaded. (Note: This is still an experimental Space for Qwen-Image-Edit-2511.) ‚≠ê Space Demo: prithivMLmods/Qwen-Image-Edit-2511-LoRAs-Fast ‚≠ê GitHub: https://github.com/PRITHIVSAKTHIUR/Qwen-Image-Edit-2511-LoRAs-Fast-Multi-Image-Rerun ‚≠ê Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/163304413191334</guid></item><item><title>‚úÖ New Article: *Pattern-Learning-Bridge (PLB)*</title><link>https://huggingface.co/posts/kanaria007/140378798774766</link><description>‚úÖ New Article: *Pattern-Learning-Bridge (PLB)* Title: üß© Pattern-Learning-Bridge: How SI-Core Actually Learns From Its Own Failures üîó https://huggingface.co/blog/kanaria007/learns-from-its-own-failures --- Summary: Most stacks ‚Äúlearn‚Äù by fine-tuning weights and redeploying ‚Äî powerful, but opaque. SI-Core already produces *structured evidence* (jump logs, ethics traces, effect ledgers, goal vectors, rollback traces), so learning can be *structural* instead: *Upgrade policies, compensators, SIL code, and goal structures ‚Äî using runtime evidence.* &gt; Learning isn‚Äôt a model tweak. &gt; *It‚Äôs upgrading the structures that shape behavior.* --- Why It Matters: ‚Ä¢ Makes improvement *localized and explainable* (what changed, where, and why) ‚Ä¢ Keeps ‚Äúself-improvement‚Äù *governable* (versioned deltas + review + CI/CD) ‚Ä¢ Turns incidents/metric drift into *actionable patches*, not postmortem PDFs ‚Ä¢ Scales to real ops: ethics policies, rollback plans, semantic compression, goal estimators --- What‚Äôs...</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/140378798774766</guid></item><item><title>Happy Holidays all! geofractal architectural expansions; timm is now a core component for experimenting. As it stands, the system is growing rapidly in one direction, and timm brings a whole lot to the table in another rapid-prototyping direction. Therefore, timm is now a core component for ease-of-use.</title><link>https://huggingface.co/posts/AbstractPhil/257242713648796</link><description>Happy Holidays all! geofractal architectural expansions; timm is now a core component for experimenting. As it stands, the system is growing rapidly in one direction, and timm brings a whole lot to the table in another rapid-prototyping direction. Therefore, timm is now a core component for ease-of-use. BaseUtil is a new core component; aka src.geofractal.router.base_util inherits BaseComponent's behavior, so it should allow device movement for util operations which will direct utilization for device-to-device behavior for the upcoming accelerate integration. I'm trying to mitigate the base component structure as much as possible, but the need to chain components in specific orders presented a unique problem. By compartmentalizing utils into structures that can be delegated and moved, these structures can be repurposed, expanded autonomously, reduced autonomously, and more. ChainComponent inherits a subsystem specifically designed to organize multi-system multi-device formulas...</description><pubDate>Sun, 28 Dec 2025 05:29:40 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AbstractPhil/257242713648796</guid></item></channel></rss>