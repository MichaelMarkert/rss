<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Just uploaded a detailed blog about my findings in optimizing NeuTTS to generate 200 seconds of audio in a single second. Also went in depth in NeuTTSâ€™s architecture. Will be happy to answer any questions.</title><link>https://huggingface.co/posts/YatharthS/933040846295981</link><description>Just uploaded a detailed blog about my findings in optimizing NeuTTS to generate 200 seconds of audio in a single second. Also went in depth in NeuTTSâ€™s architecture. Will be happy to answer any questions. https://huggingface.co/blog/YatharthS/making-neutts-200x-realtime See translation</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/933040846295981</guid></item><item><title>Publishing our research on dual-motor backlash compensation for STS3215 servos. To complete our arXiv submission, we need a quick endorsement from someone who has published in robotics (cs.RO/eess.SY).</title><link>https://huggingface.co/posts/branikita/234726599671172</link><description>Publishing our research on dual-motor backlash compensation for STS3215 servos. To complete our arXiv submission, we need a quick endorsement from someone who has published in robotics (cs.RO/eess.SY). If you can help, hereâ€™s the code: L64QM3 Thank you! See translation</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/234726599671172</guid></item><item><title>SceneWeaver â€” AI-Powered Background Generation &amp; Image Composition ğŸ¨âœ¨</title><link>https://huggingface.co/posts/DawnC/810522223628641</link><description>SceneWeaver â€” AI-Powered Background Generation &amp; Image Composition ğŸ¨âœ¨ Transform ordinary portraits into professional studio shots with just one click! What can SceneWeaver do? - ğŸ“¸ Upload any portrait photo and instantly generate stunning, professional-quality backgrounds - ğŸ­ Smart Subject Detection â€” Automatically identifies and extracts people, pets, or objects from your photos, even handling tricky cases like dark clothing and cartoon characters. - ğŸŒ„ Creative Scene Library â€” Choose from 24 professionally curated backgrounds spanning offices, nature landscapes, urban settings, artistic styles, and seasonal themes, or describe your own custom vision. - âš™ï¸ Professional Results â€” Delivers studio-quality compositions in seconds, saving hours of manual editing work while maintaining natural lighting and color harmony. What's next? ğŸ¬ Enhanced context-aware generation ğŸ¨ Batch processing for multiple style variations ğŸ”§ Higher resolution output support ğŸŒ Accessible cloud deployment Current...</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/810522223628641</guid></item><item><title>NEW Model Alert:</title><link>https://huggingface.co/posts/unmodeled-tyler/762230736035210</link><description>NEW Model Alert: vanta-research/atom-olmo3-7b We are excited at VANTA Research to release our atom-olmo3-7b model using the brand new Olmo3 architecture from Allen AI. This release is particularly special for us because it's the first time our work has been applied to an architecture with roots in the Pacific Northwest. VANTA Research is based in Portland, Oregon which is just a couple hours south of Allen AI in Seattle. Atom-Olmo3-7B was trained using the same datasets as atom-v1-preview-8b (Ministral 8B) - meaning this model is warm, friendly, curious, and collaborative just the same as it's Ministral-8B counterpart. Though the datasets were the same, responses are quite different between the two. Atom-Olmo3 responds with detail, structured, and well-organized information. Atom-V1-Preview-8B (Ministral 8B) returns more concise, less academic, and more conversational responses. Both models are native in human-AI collaboration and exploratory learning - though they each present it...</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/762230736035210</guid></item><item><title>@Reubencf</title><link>https://huggingface.co/posts/mybbnae/820891401991666</link><description>@ Reubencf made an WebOS check it out MCP-1st-Birthday/Reuben_OS See translation</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mybbnae/820891401991666</guid></item><item><title>Couple months ago I fineâ€‘tuned Qwen3 Embeddings with LoRA on the LSPC dataset. This time I went the opposite way: a small, taskâ€‘specific 80M encoder with bidirectional attention, trained endâ€‘toâ€‘end. It outperforms the Qwen3 LoRA baseline on the same data (0.9315 macroâ€‘F1 vs 0.8360). Details and code:</title><link>https://huggingface.co/posts/aufklarer/147735626089995</link><description>Couple months ago I fineâ€‘tuned Qwen3 Embeddings with LoRA on the LSPC dataset. This time I went the opposite way: a small, taskâ€‘specific 80M encoder with bidirectional attention, trained endâ€‘toâ€‘end. It outperforms the Qwen3 LoRA baseline on the same data (0.9315 macroâ€‘F1 vs 0.8360). Details and code: https://blog.ivan.digital/beating-qwen3-lora-with-a-tiny-pytorch-encoder-on-the-large-scale-product-corpus-afe536de205f See translation</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aufklarer/147735626089995</guid></item><item><title>ğŸ—£ï¸ Introducing the Duality AI +  LunateAI Challenge- Geospatial Object Detection: Rural Buildings!</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/527488277094596</link><description>ğŸ—£ï¸ Introducing the Duality AI + LunateAI Challenge- Geospatial Object Detection: Rural Buildings! Train a model to detect difficult detection instances, such as a low number of pixels or weak feature responses, in rural aerial imagery, to win ğŸ†PRIZESğŸ† and ğŸ¤©RECOGNITIONğŸ¤©. Sign up here: https://www.kaggle.com/competitions/duality-ai-lunate-ai-geospatial-object-detection/overview This is the first competition in the ğŸŒGeospatial Kaggle Challenge SeriesğŸŒ, which will explore how geospatial-based digital twins can train an AI model for real-world applications. Duality is excited to be partnering with LunateAI, a high-end advisory business founded by the award-winning, industry-recognized global leader Dr. Nadine Alameh to usher in a new era of geospatial impact in conjunction with advances in computing and AI. Lunate helps government and industry leaders ğŸ¤” rethink, ğŸ’¡redesign, and ğŸ“ execute transformative geospatial strategies using AI, cloud, and Lunateâ€™s unparalleled global expertise. Read...</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/527488277094596</guid></item><item><title>Applying Hazard and Entropy Analysis to LLMs</title><link>https://huggingface.co/posts/mike-ravkine/606116479128907</link><description>Applying Hazard and Entropy Analysis to LLMs Here's an example of a model that behaves perfectly well up to 8k, smoothly increasing its entropy before going into a struggle zone, collapsing, seeing a region of recovery and finally falling down hard at the 16k wall. Is your model implementation behaving badly like this? Would you know if it was? ğŸ‘€ See translation</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mike-ravkine/606116479128907</guid></item><item><title>Speed Painting  is transforming image â€œFloral Spirit: The Face of Natureâ€ into hand-written video. Please check the result.</title><link>https://huggingface.co/posts/wang12390/249978853611053</link><description>Speed Painting is transforming image â€œFloral Spirit: The Face of Natureâ€ into hand-written video. Please check the result. This is input image. This is output video. This is huggingface space: Miragic-AI/Miragic-Speed-Painting This is website. https://miragic.ai/products/speed-painting See translation</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wang12390/249978853611053</guid></item><item><title>No SOTA from gpt5 codex</title><link>https://huggingface.co/posts/onekq/122975793150084</link><description>No SOTA from gpt5 codex onekq-ai/WebApp1K-models-leaderboard See translation</description><pubDate>Sun, 23 Nov 2025 13:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/122975793150084</guid></item></channel></rss>