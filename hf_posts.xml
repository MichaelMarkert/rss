<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Agentic AI Era: Analyzing MCP vs MCO üöÄ</title><link>https://huggingface.co/posts/openfree/305569626054328</link><description>Agentic AI Era: Analyzing MCP vs MCO üöÄ Hello everyone! With the rapid advancement of AI agent technology, two architectures have come into the spotlight: MCP (Model Context Protocol) and MCO (Model Context Open-json). Today, we‚Äôll introduce the key features and differences of these two approaches. VIDraft/Agentic-AI-CHAT MCP: The Traditional Approach üèõÔ∏è Centralized Function Registry: All functions are hardcoded into the core system. Static Function Definitions &amp; Tight Coupling: New features require changes to the core application code, limiting scalability. Monolithic Design: Complex deployment and version management can cause a single error to affect the whole system. Code Example: '''py FUNCTION_REGISTRY = { "existing_function": existing_function, "new_function": new_function # Adding a new function } ''' MCO: A Revolutionary Approach üÜï JSON-based Function Definitions: Function details are stored in external JSON files, enabling dynamic module loading. Loose Coupling &amp;...</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/305569626054328</guid></item><item><title>üî• AgenticAI: The Ultimate Multimodal AI with 16 MBTI Girlfriend Personas! üî•</title><link>https://huggingface.co/posts/seawolf2357/796388354612946</link><description>üî• AgenticAI: The Ultimate Multimodal AI with 16 MBTI Girlfriend Personas! üî• Hello AI community! Today, our team is thrilled to introduce AgenticAI, an innovative open-source AI assistant that combines deep technical capabilities with uniquely personalized interaction. üíò üõ†Ô∏è MBTI 16 Types SPACES Collections link seawolf2357/heartsync-mbti-67f793d752ef1fa542e16560 ‚ú® 16 MBTI Girlfriend Personas Complete MBTI Implementation: All 16 MBTI female personas modeled after iconic characters (Dana Scully, Lara Croft, etc.) Persona Depth: Customize age groups and thinking patterns for hyper-personalized AI interactions Personality Consistency: Each MBTI type demonstrates consistent problem-solving approaches, conversation patterns, and emotional expressions üöÄ Cutting-Edge Multimodal Capabilities Integrated File Analysis: Deep analysis and cross-referencing of images, videos, CSV, PDF, and TXT files Advanced Image Understanding: Interprets complex diagrams, mathematical equations, charts, and...</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/796388354612946</guid></item><item><title>üá∑üá∫ Russian Forum Messages Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/381466531674007</link><description>üá∑üá∫ Russian Forum Messages Dataset - nyuuzyou/ruforum Collection of approximately 58 million Russian forum messages featuring: - Complete message content from Russian online forums spanning 2010-2025 - Comprehensive metadata including unique message IDs and timestamps - Full text content preserving original user discussions and interactions - Monolingual dataset focused exclusively on Russian language content This dataset offers a unique textual archive of Russian online conversations suitable for text generation, sentiment analysis, and language modeling research. Released to the public domain under CC0 1.0 license. See translation</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/381466531674007</guid></item><item><title>I have made a Rust project with integration of the latest state-of-the-art model for object detection, it outperforms YOLO!</title><link>https://huggingface.co/posts/Yehor/936075739202200</link><description>I have made a Rust project with integration of the latest state-of-the-art model for object detection, it outperforms YOLO! Check it out: https://github.com/egorsmkv/rf-detr-usls See translation</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Yehor/936075739202200</guid></item><item><title>16 new research on inference-time scaling:</title><link>https://huggingface.co/posts/Kseniase/504548986821494</link><description>16 new research on inference-time scaling: For the last couple of weeks a large amount of studies on inference-time scaling has emerged. And it's so cool, because each new paper adds a trick to the toolbox, making LLMs more capable without needing to scale parameter count of the models. So here are 13 new methods + 3 comprehensive studies on test-time scaling: 1. Inference-Time Scaling for Generalist Reward Modeling (2504.02495) Probably, the most popular study. It proposes to boost inference-time scalability by improving reward modeling. To enhance performance, DeepSeek-GRM uses adaptive critiques, parallel sampling, pointwise generative RM, and Self-Principled Critique Tuning (SPCT) 2. T1: Tool-integrated Self-verification for Test-time Compute Scaling in Small Language Models (2504.04718) Allows small models to use external tools, like code interpreters and calculator, to enhance self-verification 3. Z1: Efficient Test-time Scaling with Code (2504.00810) Proposes to train LLMs on...</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/504548986821494</guid></item><item><title>Shanghai AI Lab - OpenGV team just released InternVL3 üî•</title><link>https://huggingface.co/posts/AdinaY/929657833669065</link><description>Shanghai AI Lab - OpenGV team just released InternVL3 üî• OpenGVLab/internvl3-67f7f690be79c2fe9d74fe9d ‚ú® 1/2/8/9/14/38/28B with MIT license ‚ú® Stronger perception &amp; reasoning vs InternVL 2.5 ‚ú® Native Multimodal Pre-Training for even better language performance See translation</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/929657833669065</guid></item><item><title>Super grateful to</title><link>https://huggingface.co/posts/odellus/648294233512756</link><description>Super grateful to @ marriola for the release of the block diffusion code and model. I'm generating text with diffusion locally! Couldn't be more pleased. See translation</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/odellus/648294233512756</guid></item><item><title>PiFlash</title><link>https://huggingface.co/posts/S-Dreamer/228566884248971</link><description>PiFlash A simple web-based tool to flash Raspberry Pi OS images to your SD cards. No additional software required! S-Dreamer/piflash See translation</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/S-Dreamer/228566884248971</guid></item><item><title>Article:</title><link>https://huggingface.co/posts/JLouisBiz/528734483774826</link><description>Article: https://huggingface.co/blog/JLouisBiz/semantical-website-links You don't need to do the tedious work of finding all those links on your huge website. Automating semantic links on websites using Large Language Models (LLMs) enhances user experience and efficiency. Here's a simplified workflow: 1. Store LLM embeddings in PostgreSQL: Use the vector data type to store text embeddings generated by an LLM. 2. Divide page texts into chunks for processing. 3. Generate embeddings using an LLM for each chunk of text. 4. Create template markup around specific terms needing links. An automated program then: - Converts marked-up terms to their corresponding LLMs' embeddings, - Compares these with stored database embeddings (using cosine similarity), - Identifies the most relevant page based on highest similarity score, and - Automatically adds a link from the original content to this contextually related information. This process improves navigation by directing users to highly...</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JLouisBiz/528734483774826</guid></item><item><title>I'm looking for a YouTube video summarizer to run locally.  I did a search, but all of the models and spaces I was able to find here didn't work, which I find surprising, since it's a great tool I already use.  Perhaps one of you can provide a better option, or just tell me what this actually is to get it:</title><link>https://huggingface.co/posts/Fishtiks/595357291314987</link><description>I'm looking for a YouTube video summarizer to run locally. I did a search, but all of the models and spaces I was able to find here didn't work, which I find surprising, since it's a great tool I already use. Perhaps one of you can provide a better option, or just tell me what this actually is to get it: https://dev.gptcall.pages.dev/chat#id=&amp;contactName=Youtube+summarizer Other functionality I'd like to see is a genre-based music creation and alteration model. "Make it country" or "do a freestyle rap," as examples. I'm willing to work with someone on this, because I'd need help understanding. I'd also like to make medical AI, like Dr. Samantha, that functions like a PDR well, and doesn't get confused by drug names. See translation</description><pubDate>Mon, 14 Apr 2025 09:26:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Fishtiks/595357291314987</guid></item></channel></rss>