<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>AgentCPM-Exploreüî• on device agent foundation model released by OpenBMB</title><link>https://huggingface.co/posts/AdinaY/646030921039082</link><description>AgentCPM-Exploreüî• on device agent foundation model released by OpenBMB openbmb/AgentCPM-Explore ‚ú® 4B - Apache2.0 ‚ú® Supports 100+ multi-turn environment interactions with search + verification ‚ú® Full training/inference stack is openly shared as well See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/646030921039082</guid></item><item><title>LTX-2 Camera-Control LoRA demo with dolly-in/out and dolly-left/right is now available on Hugging Face, paired with ltx-2-19b-distilled-lora for fast inference. It also includes dynamic GPU duration adjustments for long video generations. Click the related Space links below.</title><link>https://huggingface.co/posts/prithivMLmods/771186692524026</link><description>LTX-2 Camera-Control LoRA demo with dolly-in/out and dolly-left/right is now available on Hugging Face, paired with ltx-2-19b-distilled-lora for fast inference. It also includes dynamic GPU duration adjustments for long video generations. Click the related Space links below. ü§óTry it now on : prithivMLmods/LTX-2-LoRAs-Camera-Control-Dolly ‚≠êGithub: https://github.com/PRITHIVSAKTHIUR/LTX-2-LoRAs-Camera-Control-Dolly üïπÔ∏èCollection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection To learn more, visit the app page or the respective model pages. See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/771186692524026</guid></item><item><title>New REPL environment in OpenEnv available! ‚ú®</title><link>https://huggingface.co/posts/sergiopaniego/454747936446679</link><description>New REPL environment in OpenEnv available! ‚ú® Used in the Recursive Language Models (RLM) paper by Alex Zhang. Ready for inference &amp; post-training using trajectories. Handles long contexts: &gt; Run Python code in a sandbox &gt; Make recursive calls to LMs &gt; Explore data programmatically &gt; Return final result Docs: https://meta-pytorch.org/OpenEnv/environments/repl/ Inference script: https://github.com/meta-pytorch/OpenEnv/blob/main/examples/repl_oolong_simple.py See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/454747936446679</guid></item><item><title>From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding upüöÄ</title><link>https://huggingface.co/posts/AdinaY/245167368794687</link><description>From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding upüöÄ Now BaichuanAI joins with Baichuan-M3 üè• an open medical LLM trained for clinical decision-making https://huggingface.co/collections/baichuan-inc/baichuan-m3 ‚ú® 235B - Apache2.0 ‚ú® Lower hallucinations via Fact-Aware RL ‚ú® Built for long medical chats See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/245167368794687</guid></item><item><title>Based on 2025 Chinese AI Timeline, here are some interesting takeaways:</title><link>https://huggingface.co/posts/AdinaY/528053481951824</link><description>Based on 2025 Chinese AI Timeline, here are some interesting takeaways: ‚ú® DeepSeek cadence: They shipped almost every month! (except Feb 2025) ‚ú® Qwen trajectory: Not a single ‚Äúhit‚Äù model, but an expanding product line. VL/Math/Coder/Reranker/Embedding/Omni/Next/Image ‚ú® Multimodal trend: Steadily rising share, shifting from generation to editing + tooling. ‚ú® Reasoning as a main track: more engineered, system-level reasoning. ‚ú® From foundation to components: growth in infra models (embeddings, rerankers, OCR, speech) signals a move toward deployable stacks. ‚ú® Ecosystem broadening: more players beyond the top labs. Follow for more updatesüëâ zh-ai-community See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/528053481951824</guid></item><item><title>Building powerful multilingual AI shouldn't mean sacrificing user privacy.</title><link>https://huggingface.co/posts/MikeDoes/151930847327570</link><description>Building powerful multilingual AI shouldn't mean sacrificing user privacy. We're highlighting a solution-oriented report from researchers Sahana Naganandh, Vaibhav V, and Thenmozhi M at Vellore Institute of Technology that investigates this exact challenge. The direct connection to our mission is clear: the paper showcases the PII43K dataset as a privacy-preserving alternative to high-risk, raw multilingual data The report notes that our dataset, with its structured anonymization, is a "useful option for privacy-centric AI applications." It's always a delight when academic research independently validates our data-first approach to solving real-world privacy problems. This is how we build a safer AI future together. üîó Read the full report here to learn more: https://assets.cureusjournals.com/artifacts/upload/technical_report/pdf/3689/20250724-59151-93w9ar.pdf üöÄ Stay updated on the latest in privacy-preserving AI‚Äîfollow us on LinkedIn:...</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/151930847327570</guid></item><item><title>Agentic AI doesn‚Äôt fail because it lacks intelligence ‚Äî it fails because it lacks context.</title><link>https://huggingface.co/posts/TravisMuhlestein/396736901039998</link><description>Agentic AI doesn‚Äôt fail because it lacks intelligence ‚Äî it fails because it lacks context. As agents become more autonomous, the real challenge shifts from generation to governance: understanding when, why, and under what constraints an agent should act. At GoDaddy, we‚Äôve been treating context as a first-class primitive for agentic systems ‚Äî combining identity, intent, permissions, and environment so agents can operate responsibly in production. Context is what turns automation into judgment. Without it, autonomy becomes risk. This post outlines how we‚Äôre thinking about the transition from task execution to context-aware agentic systems, and what that means for building AI that can be trusted at scale. üëâ How we build context for agentic AI: https://www.godaddy.com/resources/news/how-godaddy-builds-context-for-agentic-ai Curious how others here are modeling context, trust boundaries, and decision constraints in agentic architectures. See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/TravisMuhlestein/396736901039998</guid></item><item><title>‚úÖ New Article: Designing Semantic Memory (v0.1)</title><link>https://huggingface.co/posts/kanaria007/596222805860445</link><description>‚úÖ New Article: Designing Semantic Memory (v0.1) Title: üß† Designing Semantic Memory: SIM/SIS Patterns for Real Systems üîó https://huggingface.co/blog/kanaria007/designing-semantic-memory --- Summary: Semantic Compression is about *what meaning to keep*. This article is about *where that meaning lives*‚Äîand how to keep it *queryable, explainable, and governable* using two layers: * *SIM*: operational semantic memory (low-latency, recent, jump-loop-adjacent) * *SIS*: archival/analytic semantic store (long retention, heavy queries, audits) Core idea: store ‚Äúmeaning‚Äù as *typed semantic units* with scope, provenance, goal tags, retention, and *backing_refs* (URI/hash/ledger anchors) so you can answer *‚Äúwhy did we do X?‚Äù* without turning memory into a blob. --- Why It Matters: ‚Ä¢ Prevents ‚Äúsemantic junk drawer‚Äù memory: *units become contracts*, not vibes ‚Ä¢ Makes audits and incidents tractable: *reconstruct semantic context* (L3-grade) ‚Ä¢ Preserves reversibility/accountability with...</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/596222805860445</guid></item><item><title>why ACE-Step model isn't popular that much? imo it makes really good music.</title><link>https://huggingface.co/posts/efecelik/542033581015704</link><description>why ACE-Step model isn't popular that much? imo it makes really good music. ACE-Step/ACE-Step-v1-3.5B See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/efecelik/542033581015704</guid></item><item><title>I‚Äôm looking for AI engineers and researchers to join my company as part of the core team. We‚Äôll be working on cutting-edge research and hands-on implementation across LLMs and related systems. I‚Äôm especially interested in founding engineers for my ai startup, who want to build from the ground up and shape both the product and the research direction. If this sounds interesting to you, reply to this post and message me on Discord ‚Äî my username is "ujjwal_tyagi.shirova", Please also attach your Resume and Details of your open source projects (if any related to LLMs) on discord, avoid sharing here as a reply to this post.</title><link>https://huggingface.co/posts/Ujjwal-Tyagi/141864984025794</link><description>I‚Äôm looking for AI engineers and researchers to join my company as part of the core team. We‚Äôll be working on cutting-edge research and hands-on implementation across LLMs and related systems. I‚Äôm especially interested in founding engineers for my ai startup, who want to build from the ground up and shape both the product and the research direction. If this sounds interesting to you, reply to this post and message me on Discord ‚Äî my username is "ujjwal_tyagi.shirova", Please also attach your Resume and Details of your open source projects (if any related to LLMs) on discord, avoid sharing here as a reply to this post. See translation</description><pubDate>Wed, 14 Jan 2026 09:34:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Ujjwal-Tyagi/141864984025794</guid></item></channel></rss>