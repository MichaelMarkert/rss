<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Qwen Image Edit Full Tutorial: 26 Different Demo Cases, Prompts &amp; Images, Pwns FLUX Kontext Dev</title><link>https://huggingface.co/posts/MonsterMMORPG/783922297746182</link><description>Qwen Image Edit Full Tutorial: 26 Different Demo Cases, Prompts &amp; Images, Pwns FLUX Kontext Dev Tutorial Link https://youtu.be/gLCMhbsICEQ Extra Info I tested newly arrived Qwen-Image-Edit-Lightning-8steps-V1.0 (arrived after tutorial recorded) and definitely our existing preset which uses Qwen-Image-Lightning-8steps-V1.1 is better than it, so this tutorial and presets are still 100% best quality and up-to-date Info Qwen Image Edit just has been published and since then I have been experimenting to prepare you this amazing tutorial. I have literally shown 26 unique cases and provided demo images and prompts. After watching this tutorial your image editing skills will move to next level i promise you that. Also this tutorial will give you a lot of ideas. See translation</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/783922297746182</guid></item><item><title>Okay this is insane... WebGPU-accelerated semantic video tracking, powered by DINOv3 and Transformers.js! ü§Ø</title><link>https://huggingface.co/posts/Xenova/448209562329557</link><description>Okay this is insane... WebGPU-accelerated semantic video tracking, powered by DINOv3 and Transformers.js! ü§Ø Demo (+ source code): webml-community/DINOv3-video-tracking This will revolutionize AI-powered video editors... which can now run 100% locally in your browser, no server inference required (costs $0)! üòç How does it work? ü§î 1Ô∏è‚É£ Generate and cache image features for each frame 2Ô∏è‚É£ Create a list of embeddings for selected patch(es) 3Ô∏è‚É£ Compute cosine similarity between each patch and the selected patch(es) 4Ô∏è‚É£ Highlight those whose score is above some threshold ... et voil√†! ü•≥ You can also make selections across frames to improve temporal consistency! This is super useful if the object changes its appearance slightly throughout the video. Excited to see what the community builds with it! See translation</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Xenova/448209562329557</guid></item><item><title>‚úÖ New Article: *Relationships as Structured Reciprocity*</title><link>https://huggingface.co/posts/kanaria007/706135056688184</link><description>‚úÖ New Article: *Relationships as Structured Reciprocity* Title: ü§ù Relationships: Ethics as Cross-Construct Jump Series üîó https://huggingface.co/blog/kanaria007/structured-relationships --- Summary: Relationships are often framed as *emotion and chance*. Structured Intelligence reframes them as *reciprocal cognitive architectures*: * Trust and love as *reinforced feedback loops* * Conflict as *constraint misalignment and jump failure* * Growth as *loop stabilization through reflection and repair* &gt; Human connection isn‚Äôt mystery ‚Äî &gt; *it‚Äôs structure that learns to align across minds.* --- Why It Matters: ‚Ä¢ Reveals *how trust, betrayal, and repair follow structural patterns* ‚Ä¢ Bridges *psychology, sociology, and cognitive modeling* ‚Ä¢ Enables *AI that supports human connection without mimicry* --- What‚Äôs Inside: ‚Ä¢ Relationships as *multi‚Äëagent jump and memory loops* ‚Ä¢ *Attachment and reciprocity* as structural alignment ‚Ä¢ *Conflict resolution* as rollback and loop repair ‚Ä¢ Implications...</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/706135056688184</guid></item><item><title>Just applied for HF Community Grant for ‚ÄúHugging Research‚Äù ‚Äî  a lightweight CodeAgent‚Äëbased research assistant built on Hugging Face‚Äôs Open Deep Research project for the Hugging Face Hub (models, datasets, Spaces, users, collections, papers). It gathers links via dedicated tools and organizes them for easy review.</title><link>https://huggingface.co/posts/daqc/944546045325401</link><description>Just applied for HF Community Grant for ‚ÄúHugging Research‚Äù ‚Äî a lightweight CodeAgent‚Äëbased research assistant built on Hugging Face‚Äôs Open Deep Research project for the Hugging Face Hub (models, datasets, Spaces, users, collections, papers). It gathers links via dedicated tools and organizes them for easy review. As this is for the community, comments and suggestions are appreciated: daqc/hugging-research#1 See translation</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/daqc/944546045325401</guid></item><item><title>Run DeepSeek-V3.1 locally on 170GB RAM with Dynamic 1-bit GGUFs!üêã</title><link>https://huggingface.co/posts/danielhanchen/385540082056286</link><description>Run DeepSeek-V3.1 locally on 170GB RAM with Dynamic 1-bit GGUFs!üêã GGUFs: unsloth/DeepSeek-V3.1-GGUF The 715GB model gets reduced to 170GB (-80% size) by smartly quantizing layers. The 1-bit GGUF passes all our code tests &amp; we fixed the chat template for llama.cpp supported backends. Guide: https://docs.unsloth.ai/basics/deepseek-v3.1 See translation</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/385540082056286</guid></item><item><title>ü§ñ Global AI News Stream - 100% Unmanned AI News Automation Platform</title><link>https://huggingface.co/posts/openfree/336669979956450</link><description>ü§ñ Global AI News Stream - 100% Unmanned AI News Automation Platform üöÄ Fully Automated News Generation with Just One Keyword! Link: openfree/News-AI üéØ Incredibly Simple: Just Enter a Keyword or URL! ‚ú® One Input, Complete Automation! ‚ú® Simply enter one keyword or one URL, and the system springs into action! üöÄ From web crawling to AI analysis, article writing, image generation, and auto-publishing - everything happens automatically. Examples: üí¨ Type "GPT-5" ‚Üí Instant GPT-5 news article generation! üîó Paste "https://openai.com/blog/..." ‚Üí Auto-extracts keywords from URL and creates related articles! üéØ Enter "Tesla Bot" ‚Üí Latest Tesla Bot developments instantly generated! üíé Key Features - One Input, Everything Done! üîç Smart Keyword/URL Processing Just type a keyword or paste any website URL! The system automatically extracts core keywords and gathers all relevant information to generate complete news articles. For URLs, it intelligently parses keywords from domains and paths. üï∑Ô∏è Instant...</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/336669979956450</guid></item><item><title>If</title><link>https://huggingface.co/posts/ProCreations/306123757721653</link><description>If @ clem comments on this post within the week with a task for me to classify with text and a paramater size for the model, within 48 hours I will create a new dataset, train the model, and post it all. Paramater size must be bellow 50 million params, and task can be text only, and genuinely possible. if I complete it, Clem must tell everyone on Twitter/x to follow me on huggingface and link it let's see if he comments See translation</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ProCreations/306123757721653</guid></item><item><title>Was going to post this on /r/LocalLLaMa, but apparently it's without moderation at this time :')</title><link>https://huggingface.co/posts/bartowski/460622149989234</link><description>Was going to post this on /r/LocalLLaMa, but apparently it's without moderation at this time :') bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF Was able to use previous mistral chat templates, some hints from Qwen templates, and Claude to piece together a seemingly working chat template, tested it with llama.cpp server and got perfect results, though lmstudio still seems to be struggling for some reason (don't know how to specify a jinja file there) Outlined the details of the script and results in my llama.cpp PR to add the jinja template: https://github.com/ggml-org/llama.cpp/pull/14349 Start server with a command like this: ./llama-server -m /models/mistralai_Mistral-Small -3 .2 -24 B-Instruct -2506 -Q4_K_M.gguf --jinja --chat-template-file /models/Mistral-Small -3 .2 -24 B-Instruct -2506 .jinja and it should be perfect! Hoping it'll work for ALL tools if lmstudio gets an update or something, not just llama.cpp, but very happy to see it works flawlessly in llama.cpp...</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/bartowski/460622149989234</guid></item><item><title>What can you do with the VyvoTTS library?</title><link>https://huggingface.co/posts/kadirnar/744212073989909</link><description>What can you do with the VyvoTTS library? - You can train a model in a language it has never been trained in using the PT model. There‚Äôs no need for large datasets. - With the PT model, you can easily replicate the voice of any character you want. Just 1k samples are enough. - You can add emotion support with a small dataset. Github: https://github.com/Vyvo-Labs/VyvoTTS HuggingFace: Vyvo See translation</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kadirnar/744212073989909</guid></item><item><title>Dropping new adapters for Qwen-Image, including Qwen-Image-Studio-Realism, Qwen-Image-Anime-LoRA, Qwen-Image-Sketch-Smudge, Qwen-Image-Synthetic-Face, and Qwen-Image-Fragmented-Portraiture, with various style intermix compatibilities. For more details, visit the model card.</title><link>https://huggingface.co/posts/prithivMLmods/781883261064358</link><description>Dropping new adapters for Qwen-Image, including Qwen-Image-Studio-Realism, Qwen-Image-Anime-LoRA, Qwen-Image-Sketch-Smudge, Qwen-Image-Synthetic-Face, and Qwen-Image-Fragmented-Portraiture, with various style intermix compatibilities. For more details, visit the model card. ‚§∑ Studio Realism : prithivMLmods/Qwen-Image-Studio-Realism ‚§∑ Image Anime LoRA : prithivMLmods/Qwen-Image-Anime-LoRA ‚§∑ Sketch Smudge : prithivMLmods/Qwen-Image-Sketch-Smudge ‚§∑ Synthetic Face : prithivMLmods/Qwen-Image-Synthetic-Face ‚§∑ Fragmented Portraiture : prithivMLmods/Qwen-Image-Fragmented-Portraiture Try it here at ‚ú¶Ô∏é Qwen-Image-LoRA-DLC : prithivMLmods/Qwen-Image-LoRA-DLC ‚ú¶Ô∏é Qwen-Image-Diffusion : prithivMLmods/Qwen-Image-Diffusion Collection ‚ú¶Ô∏é Qwen-Image-Exp-LoRA : prithivMLmods/qwen-image-exp-lora-68a978fe11400bc3165b0c4d ‚ú¶Ô∏é Image Gen Apps (Diffusion) - LastUpdated 08/18 : prithivMLmods/image-gen-apps-diffusion-lastupdated-08-18-68a2f4c5ef3e5e394eacc20a . . . To know more, visit the following spaces,...</description><pubDate>Tue, 26 Aug 2025 05:23:41 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/781883261064358</guid></item></channel></rss>