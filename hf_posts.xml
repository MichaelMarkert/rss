<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Whisper-WebUI Premium - Ultra Fast and High Accuracy Speech to Text Transcripton App for All Languages - Windows, RunPod, Massed Compute 1-Click Installers - Supporting RTX 1000 to 5000 series</title><link>https://huggingface.co/posts/MonsterMMORPG/232609167066612</link><description>Whisper-WebUI Premium - Ultra Fast and High Accuracy Speech to Text Transcripton App for All Languages - Windows, RunPod, Massed Compute 1-Click Installers - Supporting RTX 1000 to 5000 series Latest installer zip file : https://www.patreon.com/posts/145395299 New Features Password protected version, password is just 1 : WhisperWeb_UI_v1_password_is_1.zip It has better interface, more features, default settings set for maximum accuracy It will show transcription realtime both on Gradio interface and also on CMD It will show better status and output at the cmd like starting time, starting file, etc It will save every generated transcription properly with same name as input file name with proper name sanitization After deep scan of the entire pipeline, default parameters are set for maximum accuracy and quality 1-Click installers for Windows local PC, RunPod (Linux-Cloud) and Massed Compute (Linux-Cloud) The app the installers are made for RTX 1000 series to RTX 5000 series with pre-...</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/232609167066612</guid></item><item><title>15 Outstanding Research Papers from NeurIPS 2025</title><link>https://huggingface.co/posts/Kseniase/673116238988658</link><description>15 Outstanding Research Papers from NeurIPS 2025 NeurIPS 2025, as a premier annual event in machine learning and computational neuroscience, tackles major topics like the future of AI, current research, and the most difficult challenges. While we‚Äôre not attending this year, we‚Äôre closely following the updates and today we pull together a quick, easy-to-digest roundup of a few standout papers so you can jump in without getting overwhelmed. Here is a list of 15 papers from NeurIPS 2025, including 8 top research papers that received awards, along with 7 others that caught our attention: 1. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks ‚Üí https://neurips.cc/virtual/2025/loc/san-diego/test-of-time/128328 Test of Time Award winner. Introduces the RPN, a small convnet that predicts objectness and boxes on shared features, enabling Faster R-CNN to share computation and run around 5 fps on a GPU 2. Artificial Hivemind: The Open-Ended Homogeneity of LMs (and...</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/673116238988658</guid></item><item><title>Two new releases today!</title><link>https://huggingface.co/posts/sequelbox/418257138244612</link><description>Two new releases today! Firstly, our new Raiden-Mini dataset, powered by DeepSeek's newest deepseek-ai/DeepSeek-V3.2-Speciale model! - A V3.2-Speciale reasoning showcase: the Raiden prompts test the model's creative, analytic, and general reasoning skills! - HEAD TO HEAD: a comparison subset pits V3.2-Speciale against V3.2 with the same prompts, providing a direct look at each model's advantages! Get the new Raiden-Mini dataset: sequelbox/Raiden-Mini-DeepSeek-V3.2-Speciale On the model side, we've also brought Shining Valiant 3 to Ministral 3! - Science-reasoning: sequelbox/Celestia3-DeepSeek-R1-0528 for physics, biology, chemistry, compsci, astronomy, Earth science, and information theory. - AI to build AI: the sequelbox/Mitakihara-DeepSeek-R1-0528 dataset for high-quality reasoning performance on AI, MLOps, math and CUDA, complex adaptive and agentic systems, cognition, logic, linguistics, simulation, knowledge management, and more! - Creative reasoning and general chat...</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sequelbox/418257138244612</guid></item><item><title>NEW:</title><link>https://huggingface.co/posts/sergiopaniego/936636401476551</link><description>NEW: @ EssentialAI just released Rnj-1, their first 8B model. You can easily fine-tune it with GRPO using TRL to add reasoning capabilities to a compact mode Free Colab link: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_rnj_1_instruct.ipynb More free TRL notebooks: https://huggingface.co/docs/trl/main/en/example_overview#notebooks See translation</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/936636401476551</guid></item><item><title>Currently having a blast learning the transformers library.</title><link>https://huggingface.co/posts/melvindave/358781763788308</link><description>Currently having a blast learning the transformers library. I noticed that model cards usually have Transformers code as usage examples. So I tried to figure out how to load a model just using the transformers library without using ollama, lmstudio, or llamacpp. Learned how to install dependencies required to make it work like pytorch and CUDA. I also used Conda for python environment dependencies. Once I got the model loaded and sample inference working, I made an API to serve it. I know it's very basic stuff for machine learning experts here in HF but I'm completely new to this so I'm happy to get it working! Model used: Qwen/Qwen3-VL-8B-Instruct GPU: NVIDIA GeForce RTX 3090 Here's the result of my experimentation See translation</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/melvindave/358781763788308</guid></item><item><title>ScalingOpt is continuously evolving! We are steadily expanding the Community section with new content. For our Blog, we've launched by featuring work from Jianlin Su and are actively translating insightful posts from scientific communities into English to share on ScalingOpt (we'll keep curating excellent community blogs and providing English versions alongside the originals).</title><link>https://huggingface.co/posts/Juanxi/495581503787018</link><description>ScalingOpt is continuously evolving! We are steadily expanding the Community section with new content. For our Blog, we've launched by featuring work from Jianlin Su and are actively translating insightful posts from scientific communities into English to share on ScalingOpt (we'll keep curating excellent community blogs and providing English versions alongside the originals). We operate under the Creative Commons Attribution-NonCommercial principle, sharing knowledge freely and openly. We welcome your ideas, suggestions, and feedback to help shape ScalingOpt's future. If you find this initiative valuable, please consider following and starring the project to show your support. Thank you! See translation</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Juanxi/495581503787018</guid></item><item><title>Introducing the D.Markdown Experimental Models, Proxima and Epsilon OCR models, built on top of Qwen3-VL and Qwen2.5-VL respectively. Proxima is optimized for Markdown generation and is capable of embedding inline programming code snippets and generating rich nodes such as HTML, XML, JSON, and YAML. Epsilon is optimized for reconstructing complex layouts including tables, forms, and mathematical content. üåå‚ú®</title><link>https://huggingface.co/posts/prithivMLmods/177760462404074</link><description>Introducing the D.Markdown Experimental Models, Proxima and Epsilon OCR models, built on top of Qwen3-VL and Qwen2.5-VL respectively. Proxima is optimized for Markdown generation and is capable of embedding inline programming code snippets and generating rich nodes such as HTML, XML, JSON, and YAML. Epsilon is optimized for reconstructing complex layouts including tables, forms, and mathematical content. üåå‚ú® ‚óè proxima-ocr-d.markdown-post3.0.l: prithivMLmods/proxima-ocr-d.markdown-post3.0.l ‚óè epsilon-ocr-d.markdown-post3.0.m: prithivMLmods/epsilon-ocr-d.markdown-post3.0.m ‚óè proxima-ocr-d.markdown-post3.0.l-gguf: prithivMLmods/proxima-ocr-d.markdown-post3.0.l-GGUF ‚óè epsilon-ocr-d.markdown-post3.0.m-gguf: prithivMLmods/epsilon-ocr-d.markdown-post3.0.m-GGUF ‚óè Collection: https://huggingface.co/collections/prithivMLmods/dynamic-markdowns ‚óè Multimodal Apps: https://huggingface.co/collections/prithivMLmods/multimodal-implementations üëâ These models are stage progression models, and currently...</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/177760462404074</guid></item><item><title>Recently, Essential AI released a new 8B base model</title><link>https://huggingface.co/posts/codelion/196218932923903</link><description>Recently, Essential AI released a new 8B base model EssentialAI/rnj-1 they highlighted the importance of data mix for pretraning - "In the long run, we expect our methods to automatically represent, transform, and blend data to optimize measurable abilities in pre-training. Our work on modeling data taxonomies led to new approaches for jointly clustering and mixing data distributions under data repetition penalties. Many improvements in our STEM abilities can be traced back to this. " This resonates with the recent work we did around optimal dataset mixing for pretraining where we saw have the right mix can increase the efficiency of training - https://huggingface.co/blog/codelion/optimal-dataset-mixing See translation</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/196218932923903</guid></item><item><title>Don't forget to checkout our latest amazing training tutorial</title><link>https://huggingface.co/posts/MonsterMMORPG/781719759837719</link><description>Don't forget to checkout our latest amazing training tutorial Z-Image Turbo LoRA training with AI Toolkit and Z-Image ControlNet Full Tutorial for Highest Quality https://youtu.be/ezD6QO14kRc See translation</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/781719759837719</guid></item><item><title>Want to get started with fine-tuning but don‚Äôt know where to begin? ü§ì‚òùÔ∏è</title><link>https://huggingface.co/posts/sergiopaniego/364808323176425</link><description>Want to get started with fine-tuning but don‚Äôt know where to begin? ü§ì‚òùÔ∏è We‚Äôre expanding our collection of beginner-friendly free Colab notebooks so you can learn and fine-tune models using TRL at no cost üî¨ Check out the full list of free notebooks: https://huggingface.co/docs/trl/main/en/example_overview#notebooks üî¨ If you want more advanced content, we also have a lot to cover in the community tutorials: https://huggingface.co/docs/trl/community_tutorials And now the obvious question: what would you like us to add next? See translation</description><pubDate>Wed, 10 Dec 2025 05:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/364808323176425</guid></item></channel></rss>