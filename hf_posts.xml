<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Agentic AI Era: Analyzing MCP vs MCO üöÄ</title><link>https://huggingface.co/posts/openfree/305569626054328</link><description>Agentic AI Era: Analyzing MCP vs MCO üöÄ Hello everyone! With the rapid advancement of AI agent technology, two architectures have come into the spotlight: MCP (Model Context Protocol) and MCO (Model Context Open-json). Today, we‚Äôll introduce the key features and differences of these two approaches. VIDraft/Agentic-AI-CHAT MCP: The Traditional Approach üèõÔ∏è Centralized Function Registry: All functions are hardcoded into the core system. Static Function Definitions &amp; Tight Coupling: New features require changes to the core application code, limiting scalability. Monolithic Design: Complex deployment and version management can cause a single error to affect the whole system. Code Example: '''py FUNCTION_REGISTRY = { "existing_function": existing_function, "new_function": new_function # Adding a new function } ''' MCO: A Revolutionary Approach üÜï JSON-based Function Definitions: Function details are stored in external JSON files, enabling dynamic module loading. Loose Coupling &amp;...</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/305569626054328</guid></item><item><title>üá∑üá∫ Russian Forum Messages Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/381466531674007</link><description>üá∑üá∫ Russian Forum Messages Dataset - nyuuzyou/ruforum Collection of approximately 58 million Russian forum messages featuring: - Complete message content from Russian online forums spanning 2010-2025 - Comprehensive metadata including unique message IDs and timestamps - Full text content preserving original user discussions and interactions - Monolingual dataset focused exclusively on Russian language content This dataset offers a unique textual archive of Russian online conversations suitable for text generation, sentiment analysis, and language modeling research. Released to the public domain under CC0 1.0 license. See translation</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/381466531674007</guid></item><item><title>If you've followed the progress of robotics in the past 18 months, you've likely noticed how robotics is increasingly becoming the next frontier that AI will unlock.</title><link>https://huggingface.co/posts/thomwolf/895902166332251</link><description>If you've followed the progress of robotics in the past 18 months, you've likely noticed how robotics is increasingly becoming the next frontier that AI will unlock. At Hugging Face‚Äîin robotics and across all AI fields‚Äîwe believe in a future where AI and robots are open-source, transparent, and affordable; community-built and safe; hackable and fun. We've had so much mutual understanding and passion working with the Pollen Robotics team over the past year that we decided to join forces! You can already find our open-source humanoid robot platform Reachy 2 on the Pollen website and the Pollen community and people here on the hub at pollen-robotics We're so excited to build and share more open-source robots with the world in the coming months! See translation</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/thomwolf/895902166332251</guid></item><item><title>16 new research on inference-time scaling:</title><link>https://huggingface.co/posts/Kseniase/504548986821494</link><description>16 new research on inference-time scaling: For the last couple of weeks a large amount of studies on inference-time scaling has emerged. And it's so cool, because each new paper adds a trick to the toolbox, making LLMs more capable without needing to scale parameter count of the models. So here are 13 new methods + 3 comprehensive studies on test-time scaling: 1. Inference-Time Scaling for Generalist Reward Modeling (2504.02495) Probably, the most popular study. It proposes to boost inference-time scalability by improving reward modeling. To enhance performance, DeepSeek-GRM uses adaptive critiques, parallel sampling, pointwise generative RM, and Self-Principled Critique Tuning (SPCT) 2. T1: Tool-integrated Self-verification for Test-time Compute Scaling in Small Language Models (2504.04718) Allows small models to use external tools, like code interpreters and calculator, to enhance self-verification 3. Z1: Efficient Test-time Scaling with Code (2504.00810) Proposes to train LLMs on...</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/504548986821494</guid></item><item><title>sooo many open AI releases past week, let's summarize! ü§ó</title><link>https://huggingface.co/posts/merve/599885414055130</link><description>sooo many open AI releases past week, let's summarize! ü§ó merve/april-11-releases-67fcd78be33d241c0977b9d2 multimodal &gt; Moonshot AI released Kimi VL Thinking, first working open-source multimodal reasoning model and Kimi VL Instruct, both 16B MoEs with 3B active params (OS) &gt; InternVL3 released based on Qwen2.5VL, 7 ckpts with various sizes (1B to 78B) LLMs &gt; NVIDIA released Llama-3_1-Nemotron-Ultra-253B-v1 an LLM built on Llama 405B for reasoning, chat and tool use &gt; Agentica released DeepCoder-14B-Preview, fine-tuned version of DeepSeek-R1-Distilled-Qwen-14B on problem-test pairs, along with the compiled dataset &gt; Zyphra/ZR1-1.5B is a new small reasoning LLM built on R1-Distill-1.5B (OS) &gt; Skywork-OR1-32B-Preview is a new reasoning model by Skywork Image Generation &gt; HiDream releases three new models, HiDream I1 Dev, I1 Full, and I1 fast for image generation (OS) *OS ones have Apache 2.0 or MIT licenses See translation</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/599885414055130</guid></item><item><title>We‚Äôre back‚Äîwith higher stakes, new datasets, and more chances to stand out. Duality AI's Synthetic-to-Real Object Detection Challenge 2 is LIVE!üö¶</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/356661920833488</link><description>We‚Äôre back‚Äîwith higher stakes, new datasets, and more chances to stand out. Duality AI's Synthetic-to-Real Object Detection Challenge 2 is LIVE!üö¶ ‚úç Sign up here: https://lnkd.in/g2avFP_X After the overwhelming response to Challenge 1, we're pushing the boundaries even further in Challenge 2, where your object detection models will be put to the test in the real world after training only on synthetic data. üëâ Join our Synthetic-to-Real Object Detection Challenge 2 on Kaggle! What‚Äôs Different This Time? Unlike our first challenge, we‚Äôre now diving deep into data manipulation. Competitors can: üîπAccess 4 new supplemental datasets via FalconCloud with varying lighting, occlusions, and camera angles. üîπGenerate your own synthetic datasets using FalconEditor to simulate edge cases. üîπMix, match, and build custom training pipelines for maximum mAP@50 performance This challenge isn‚Äôt just about using synthetic data‚Äîit‚Äôs about mastering how to craft the right synthetic data. Ready to test your...</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/356661920833488</guid></item><item><title>Access requests enabled for latest GLM models</title><link>https://huggingface.co/posts/bartowski/160920719239523</link><description>Access requests enabled for latest GLM models While a fix is being implemented ( https://github.com/ggml-org/llama.cpp/pull/12957 ) I want to leave the models up for visibility and continued discussion, but want to prevent accidental downloads of known broken models (even though there are settings that could fix it at runtime for now) With this goal, I've enabled access requests. I don't really want your data, so I'm sorry that I don't think there's a way around that? But that's what I'm gonna do for now, and I'll remove the gate when a fix is up and verified and I have a chance to re-convert and quantize! Hope you don't mind in the mean time :D See translation</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/bartowski/160920719239523</guid></item><item><title>üî• New reasoning models from the Chinese community, by Skywork Â§©Â∑•-ÊòÜ‰ªë‰∏áÁª¥</title><link>https://huggingface.co/posts/AdinaY/225696597302421</link><description>üî• New reasoning models from the Chinese community, by Skywork Â§©Â∑•-ÊòÜ‰ªë‰∏áÁª¥ Skywork/skywork-or1-67fa1bcb41b436ef2def76b9 ‚ú®Skywork OR1-Math-7B &gt; Optimized for math reasoning ‚ú®Skywork-OR1-7B-preview &gt; Excels in math &amp; coding ‚ú®Skywork-OR1-32B-preview &gt; Matches Deepseek-R1 on math (AIME24/25) and coding (LiveCodeBench) Released under the Apache 2.0 license ü•≥ Final version coming in 2 weeks! See translation</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/225696597302421</guid></item><item><title>Article:</title><link>https://huggingface.co/posts/JLouisBiz/528734483774826</link><description>Article: https://huggingface.co/blog/JLouisBiz/semantical-website-links You don't need to do the tedious work of finding all those links on your huge website. Automating semantic links on websites using Large Language Models (LLMs) enhances user experience and efficiency. Here's a simplified workflow: 1. Store LLM embeddings in PostgreSQL: Use the vector data type to store text embeddings generated by an LLM. 2. Divide page texts into chunks for processing. 3. Generate embeddings using an LLM for each chunk of text. 4. Create template markup around specific terms needing links. An automated program then: - Converts marked-up terms to their corresponding LLMs' embeddings, - Compares these with stored database embeddings (using cosine similarity), - Identifies the most relevant page based on highest similarity score, and - Automatically adds a link from the original content to this contextually related information. This process improves navigation by directing users to highly...</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JLouisBiz/528734483774826</guid></item><item><title>Mental Health Chatbot by Fine-Tuning Llama 4</title><link>https://huggingface.co/posts/ImranzamanML/867733824317401</link><description>Mental Health Chatbot by Fine-Tuning Llama 4 https://huggingface.co/blog/ImranzamanML/llama-4-fine-tuning-with-mental-health-counseling See translation</description><pubDate>Tue, 15 Apr 2025 17:19:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ImranzamanML/867733824317401</guid></item></channel></rss>