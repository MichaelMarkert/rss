<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ğŸ¤—ğŸ§ª</title><link>https://huggingface.co/posts/prithivMLmods/223082724733311</link><description>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ğŸ¤—ğŸ§ª â— Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC â— Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection â— Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo â— Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- â— FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 â— FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC â— Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC â— Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast â— Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/223082724733311</guid></item><item><title>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! ğŸ”¥</title><link>https://huggingface.co/posts/danielhanchen/963278821580490</link><description>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! ğŸ”¥ Has 1M context window &amp; best in class performance for SWE-Bench, reasoning &amp; chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF ğŸ’š Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/963278821580490</guid></item><item><title>Great News !</title><link>https://huggingface.co/posts/Reubencf/239576255947718</link><description>Great News ! Reubencf/Nano_Banana_Editor Now supports black-forest-labs/FLUX.1-Kontext-dev and Qwen/Qwen-Image-Edit-2509 Just log in with Huggingface and try it out See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reubencf/239576255947718</guid></item><item><title>New Preview Model:</title><link>https://huggingface.co/posts/unmodeled-tyler/439099944779481</link><description>New Preview Model: unmodeled-tyler/vanta-research-loux-preview VANTA Research is excited to announce a small lab preview of our new 675B fine tune, Loux-Large. Loux is an AI model with a sophisticated, rebellious edge designed to assist and collaborate with engineers, builders, and people working on technical projects. If you enjoy working with Loux and would like full access, let us know by liking the space or opening a discussion in the community! See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/439099944779481</guid></item><item><title>ğŸ¤¯ ğŸ¤¯ Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ğŸ¤¯ ğŸ¤¯</title><link>https://huggingface.co/posts/YatharthS/190514854652270</link><description>ğŸ¤¯ ğŸ¤¯ Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ğŸ¤¯ ğŸ¤¯ Github link: https://github.com/ysharma3501/MiraTTS Model link: https://github.com/ysharma3501/MiraTTS Blog explaining llm tts models: https://huggingface.co/blog/YatharthS/llm-tts-models See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/190514854652270</guid></item><item><title>Finch ğŸ’° an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance &amp; accounting work.</title><link>https://huggingface.co/posts/AdinaY/236108821864145</link><description>Finch ğŸ’° an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance &amp; accounting work. FinWorkBench/Finch âœ¨ Built from real enterprise data (Enron + financial institutions), not synthetic tasks âœ¨ Tests end-to-end finance workflows âœ¨ Multimodal &amp; cross-file reasoning âœ¨ Expert annotated (700+ hours) and genuinely challenging hard See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/236108821864145</guid></item><item><title>Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on.</title><link>https://huggingface.co/posts/ronantakizawa/412513789590360</link><description>Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on. #github #developers ronantakizawa/github-top-developers See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/412513789590360</guid></item><item><title>ğŸš¨ Phare LLM benchmark V2: Reasoning models don't guarantee better security</title><link>https://huggingface.co/posts/davidberenstein1957/505419805971375</link><description>ğŸš¨ Phare LLM benchmark V2: Reasoning models don't guarantee better security Read the full blog here: https://huggingface.co/blog/davidberenstein1957/phare-llm-benchmark-v2 See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/davidberenstein1957/505419805971375</guid></item><item><title>Intelligent Inpainting for Precise Creative Control ğŸ¨âœ¨</title><link>https://huggingface.co/posts/DawnC/393405474084583</link><description>Intelligent Inpainting for Precise Creative Control ğŸ¨âœ¨ Transform your images with AI-powered precision! SceneWeaver delivers professional-quality image composition with intelligent background replacement and advanced object manipulation. What's New in This Update? ğŸ–Œï¸ Object Replacement â€” Select and transform any element in your scene with natural language prompts while maintaining perfect visual consistency with surrounding content ğŸ—‘ï¸ Object Removal â€” Intelligently remove unwanted objects with context-aware generation that preserves natural lighting, shadows, and scene coherence ğŸ¯ Context-Aware Processing â€” Advanced inpainting technology ensures seamless integration across all regenerated regions Core Capabilities âš¡ One-click transformation with smart subject detection, 24 curated professional backgrounds, custom scene generation through text prompts, and studio-quality results powered by BiRefNet, Stable Diffusion XL, and ControlNet Inpainting. Current Infrastructure &amp; Future...</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/393405474084583</guid></item><item><title>ğŸ“¢ For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios.</title><link>https://huggingface.co/posts/nicolay-r/350400879019559</link><description>ğŸ“¢ For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios. ğŸŒŸ bulk-chain: https://github.com/nicolay-r/bulk-chain ğŸ”‘ This features the no-string framework for quierrying LLMs in various modes: sync, async and with optional support for output streaming. ğŸ“¦ï¸ In the latest 1.2.0 release, the updates on outlining API parameters for inference mode. ğŸŒŸ Integration into web: https://github.com/nicolay-r/bulk-chain-web-integration See translation</description><pubDate>Thu, 18 Dec 2025 09:32:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/350400879019559</guid></item></channel></rss>