<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>first vision language model built off</title><link>https://huggingface.co/posts/merve/292180054306518</link><description>first vision language model built off openai/gpt-oss-20b just dropped! ğŸ”¥ InternVL3.5 comes with 32 models ğŸ¤¯ pre-trained, fine-tuned, aligned in various sizes OpenGVLab/internvl35-68ac87bd52ebe953485927fb comes with gpt-oss or Qwen3 for LLM part â¤µï¸ See translation</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/292180054306518</guid></item><item><title>MiniCPM-V 4.5 ğŸš€ New MLLM for image, multi-image &amp; video understanding, running even on your phone, released by OpenBMB</title><link>https://huggingface.co/posts/AdinaY/473496396970919</link><description>MiniCPM-V 4.5 ğŸš€ New MLLM for image, multi-image &amp; video understanding, running even on your phone, released by OpenBMB openbmb/MiniCPM-V-4_5 âœ¨ SOTA vision language capability âœ¨ 96Ã— video token compression &gt; high-FPS &amp; long video reasoning âœ¨ Switchable fast vs deep thinking modes âœ¨ Strong OCR, document parsing, supports 30+ languages See translation</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/473496396970919</guid></item><item><title>I recently added a recipe in ellora to improve reasoning capabilities to Gemma-3-1B using self-supervised learning. Model now shows step-by-step thinking in &lt;think&gt; tags before answering.</title><link>https://huggingface.co/posts/codelion/968650774475150</link><description>I recently added a recipe in ellora to improve reasoning capabilities to Gemma-3-1B using self-supervised learning. Model now shows step-by-step thinking in &lt;think&gt; tags before answering. Logic puzzle accuracy: 61% â†’ 84%. 3 hours training on single GPU. ğŸ§  Used GRPO where model generates multiple responses and learns to prefer better reasoning. Works surprisingly well for making smaller models more transparent. ğŸ”— Colab: https://colab.research.google.com/github/codelion/ellora/blob/main/Ellora_Recipe_2_Reasoning_LoRA_with_Self-Rewarding_GRPO.ipynb ğŸ¤— Model: codelion/gemma-3-1b-it-reasoning-grpo-lora ğŸ’» Code: https://github.com/codelion/ellora See translation</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/968650774475150</guid></item><item><title>ğŸ‰ Fashion Fit 360: The New Standard in AI Virtual Try-On!</title><link>https://huggingface.co/posts/ginipick/809439997973106</link><description>ğŸ‰ Fashion Fit 360: The New Standard in AI Virtual Try-On! ğŸš€ Now Live and Free to Use!Say goodbye to online shopping uncertainty - "Will this look good on me?" - with our revolutionary solution!Fashion Fit 360 is a cutting-edge AI-powered virtual fitting service that transforms your fashion shopping experience. LINK: ginigen/Fashion-Fit360 âœ¨ Core Features ğŸ”„ 360-Degree Multi-Pose Generation Transform a single front-facing photo into 6 different viewing angles! Front, side, and back views for complete visualization Experience a real fitting room mirror effect Check fit and style from every perspective ğŸ‘— 15 Fashion Item Categories Apparel: Tops, bottoms, dresses Jewelry: Necklaces, earrings, rings, bracelets Accessories: Sunglasses, eyewear, hats, ties, bow ties, belts Essentials: Bags, shoes ğŸ¯ Perfect For: ğŸ›ï¸ Online Shopping Enthusiasts: Preview before purchase - zero return hassles! ğŸ’ Jewelry Lovers: Virtually try expensive pieces before investing ğŸ Thoughtful Gift-Givers: Test items...</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/809439997973106</guid></item><item><title>ğŸ”’ Ansim Blur: Privacy-First Face Blurring for the AI Era</title><link>https://huggingface.co/posts/openfree/464899901167090</link><description>ğŸ”’ Ansim Blur: Privacy-First Face Blurring for the AI Era ğŸš¨ The Privacy Crisis is Now Smart CCTVs ğŸ“¹, delivery robots ğŸ¤–, and autonomous vehicles ğŸš— are everywhere. Your face is being captured, transmitted, and stored without your knowledge or consent. openfree/Face-blurring The privacy threat is real: 24/7 surveillance cameras recording your every move Companies harvesting facial biometric data at scale Your face becoming a commodity without your permission ğŸ’¡ The Solution: Ansim Blur Real-time face anonymization powered by YOLOv8 ğŸ¯ âœ… Process images, videos, and live streams âœ… Automatic GPU/CPU detection for universal deployment âœ… Choose between Gaussian blur or mosaic pixelation âœ… Fine-tune detection sensitivity for your needs âœ… Preserve audio tracks in video processing ğŸ›¡ï¸ Real-World Applications Enterprise Use Cases Privacy compliance for robotics and drone footage CCTV feed anonymization for regulatory requirements Customer data protection in retail analytics Personal Protection...</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/464899901167090</guid></item><item><title>OpenGVLab's InternVL3_5-2B-MPO [Mixed Preference Optimization (MPO)] is a compact vision-language model in the InternVL3.5 series. You can now experience it in the Tiny VLMs Lab, an app featuring 15+ multimodal VLMs ranging from 250M to 4B parameters. These models support tasks such as OCR, reasoning, single-shot answering with small models, and captioning (including ablated variants), across a broad range of visual categories. They are also capable of handling images with complex, sensitive, or nuanced content, while adapting to varying aspect ratios and resolutions.</title><link>https://huggingface.co/posts/prithivMLmods/835910169748717</link><description>OpenGVLab's InternVL3_5-2B-MPO [Mixed Preference Optimization (MPO)] is a compact vision-language model in the InternVL3.5 series. You can now experience it in the Tiny VLMs Lab, an app featuring 15+ multimodal VLMs ranging from 250M to 4B parameters. These models support tasks such as OCR, reasoning, single-shot answering with small models, and captioning (including ablated variants), across a broad range of visual categories. They are also capable of handling images with complex, sensitive, or nuanced content, while adapting to varying aspect ratios and resolutions. âœ¨ Space/App : prithivMLmods/Tiny-VLMs-Lab ğŸ«™ Model : OpenGVLab/InternVL3_5-2B-MPO â†—ï¸ Collection: OpenGVLab/internvl35-68ac87bd52ebe953485927fb ğŸ—ï¸ Paper : https://arxiv.org/pdf/2508.18265 â†—ï¸ Multimodal Space Collection : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 To learn more, visit the relevant spaces, collections, and model cards. See translation</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/835910169748717</guid></item><item><title>ğŸ¤– Global AI News Stream - 100% Unmanned AI News Automation Platform</title><link>https://huggingface.co/posts/openfree/336669979956450</link><description>ğŸ¤– Global AI News Stream - 100% Unmanned AI News Automation Platform ğŸš€ Fully Automated News Generation with Just One Keyword! Link: openfree/News-AI ğŸ¯ Incredibly Simple: Just Enter a Keyword or URL! âœ¨ One Input, Complete Automation! âœ¨ Simply enter one keyword or one URL, and the system springs into action! ğŸš€ From web crawling to AI analysis, article writing, image generation, and auto-publishing - everything happens automatically. Examples: ğŸ’¬ Type "GPT-5" â†’ Instant GPT-5 news article generation! ğŸ”— Paste "https://openai.com/blog/..." â†’ Auto-extracts keywords from URL and creates related articles! ğŸ¯ Enter "Tesla Bot" â†’ Latest Tesla Bot developments instantly generated! ğŸ’ Key Features - One Input, Everything Done! ğŸ” Smart Keyword/URL Processing Just type a keyword or paste any website URL! The system automatically extracts core keywords and gathers all relevant information to generate complete news articles. For URLs, it intelligently parses keywords from domains and paths. ğŸ•·ï¸ Instant...</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/336669979956450</guid></item><item><title>âœ… New Article: *Relationships as Structured Reciprocity*</title><link>https://huggingface.co/posts/kanaria007/706135056688184</link><description>âœ… New Article: *Relationships as Structured Reciprocity* Title: ğŸ¤ Relationships: Ethics as Cross-Construct Jump Series ğŸ”— https://huggingface.co/blog/kanaria007/structured-relationships --- Summary: Relationships are often framed as *emotion and chance*. Structured Intelligence reframes them as *reciprocal cognitive architectures*: * Trust and love as *reinforced feedback loops* * Conflict as *constraint misalignment and jump failure* * Growth as *loop stabilization through reflection and repair* &gt; Human connection isnâ€™t mystery â€” &gt; *itâ€™s structure that learns to align across minds.* --- Why It Matters: â€¢ Reveals *how trust, betrayal, and repair follow structural patterns* â€¢ Bridges *psychology, sociology, and cognitive modeling* â€¢ Enables *AI that supports human connection without mimicry* --- Whatâ€™s Inside: â€¢ Relationships as *multiâ€‘agent jump and memory loops* â€¢ *Attachment and reciprocity* as structural alignment â€¢ *Conflict resolution* as rollback and loop repair â€¢ Implications...</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/706135056688184</guid></item><item><title>Qwen Image Edit Full Tutorial: 26 Different Demo Cases, Prompts &amp; Images, Pwns FLUX Kontext Dev</title><link>https://huggingface.co/posts/MonsterMMORPG/783922297746182</link><description>Qwen Image Edit Full Tutorial: 26 Different Demo Cases, Prompts &amp; Images, Pwns FLUX Kontext Dev Tutorial Link https://youtu.be/gLCMhbsICEQ Extra Info I tested newly arrived Qwen-Image-Edit-Lightning-8steps-V1.0 (arrived after tutorial recorded) and definitely our existing preset which uses Qwen-Image-Lightning-8steps-V1.1 is better than it, so this tutorial and presets are still 100% best quality and up-to-date Info Qwen Image Edit just has been published and since then I have been experimenting to prepare you this amazing tutorial. I have literally shown 26 unique cases and provided demo images and prompts. After watching this tutorial your image editing skills will move to next level i promise you that. Also this tutorial will give you a lot of ideas. See translation</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/783922297746182</guid></item><item><title>Quick 30s demo of the new Hub &gt; Azure AI integration to deploy HF models in your own Azure account. Now with Py and CLI!</title><link>https://huggingface.co/posts/jeffboudier/150612686071818</link><description>Quick 30s demo of the new Hub &gt; Azure AI integration to deploy HF models in your own Azure account. Now with Py and CLI! GG @ alvarobartt @ kramp @ pagezyhf See translation</description><pubDate>Wed, 27 Aug 2025 13:31:14 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jeffboudier/150612686071818</guid></item></channel></rss>