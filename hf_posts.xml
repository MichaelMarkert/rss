<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models üî•</title><link>https://huggingface.co/posts/victor/750233862472141</link><description>Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models üî• https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe See translation</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/victor/750233862472141</guid></item><item><title>ü§Ø ü§Ø Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ü§Ø ü§Ø</title><link>https://huggingface.co/posts/YatharthS/190514854652270</link><description>ü§Ø ü§Ø Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ü§Ø ü§Ø Github link: https://github.com/ysharma3501/MiraTTS Model link: https://github.com/ysharma3501/MiraTTS Blog explaining llm tts models: https://huggingface.co/blog/YatharthS/llm-tts-models See translation</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/190514854652270</guid></item><item><title>üö® New tool for the</title><link>https://huggingface.co/posts/Nymbo/749803216260872</link><description>üö® New tool for the Nymbo/Tools MCP server: The new Agent_Skills tool provides full support for Agent Skills (Claude Skills but open-source). How it works: The tool exposes the standard discover/info/resources/validate actions. Skills live in /Skills under the same File_System root, and any bundled scripts run through Shell_Command , no new infrastructure required. Agent_Skills(action= "discover" ) # List all available skills Agent_Skills(action= "info" , skill_name= "music-downloader" ) # Full SKILL.md Agent_Skills(action= "resources" , skill_name= "music-downloader" ) # Scripts, refs, assets I've included a music-downloader skill as a working demo, it wraps yt-dlp for YouTube/SoundCloud audio extraction. Caveat: On HF Spaces, Shell_Command works for most tasks, but some operations (like YouTube downloads) are restricted due to the container environment. For full functionality, run the server locally on your machine. Try it out ~ https://www.nymbo.net/nymbot See translation</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Nymbo/749803216260872</guid></item><item><title>Google DeepMind releases FunctionGemma, a 240M model specialized in üîß tool calling, built for fine-tuning</title><link>https://huggingface.co/posts/sergiopaniego/463044021249760</link><description>Google DeepMind releases FunctionGemma, a 240M model specialized in üîß tool calling, built for fine-tuning TRL has day-0 support. To celebrate, we‚Äôre sharing 2 new resources: &gt; Colab guide to fine-tune it for üåê browser control with BrowserGym OpenEnv &gt; Standalone training script &gt; Colab notebook: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_functiongemma_browsergym_openenv.ipynb &gt; Training script: https://github.com/huggingface/trl/blob/main/examples/scripts/openenv/browsergym_llm.py (command to run it inside the script) &gt; More notebooks in TRL: https://huggingface.co/docs/trl/example_overview#notebooks See translation</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/463044021249760</guid></item><item><title>" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI ". r2r-protocol (Robot2Robot Protocol) is now officially open source! üîì</title><link>https://huggingface.co/posts/rajkumarrawal/519682431601479</link><description>" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI ". r2r-protocol (Robot2Robot Protocol) is now officially open source! üîì "pip install r2r-protocol" Whether you're a developer, researcher, or tech enthusiast, we invite you to explore, use, and contribute to the project. üîó Check it out here: [ https://github.com/Tech-Parivartan/r2r-protocol?tab=readme-ov-file ] Let‚Äôs build the future together! üí° AiParivartanResearchLab techparivartan Documentation of the r2r-protocal : [ https://techparivartanai.notion.site/Robot-to-Robot-r2r-Protocol-1f008f0fb18780439d70e8b9bbbdb869 ] The R2R Protocol enables seamless robot-to-robot interaction across industrial automation, swarm robotics, logistics, and multi-agent systems. It defines structured message formats, negotiation logic, discovery mechanisms, and extensible APIs. #r2r_protocol #robot2robot_protocol #ai...</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/rajkumarrawal/519682431601479</guid></item><item><title>Next week, we will release full documentation for the SO ARM 101 with a parallel gripper, featuring leader and follower arms and support for widely used stereo cameras.</title><link>https://huggingface.co/posts/branikita/131682304514806</link><description>Next week, we will release full documentation for the SO ARM 101 with a parallel gripper, featuring leader and follower arms and support for widely used stereo cameras. See translation</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/131682304514806</guid></item><item><title>Google releases FunctionGemma, a new 270M parameter model that runs on just 0.5 GB RAM.‚ú®</title><link>https://huggingface.co/posts/danielhanchen/264398594064230</link><description>Google releases FunctionGemma, a new 270M parameter model that runs on just 0.5 GB RAM.‚ú® Built for tool-calling, run locally on your phone at 50+ tokens/s, or fine-tune with Unsloth &amp; deploy to your phone. GGUF: unsloth/functiongemma-270m-it-GGUF Docs + Notebook: https://docs.unsloth.ai/models/functiongemma See translation</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/264398594064230</guid></item><item><title>Update: Our engineer Alan has received a batch of components for the manipulator assemblies ‚Äî including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year.</title><link>https://huggingface.co/posts/branikita/654655990580208</link><description>Update: Our engineer Alan has received a batch of components for the manipulator assemblies ‚Äî including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year. See translation</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/654655990580208</guid></item><item><title>üçì One of the coolest parts about being an early Strawberry user has been the opportunity to build on the app at the ground floor.</title><link>https://huggingface.co/posts/ZennyKenny/672558817086708</link><description>üçì One of the coolest parts about being an early Strawberry user has been the opportunity to build on the app at the ground floor. The platform already has a ton of great integrations that let you interact with your external apps directly with tools, but I wanted to add the ability to do stuff in Slack as well. üí™ So I took the base Anthropic Slack MCP server, added a whole bunch of new tools, and generalized it as an HTTP-based SSE-server and deployed it in like 2 minutes with Railway so that Strawberry could make use of it (as can Claude or any other MCP client). Now, you can Chat with your Strawberry Companion (or Claude, or whatever) and do things like: ‚û°Ô∏è Get caught up across all of your Slack channels after a long weekend or noisy incident without having to read 20 threads in 10 different channels ‚û°Ô∏è Create, read, and edit Canvases, Messages, and Channels ‚û°Ô∏è Take any resources or content that you're using in your Chat and inject it directly into Slack without copy / paste üòé I'm...</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/672558817086708</guid></item><item><title>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™</title><link>https://huggingface.co/posts/prithivMLmods/223082724733311</link><description>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™ ‚óè Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC ‚óè Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection ‚óè Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo ‚óè Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- ‚óè FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 ‚óè FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC ‚óè Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC ‚óè Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast ‚óè Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...</description><pubDate>Sat, 20 Dec 2025 05:25:12 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/223082724733311</guid></item></channel></rss>