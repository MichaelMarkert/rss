<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Exciting New Tool for Knowledge Graph Extraction from Plain Text!</title><link>https://huggingface.co/posts/singhsidhukuldeep/815565847250252</link><description>Exciting New Tool for Knowledge Graph Extraction from Plain Text! I just came across a groundbreaking new tool called KGGen that's solving a major challenge in the AI world - the scarcity of high-quality knowledge graph data. KGGen is an open-source Python package that leverages language models to extract knowledge graphs (KGs) from plain text. What makes it special is its innovative approach to clustering related entities, which significantly reduces sparsity in the extracted KGs. The technical approach is fascinating: 1. KGGen uses a multi-stage process involving an LLM (GPT-4o in their implementation) to extract entities and relations from source text 2. It aggregates graphs across sources to reduce redundancy 3. Most importantly, it applies iterative LM-based clustering to refine the raw graph The clustering stage is particularly innovative - it identifies which nodes and edges refer to the same underlying entities or concepts. This normalizes variations in tense, plurality,...</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/singhsidhukuldeep/815565847250252</guid></item><item><title>9 types of "Chain-of-..." approaches:</title><link>https://huggingface.co/posts/Kseniase/433849056207490</link><description>9 types of "Chain-of-..." approaches: Chain-of-Thought (CoT) prompting enhances reasoning in AI models by breaking down complex problems into step-by-step logical sequences. It continues proving its effectiveness, especially in top-performing reasoning models. However, there are other similar methods, that expand CoT and can be used for different purposes. Here are 9 of them: 1. Chain-of-Action-Thought (COAT) -&gt; Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search (2502.02508) Helps model decide when to keep thinking, double-check their work, or try a different approach, using special guiding tokens. 2. Chain of Draft (CoD) -&gt; Chain of Draft: Thinking Faster by Writing Less (2502.18600) It helps model generate short but meaningful reasoning steps, cutting costs and making processing faster 3. Chain-of-Agents -&gt; Chain of Agents: Large Language Models Collaborating on Long-Context Tasks (2406.02818) Uses multi-agent...</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/433849056207490</guid></item><item><title>Exciting releases from the Chinese community this Februaryüî•</title><link>https://huggingface.co/posts/AdinaY/776127015570604</link><description>Exciting releases from the Chinese community this Februaryüî• üëâ zh-ai-community/2025-february-67a35aaa68e97812def5b6ef MLLM: ‚ú® Ovis2 by Alibaba AIDC-AI/ovis2-67ab36c7e497429034874464 ‚ú® Step Audio Chat by StepFun AI stepfun-ai/step-audio-67b33accf45735bb21131b0b Audio: ‚ú® Step Audio TTS by StepFunAI stepfun-ai/Step-Audio-TTS-3B ‚ú® InspireMusic by Alibaba https://huggingface.co/FunAudioLLM ‚ú® Baichuan Audio by BaichuanAI baichuan-inc/Baichuan-Audio-Instruct Video: ‚ú® Wan2.1 by Alibaba_Wan Wan-AI/Wan2.1-T2V-14B ‚ú® Stepvideo-T2V by StepFun AI stepfun-ai/stepvideo-t2v ‚ú® SkyReels-V1 by Skywork Skywork/skyreels-v1-67b34676ff65b4ec02d16307 ‚ú® LLaDA-8B by RenminUniversity GSAI-ML/LLaDA-8B-Instruct MoE: ‚ú® Moonlight-16B by MoonshotAI (Kimi) moonshotai/Moonlight-16B-A3B-Instruct Reasoning: ‚ú® TinyR1-32B by Qihoo360 qihoo360/TinyR1-32B-Preview Dataset: ‚ú® Chinese DeepSeek R1-Distill data -110k Congliu/Chinese-DeepSeek-R1-Distill-data-110k See translation</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/776127015570604</guid></item><item><title>Introducing a new architecture, MedIT One ‚Äì a single-token transformer with LSTM-like recurrence.</title><link>https://huggingface.co/posts/mkurman/255930071052172</link><description>Introducing a new architecture, MedIT One ‚Äì a single-token transformer with LSTM-like recurrence. It is extremely fast in training and inference, but we lack funding for large-scale training. Enjoy üçì https://github.com/MedITSolutionsKurman/medit-one See translation</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mkurman/255930071052172</guid></item><item><title>I think we have released the best Arabic model under 25B at least based on</title><link>https://huggingface.co/posts/MohamedRashad/233650928001403</link><description>I think we have released the best Arabic model under 25B at least based on inceptionai/AraGen-Leaderboard Yehia = ALLaM-AI/ALLaM-7B-Instruct-preview + GRPO and its ranked number one model under the 25B parameter size mark. Now, i said "i think" not "i am sure" because this model used the same metric of evaluation the AraGen developers use (the 3C3H) as a reward model to improve its responses and this sparks the question. Is this something good for users or is it another type of overfitting that we don't want ? I don't know if this is a good thing or a bad thing but what i know is that you can try it from here: Navid-AI/Yehia-7B-preview or Download it for your personal experiments from here: Navid-AI/Yehia-7B-preview Ramada Kareem üåô See translation</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MohamedRashad/233650928001403</guid></item><item><title>Comparing reconstruction quality of various VAEs with an interactive demo</title><link>https://huggingface.co/posts/rizavelioglu/517500066145145</link><description>Comparing reconstruction quality of various VAEs with an interactive demo rizavelioglu/vae-comparison See translation</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/rizavelioglu/517500066145145</guid></item><item><title>Wan 2.1 AI Video Model: Ultimate Step-by-Step Tutorial for Windows &amp; Affordable Private Cloud Setup :</title><link>https://huggingface.co/posts/MonsterMMORPG/359700355865540</link><description>Wan 2.1 AI Video Model: Ultimate Step-by-Step Tutorial for Windows &amp; Affordable Private Cloud Setup : https://youtu.be/hnAhveNy-8s https://youtu.be/hnAhveNy-8s Please check all screenshots to see latest news and updates after the tutorial video Alibaba‚Äôs new Wan 2.1 text-to-video, video-to-video and image-to-video Open Source AI is unbelievable. In this tutorial I will show how you can install Wan 2.1 all publicly published models into your Windows PC with 1-click installation and use them with the easiest possible way. With the Gradio APP I have developed, you will be able to use Wan AI with as low as 3.5GB VRAM having GPUs. Furthermore, for those who want to utilize powerful private cloud GPUs with cheapest possible prices, I will show how to 1-click and install Wan 2.1 on Massed Compute and on RunPod. Additionally, I will compare performance of RTX 3090 TI with RTX 5090 on all Wan 2.1 models. You will be shocked to see performance of RTX 5090. Also the APP I developed supports...</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/359700355865540</guid></item><item><title>üöÄ ftBoost is LIVE ‚Äì Stop Struggling with Fine-Tuning Data!</title><link>https://huggingface.co/posts/zamal/150460964459295</link><description>üöÄ ftBoost is LIVE ‚Äì Stop Struggling with Fine-Tuning Data! Alright folks, if you‚Äôre tired of manually crafting fine-tuning datasets, ftBoost is here to do the heavy lifting. One-click, LangChain-Groq-powered data augmentation that scales your training data in OpenAI, Gemini, Mistral, and LLaMA formats‚Äîautomatically. üî• What‚Äôs inside? ‚úÖ Smart Augmentations ‚Äì Paraphrasing, back translation, synonym swapping &amp; synthetic noise. ‚úÖ No more JSONL headaches ‚Äì Auto-formats everything for OpenAI, Gemini, Mistral &amp; LLaMA. ‚úÖ Custom tuning ‚Äì Adjust similarity, diversity, and fluency in real-time. ‚úÖ Upload, generate, download ‚Äì That‚Äôs it. ‚ö° If you‚Äôre fine-tuning LLMs, this will save you hours. üöÄ Try it now: üëâ zamal/Finetune-Boost üåü Give us a star on GitHub! Let me know what you think &amp; how it boosts your workflow! üî• See translation</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/zamal/150460964459295</guid></item><item><title>-UPDATED-</title><link>https://huggingface.co/posts/csabakecskemeti/207602570873500</link><description>-UPDATED- 4bit inference is working! The blogpost is updated with code snippet and requirements.txt https://devquasar.com/uncategorized/all-about-amd-and-rocm/ -UPDATED- I've played around with an MI100 and ROCm and collected my experience in a blogpost: https://devquasar.com/uncategorized/all-about-amd-and-rocm/ Unfortunately I've could not make inference or training work with model loaded in 8bit or use BnB, but did everything else and documented my findings. See translation</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/207602570873500</guid></item><item><title>Squeezing out tensor bits?</title><link>https://huggingface.co/posts/eaddario/832567461491467</link><description>Squeezing out tensor bits? I have been tinkering with quantization and pruning to reduce model sizes. So far, I've had modest success in producing, on average, 8% smaller versions with negligible loss of quality, and I think further reductions in the 10-15% range are realistic, but I've come across a behaviour I wasn't expecting! Part of the process I'm following consists of quantizing the embedding and output layers aggressively. Since the embedding layer is more about lookup than complex computation, the vectors representing the relative distances between embeddings are usually preserved well enough making this layer fairly robust to quantization. So far, so good. The output layer, on the other hand, maps the final hidden state to the vocabulary logits and therefore, small changes in these logits could lead to a different probability distribution over the vocabulary, resulting in incorrect word predictions, or so I thought. Surprisingly, I'm finding that even at Q2_K the loss of...</description><pubDate>Tue, 04 Mar 2025 13:28:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eaddario/832567461491467</guid></item></channel></rss>