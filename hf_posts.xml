<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸ§  ThinkFlow: The Revolutionary Platform That Gives LLMs the Power to Think ğŸš€</title><link>https://huggingface.co/posts/openfree/953705052271600</link><description>ğŸ§  ThinkFlow: The Revolutionary Platform That Gives LLMs the Power to Think ğŸš€ Hello AI community! We're excited to introduce you to ThinkFlow, an innovative service that transforms how language models solve problems. ğŸ‰ VIDraft/ThinkFlow-llama âœ¨ What is ThinkFlow? ThinkFlow is a groundbreaking platform that automatically applies step-by-step reasoning capabilities to existing LLM models without any modifications. It makes complex problem-solving transparent, allowing you to witness the model's thought process in real-time. ğŸ” Key Features Reasoning Without Model Modifications: Add step-by-step reasoning while utilizing existing LLMs as they are âš™ï¸ Visualized Thinking Process: See exactly how the model analyzes and solves problems ğŸ‘ï¸ Before &amp; After Comparison: Compare standard responses with reasoning-enhanced outputs in real-time ğŸ“Š Improved Accuracy: Deliver more accurate solutions for complex math and logic problems ğŸ“ˆ Educational Value: Teach students systematic approaches to problem-...</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/953705052271600</guid></item><item><title>ğŸ“š Papers Leaderboard - See the Latest AI Research Trends at a Glance! âœ¨</title><link>https://huggingface.co/posts/seawolf2357/553204712342429</link><description>ğŸ“š Papers Leaderboard - See the Latest AI Research Trends at a Glance! âœ¨ Hello, AI research community! Today I'm introducing a new tool for exploring research papers. Papers Leaderboard is an open-source dashboard that makes it easy to find and filter the latest AI research papers. Heartsync/Papers-Leaderboard ğŸŒŸ Key Features Date Filtering: View only papers published within a specific timeframe (from May 5, 2023 to present) Title Search: Quickly find papers containing your keywords of interest Abstract Search: Explore paper content more deeply by searching for keywords within abstracts Automatic Updates: The database is updated with the latest papers every hour ğŸ’¡ How to Use It? Select a start date and end date Enter keywords you want to find in titles or abstracts Adjust the maximum number of search results for abstract searches Results are displayed neatly in table format See translation</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/553204712342429</guid></item><item><title>ğŸŒ AI Token Visualization Tool with Perfect Multilingual Support</title><link>https://huggingface.co/posts/aiqtech/339494015180136</link><description>ğŸŒ AI Token Visualization Tool with Perfect Multilingual Support Hello! Today I'm introducing my Token Visualization Tool with comprehensive multilingual support. This web-based application allows you to see how various Large Language Models (LLMs) tokenize text. aiqtech/LLM-Token-Visual âœ¨ Key Features ğŸ¤– Multiple LLM Tokenizers: Support for Llama 4, Mistral, Gemma, Deepseek, QWQ, BERT, and more ğŸ”„ Custom Model Support: Use any tokenizer available on HuggingFace ğŸ“Š Detailed Token Statistics: Analyze total tokens, unique tokens, compression ratio, and more ğŸŒˆ Visual Token Representation: Each token assigned a unique color for visual distinction ğŸ“‚ File Analysis Support: Upload and analyze large files ğŸŒ Powerful Multilingual Support The most significant advantage of this tool is its perfect support for all languages: ğŸ“ Asian languages including Korean, Chinese, and Japanese fully supported ğŸ”¤ RTL (right-to-left) languages like Arabic and Hebrew supported ğŸˆº Special characters and emoji...</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aiqtech/339494015180136</guid></item><item><title>ğŸ¤– AI Academic Paper Generator: Your Research Partner ğŸ“</title><link>https://huggingface.co/posts/ginipick/639223795082206</link><description>ğŸ¤– AI Academic Paper Generator: Your Research Partner ğŸ“ Hello, researchers! Today I'm introducing my AI Academic Paper Generation System. This application is built with Streamlit and provides AI agents to assist with every stage of the academic research process. ginipick/AgentX-Papers âœ¨ Key Features ğŸ“š Literature Research: AI reviews and summarizes relevant research ğŸ“ Paper Outline: Generates a well-structured paper outline âœï¸ Draft Writing: Creates a paper draft based on your research topic ğŸ”— Citation Generation: Automatically generates academic citations ğŸ–‹ï¸ Editing &amp; Polishing: Checks grammar, context, and logical flow ğŸŒ Multilingual Support: Interface available in English and Korean ğŸš€ How to Use Enter basic information like research topic, paper title, and deadline AI agents generate everything from literature review to final paper Download your completed paper or consult with the chatbot for further assistance ğŸ’¡ What Makes It Special This tool integrates all stages of academic...</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/639223795082206</guid></item><item><title>New king of open VLMs: InternVL3 takes Qwen 2.5's crown! ğŸ‘‘</title><link>https://huggingface.co/posts/m-ric/531366391123392</link><description>New king of open VLMs: InternVL3 takes Qwen 2.5's crown! ğŸ‘‘ InternVL have been a wildly successful series of model : and the latest iteration has just taken back their crown thanks to their superior, natively multimodal vision training pipeline. â¡ï¸ Most of the vision language models (VLMs) these days are built like Frankenstein : take a good text-only Large Language Model (LLM) backbone, stitch a specific vision transformer (ViT) on top of it. Then the training is sequential ğŸ”¢ : 1. Freeze the LLM weights while you train the ViT only to work with the LLM part, then 2. Unfreeze all weights to train all weights in order to work together. ğŸ’« The Shanghai Lab decided to challenge this paradigm and chose this approach that they call "native". For each of their model sizes, they still start from a good LLM (mostly Qwen-2.5 series, did I tell you I'm a huge fan of Qwen? â¤ï¸), and stitch the ViT, but they don't freeze anything : they train all weights together with interleaved text and image...</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/m-ric/531366391123392</guid></item><item><title>Dropping an entire collection of Style Intermixing Adapters on StrangerZone HF â€” including Realism, Anime, Sketch, Texture-Rich 3D Experimentals, Automotive Concept Images, and LoRA models based on Flux.1, SD 3.5 Turbo/Large, Stable Diffusion XL ğŸ¨</title><link>https://huggingface.co/posts/prithivMLmods/567717355691306</link><description>Dropping an entire collection of Style Intermixing Adapters on StrangerZone HF â€” including Realism, Anime, Sketch, Texture-Rich 3D Experimentals, Automotive Concept Images, and LoRA models based on Flux.1, SD 3.5 Turbo/Large, Stable Diffusion XL ğŸ¨ â•°â”ˆâ¤Collection : âœ sketch : strangerzonehf/sketch-fav-675ba869c7ceaec7e652ee1c âœ sketch2 : strangerzonehf/q-series-sketch-678e3503bf3a661758429717 âœ automotive : strangerzonehf/automotive-3d-675bb31a491d8c264d45d843 âœ texture 3d : strangerzonehf/flux-3dxl-engine-674833c14a001d5b1fdb5139 âœ super 3d : strangerzonehf/super-3d-engine-6743231d69f496df97addd2b âœ style mix : strangerzonehf/mixer-engine-673582c9c5939d8aa5bf9533 âœ realism : strangerzonehf/realism-engine-67343495b6daf0fbdb904cc1 â•°â”ˆâ¤The Entire Collection : âœ flux.1 : prithivMLmods/flux-lora-collections-66dd5908be2206cfaa8519be âœ flux-ultimate-lora-collection : strangerzonehf/Flux-Ultimate-LoRA-Collection âœ sd 3.5 large / turbo : prithivMLmods/sd-35-large-lora-671b39d7bc2e7f71a446b163...</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/567717355691306</guid></item><item><title>ğŸ¦… SmolLM2-Eagle Collection -</title><link>https://huggingface.co/posts/nyuuzyou/125489545915443</link><description>ğŸ¦… SmolLM2-Eagle Collection - nyuuzyou/smollm2-eagle-680263bf97f0c7e6bbe4936b Collection of fine-tuned bilingual language models featuring: - Models in three parameter sizes: 135M, 360M, and 1.7B based on HuggingFaceTB's SmolLM2 models - Both standard and GGUF formats for flexible deployment in llama.cpp and Ollama - Fine-tuned on nyuuzyou/EagleSFT dataset (536,231 Russian-English QA pairs derived from 739k+ real user queries) - Experimental Russian language capabilities while maintaining English performance - Limited Russian capabilities due to SFT-only approach without Russian pre-training - Environmental impact: ~19.75 kg CO2eq This collection provides compact models for research on bilingual language capabilities, resource-constrained environments, and educational applications. Not recommended for production use due to experimental nature and inherent limitations. Available under Apache 2.0 license. See translation</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/125489545915443</guid></item><item><title>Hereâ€™s a cool paper I found: â€œMassive Image Embedding Benchmark (MIEB).â€ It is a new tool to test how good image embedding models are. It has 130 different tasks grouped into 8 categories, like image search, classification, clustering similar images, answering questions based on images, and understanding documents. It even covers 38 different languages.</title><link>https://huggingface.co/posts/merterbak/685608427471874</link><description>Hereâ€™s a cool paper I found: â€œMassive Image Embedding Benchmark (MIEB).â€ It is a new tool to test how good image embedding models are. It has 130 different tasks grouped into 8 categories, like image search, classification, clustering similar images, answering questions based on images, and understanding documents. It even covers 38 different languages. The authors tested 50 models and found that no single model was best at everything. Some models were great at recognizing text inside images but struggled to handle complicated tasks like matching images and text that appear together. Paper: https://arxiv.org/pdf/2504.10471v1 Code: https://github.com/embeddings-benchmark/mteb See translation</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merterbak/685608427471874</guid></item><item><title>anyone have all their spaces stuck in building now?</title><link>https://huggingface.co/posts/educrpg/528156241277720</link><description>anyone have all their spaces stuck in building now? See translation</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/educrpg/528156241277720</guid></item><item><title>I recently had the opportunity to present at a Computer Vision Hangout, sharing my journey from autonomous drone competition to fine-tuning Vision-Language Models.</title><link>https://huggingface.co/posts/samuellimabraz/467652159201775</link><description>I recently had the opportunity to present at a Computer Vision Hangout, sharing my journey from autonomous drone competition to fine-tuning Vision-Language Models. I built an interactive presentation app! Here's a glimpse of the topics: ğŸš Black Bee Drones: My first steps into CV with Latin America's first autonomous drone team. Covering classical CV techniques (filtering, edge detection), the IMAV 2023 mission (ArUco detection, line following with PID control), and links to demos for OpenCV basics and PID simulation. ğŸ¤– Asimo Foundation: Using MediaPipe for gesture control of a robotic arm in an educational project. â˜• CafeDL: Building a small Deep Learning framework from scratch in Java (inspired by Keras, using ND4J) and training a CNN for a QuickDraw-like app. ğŸ¢ Tech4Humans: Real-world applications, including open-source signature detection and efficient fine-tuning of VLMs for document extraction. Check out the interactive demos (also embedded in the main app): 1ï¸âƒ£ CV Hangout App:...</description><pubDate>Sun, 20 Apr 2025 13:27:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/samuellimabraz/467652159201775</guid></item></channel></rss>