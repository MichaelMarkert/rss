<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>HOW TO ADD MCP SUPPORT TO ANY ğŸ¤— SPACE</title><link>https://huggingface.co/posts/abidlabs/810486848644944</link><description>HOW TO ADD MCP SUPPORT TO ANY ğŸ¤— SPACE Gradio now supports MCP! If you want to convert an existing Space, like this one hexgrad/Kokoro-TTS , so that you can use it with Claude Desktop / Cursor / Cline / TinyAgents / or any LLM that supports MCP, here's all you need to do: 1. Duplicate the Space (in the Settings Tab) 2. Upgrade the Gradio sdk_version to 5.28 (in the README.md ) 3. Set mcp_server=True in launch() 4. (Optionally) add docstrings to the function so that the LLM knows how to use it, like this: def generate ( text, speed= 1 ): """ Convert text to speech audio. Parameters: text (str): The input text to be converted to speech. speed (float, optional): Playback speed of the generated speech. That's it! Now your LLM will be able to talk to you ğŸ¤¯ See translation</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/810486848644944</guid></item><item><title>ğŸ¨ Renoir Studio: Impressionist Masterpieces Reborn Through AI âœ¨</title><link>https://huggingface.co/posts/ginipick/692850049335646</link><description>ğŸ¨ Renoir Studio: Impressionist Masterpieces Reborn Through AI âœ¨ ğŸŒŸ Experience Renoir's Magical Brushstrokes with AI! ğŸ”— Try it now: ginigen/flux-lora-renoir ğŸ”— Model page: openfree/pierre-auguste-renoir ğŸ”— Collection: openfree/painting-art-ai-681453484ec15ef5978bbeb1 Hello, AI art enthusiasts! ğŸ’– Today I'm introducing a special model - Pierre-Auguste Renoir Studio. Create your own beautiful artwork in the style of the 19th century French Impressionist master! ğŸ–¼ï¸ âœ¨ Why Renoir's Style? Renoir is famous for his luminous colors and soft brushstrokes. His works feature: ğŸŒ Warm sunshine and dancing light ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ The beauty of everyday life and joyful moments ğŸŒ¸ Vibrant nature and portraits of beautiful women ğŸ­ Lively Parisian social gatherings and outdoor scenes ğŸ”¬ Technical Features This model was developed as a flux-based learning model trained on a curated collection of high-resolution masterpieces from renowned global artists. The LoRA fine-tuning process leveraged exceptional quality open-...</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/692850049335646</guid></item><item><title>Iâ€™m excited to share that Iâ€™ve completed the Hugging Face Agents Course and earned my certificate.</title><link>https://huggingface.co/posts/lukmanaj/906857593942972</link><description>Iâ€™m excited to share that Iâ€™ve completed the Hugging Face Agents Course and earned my certificate. Over the past few months, I explored how to build intelligent, autonomous agents using cutting-edge tools like smolagents, LlamaIndex, and LangGraph. The course covered everything from the fundamentals of agents to advanced topics like fine-tuning for function-calling, observability, evaluation, and even agents in games. Some key content included: 1. Introduction to AI Agents 2. Agentic RAG use cases 3. Multi-framework implementation: smolagents, LlamaIndex, and LangGraph 4. Building, testing, and certifying a complete agent project This was a hands-on, practical experience that deepened my understanding of how to design reliable, tool-using LLM agents. Looking forward to leveraging these skills in real-world applications in healthcare, logistics, and beyond. Many thanks to the Hugging Face team for putting this together. Letâ€™s build safe and useful agents! See translation</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/lukmanaj/906857593942972</guid></item><item><title>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me!</title><link>https://huggingface.co/posts/fdaudens/694548457778636</link><description>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me! Just tested it with Steve Jobs' Stanford speech and was speechless (pun intended). The video isnâ€™t sped up. 3 things that floored me: - Transcription took just 10 seconds for a 15-min file - Got a CSV with perfect timestamps, punctuation &amp; capitalization - Stunning accuracy (correctly captured "Reed College" and other specifics) NVIDIA also released a demo where you can click any transcribed segment to play it instantly. The improvement is significant: number 1 on the ASR Leaderboard, 6% error rate (best in class) with complete commercial freedom (cc-by-4.0 license). Time to update those Whisper pipelines! H/t @ Steveeeeeeen for the finding! Model: nvidia/parakeet-tdt-0.6b-v2 Demo: nvidia/parakeet-tdt-0.6b-v2 ASR Leaderboard: hf-audio/open_asr_leaderboard See translation</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/694548457778636</guid></item><item><title>One of the biggest challenges I've been facing since I started developing [ğğğŸğˆğ­ğƒğ¨ğ°ğ§](</title><link>https://huggingface.co/posts/as-cle-bert/299436064475061</link><description>One of the biggest challenges I've been facing since I started developing [ğğğŸğˆğ­ğƒğ¨ğ°ğ§]( https://github.com/AstraBert/PdfItDown ) was handling correctly the conversion of files like Excel sheets and CSVs: table conversion was bad and messy, almost unusable for downstream tasksğŸ«£ That's why today I'm excited to introduce ğ«ğğšğğğ«ğ¬, the new feature of PdfItDown v1.4.0!ğŸ‰ With ğ˜³ğ˜¦ğ˜¢ğ˜¥ğ˜¦ğ˜³ğ˜´, you can choose among three (for nowğŸ‘€) flavors of text extraction and conversion to PDF: - ğ——ğ—¼ğ—°ğ—¹ğ—¶ğ—»ğ—´, which does a fantastic work with presentations, spreadsheets and word documentsğŸ¦† - ğ—Ÿğ—¹ğ—®ğ—ºğ—®ğ—£ğ—®ğ—¿ğ˜€ğ—² by LlamaIndex, suitable for more complex and articulated documents, with mixture of texts, images and tablesğŸ¦™ - ğ— ğ—®ğ—¿ğ—¸ğ—œğ˜ğ——ğ—¼ğ˜„ğ—» by Microsoft, not the best at handling highly structured documents, by extremly flexible in terms of input file format (it can even convert XML, JSON and ZIP files!)âœ’ï¸ You can use this new feature in your python scripts (check the attached code snippet!ğŸ˜‰) and in the command line interface as well!ğŸ...</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/299436064475061</guid></item><item><title>ğŸš€ Introducing Phi-4-reasoning-plus: Powerful 14B Reasoning Model by Microsoft!</title><link>https://huggingface.co/posts/openfree/886239913784185</link><description>ğŸš€ Introducing Phi-4-reasoning-plus: Powerful 14B Reasoning Model by Microsoft! VIDraft/phi-4-reasoning-plus ğŸŒŸ Key Highlights Compact Size (14B parameters): Efficient for use in environments with limited computing resources, yet powerful in performance. Extended Context (32k tokens): Capable of handling lengthy and complex input sequences. Enhanced Reasoning: Excels at multi-step reasoning, particularly in mathematics, science, and coding challenges. Chain-of-Thought Methodology: Provides a detailed reasoning process, followed by concise, accurate summaries. ğŸ… Benchmark Achievements Despite its smaller size, Phi-4-reasoning-plus has delivered impressive results, often surpassing significantly larger models: Mathematical Reasoning (AIME 2025): Achieved an accuracy of 78%, significantly outperforming larger models like DeepSeek-R1 Distilled (51.5%) and Claude-3.7 Sonnet (58.7%). Olympiad-level Math (OmniMath): Strong performance with an accuracy of 81.9%, surpassing DeepSeek-R1...</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/886239913784185</guid></item><item><title>Hi folks! Excited to share a new feature from the Gradio team along with a tutorial.</title><link>https://huggingface.co/posts/abidlabs/767083410530735</link><description>Hi folks! Excited to share a new feature from the Gradio team along with a tutorial. If you don't already know, Gradio is an open-source Python library used to build interfaces for machine learning models. Beyond just creating UIs, Gradio also exposes API capabilities and now, Gradio apps can be launched Model Context Protocol (MCP) servers for LLMs. If you already know how to use Gradio, there are only two additional things you need to do: * Add standard docstrings to your function (these will be used to generate the descriptions for your tools for the LLM) * Set mcp_server=True in launch() Here's a complete example (make sure you already have the latest version of Gradio installed): import gradio as gr def letter_counter ( word, letter ): """Count the occurrences of a specific letter in a word. Args: word: The word or phrase to analyze letter: The letter to count occurrences of Returns: The number of times the letter appears in the word """ return...</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/767083410530735</guid></item><item><title>VisionScout â€” Now with Scene Understanding! ğŸš€</title><link>https://huggingface.co/posts/DawnC/822045713383062</link><description>VisionScout â€” Now with Scene Understanding! ğŸš€ I'm excited to share a major update to VisionScout, my interactive vision tool that combines powerful object detection with emerging scene understanding capabilities! ğŸ‘€ğŸ” What can VisionScout do today? ğŸ–¼ï¸ Upload any image and detect 80 object types using YOLOv8. ğŸ”„ Instantly switch between Nano, Medium, and XLarge models depending on speed vs. accuracy needs. ğŸ¯ Filter specific classes (people, vehicles, animals, etc.) to focus only on what matters to you. ğŸ“Š View detailed statistics on detected objects, confidence levels, and spatial distribution. â­ï¸ NEW: Scene understanding layer now added! - Automatically interprets the scene based on detected objects. - Uses a combination of rule-based reasoning and CLIP-powered semantic validation. - Outputs descriptions, possible activities, and even safety concerns. Whatâ€™s coming next? ğŸ” Expanding YOLOâ€™s object categories. ğŸ¥ Adding video processing and multi-frame object tracking. âš¡ Faster real-time...</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/822045713383062</guid></item><item><title>ğŸ–¼ï¸ OpenClipart SVG Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/253978208604387</link><description>ğŸ–¼ï¸ OpenClipart SVG Dataset - nyuuzyou/openclipart Collection of 178,604 Public Domain Scalable Vector Graphics (SVG) clipart images featuring: - Comprehensive metadata: title, description, artist name, tags, original page URL, and more. - Contains complete SVG XML content (minified) for direct use or processing. - All images explicitly released into the public domain under the CC0 license. - Organized in a single train split with 178,604 entries. See translation</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/253978208604387</guid></item><item><title>Microsoft released their new fine-tuned phi-4 models with reasoning data yesterday. They outperform/rival much larger models . Check out them if you haven't yet. ğŸš€</title><link>https://huggingface.co/posts/merterbak/465113700174187</link><description>Microsoft released their new fine-tuned phi-4 models with reasoning data yesterday. They outperform/rival much larger models . Check out them if you haven't yet. ğŸš€ Phi4 mini reasoning(SFT): microsoft/Phi-4-mini-reasoning Phi-4 reasoning(SFT): microsoft/Phi-4-reasoning Phi-4 reasoning plus (SFT + RL): microsoft/Phi-4-reasoning-plus Demo: https://github.com/marketplace/models/azureml/Phi-4-reasoning/playground Articles: https://arxiv.org/pdf/2504.21318 https://arxiv.org/pdf/2504.21233 Blog: https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/ See translation</description><pubDate>Sat, 03 May 2025 17:18:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merterbak/465113700174187</guid></item></channel></rss>