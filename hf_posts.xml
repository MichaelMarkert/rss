<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸ¯ Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! âœ¨</title><link>https://huggingface.co/posts/ginipick/807578740801859</link><description>ğŸ¯ Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! âœ¨ Hello AI enthusiasts! ğŸ™‹â€â™€ï¸ Today I'm introducing a truly magical project: Open Ghibli Studio ğŸ¨ ginigen/FLUX-Open-Ghibli-Studio ğŸŒŸ What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! ğŸï¸âœ¨ ğŸ”§ How Does It Work? ğŸ“¸ Upload your photo ğŸ¤– Florence-2 AI analyzes the image and generates a description âœï¸ "Ghibli style" is added to the description ğŸ­ Magic transformation happens using the FLUX.1 model and Ghibli LoRA! âš™ï¸ Customization Options Want more control? Adjust these in the advanced settings: ğŸ² Set a seed (for reproducible results) ğŸ“ Adjust image dimensions ğŸ” Guidance scale (prompt adherence) ğŸ”„ Number of generation steps ğŸ’« Ghibli style intensity ğŸš€ Try It Now! Click the "Transform to Ghibli Style" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? ğŸŒˆ ğŸŒ¿ Note: For best results,...</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/807578740801859</guid></item><item><title>ğŸ”¥ 'Open Meme Studio': Your Creative Meme Factory ğŸ­âœ¨</title><link>https://huggingface.co/posts/openfree/925352420925810</link><description>ğŸ”¥ 'Open Meme Studio': Your Creative Meme Factory ğŸ­âœ¨ Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. ğŸš€ VIDraft/Open-Meme-Studio ğŸ¯ Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! ğŸ› ï¸ Features You'll Love ğŸ“¸ Transform and reinterpret existing meme templates ğŸ­ Freely change expressions and poses ğŸ‘“ Add props (sunglasses, hats, etc.) ğŸï¸ Change backgrounds and composite characters ğŸ¨ Apply various artistic styles ğŸ’ª Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/925352420925810</guid></item><item><title>ğŸ¨ Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition ğŸŒâœ¨</title><link>https://huggingface.co/posts/seawolf2357/883323339740165</link><description>ğŸ¨ Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition ğŸŒâœ¨ Hello creators! Today I'm introducing a special image generator that combines the beautiful aesthetics of Studio Ghibli with multilingual text integration! ğŸ˜ seawolf2357/Ghibli-Multilingual-Text-rendering âœ¨ Key Features Ghibli-Style Image Generation - High-quality animation-style images based on FLUX.1 Multilingual Text Rendering - Support for Korean, Japanese, English, and all languages! ğŸ‡°ğŸ‡·ğŸ‡¯ğŸ‡µğŸ‡¬ğŸ‡§ Automatic Image Editing with Simple Prompts - Just input your desired text and you're done! Two Stylistic Variations Provided - Get two different results from a single prompt Full Hugging Face Spaces Support - Deploy and share instantly! ğŸš€ How Does It Work? Enter a prompt describing your desired image (e.g., "a cat sitting by the window") Input the text you want to add (any language works!) Select the text position, size, and color Two different versions are automatically generated! ğŸ’¯...</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/883323339740165</guid></item><item><title>Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possibleâ€”just look at the â€œTâ€ in ChatGPT, which comes from the Transformer architecture openly shared by Google.</title><link>https://huggingface.co/posts/clem/267300235555885</link><description>Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possibleâ€”just look at the â€œTâ€ in ChatGPT, which comes from the Transformer architecture openly shared by Google. Then came the myth that AI was too dangerous to share, and companies started optimizing for short-term revenue. That led many major AI labs and researchers to stop sharing and collaborating. With OAI and sama now saying they're willing to share open weights again, we have a real chance to return to a golden age of AI progress and democratizationâ€”powered by openness and collaboration, in the US and around the world. This is incredibly exciting. Letâ€™s go, open science and open-source AI! See translation</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/267300235555885</guid></item><item><title>Curious how Duality AI crafts synthetic data that can bridge the sim2real gap?</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/493599242742163</link><description>Curious how Duality AI crafts synthetic data that can bridge the sim2real gap? We just published an article here on HuggingFace outlining our process, with bonus dataset releases! Read it here: https://huggingface.co/blog/DualityAI-RebekahBogdanoff/training-yolov8-with-synthetic-data-from-falcon See translation</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/493599242742163</guid></item><item><title>ğŸš€ Rapidata: Setting the Standard for Model Evaluation</title><link>https://huggingface.co/posts/jasoncorkill/394806250895359</link><description>ğŸš€ Rapidata: Setting the Standard for Model Evaluation Rapidata is proud to announce our first independent appearance in academic research, featured in the Lumina-Image 2.0 paper. This marks the beginning of our journey to become the standard for testing text-to-image and generative models. Our expertise in large-scale human annotations allows researchers to refine their models with accurate, real-world feedback. As we continue to establish ourselves as a key player in model evaluation, weâ€™re here to support researchers with high-quality annotations at scale. Reach out to info@rapidata.ai to see how we can help. Lumina-Image 2.0: A Unified and Efficient Image Generative Framework (2503.21758) See translation</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jasoncorkill/394806250895359</guid></item><item><title>What, How, Where, and How Well? This paper reviews test-time scaling methods and all you need to know about them:</title><link>https://huggingface.co/posts/hesamation/178289696524550</link><description>What, How, Where, and How Well? This paper reviews test-time scaling methods and all you need to know about them: &gt; parallel, sequential, hybrid, internal scaling &gt; how to scale (SFT, RL, search, verification) &gt; metrics and evals of test-time scaling ğŸ”—paper: What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models (2503.24235) If you want to learn what inference-time compute scaling is @ rasbt has a great blog post on that: https://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling See translation</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/178289696524550</guid></item><item><title>Dolphin ğŸ¬ an open ASR model released by DataOceanAI, one of the biggest AI data provider in China ğŸ”¥</title><link>https://huggingface.co/posts/AdinaY/602638381866736</link><description>Dolphin ğŸ¬ an open ASR model released by DataOceanAI, one of the biggest AI data provider in China ğŸ”¥ âœ¨ Supports 40 Eastern languages &amp; 22 Chinese dialects âœ¨ Apache2.0 âœ¨ With 21.2M hours of data (7.4M open data) Model: DataoceanAI/dolphin-base DataoceanAI/dolphin-small Paper: Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages (2503.20212) See translation</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/602638381866736</guid></item><item><title>The Rise of Specialized LLMs for Enterprise -https://mltblog.com/3QXXE4I</title><link>https://huggingface.co/posts/vincentg64/309576040156740</link><description>The Rise of Specialized LLMs for Enterprise -https://mltblog.com/3QXXE4I In this article, I discuss the main problems of standard LLMs (OpenAI and the likes), and how the new generation of LLMs addresses these issues. The focus is on Enterprise LLMs. LLMs with Billions of Parameters: Most of the LLMs still fall in that category. The first ones (ChatGPT) appeared around 2022, though Bert is an early precursor. Most recent books discussing LLMs still define them as transformer architecture with deep neural networks (DNNs), costly training, and reliance on GPUs. The training is optimized to predict the next tokens or missing tokens. However, this task is remotely relevant to what modern LLMs now deliver to the user, see here. Yet it requires time and intensive computer resources. Indeed, this type of architecture works best with billions or trillions of tokens. In the end, most of these tokens are noise, requiring smart distillation for performance improvement. The main issues are: â¡ï¸...</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/vincentg64/309576040156740</guid></item><item><title>ok, there must be a problem. HF charged me 0.12$ for 3 inference requests to text models</title><link>https://huggingface.co/posts/Reality123b/155118307932581</link><description>ok, there must be a problem. HF charged me 0.12$ for 3 inference requests to text models See translation</description><pubDate>Thu, 03 Apr 2025 13:30:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reality123b/155118307932581</guid></item></channel></rss>