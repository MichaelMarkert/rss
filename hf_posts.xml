<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments</title><link>https://huggingface.co/posts/sergiopaniego/565991505089039</link><description>we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments train a model to interact with a browser (üéÆ BrowserGym Env), play Wordle (üéÆ Wordle Env) and moooore! TRL (GRPO + vLLM) + OpenEnv! ‚ö°Ô∏è üìù go play with them: https://github.com/huggingface/trl/tree/main/examples/scripts/openenv üìù examples list: https://huggingface.co/docs/trl/main/en/example_overview#scripts See translation</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/565991505089039</guid></item><item><title>GLM 4.6 is on a par with Gemini 2</title><link>https://huggingface.co/posts/onekq/568645222085642</link><description>GLM 4.6 is on a par with Gemini 2 onekq-ai/WebApp1K-models-leaderboard See translation</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/568645222085642</guid></item><item><title>Transforming Ideas Into Art: My New AI Speed Painting Demo</title><link>https://huggingface.co/posts/wang12390/386545539363465</link><description>Transforming Ideas Into Art: My New AI Speed Painting Demo I‚Äôm excited to share my latest AI speed painting demonstration, showcasing how quickly and smoothly AI can transform a simple idea into a fully rendered artwork. This video highlights the power of real-time AI brushwork, dynamic color composition, and fluid scene construction ‚Äî all generated using my custom Miragic Speed Painting engine. What This Demo Shows - Ultra-fast painting generation from start to finish - Smooth, natural brushstrokes that feel hand-drawn - Stable composition and color consistency - A cinematic visual style suitable for creative projects - No diffusion-style noise or randomness ‚Äî just pure painting Speed painting is perfect for: - Content creators and video editors - Graphic designers and social media marketers - Artists exploring quick concepts - Businesses needing fast creative assets - Anyone who wants beautiful visuals‚Ä¶ without waiting minutes or hours Watch the Video I‚Äôve attached the full speed...</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wang12390/386545539363465</guid></item><item><title>[Version 1.0] Training  Wan 2.2 LoRAs has never been easier</title><link>https://huggingface.co/posts/obsxrver/107938712743937</link><description>[Version 1.0] Training Wan 2.2 LoRAs has never been easier ( https://github.com/obsxrver/wan22-lora-training ) If you‚Äôve been wanting to train your own Wan 2.2 Video LoRAs but are intimidated by the hardware requirements, parameter tweaking insanity, or the installation nightmare‚ÄîI built a solution that handles it all for you. This is currently the easiest, fastest, and cheapest way to get a high-quality training run done. Why this method? * Zero Setup: No installing Python, CUDA, or hunting for dependencies. You launch a pre-built [Vast.AI]( http://Vast.AI ) template, and it's ready in minutes. * Full WebUI: Drag-and-drop your videos/images, edit captions, and click "Start." No terminal commands required. * Extremely Cheap: You can rent a dual RTX 5090 node, train a full LoRA in 2-3 hours, and auto-shutdown. Total cost is usually $3 or less. * Auto-Save: It automatically uploads your finished LoRA to your Cloud Storage (Google Drive/S3/Dropbox) and kills the instance so you don't...</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/obsxrver/107938712743937</guid></item><item><title>üó£Ô∏è Introducing the Duality AI +  LunateAI Challenge- Geospatial Object Detection: Rural Buildings!</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/527488277094596</link><description>üó£Ô∏è Introducing the Duality AI + LunateAI Challenge- Geospatial Object Detection: Rural Buildings! Train a model to detect difficult detection instances, such as a low number of pixels or weak feature responses, in rural aerial imagery, to win üèÜPRIZESüèÜ and ü§©RECOGNITIONü§©. Sign up here: https://www.kaggle.com/competitions/duality-ai-lunate-ai-geospatial-object-detection/overview This is the first competition in the üåéGeospatial Kaggle Challenge Seriesüåè, which will explore how geospatial-based digital twins can train an AI model for real-world applications. Duality is excited to be partnering with LunateAI, a high-end advisory business founded by the award-winning, industry-recognized global leader Dr. Nadine Alameh to usher in a new era of geospatial impact in conjunction with advances in computing and AI. Lunate helps government and industry leaders ü§î rethink, üí°redesign, and üìù execute transformative geospatial strategies using AI, cloud, and Lunate‚Äôs unparalleled global expertise. Read...</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/527488277094596</guid></item><item><title>NEW Model Alert:</title><link>https://huggingface.co/posts/unmodeled-tyler/762230736035210</link><description>NEW Model Alert: vanta-research/atom-olmo3-7b We are excited at VANTA Research to release our atom-olmo3-7b model using the brand new Olmo3 architecture from Allen AI. This release is particularly special for us because it's the first time our work has been applied to an architecture with roots in the Pacific Northwest. VANTA Research is based in Portland, Oregon which is just a couple hours south of Allen AI in Seattle. Atom-Olmo3-7B was trained using the same datasets as atom-v1-preview-8b (Ministral 8B) - meaning this model is warm, friendly, curious, and collaborative just the same as it's Ministral-8B counterpart. Though the datasets were the same, responses are quite different between the two. Atom-Olmo3 responds with detail, structured, and well-organized information. Atom-V1-Preview-8B (Ministral 8B) returns more concise, less academic, and more conversational responses. Both models are native in human-AI collaboration and exploratory learning - though they each present it...</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/762230736035210</guid></item><item><title>Publishing our research on dual-motor backlash compensation for STS3215 servos. To complete our arXiv submission, we need a quick endorsement from someone who has published in robotics (cs.RO/eess.SY).</title><link>https://huggingface.co/posts/branikita/234726599671172</link><description>Publishing our research on dual-motor backlash compensation for STS3215 servos. To complete our arXiv submission, we need a quick endorsement from someone who has published in robotics (cs.RO/eess.SY). If you can help, here‚Äôs the code: L64QM3 Thank you! See translation</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/234726599671172</guid></item><item><title>üöÄ We're excited to support the ERNIE AI Developer Challenge!</title><link>https://huggingface.co/posts/hiyouga/713531971190066</link><description>üöÄ We're excited to support the ERNIE AI Developer Challenge! Fine-tune ERNIE with LLaMA-Factory and compete for $3,000 prizes by building the most impactful model ‚Äî with submissions reviewed by the core developers of LLaMA-Factory. üëâ Join Now: https://baiduernieai.devpost.com/?utm_source=LLaMAFactory&amp;utm_medium=partner&amp;utm_campaign=ERNIE+AI+Developer+Challenge See translation</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hiyouga/713531971190066</guid></item><item><title>Just released a heavily optimized library for NeuTTS. It's over 200x realtime meaning it can generate over 200 seconds of audio in a single second using batching and supports voice cloning!!ü§Øü§Ø</title><link>https://huggingface.co/posts/YatharthS/337806794067446</link><description>Just released a heavily optimized library for NeuTTS. It's over 200x realtime meaning it can generate over 200 seconds of audio in a single second using batching and supports voice cloning!!ü§Øü§Ø Link: https://github.com/ysharma3501/FastNeuTTS See translation</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/337806794067446</guid></item><item><title>Try the all-new trending Qwen-Image-Edit-2509 (Multi-Image-Edits) specialized adapter demos, including Cloth-Design-Fuse, Texture Edit, Guided-Objects-Patching, and more ‚Äî all in a single Hugging Face Space. The demo link is provided below. ü§óüî•</title><link>https://huggingface.co/posts/prithivMLmods/663896599381140</link><description>Try the all-new trending Qwen-Image-Edit-2509 (Multi-Image-Edits) specialized adapter demos, including Cloth-Design-Fuse, Texture Edit, Guided-Objects-Patching, and more ‚Äî all in a single Hugging Face Space. The demo link is provided below. ü§óüî• ‚Æû Space[Demo]: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast-Fusion ‚Æû Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection ‚Æû Base Model: Qwen/Qwen-Image-Edit-2509 Similar applications‚ÜóÔ∏è ‚Æû Kontext-Photo-Mate-v2: prithivMLmods/Kontext-Photo-Mate-v2 ‚Æû Photo-Mate-i2i: prithivMLmods/Photo-Mate-i2i ‚Æû Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Sat, 22 Nov 2025 05:22:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/663896599381140</guid></item></channel></rss>