<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Qwen3-Next can now be Run locally! (30GB RAM)</title><link>https://huggingface.co/posts/danielhanchen/212249714773740</link><description>Qwen3-Next can now be Run locally! (30GB RAM) Instruct GGUF: unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF The models come in Thinking and Instruct versions and utilize a new architecture, allowing it to have ~10x faster inference than Qwen32B. ğŸ’œ Step-by-step Guide: https://docs.unsloth.ai/models/qwen3-next Thinking GGUF: unsloth/Qwen3-Next-80B-A3B-Thinking-GGUF See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/212249714773740</guid></item><item><title>9 Recent advances in Multi-Agent Systems (all open-source)</title><link>https://huggingface.co/posts/Kseniase/298526462161147</link><description>9 Recent advances in Multi-Agent Systems (all open-source) The idea to split tasks across multiple agents instead of relying on one universal agent is now seen as one of the most effective ways to build an AI stack. Concepts like â€œagent swarmsâ€ were highlighted at the AI Engineer Code Summit in NYC (Nov 20â€“21) as the winning architecture. And this trend is not only about coding and software. It applies across all AI domains. So here is some recent research that helps keep multi-agent systems (MAS) better and up-to-date: 1. LatentMAS â†’ Latent Collaboration in Multi-Agent Systems (2511.20639) AI agents share their hidden "thoughts" directly in latent space instead of talking through text. This makes collaboration and reasoning way faster and accurate (no extra training needed) 2. Puppeteer â†’ Multi-Agent Collaboration via Evolving Orchestration (2505.19591) Uses a â€œpuppeteerâ€ LLM that dynamically decides which agents (â€œpuppetsâ€) to call and in what order. By learning this orchestration...</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/298526462161147</guid></item><item><title>hello, who can help me setup a local LLM and RAG for my job i can pay</title><link>https://huggingface.co/posts/aiconta/768879073281998</link><description>hello, who can help me setup a local LLM and RAG for my job i can pay See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aiconta/768879073281998</guid></item><item><title>Introducing Anim Lab AIâš¡</title><link>https://huggingface.co/posts/ovi054/498416611324104</link><description>Introducing Anim Lab AIâš¡ My submission for the MCP 1st Birthday Hackathon Turn any math concept or logic into a clear video explanation instantly using AI. ğŸ‘‰ Try it now: MCP-1st-Birthday/anim-lab-ai Demo outputs are attached ğŸ‘‡ See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/498416611324104</guid></item><item><title>4æœˆï¼Ÿã”ã‚ã«å‚åŠ ã—ãŸCerebrasã®ãƒãƒƒã‚«ã‚½ãƒ³ã‹ã‚‰ä½•æ•…ã‹Huggingfaceã®proãƒ—ãƒ©ãƒ³ãŒç¶šã„ã¦ã‚‹ã‚“ã§ã™ã‚ˆã­...</title><link>https://huggingface.co/posts/Holy-fox/916850799845292</link><description>4æœˆï¼Ÿã”ã‚ã«å‚åŠ ã—ãŸCerebrasã®ãƒãƒƒã‚«ã‚½ãƒ³ã‹ã‚‰ä½•æ•…ã‹Huggingfaceã®proãƒ—ãƒ©ãƒ³ãŒç¶šã„ã¦ã‚‹ã‚“ã§ã™ã‚ˆã­... å¤šåˆ†ãƒãƒƒã‚«ã‚½ãƒ³æœŸé–“ã ã‘ã®ã¯ãšãªã‚“ã ã‘ã©ã€å¤–ã‚Œãªã„ã®ã‚ˆã­ã€‚ ã¾ã‚ã€ã‚¯ãƒ¬ã‚«ã¨ã‹ã¯ç™»éŒ²ã—ã¦ãªã„ã‹ã‚‰å¤§ä¸ˆå¤«ã ã¨ã¯æ€ã†ã‘ã© See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Holy-fox/916850799845292</guid></item><item><title>nanochat is now in transformers!</title><link>https://huggingface.co/posts/sergiopaniego/367599205240435</link><description>nanochat is now in transformers! The LLM by @ karpathy is officially in the library, and we wrote a blog covering: how did we port the model, differences from the original, and how to run or train it. go read it ğŸ¤“ nanochat-students/transformers See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/367599205240435</guid></item><item><title>PatchDNA, a DNA foundation model based on Meta's BLT tokenization strategy</title><link>https://huggingface.co/posts/monsoon-nlp/310592706664780</link><description>PatchDNA, a DNA foundation model based on Meta's BLT tokenization strategy https://www.biorxiv.org/content/10.1101/2025.11.28.691095v1 See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/monsoon-nlp/310592706664780</guid></item><item><title>Exciting updates to the Wikipedia Monthly dataset for November! ğŸš€</title><link>https://huggingface.co/posts/omarkamali/466219030497250</link><description>Exciting updates to the Wikipedia Monthly dataset for November! ğŸš€ ãƒ» Fixed a bug to remove infobox leftovers and other wiki markers such as __TOC__ ãƒ» New python package https://pypi.org/project/wikisets : a dataset builder with efficient sampling so you can combine the languages you want seamlessly for any date (ideal for pretraining data but works for any purpose) ãƒ» Moved the pipeline to a large server. Much higher costs but with better reliability and predictability (let me know if you'd like to sponsor this!). ãƒ» Dataset sizes are unfortunately missing for this month due to shenanigans with the migration, but should be back in December's update. Check out the dataset: omarkamali/wikipedia-monthly See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/omarkamali/466219030497250</guid></item><item><title>The second point re Ilya post is about RL pain point, i.e. sparse reward. I'm optimistic on this front.</title><link>https://huggingface.co/posts/onekq/883065229185541</link><description>The second point re Ilya post is about RL pain point, i.e. sparse reward. I'm optimistic on this front. Our actions are driven by unspeakable instincts, which left no traces in training set (pretraining or synthetic). These process rewards (motion sensing, vision etc.) help you master new skills quickly, like biking. Outcome reward only (falling off the bike) is indeed too sparse. But lots of tasks can benefit from outcome rewards alone. Many latest RL works to upgrade SQL skills use success-failure reward only, with executable as optional reward. Additionally, scale is the secret sauce for models to surpass humans. A human agent can learn a task quickly, but is capacity limited. But a model agent can process tasks in the scale of many human lifetimes. This made up for the inadequacy of process rewards. Many such tasks happen to be economically viable, i.e. salary-making jobs. See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/883065229185541</guid></item><item><title>We (</title><link>https://huggingface.co/posts/chimbiwide/755549062499957</link><description>We ( @ KeeganC and @ chimbiwide ) are happy to announce that our Gemma3NPC models have reached 2600+ downloads! We welcome anyone to give feedback and advice on our work, we are working hard to create new models and datasets. Visit our organization to check out our work: npcLM See translation</description><pubDate>Mon, 01 Dec 2025 09:33:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/chimbiwide/755549062499957</guid></item></channel></rss>