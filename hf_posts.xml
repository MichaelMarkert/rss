<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Saying Claude 4 is "the best coding model in the world" from the SWEBench scores is super misleading, and here is why:</title><link>https://huggingface.co/posts/clefourrier/447221869970447</link><description>Saying Claude 4 is "the best coding model in the world" from the SWEBench scores is super misleading, and here is why: If you look at the announcement table, their model has the best scores, but... if you look at the very bottom, in font 4, you'll see that the metric they report is actually not the same metric as the one used for the other models! Comparing "pass@1 averaged 10 times" to "normal pass@1" is like grading one student by allowing them to take the test 10 times and averaging question scores, when the other students only get one chance at grading. The first way to grade (avg@10) is actually quite good statistically, much better than what model creators usually report, because models tend to be quite inconsistent - sometimes good, sometimes bad... But! You want to do it for all models then, and report with error bars. The issue is that, if you do... well, it's going to be harder to say your model is the best, because the error bars will overlap between models, by a lot....</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clefourrier/447221869970447</guid></item><item><title>Curated list of **Next Gen Code Generation** papers &amp; benchmarks! 🔥 with 60+ ⭐️ now!</title><link>https://huggingface.co/posts/YerbaPage/971729248373235</link><description>Curated list of **Next Gen Code Generation** papers &amp; benchmarks! 🔥 with 60+ ⭐️ now! Stay ahead with the latest in: ✅ Repo-level Issue Resolution (SWE-bench, Agents) ✅ Repo-level Code Completion (Repo understanding) ✅ Datasets &amp; Benchmarks 👉 Check it out: https://github.com/YerbaPage/Awesome-Repo-Level-Code-Generation 🔥 💡PRs are welcomed! See translation</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/971729248373235</guid></item><item><title>✨ Today we’re releasing Tiny Agents in Python — an MCP-powered Agent in ~70 lines of code 🐍</title><link>https://huggingface.co/posts/celinah/946156020996069</link><description>✨ Today we’re releasing Tiny Agents in Python — an MCP-powered Agent in ~70 lines of code 🐍 Inspired by Tiny Agents in JS from @ julien-c , we ported the idea to Python and integrated it directly into huggingface_hub — with a built-in MCP Client and a Tiny Agents CLI. TL;DR: With MCP (Model Context Protocol), you can expose tools like web search or image generation and connect them directly to LLMs. It’s simple — and surprisingly powerful. pip install "huggingface_hub[mcp]&gt;=0.32.0" We wrote a blog post where we show how to run Tiny Agents, and dive deeper into how they work and how to build your own. 👉 https://huggingface.co/blog/python-tiny-agents See translation</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/celinah/946156020996069</guid></item><item><title>&gt; New Model</title><link>https://huggingface.co/posts/KaraKaraWitch/569360445188531</link><description>&gt; New Model &gt; Looks at Model Card &gt; "Open-Weights" See translation</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/KaraKaraWitch/569360445188531</guid></item><item><title>Uggghhh what a busy week.</title><link>https://huggingface.co/posts/ProCreations/111888750511212</link><description>Uggghhh what a busy week. Been up all night fixing Intellite and I got some progress I wanted to share. ALL errors we experienced (there’s a lot): Gradient vanishing (AI dies) Gradient explosion (AI barely learns and destabilizes) Activation Explosion (AI dies) Layer Scale Crushing Signal (AI dies) Activation Explosion (again) (AI dies) All fixed, but now it keeps overfitting on datasets due to a dataset handler error 😩 See translation</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ProCreations/111888750511212</guid></item><item><title>Here’s what happens when a national institution builds its own digital intelligence: France’s Ministry of Culture just released 17K+ real users testing 30+ chatbots in French. Raw, diverse, and a goldmine for studying LLMs in the wild.</title><link>https://huggingface.co/posts/fdaudens/207889594956018</link><description>Here’s what happens when a national institution builds its own digital intelligence: France’s Ministry of Culture just released 17K+ real users testing 30+ chatbots in French. Raw, diverse, and a goldmine for studying LLMs in the wild. ministere-culture/comparia-conversations See translation</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/207889594956018</guid></item><item><title>🎉🥳 SOTA!!! 🚀👑</title><link>https://huggingface.co/posts/onekq/484907766797591</link><description>🎉🥳 SOTA!!! 🚀👑 🥇 Claude 4 Opus !!🥇 7 months!! ⌛⌛ I thought the day would never come. But here it is. onekq-ai/WebApp1K-models-leaderboard Cost me quite a bit of 💵money 💵 but it is all worth it. Enjoy and make out of this as much as you can! See translation</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/484907766797591</guid></item><item><title>12 Types of JEPA</title><link>https://huggingface.co/posts/Kseniase/646284586461230</link><description>12 Types of JEPA JEPA, or Joint Embedding Predictive Architecture, is an approach to building AI models introduced by Yann LeCun. It differs from transformers by predicting the representation of a missing or future part of the input, rather than the next token or pixel. This encourages conceptual understanding, not just low-level pattern matching. So JEPA allows teaching AI to reason abstractly. Here are 12 types of JEPA you should know about: 1. I-JEPA -&gt; Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture (2301.08243) A non-generative, self-supervised learning framework designed for processing images. It works by masking parts of the images and then trying to predict those masked parts 2. MC-JEPA -&gt; MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features (2307.12698) Simultaneously interprets video data - dynamic elements (motion) and static details (content) - using a shared encoder 3. V-JEPA...</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/646284586461230</guid></item><item><title>🎙️ AI Podcast Generator - Professional Conversation Creation Tool</title><link>https://huggingface.co/posts/openfree/554631338965323</link><description>🎙️ AI Podcast Generator - Professional Conversation Creation Tool 📖 Project Overview Transform any URL, PDF, or keyword into professional podcast conversations automatically! This AI-powered tool creates engaging, expert-level dialogues in minutes. 🚀 openfree/AI-Podcast ✨ Key Features: Multiple Input URL: Web articles, blog posts, news content PDF: Research papers, documents, reports Keywords: Topics like "AI Ethics", "Quantum Computing" 🤖 Smart AI Conversation Generation Local LLM: Mistral-Small 24B model for privacy protection API Fallback: Together AI API support Expert Style: In-depth discussions between host and expert Length: 12-20 exchanges for comprehensive coverage 🌏 Multilingual Support English: Alex (Host) &amp; Jordan (Expert) Korean: Junsu (Host) &amp; Minho (Expert) 🎵 High-Quality Text-to-Speech Edge-TTS: Natural cloud-based voices Spark-TTS: Local AI voice model MeloTTS: GPU-powered local synthesis 🔍 Real-time Information Search Brave Search API for latest information...</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/554631338965323</guid></item><item><title>Hello everyone! Good news!</title><link>https://huggingface.co/posts/yukiarimo/528629553860992</link><description>Hello everyone! Good news! The long-awaited Yuna Ai V4 Miru model was finally released: yukiarimo/yuna-ai-v4-miru Now, she can see both images and videos! She has internal knowledge of multiple languages, including primary English, Japanese, and Russian, and she has a built-in ability for Quantum Thinking! Note that half of the features might be unstable. That’s why, for the next half-year, we will not be writing a dataset; it will be created on the fly as she lives! Eventually, she will learn the needed skills in the upcoming interactions! This is a unique model—the first vision model of Yuna with almost 12B parameters (closer to the atomic version, but smarter)! Weights are already on the hub, and support with good documentation will come in a week. Have fun! Please feel free to drop a little donation for our team to help us buy more Colab Compute Units, as more models are on their way! https://www.patreon.com/c/YukiArimo Thank you guys! See translation</description><pubDate>Sun, 25 May 2025 17:18:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/yukiarimo/528629553860992</guid></item></channel></rss>