<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LLMs can leak their post-training data (RL included) üíß</title><link>https://huggingface.co/posts/anakin87/201202681111752</link><description>LLMs can leak their post-training data (RL included) üíß New interesting paper on this topic from Google DeepMind: Extracting alignment data in open models (2510.18554) It's known that Language Models memorize data that can be extracted via prompting. In this paper, the authors investigate this aspect: - using open models, where prompting can be fully customized by the user, including special tokens. - focusing on open-source models like Olmo, where full training data is available. üì§ How do they extract data? During post-training (like SFT), new tokens such as &lt;|user|&gt; are introduced. The authors hypothesize prompting the model with these tokens can make it output its alignment data (remember Magpie?). For example, for SFT, their extraction prompt is &lt;|endoftext|&gt;&lt;|user|&gt;. üìè Evaluating memorization The authors compare each sampled example with the original data using vector search with embedding similarity. They find that many outputs are semantically very similar to the original...</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/anakin87/201202681111752</guid></item><item><title>Reached 1000+ total downloads across my models and datasets! üéâ</title><link>https://huggingface.co/posts/ronantakizawa/435117440357729</link><description>Reached 1000+ total downloads across my models and datasets! üéâ Follow me for more @ ronantakizawa See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/435117440357729</guid></item><item><title>Hugging Face MCP Server v0.2.45</title><link>https://huggingface.co/posts/evalstate/865812476358807</link><description>Hugging Face MCP Server v0.2.45 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ - New! Experimental dynamic_space tool. - Default Image Generator changed to Qwen-Image-Fast See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/evalstate/865812476358807</guid></item><item><title>This shared notebook comprises the MMLU benchmark evaluating task for my latest reasoning model for the sociology field. The results show that using Few-shot prompting in the system prompt can significantly improve the model's performance at answering questions.</title><link>https://huggingface.co/posts/alibidaran/312503029386627</link><description>This shared notebook comprises the MMLU benchmark evaluating task for my latest reasoning model for the sociology field. The results show that using Few-shot prompting in the system prompt can significantly improve the model's performance at answering questions. Model's link: alibidaran/GRPO_LLAMA3-instructive_reasoning1 Notebook evaluation: https://www.kaggle.com/code/alibidaran/mmlu-socialogy-thinking-evals?scriptVersionId=277240033 See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/alibidaran/312503029386627</guid></item><item><title>The reaction on the QAT post is beyond expectations so below is my optimizer post as promised. But I found that I had lots of explanation to do about optimizer itself. So this post is actually a historical recount. The Muon optimizer  (used by Kimi) post (coming very soon) can only continue after this.</title><link>https://huggingface.co/posts/onekq/566639652632782</link><description>The reaction on the QAT post is beyond expectations so below is my optimizer post as promised. But I found that I had lots of explanation to do about optimizer itself. So this post is actually a historical recount. The Muon optimizer (used by Kimi) post (coming very soon) can only continue after this. https://huggingface.co/blog/onekq/adam-optimizer If you know Adam(W) optimizer already, you can just skip and sorry for the wait. Otherwise, it should be a useful read. See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/566639652632782</guid></item><item><title>Introducing the Japanese honorifics dataset: a dataset with 137 sentences covering the three main keigo forms: Â∞äÊï¨Ë™û (Sonkeigo), Ë¨ôË≠≤Ë™û (Kenj≈çgo), and ‰∏ÅÂØßË™û (Teineigo). Each entry includes the base form, all three honorific transformations, and English translations for essential phrases in Japanese. This dataset is perfect for training and evaluating the Japanese skill level of LLMs.</title><link>https://huggingface.co/posts/ronantakizawa/135864739980663</link><description>Introducing the Japanese honorifics dataset: a dataset with 137 sentences covering the three main keigo forms: Â∞äÊï¨Ë™û (Sonkeigo), Ë¨ôË≠≤Ë™û (Kenj≈çgo), and ‰∏ÅÂØßË™û (Teineigo). Each entry includes the base form, all three honorific transformations, and English translations for essential phrases in Japanese. This dataset is perfect for training and evaluating the Japanese skill level of LLMs. #japanese #japanesedataset ronantakizawa/japanese-honorifics See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/135864739980663</guid></item><item><title>Try the all-new trending Qwen-Image-Edit specialized adapter demos, including Photo-to-Anime, Light Restoration, Multi-Angle Edits, Relighting, and more ‚Äî all in a single Hugging Face Space. Below is the demo link. ü§óüå†</title><link>https://huggingface.co/posts/prithivMLmods/809040430953807</link><description>Try the all-new trending Qwen-Image-Edit specialized adapter demos, including Photo-to-Anime, Light Restoration, Multi-Angle Edits, Relighting, and more ‚Äî all in a single Hugging Face Space. Below is the demo link. ü§óüå† ‚Æû Demo-Space: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast ‚Æû How-to-Use: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast#2 ‚Æû Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/809040430953807</guid></item><item><title>The methods for generating these interesting AI images:</title><link>https://huggingface.co/posts/fd3ffff/556790752142004</link><description>The methods for generating these interesting AI images: 1. Open https://imini.com/ 2. Enter the instruction word. 3. Click "Generate Now". 4. Download, save or share on social media platforms. See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fd3ffff/556790752142004</guid></item><item><title>Developing with ZeroGPU without a PRO account is painful. They give you so many requests at once, but then have like a 24 hour cooldown. I vote less requests in a batch, but then a shorter cooldown.</title><link>https://huggingface.co/posts/nroggendorff/877752190149689</link><description>Developing with ZeroGPU without a PRO account is painful. They give you so many requests at once, but then have like a 24 hour cooldown. I vote less requests in a batch, but then a shorter cooldown. or just less of a cooldown, but i understand if that is not allowed See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/877752190149689</guid></item><item><title>Miragic AI Launches Powerful Text-to-Image and Image-to-Image Generator</title><link>https://huggingface.co/posts/wang12390/554735514138546</link><description>Miragic AI Launches Powerful Text-to-Image and Image-to-Image Generator Miragic has developed an advanced image-generation tool that supports both text-to-image and image-to-image creation, powered by Flux Kontext Dev and the GPT-Image model. The tool performs exceptionally well and has received a large amount of positive customer feedback. Additionally, Miragic offers highly flexible pricing, making it accessible for a wide range of users. https://miragic.ai/products/image-generator See translation</description><pubDate>Sat, 15 Nov 2025 09:22:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wang12390/554735514138546</guid></item></channel></rss>