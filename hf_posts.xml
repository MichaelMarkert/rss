<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Liquid just released two 450M and 1.6B param VLMs!</title><link>https://huggingface.co/posts/mlabonne/575026837446793</link><description>Liquid just released two 450M and 1.6B param VLMs! They're super fast and leverage SigLIP2 NaFlex encoders to handle native resolutions without distortion. It's ideal for on-device deployment in constrained environments like phones. It's available today on Hugging Face, with an inference and a fine-tuning Colab notebooks. LiquidAI/LFM2-VL-450M LiquidAI/LFM2-VL-1.6B See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mlabonne/575026837446793</guid></item><item><title>Introducing the Computer Says No Dataset:</title><link>https://huggingface.co/posts/mrs83/441245217845502</link><description>Introducing the Computer Says No Dataset: ethicalabs/computer-says-no An LLM can do almost anything, but should it? This dataset provides clear examples of when LLMs should decline requests, such as: - Counting characters (e.g., "number of 'r's in 'raspberry'" ‚Äì seriously, you‚Äôve got this) - Solving basic equations (like *5.9 = x + 5.11* ‚Äì please, show that calculator some love) Inspired by Little Britain's iconic "Computer Says No" sketch, we address a critical issue in AI systems today: the waste of using a rocket launcher to swat flies (aka powerful models for trivial tasks). Goals: - Reduce waste by saving compute for tasks that actually need it - Guide users to better tools - Spark discussion about ethical AI This isn‚Äôt a training set. It‚Äôs a provocation: if we don‚Äôt define AI's limits, who will? See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mrs83/441245217845502</guid></item><item><title>Is there a "one-size-fits-all" recipe for quantizing Large Language Models? ü§î</title><link>https://huggingface.co/posts/badaoui/360505768110002</link><description>Is there a "one-size-fits-all" recipe for quantizing Large Language Models? ü§î As part of my ongoing work in mixed-precision quantization, I've been exploring this question by measuring layer-by-layer sensitivity. The goal is to see if we can find universal rules for which layers can be quantized aggressively without impacting performance.The results are fascinating and reveal two key insights: 1Ô∏è‚É£ Sensitivity profiles are like architectural "fingerprints." Models from the same family share strikingly similar sensitivity patterns. As you can see in the charts below for the Gemma and SmolLM families, the ranking and relative sensitivity of the layers remain remarkably consistent. This suggests that the underlying architecture is a primary driver of a model's quantization behavior. 2Ô∏è‚É£ A "universal" mixed-precision quantization strategy is challenging. While models within a family are similar, these "fingerprints" change dramatically when comparing different architectures like LLaMA,...</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/badaoui/360505768110002</guid></item><item><title>Update on</title><link>https://huggingface.co/posts/ovi054/459497213356295</link><description>Update on ovi054/Qwen-Image-LORA ‚ö° You can now load a Qwen LoRA in this space as follows: 1. Model ID: flymy-ai/qwen-image-realism-lora 2. Model link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora 3. Specific file link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /blob/m ain/flymy_realism.safetensors 4. Direct download link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /resolve/m ain/flymy_realism.safetensors You can also use an external .safetensors download link (if Hugging Face doesn‚Äôt block it). It is useful if a model repository contains multiple weights and you want to load a specific one. üëâ Try it now: ovi054/Qwen-Image-LORA See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/459497213356295</guid></item><item><title>Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B &amp; LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU!</title><link>https://huggingface.co/posts/prithivMLmods/730170022133992</link><description>Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B &amp; LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU! ‚Üó LFM2-VL-1.6B-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-1.6B-LiquidAI/LFM2-VL-1.6B_ReportLab.ipynb ‚Üó LFM2-VL-450M-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-450M-LiquidAI/LFM2-VL-450M_ReportLab.ipynb . . . To know more about it, visit the multimodal outpost notebooks !! See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/730170022133992</guid></item><item><title>So you can now SFT a model with hf jobs + TRL in ONE command lol üèéÔ∏èüí®</title><link>https://huggingface.co/posts/sergiopaniego/261394982300861</link><description>So you can now SFT a model with hf jobs + TRL in ONE command lol üèéÔ∏èüí® Without worrying about infrastructure since it runs entirely on HF! docs: https://huggingface.co/docs/huggingface_hub/main/en/guides/jobs blog: https://huggingface.co/blog/hf-cli See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/261394982300861</guid></item><item><title>No, I did not create those bots that just got banned today.</title><link>https://huggingface.co/posts/nroggendorff/812423234168314</link><description>No, I did not create those bots that just got banned today. See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/812423234168314</guid></item><item><title>‚úÖ New Article: *Media as Cognitive Infrastructure*</title><link>https://huggingface.co/posts/kanaria007/811473012655185</link><description>‚úÖ New Article: *Media as Cognitive Infrastructure* Title: üì∞ Protocolic Media: Structured Intelligence and the Future of Cognitive Environments üîó https://huggingface.co/blog/kanaria007/protocolic-media --- Summary: Media doesn‚Äôt just *deliver content* ‚Äî it *shapes how collective thought moves*. Every feed, stream, and algorithm is *a scaffold for attention and reasoning*, determining *what we notice, connect, and forget*. Structured Intelligence reframes media as *cognitive infrastructure*: not passive transmission, but *active architecture for collective reasoning*. &gt; Media isn‚Äôt flow ‚Äî &gt; *it‚Äôs the frame of shared cognition.* --- Why It Matters: ‚Ä¢ Modern media amplifies *bias, noise, and cognitive drift* ‚Ä¢ Traditional moderation reacts *after harm occurs* ‚Ä¢ Structured approaches support: * *Traceable content flows with coherence checks* * *Ethical filtering without black‚Äëbox censorship* * *Reflective scaffolds that encourage deliberate reasoning* --- What‚Äôs Inside: ‚Ä¢ Media reframed...</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/811473012655185</guid></item><item><title>It's just a matter of time before all the data leakage and data scraping associated with building, training, and using AI results in some kind of major scandal.</title><link>https://huggingface.co/posts/ZennyKenny/202723059163333</link><description>It's just a matter of time before all the data leakage and data scraping associated with building, training, and using AI results in some kind of major scandal. That's why I think this paper by @ spintronic is so important: Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN (2508.06647) Glad to know that there are already researchers looking to mitigate and address this risk before the s**t hits the fan. See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/202723059163333</guid></item><item><title>Decoding the Shift and Diffusion Models Training Like Qwen Image, FLUX, SDXL, and More :</title><link>https://huggingface.co/posts/MonsterMMORPG/285728110006184</link><description>Decoding the Shift and Diffusion Models Training Like Qwen Image, FLUX, SDXL, and More : https://huggingface.co/blog/MonsterMMORPG/decoding-the-shift-and-diffusion-models-training Full article : https://huggingface.co/blog/MonsterMMORPG/decoding-the-shift-and-diffusion-models-training Hopefully I am going to focus on Qwen Image training tutorial and 1-click installers with GUI and presets starting from this week. So here some important info. You don't need to know, learn or understand this but this is for people who wants to learn and understand more. See translation</description><pubDate>Thu, 14 Aug 2025 17:21:42 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/285728110006184</guid></item></channel></rss>