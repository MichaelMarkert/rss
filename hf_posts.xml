<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>üî• AgenticAI: The Ultimate Multimodal AI with 16 MBTI Girlfriend Personas! üî•</title><link>https://huggingface.co/posts/seawolf2357/796388354612946</link><description>üî• AgenticAI: The Ultimate Multimodal AI with 16 MBTI Girlfriend Personas! üî• Hello AI community! Today, our team is thrilled to introduce AgenticAI, an innovative open-source AI assistant that combines deep technical capabilities with uniquely personalized interaction. üíò üõ†Ô∏è MBTI 16 Types SPACES Collections link seawolf2357/heartsync-mbti-67f793d752ef1fa542e16560 ‚ú® 16 MBTI Girlfriend Personas Complete MBTI Implementation: All 16 MBTI female personas modeled after iconic characters (Dana Scully, Lara Croft, etc.) Persona Depth: Customize age groups and thinking patterns for hyper-personalized AI interactions Personality Consistency: Each MBTI type demonstrates consistent problem-solving approaches, conversation patterns, and emotional expressions üöÄ Cutting-Edge Multimodal Capabilities Integrated File Analysis: Deep analysis and cross-referencing of images, videos, CSV, PDF, and TXT files Advanced Image Understanding: Interprets complex diagrams, mathematical equations, charts, and...</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/796388354612946</guid></item><item><title>I have made a Rust project with integration of the latest state-of-the-art model for object detection, it outperforms YOLO!</title><link>https://huggingface.co/posts/Yehor/936075739202200</link><description>I have made a Rust project with integration of the latest state-of-the-art model for object detection, it outperforms YOLO! Check it out: https://github.com/egorsmkv/rf-detr-usls See translation</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Yehor/936075739202200</guid></item><item><title>Shanghai AI Lab - OpenGV team just released InternVL3 üî•</title><link>https://huggingface.co/posts/AdinaY/929657833669065</link><description>Shanghai AI Lab - OpenGV team just released InternVL3 üî• OpenGVLab/internvl3-67f7f690be79c2fe9d74fe9d ‚ú® 1/2/8/9/14/38/28B with MIT license ‚ú® Stronger perception &amp; reasoning vs InternVL 2.5 ‚ú® Native Multimodal Pre-Training for even better language performance See translation</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/929657833669065</guid></item><item><title>üá∑üá∫ Russian Forum Messages Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/381466531674007</link><description>üá∑üá∫ Russian Forum Messages Dataset - nyuuzyou/ruforum Collection of approximately 58 million Russian forum messages featuring: - Complete message content from Russian online forums spanning 2010-2025 - Comprehensive metadata including unique message IDs and timestamps - Full text content preserving original user discussions and interactions - Monolingual dataset focused exclusively on Russian language content This dataset offers a unique textual archive of Russian online conversations suitable for text generation, sentiment analysis, and language modeling research. Released to the public domain under CC0 1.0 license. See translation</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/381466531674007</guid></item><item><title>**Video**:</title><link>https://huggingface.co/posts/JLouisBiz/947336957437059</link><description>**Video**: https://www.youtube.com/watch?v=jRKRsGsLfW0 **Integrating large language model with file manager to describe your illegally downloaded movies.** When you have a bunch of movies downloaded by Torrent, you maybe want a description and description is missing. This video shows how you can use the script to invoke the large language model. And then you get a description of a movie in a second or three. See translation</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JLouisBiz/947336957437059</guid></item><item><title>Super grateful to</title><link>https://huggingface.co/posts/odellus/648294233512756</link><description>Super grateful to @ marriola for the release of the block diffusion code and model. I'm generating text with diffusion locally! Couldn't be more pleased. See translation</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/odellus/648294233512756</guid></item><item><title>PiFlash</title><link>https://huggingface.co/posts/S-Dreamer/228566884248971</link><description>PiFlash A simple web-based tool to flash Raspberry Pi OS images to your SD cards. No additional software required! S-Dreamer/piflash See translation</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/S-Dreamer/228566884248971</guid></item><item><title>Article:</title><link>https://huggingface.co/posts/JLouisBiz/528734483774826</link><description>Article: https://huggingface.co/blog/JLouisBiz/semantical-website-links You don't need to do the tedious work of finding all those links on your huge website. Automating semantic links on websites using Large Language Models (LLMs) enhances user experience and efficiency. Here's a simplified workflow: 1. Store LLM embeddings in PostgreSQL: Use the vector data type to store text embeddings generated by an LLM. 2. Divide page texts into chunks for processing. 3. Generate embeddings using an LLM for each chunk of text. 4. Create template markup around specific terms needing links. An automated program then: - Converts marked-up terms to their corresponding LLMs' embeddings, - Compares these with stored database embeddings (using cosine similarity), - Identifies the most relevant page based on highest similarity score, and - Automatically adds a link from the original content to this contextually related information. This process improves navigation by directing users to highly...</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JLouisBiz/528734483774826</guid></item><item><title>I'm looking for a YouTube video summarizer to run locally.  I did a search, but all of the models and spaces I was able to find here didn't work, which I find surprising, since it's a great tool I already use.  Perhaps one of you can provide a better option, or just tell me what this actually is to get it:</title><link>https://huggingface.co/posts/Fishtiks/595357291314987</link><description>I'm looking for a YouTube video summarizer to run locally. I did a search, but all of the models and spaces I was able to find here didn't work, which I find surprising, since it's a great tool I already use. Perhaps one of you can provide a better option, or just tell me what this actually is to get it: https://dev.gptcall.pages.dev/chat#id=&amp;contactName=Youtube+summarizer Other functionality I'd like to see is a genre-based music creation and alteration model. "Make it country" or "do a freestyle rap," as examples. I'm willing to work with someone on this, because I'd need help understanding. I'd also like to make medical AI, like Dr. Samantha, that functions like a PDR well, and doesn't get confused by drug names. See translation</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Fishtiks/595357291314987</guid></item><item><title>It looks like Llama 4 team gamed the LMArena benchmarks by making their Maverick model output emojis, longer responses and ultra high enthusiasm! Is that ethical or not? They could certainly do a better job by working with teams like llama.cpp, just like Qwen team did with Qwen 3 before releasing the model.</title><link>https://huggingface.co/posts/etemiz/726325088198598</link><description>It looks like Llama 4 team gamed the LMArena benchmarks by making their Maverick model output emojis, longer responses and ultra high enthusiasm! Is that ethical or not? They could certainly do a better job by working with teams like llama.cpp, just like Qwen team did with Qwen 3 before releasing the model. In 2024 I started playing with LLMs just before the release of Llama 3. I think Meta contributed a lot to this field and still contributing. Most LLM fine tuning tools are based on their models and also the inference tool llama.cpp has their name on it. The Llama 4 is fast and maybe not the greatest in real performance but still deserves respect. But my enthusiasm towards Llama models is probably because they rank highest on my AHA Leaderboard: https://sheet.zoho.com/sheet/open/mz41j09cc640a29ba47729fed784a263c1d08 Looks like they did a worse job compared to Llama 3.1 this time. Llama 3.1 has been on top for a while. Ranking high on my leaderboard is not correlated to...</description><pubDate>Mon, 14 Apr 2025 05:23:20 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/726325088198598</guid></item></channel></rss>