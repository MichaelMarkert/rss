<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Just released a preview of Moondream 3!</title><link>https://huggingface.co/posts/vikhyatk/428307575853218</link><description>Just released a preview of Moondream 3! moondream/moondream3-preview This is a 9B parameter, 2B active MoE VLM with state of the art visual reasoning capabilities. More details in the release blog post: https://moondream.ai/blog/moondream-3-preview See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/vikhyatk/428307575853218</guid></item><item><title>Reproducing research code shouldn't take longer than reading the paper.</title><link>https://huggingface.co/posts/salma-remyx/494327094243098</link><description>Reproducing research code shouldn't take longer than reading the paper. For papers that include code, setting up the right environment often means hours of dependency hell and configuration debugging. At Remyx AI, we built an agent that automatically creates and tests Docker images for research papers, then shares them publicly so anyone can reproduce results with a single command. We just submitted PR #908 to integrate this directly into arXiv Labs. If you believe in making reproducible research accessible to everyone, give it a bump!: https://github.com/arXiv/arxiv-browse/pull/908 See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/494327094243098</guid></item><item><title>The Bias is YOU - LLMs Mirror Your Own Assumptions</title><link>https://huggingface.co/posts/Tanaybh/360553614352968</link><description>The Bias is YOU - LLMs Mirror Your Own Assumptions AI doesn't just have bias - it reflects yours. When you ask a question with positive framing, you get positive answers. Ask with negative framing, you get negative answers. The AI becomes a mirror of your own assumptions. Your framing determines the answer - The same topic yields opposite responses based on how you ask AIs amplify your sentiment - Negative questions often get even MORE negative responses This affects everyone - From students doing research to professionals making decisions Why This Matters This isn't a technical glitch - it's fundamental to how these systems work. They're trained on human language, and humans frame things with bias. The AI learned to match that framing. Think about the implications: - Medical professionals seeking second opinions - Students researching controversial topics - Business leaders evaluating strategies - Anyone using AI for important decisions The Stochastic Mirror Effect Let's call this...</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Tanaybh/360553614352968</guid></item><item><title>Mark you calendars for Thursday Sept 25th at 9am PST üìÜ</title><link>https://huggingface.co/posts/salma-remyx/278519022250698</link><description>Mark you calendars for Thursday Sept 25th at 9am PST üìÜ We're joining the @ ag2 team in discord to present a deep-dive into how we've used the framework to build GitRank in their Community Talks The GitRank pipeline is used to: üì∞ power personalized paper recommendations üê≥ build environments as Docker Images üéØ implement core-methods as PRs for your target repo Attached is a draft outlining what we plan to cover in the talk. Would love to gather your feedback to make this insightful for all: https://docs.google.com/presentation/d/1S0q-wGCu2dliVWb9ykGKFz61jZKZI4ipxWBv73HOFBo/edit?usp=sharing See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/278519022250698</guid></item><item><title>Are we really back to storing access tokens in plain text again?</title><link>https://huggingface.co/posts/takarajordan/879360274479598</link><description>Are we really back to storing access tokens in plain text again? { "mcpServers" : { "hf-mcp-server" : { "url" : "https://huggingface.co/mcp" , "headers" : { "Authorization" : "Bearer &lt;YOUR_HF_TOKEN&gt;" } } } } See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/takarajordan/879360274479598</guid></item><item><title>Turn Your Dog‚Äôs Photo into a 3D Figurine with Nano Banana üê∂‚ú®</title><link>https://huggingface.co/posts/Monica997/115477940297105</link><description>Turn Your Dog‚Äôs Photo into a 3D Figurine with Nano Banana üê∂‚ú® Just tested out the new Nano Banana feature, and I‚Äôm honestly impressed. I uploaded a single photo of my corgi, and within minutes, it generated a detailed 3D figurine model. What makes this really interesting for tech and design folks: AI-powered 2D ‚Üí 3D conversion (no manual modeling required) Preserves character consistency even with multiple images Export options for 3D printing or digital use (OBJ, FBX, STL) Works with pets, people, and even illustrated characters For anyone into 3D modeling, collectibles, or architecture visualization, this is a game-changer. Imagine transforming static photos into tangible 3D assets with just a few clicks. Here‚Äôs the link if you want to try it out: https://imini.com/nano-banana Has anyone else here tested Nano Banana for pets or other personal projects? Would love to hear your results! See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Monica997/115477940297105</guid></item><item><title>Many of 'em pinged me asking to make the</title><link>https://huggingface.co/posts/prithivMLmods/792537677776345</link><description>Many of 'em pinged me asking to make the nano-banana-aio to available on hf.co/spaces, so I‚Äôve transferred the app‚Äôs tech stack to make it compatible for deployment on Spaces. (Can be accessed with your own Gemini API) ü§ó‚≠êÔ∏è ‚ú¶ Yes, it is now available on Spaces: prithivMLmods/Nano-Banana-AIO Nano Banana AIO (All-in-One) App, which offers seamless image manipulation features, including single/multiple image adaptation, a canvas for free-style drawing to creative image generation, and standard text-to-image generation. All in One Banana for you! üòâ See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/792537677776345</guid></item><item><title>Gradio 6.0 is launching this year!</title><link>https://huggingface.co/posts/freddyaboulton/832825198188069</link><description>Gradio 6.0 is launching this year! We're revamping the core to give you performance improvements and unprecedented customization. Build better, faster. Check out the GitHub milestone to learn what's planned under the hood! https://github.com/gradio-app/gradio/issues?q=is:issue%20state:open%20milestone:%22Gradio%206%22 See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/freddyaboulton/832825198188069</guid></item><item><title>Announcing our new work on "Repository Level Question Answering"! üéâ</title><link>https://huggingface.co/posts/YerbaPage/735409135497339</link><description>Announcing our new work on "Repository Level Question Answering"! üéâ We introduce SWE-QA, a repository-level code QA benchmark with 576 real-world questions that require a deep understanding of the entire codebase to answer. Curious about the limits of today's LLMs on complex codebases? Check out our paper and open-source data! üíªüß† Link üëá https://arxiv.org/pdf/2509.14635 https://github.com/peng-weihan/SWE-QA-Bench #LLM #AI #SoftwareEngineering #Benchmark See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/735409135497339</guid></item><item><title>‚ö° Big things are moving.</title><link>https://huggingface.co/posts/dimentox/564176458705801</link><description>‚ö° Big things are moving. Witchborn Systems (newly recognized nonprofit) is forging the cornerstone of something we believe the world needs: a **public, governed AI layer**. Not closed. Not for sale. Not hidden. A Constitutional Layer for AI ‚Äî transparent, amendable, incorruptible. Every decision logged, every amendment public, every voice accountable. This is only the beginning. The Codex is open. The forge is hot. üî• #AI #Transparency #CollectiveIntelligence #Nonprofit #Witchborn See translation</description><pubDate>Sat, 20 Sep 2025 09:20:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dimentox/564176458705801</guid></item></channel></rss>