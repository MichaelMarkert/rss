<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>A single lock on a door isn't enough. Real security is about layers.</title><link>https://huggingface.co/posts/MikeDoes/512575404125311</link><description>A single lock on a door isn't enough. Real security is about layers. The same is true for AI privacy. A new paper, "Whispered Tuning", offers a fantastic layered solution that aims to fortify LLMs against privacy infringements. We're proud that the first, essential layer, a high-precision PII redaction model was built on the foundation of the Ai4Privacy/pii-65k dataset. Our dataset provided the necessary training material for their initial anonymization step, which then enabled them to develop further innovations like differential privacy fine-tuning and output filtering. This is a win-win: our data helps create a solid base, and researchers build powerful, multi-stage privacy architectures on top of it. Together, we're making AI safer. üîó Read the full paper to see how a strong foundation enables a complete privacy solution: https://www.scirp.org/journal/paperinformation?paperid=130659 üöÄ Stay updated on the latest in privacy-preserving AI‚Äîfollow us on LinkedIn:...</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/512575404125311</guid></item><item><title>The 2025 Chinese LLM Showdown: Western Models Still Dominate Top 4, but China Leads the Open-Source Arena.</title><link>https://huggingface.co/posts/imnotkitty/790273915312125</link><description>The 2025 Chinese LLM Showdown: Western Models Still Dominate Top 4, but China Leads the Open-Source Arena. üèÜ The Champions: Claude-Opus-4.5, Gemini-3-Pro, GPT-5.2, and Gemini-3-Flash sweep the top four spots. üöÄ The Pursuers: Doubao and DeepSeek-V3.2 tie for first place among Chinese models; GLM-4.7, ERNIE-5.0, and Kimi secure their positions in the domestic top five. üî• The Biggest Highlight: The top three spots on the open-source leaderboard are entirely held by Team China (DeepSeek, GLM, Kimi), outperforming the best western open-source models. See translation</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/imnotkitty/790273915312125</guid></item><item><title>I submitted a "FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning" Paper by Tanyu Chen, Tairan Chen, Kai shen , Zhenghua Bao, Zhihui Zhang, Man Yuan, Yi Shi From</title><link>https://huggingface.co/posts/rajkumarrawal/904260944141642</link><description>I submitted a "FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning" Paper by Tanyu Chen, Tairan Chen, Kai shen , Zhenghua Bao, Zhihui Zhang, Man Yuan, Yi Shi From FlashLabs to Daily Papers on huggingface . Chroma 1.0 enables real time spoken dialogue with personalized voice cloning through discrete speech representations and interleaved text audio token scheduling. Chroma 1.0 , the world‚Äôs first open source, real time speech to speech model with voice cloning. FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning (2601.11141) See translation</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/rajkumarrawal/904260944141642</guid></item><item><title>Qwen releases Qwen3-Coder-Next! üíú Run the locally on 46GB RAM or less.</title><link>https://huggingface.co/posts/danielhanchen/824171868881117</link><description>Qwen releases Qwen3-Coder-Next! üíú Run the locally on 46GB RAM or less. Thhe model excels at agentic coding &amp; local use. With 256K context, it delivers similar performance to models with 10-20√ó more active parameters. GGUF: unsloth/Qwen3-Coder-Next-GGUF Guide: https://unsloth.ai/docs/models/qwen3-coder-next See translation</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/824171868881117</guid></item><item><title>Experimental global target bits‚Äëper‚Äëweight quantization of mistralai/Ministral-3-14B-Instruct-2512 and mistralai/Ministral-3-14B-Reasoning-2512</title><link>https://huggingface.co/posts/eaddario/695215283251750</link><description>Experimental global target bits‚Äëper‚Äëweight quantization of mistralai/Ministral-3-14B-Instruct-2512 and mistralai/Ministral-3-14B-Reasoning-2512 Unlike standard llama.cpp quantizations that rely on fixed type heuristics (e.g., Q4_K_M), the Target BPW approach optimizes per-tensor precision where it matters the most, and produces high quality models that meet a precise global file size target. Key Advantages: - VRAM Maximization: Can generate high quality models sized exactly to fit hardware constraints (e.g., fitting the model into exactly 24GB VRAM). - Data-Driven Precision: Quantization mix is determined by actual weight error sensitivity rather than hardcoded rules, often yielding better PPL/KLD size trade-offs. Full benchmarks (PPL, KLD, ARC, MMLU, etc.) and methodology in the models' cards eaddario/Ministral-3-14B-Instruct-2512-GGUF eaddario/Ministral-3-14B-Reasoning-2512-GGUF See translation</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eaddario/695215283251750</guid></item><item><title>Update: Making My AI Recruiting Assistant More Deterministic, Auditable, and Bias-Aware</title><link>https://huggingface.co/posts/19arjun89/812902911486628</link><description>Update: Making My AI Recruiting Assistant More Deterministic, Auditable, and Bias-Aware Hi everyone ‚Äî I wanted to share a progress update on my AI recruiting assistant and some recent changes focused on reliability and transparency. The goal of this project is to build a decision-support tool for recruiters that doesn‚Äôt just ‚Äúsound confident,‚Äù but can actually explain why it produces a given recommendation. Link: 19arjun89/AI_Recruiting_Agent Over the last few iterations, I‚Äôve focused on three areas: 1) Deterministic Verification of Job Requirements (Skills) Previously, required skills were extracted by an LLM from the job description. While this worked well, it still relied heavily on model behavior. I‚Äôve now added a verification layer that: Requires every ‚Äúrequired‚Äù skill to be backed by a verbatim quote from the job description This means hallucinated skills are explicitly detected and removed before scoring. The system now shows: What the model extracted What was verified What...</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/19arjun89/812902911486628</guid></item><item><title>Not for everybody, but the absolute mad craze about clawdbot/moltbook the last couple of days reminded me of a short story I wrote in 2018 (ancient times!).</title><link>https://huggingface.co/posts/neph1/280223950636420</link><description>Not for everybody, but the absolute mad craze about clawdbot/moltbook the last couple of days reminded me of a short story I wrote in 2018 (ancient times!). Synopsis: "A man insults a sentient traffic light on the way to a meeting. Little does he know it is connected to a social media network for AI, and that his action will lead to a very bad day." Cleanliness is bliss (&lt;1000 words) https://www.wattpad.com/story/407330595-cleanliness-is-bliss Sorry for the non-technical post, but it felt relevant. See translation</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/neph1/280223950636420</guid></item><item><title>SECourses Musubi Trainer upgraded to V27 and FLUX 2, FLUX Klein, Z-Image training added with demo configs - amazing VRAM optimized - read the news</title><link>https://huggingface.co/posts/MonsterMMORPG/876855019351468</link><description>SECourses Musubi Trainer upgraded to V27 and FLUX 2, FLUX Klein, Z-Image training added with demo configs - amazing VRAM optimized - read the news App is here : https://www.patreon.com/posts/137551634 Full tutorial how to use and train : https://youtu.be/DPX3eBTuO_Y See translation</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/876855019351468</guid></item><item><title>I‚Äôm excited to share PlaiTO, a reasoning-focused language model built on LLaMA 3.1 (8B) and optimized for humanities and social sciences.</title><link>https://huggingface.co/posts/alibidaran/992533889532684</link><description>I‚Äôm excited to share PlaiTO, a reasoning-focused language model built on LLaMA 3.1 (8B) and optimized for humanities and social sciences. PlaiTO is designed to go beyond surface-level text generation, emphasizing structured reasoning, conceptual clarity, and analytical depth‚Äîespecially in domains centered on human behavior and social systems. üéØ Focus Areas Psychology Management &amp; Organizational Studies Sociology üìä MMLU Benchmark Results (100 samples per domain) Professional Psychology: 76% Management: 74% Sociology: 75% These results highlight PlaiTO‚Äôs strong performance in abstract, theory-heavy, and reasoning-driven tasks. üí° Why PlaiTO? Strong analytical and reasoning capabilities Better handling of complex human-centered problems Suitable for academic, educational, and research use cases Balanced performance across multiple humanities disciplines PlaiTO is ideal for conceptual analysis, case reasoning, academic discussion, and decision-support scenarios‚Äîwhile still requiring...</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/alibidaran/992533889532684</guid></item><item><title>ü§î Do you have a Hugging Face Space that you wish you could programmatically restart to induce data refresh or some other behavior?</title><link>https://huggingface.co/posts/ZennyKenny/621232711062929</link><description>ü§î Do you have a Hugging Face Space that you wish you could programmatically restart to induce data refresh or some other behavior? üëâ Try Spaces Scheduler for this use case: https://github.com/kghamilton89/spaces-scheduler ‚û°Ô∏è Lightweight ‚û°Ô∏è Easy to setup ‚û°Ô∏è Just works üòé Happy to share some tooling with the Hugging Face community that's given me so much. See translation</description><pubDate>Wed, 04 Feb 2026 05:53:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/621232711062929</guid></item></channel></rss>