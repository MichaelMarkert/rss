<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>11 Fascinating new Policy Optimization techniques</title><link>https://huggingface.co/posts/Kseniase/468043722468280</link><description>11 Fascinating new Policy Optimization techniques Policy optimization (PO) algorithms are central to training AI models with preference-based feedback. In recent weeks, numerous new PO methods have emerged that build on or replace the popular PPO and GRPO, solving their issues. Here are 11 of them: 1. BAlanced Policy Optimization (BAPO) â†’ BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping (2510.18927) Dynamically adjusting the clipping bounds in PPO-style updates to balance positive and negative gradients and prevent entropy collapse 2. Training-Free GRPO â†’ Training-Free Group Relative Policy Optimization (2510.08191) Instead of using numeric rewards, it compares rollouts semantically to distill useful knowledge as a token prior, which is then applied during inference to guide the modelâ€™s behavior 3. Asymmetric Importance Sampling Policy Optimization (ASPO) â†’ ASPO: Asymmetric Importance Sampling Policy Optimization...</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/468043722468280</guid></item><item><title>Experience the future of fashion with our AI-powered virtual try-on technology. See how clothes look on anyone instantly, create realistic outfit visualizations, and mix-and-match styles with unprecedented accuracy.</title><link>https://huggingface.co/posts/wang12390/323744389614625</link><description>Experience the future of fashion with our AI-powered virtual try-on technology. See how clothes look on anyone instantly, create realistic outfit visualizations, and mix-and-match styles with unprecedented accuracy. https://miragic.ai/products/virtual-try-on See translation</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wang12390/323744389614625</guid></item><item><title>Multilingual Tokenization Showdown</title><link>https://huggingface.co/posts/Norod78/977626760436669</link><description>Multilingual Tokenization Showdown Analyzing 12 LLM Tokenizers Across 204 Languages. First, I've created a dataset with Wikipedia's "Cat" article text in 272 languages: Norod78/WikiCat-Multilingual For each language entry with at least 100 words, I tokenized the text using 12 tokenizers and calculated the "Characters per token" ratio and "Word per token" ratio. The higher this ratio is, the more information each token represents on average for that language (and perhaps allowing the llm to potentially learn more per-parameter if trained on a dataset of that language). You can see a slideshow summary of the results here: https://norod.github.io/wikicat-tokenizer-eval/tokenizer-slideshow.html I hope I interpreted the results correctly, I've made the code available on GitHub so you can re-create the raw results jsonl with this repo: https://github.com/Norod/wikicat-tokenizer-eval Post on X: https://x.com/Norod78/status/1984366900550266999 See translation</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Norod78/977626760436669</guid></item><item><title>Why I think local, open-source models will eventually win.</title><link>https://huggingface.co/posts/abidlabs/941146046599374</link><description>Why I think local, open-source models will eventually win. The most useful AI applications are moving toward multi-turn agentic behavior: systems that take hundreds or even thousands of iterative steps to complete a task, e.g. Claude Code, computer-control agents that click, type, and test repeatedly. In these cases, the power of the model is not how smart it is per token, but in how quickly it can interact with its environment and tools across many steps. In that regime, model quality becomes secondary to latency. An open-source model that can call tools quickly, check that the right thing was clicked, or verify that a code change actually passes tests can easily outperform a slightly â€œsmarterâ€ closed model that has to make remote API calls for every move. Eventually, the balance tips: it becomes impractical for an agent to rely on remote inference for every micro-action. Just as no one would tolerate a keyboard that required a network request per keystroke, users wonâ€™t accept...</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/941146046599374</guid></item><item><title>I am dedicating this weekend to practicing/reading the latest b(ook)log from hugging face. It is meant to be a guide for anyone trying to go from â€œwe have a great dataset and GPUsâ€ to â€œwe built a really strong model.â€ Will share thoughts upon completion.</title><link>https://huggingface.co/posts/Shivansh000/941986646578616</link><description>I am dedicating this weekend to practicing/reading the latest b(ook)log from hugging face. It is meant to be a guide for anyone trying to go from â€œwe have a great dataset and GPUsâ€ to â€œwe built a really strong model.â€ Will share thoughts upon completion. Thanks for the treat @ eliebak @ ThomasWolf and HF team! HuggingFaceTB/smol-training-playbook See translation</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Shivansh000/941986646578616</guid></item><item><title>After training ğ’ğ¦ğ¨ğ¥ğ‹ğŒğŸ‘ on ğŸ‘ğŸ–ğŸ’ ğ‡ğŸğŸğŸğ¬ for nearly a month, I've come to realize something most people overlook: ğ¢ğ§ğŸğ«ğšğ¬ğ­ğ«ğ®ğœğ­ğ®ğ«ğ ğ¢ğ¬ ğ­ğ¡ğ ğ¦ğšğ¤ğ-ğ¨ğ«-ğ›ğ«ğğšğ¤ ğŸğšğœğ­ğ¨ğ« ğ¢ğ§ ğ‹ğ‹ğŒ ğ­ğ«ğšğ¢ğ§ğ¢ğ§ğ . ğŸ”¥</title><link>https://huggingface.co/posts/nouamanetazi/972464132222376</link><description>After training ğ’ğ¦ğ¨ğ¥ğ‹ğŒğŸ‘ on ğŸ‘ğŸ–ğŸ’ ğ‡ğŸğŸğŸğ¬ for nearly a month, I've come to realize something most people overlook: ğ¢ğ§ğŸğ«ğšğ¬ğ­ğ«ğ®ğœğ­ğ®ğ«ğ ğ¢ğ¬ ğ­ğ¡ğ ğ¦ğšğ¤ğ-ğ¨ğ«-ğ›ğ«ğğšğ¤ ğŸğšğœğ­ğ¨ğ« ğ¢ğ§ ğ‹ğ‹ğŒ ğ­ğ«ğšğ¢ğ§ğ¢ğ§ğ . ğŸ”¥ Everyone talks about model architecture and data quality. And yes, those matter immensely. But here's what nobody tells you: when your training run fails at 2 AM because of mysterious ğğ‚ğ‚ğ‹ ğğ«ğ«ğ¨ğ«ğ¬, or when your expensive GPU cluster is running at ğŸ”ğŸ% ğğŸğŸğ¢ğœğ¢ğğ§ğœğ², the problem isn't your model. It's most probably a ğ¦ğ¢ğ¬ğ®ğ¬ğ ğ¨ğŸ ğ­ğ¡ğ ğ¡ğšğ«ğğ°ğšğ«ğ. ğŸ› ï¸ Questions that seemed simple but had no clear answers: Why is ğŒğ¨ğ„ ğ­ğ«ğšğ¢ğ§ğ¢ğ§ğ  ğ¬ğ¥ğ¨ğ°ğğ« ğ­ğ¡ğšğ§ ğğğ§ğ¬ğ ğ¦ğ¨ğğğ¥ğ¬? Which ğğ‚ğ‚ğ‹ ğŸğ¥ğšğ ğ¬ should we actually set? How often should we checkpoint without killing throughput? That's why we built ğ“ğ¡ğ ğ’ğ¦ğ¨ğ¥ ğ“ğ«ğšğ¢ğ§ğ¢ğ§ğ  ğğ¥ğšğ²ğ›ğ¨ğ¨ğ¤ ğŸ“–: a complete guide covering everything from model architecture and data curation to the SmolLM3 training marathon, post-training techniques, and crucially, the ğ¢ğ§ğŸğ«ğšğ¬ğ­ğ«ğ®ğœğ­ğ®ğ«ğ ğ¥ğšğ²ğğ« that most teams get wrong. We validated real vs...</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nouamanetazi/972464132222376</guid></item><item><title>New Datasets Published:</title><link>https://huggingface.co/posts/unmodeled-tyler/973176037226952</link><description>New Datasets Published: vanta-research/poetic-imagery-small vanta-research/excitement-small We are open sourcing two of our datasets today, which were used in the training of Apollo Astralis 8B and 4B. The first dataset, poetic-imagery-small is designed to give the model's responses a bit of "depth" to them in order to encourage curiosity and thought from the user. Additionally, the excitement-small dataset is designed to teach the model how to use "excited" language conversationally. This dataset was used on both Apollo Astralis models, which effectively demonstrate general excitement during user interaction. VANTA Research is an AI safety project which aims to research and develop language models aligned for all types of thinking. These datasets were created aligned with that mission, in addition to rigorous AI safety standards. See translation</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/973176037226952</guid></item><item><title>Some weeks ago, i've just decide its time to leave LinkedIn for me.</title><link>https://huggingface.co/posts/flozi00/890663421107803</link><description>Some weeks ago, i've just decide its time to leave LinkedIn for me. It got silent around my open source activities the last year, so i thought something has to change. That's why my focus will move to share experiences and insights about hardware, drivers, kernels and linux. I won't post about how to use models, built agents or do prompting. I want to share about some deeper layers the actual hypes are built on. I will start posting summarizations of my articles here on the hub. English version: https://flozi.net/en German translated version: https://flozi.net/de Feel free to reach me if you want to read something specific. See translation</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/flozi00/890663421107803</guid></item><item><title>The 1 Billion Token Challenge: Finding the Perfect Pre-training Mix</title><link>https://huggingface.co/posts/codelion/338248148684079</link><description>The 1 Billion Token Challenge: Finding the Perfect Pre-training Mix We trained a GPT-2 model to 90%+ performance using just 1/10th the training data through 50+ systematic experiments on dataset mixing strategies. Key Finding: A static mix of 50% finePDFs + 30% DCLM-baseline + 20% FineWeb-Edu consistently outperforms complex curriculum learning approaches. Static mixing is simpler, faster, and avoids catastrophic failures from hard distribution shifts. Results: Our GPT-2-70M model (70M parameters, 1B tokens) scores 38.15% on benchmarks vs GPT-2's 39.13% - only 0.98 points behind despite 10x less data and 44% fewer parameters. It even beats GPT-2 on TruthfulQA (47.31% vs 40.69%). The takeaway: careful dataset curation matters more than total data volume. Model: codelion/gpt-2-70m Datasets: https://huggingface.co/collections/codelion/pre-training-dataset-samples Full blog: https://huggingface.co/blog/codelion/optimal-dataset-mixing See translation</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/338248148684079</guid></item><item><title>Radar data for experimentation: Access real radar datasets and expert support to build AI/ML solutions using radar data.</title><link>https://huggingface.co/posts/InezCornell/148411333647765</link><description>Radar data for experimentation: Access real radar datasets and expert support to build AI/ML solutions using radar data. Ideal for companies looking to add radar capabilities to their services â€“ access the data and guidance to help you get started quickly. Free access to: - Sample dataset as a CSV - Accompanying README file https://www.plextek.com/learn/radar-data-for-experimentation/ See translation</description><pubDate>Tue, 04 Nov 2025 05:23:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/InezCornell/148411333647765</guid></item></channel></rss>