<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸ¤ Collaborating with AMD to ensure Hugging Face Transformers runs smoothly on AMD GPUs!</title><link>https://huggingface.co/posts/pagezyhf/845836724116614</link><description>ğŸ¤ Collaborating with AMD to ensure Hugging Face Transformers runs smoothly on AMD GPUs! We run daily CI on AMD MI325 to track the health of the most important model architectures and weâ€™ve just made our internal dashboard public. By making this easily accessible, we hope to spark community contributions and improve support for everyone! See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/pagezyhf/845836724116614</guid></item><item><title>A cute Intern With Hugging Face</title><link>https://huggingface.co/posts/vansin/596257741318226</link><description>A cute Intern With Hugging Face See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/vansin/596257741318226</guid></item><item><title>gpt-oss was possible thanks to new engineering efforts in ğŸ¤— transformers. We just dropped a blog covering them:</title><link>https://huggingface.co/posts/sergiopaniego/319778709690075</link><description>gpt-oss was possible thanks to new engineering efforts in ğŸ¤— transformers. We just dropped a blog covering them: - Kernels from the Hub - MXFP4 Quantization - Tensor &amp; Expert Parallelism - Dynamic Sliding Window &amp; Cache - Continuous Batching &amp; Paged Attention Grab a coffee &amp; dive in! â˜•ï¸ https://huggingface.co/blog/faster-transformers See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/319778709690075</guid></item><item><title>Tremendous quality of life upgrade on the Hugging Face Hub - we now have auto-complete emojis ğŸ¤— ğŸ¥³ ğŸ‘ ğŸ™Œ ğŸ‰</title><link>https://huggingface.co/posts/yjernite/185479802142810</link><description>Tremendous quality of life upgrade on the Hugging Face Hub - we now have auto-complete emojis ğŸ¤— ğŸ¥³ ğŸ‘ ğŸ™Œ ğŸ‰ Get ready for lots more very serious analysis on a whole range of topics from yours truly now that we have unlocked this full range of expression ğŸ˜„ ğŸ¤” ğŸ—£ ğŸ™Š See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/yjernite/185479802142810</guid></item><item><title>Introducing Gliese-OCR-7B-Post1.0, a document content-structure retrieval VLM designed for content extraction(OCRs) and summarization. This is the third model in the Camel Doc OCR VLM series, following Camel-Doc-OCR-062825. The new version fixes formal table reconstruction issues in both En and Zh, achieving optimal performance for long-context inferences. This model also shows significant improvements in LaTeX and Markdown rendering for OCR tasks.</title><link>https://huggingface.co/posts/prithivMLmods/331773737307135</link><description>Introducing Gliese-OCR-7B-Post1.0, a document content-structure retrieval VLM designed for content extraction(OCRs) and summarization. This is the third model in the Camel Doc OCR VLM series, following Camel-Doc-OCR-062825. The new version fixes formal table reconstruction issues in both En and Zh, achieving optimal performance for long-context inferences. This model also shows significant improvements in LaTeX and Markdown rendering for OCR tasks. ğŸ¤— Gliese-OCR-7B-Post1.0 : prithivMLmods/Gliese-OCR-7B-Post1.0 âœ¨ Demo Space/App : prithivMLmods/Multimodal-VLM-v1.0 ğŸ“Œ Gliese-Post1.0 Collection : prithivMLmods/gliese-post10-68c52c4a6ca4935f5259a6d7 â¬…ï¸ Previous Versions : prithivMLmods/Camel-Doc-OCR-062825 ğŸ§¨ Gliese-OCR-7B-Post1.0 (4-bit) Notebook Demo on T4 : prithivMLmods/Gliese-OCR-7B-Post1.0 ğŸ“– GitHub [Gliese-OCR-7B-Post1.0(4-bit)-reportlab] : https://tinyurl.com/ys7zuerc Other Collections: â” Multimodal Implementations : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 â”...</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/331773737307135</guid></item><item><title>ğŸ‰ Big congratulations to the winners of the "Synthetic 2 Real Object Detection Challenge 2", the second Kaggle challenge that Duality AI hosted. This competition was more fierce than the last one, but these users managed to clench the win!</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/831958361085352</link><description>ğŸ‰ Big congratulations to the winners of the "Synthetic 2 Real Object Detection Challenge 2", the second Kaggle challenge that Duality AI hosted. This competition was more fierce than the last one, but these users managed to clench the win! ğŸ¥‡ 1st place: @ sergio-sanz-rodriguez (see the blog he produced with us outlining how he achieved his results: https://tinyurl.com/mreunr98 ) ğŸ¥ˆ 2nd place: Kaggle user Diana Shilova - https://tinyurl.com/yjjz3szm ğŸ¥‰ 3rd place: Kaggle user çœ‰é—´å°º - https://tinyurl.com/ycxskfzv View the entire leaderboard at - https://tinyurl.com/jm2ery7w Join our current Multi-Class Object Detection Synthetic2Real Kaggle competition here: https://tinyurl.com/y224rttu And we will soon be launching a new competition in a new domain! Hint: ğŸŒ„ ğŸ  ğŸŒ³ âœˆï¸ See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/831958361085352</guid></item><item><title>Most apps don't have great full-text search over their assets.</title><link>https://huggingface.co/posts/salma-remyx/853424776483426</link><description>Most apps don't have great full-text search over their assets. We've developed an agent to automate the environment building and testing of experimental codebases sourced from arXiv. We push these containerized reproductions daily to Docker Hub: https://hub.docker.com/u/remyxai However, searching for them can be challenging unless you know the specific arXiv ID associated with each paper. We are currently working on implementing a search feature in Remyx, which will make these assets easily discoverable and ready for testing ğŸ” Stay tuned! Discover your next best idea to experiment with here: https://engine.remyx.ai See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/853424776483426</guid></item><item><title>This is huge!</title><link>https://huggingface.co/posts/Jaward/119201145963061</link><description>This is huge! the opensource community is all in on open access to rl environments, PrimeIntellect youâ€™re not alone. Code: https://github.com/WooooDyy/AgentGym-RL See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/119201145963061</guid></item><item><title>I like the direction that Claude Code took in visualizing context usage. As these tools are being built, I think the work now needs to focus on control over how to clean up, inspect, and profile. Renderdoc-like maybe?</title><link>https://huggingface.co/posts/ArturoNereu/678419269367059</link><description>I like the direction that Claude Code took in visualizing context usage. As these tools are being built, I think the work now needs to focus on control over how to clean up, inspect, and profile. Renderdoc-like maybe? See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ArturoNereu/678419269367059</guid></item><item><title>ğŸš€Hello from the Project Fluently team!</title><link>https://huggingface.co/posts/ehristoforu/878870828428356</link><description>ğŸš€Hello from the Project Fluently team! âœ¨ We are happy to share with you our new universal LLM models based on Qwen3 1.7B and 4B â€” powerful, multilingual and ready to solve a wide range of problems! ğŸ› ï¸ We have conducted additional training and carefully merged them to achieve even better results and maximize the potential of the models. ğŸ†“ And most importantly â€” the models are completely open and free under the Apache-2.0 license! ğŸ”— Links to repositories: - FluentlyQwen3-4B: fluently/FluentlyQwen3-4B - FluentlyQwen3-1.7B: fluently/FluentlyQwen3-1.7B ğŸ˜ We will be very glad to hear your feedback and impressions! Your opinion is very important to us! See translation</description><pubDate>Sun, 14 Sep 2025 05:19:47 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ehristoforu/878870828428356</guid></item></channel></rss>