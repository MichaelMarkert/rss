<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Today, we're unveiling two new open-source AI robots! HopeJR for $3,000 &amp; Reachy Mini for $300 ğŸ¤–ğŸ¤–ğŸ¤–</title><link>https://huggingface.co/posts/clem/522668354429256</link><description>Today, we're unveiling two new open-source AI robots! HopeJR for $3,000 &amp; Reachy Mini for $300 ğŸ¤–ğŸ¤–ğŸ¤– Let's go open-source AI robotics! See translation</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/522668354429256</guid></item><item><title>VisionScout Major Update: Enhanced Precision Through Multi-Modal AI Integration</title><link>https://huggingface.co/posts/DawnC/538322807718464</link><description>VisionScout Major Update: Enhanced Precision Through Multi-Modal AI Integration I'm excited to share significant improvements to VisionScout that substantially enhance accuracy and analytical capabilities. â­ï¸ Key Enhancements - CLIP Zero-Shot Landmark Detection: The system now identifies famous landmarks and architectural features without requiring specific training data, expanding scene understanding beyond generic object detection. - Places365 Environmental Classification: Integration of MIT's Places365 model provides robust scene baseline classification across 365 categories, significantly improving lighting analysis accuracy and overall scene identification precision. - Enhanced Multi-Modal Fusion: Advanced algorithms now dynamically combine insights from YOLOv8, CLIP, and Places365 to optimize accuracy across diverse scenarios. - Refined LLM Narratives: Llama 3.2 integration continues to transform analytical data into fluent, contextually rich descriptions while maintaining...</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/538322807718464</guid></item><item><title>ğŸ¤—ğŸ‘¨ğŸ»â€ğŸ“</title><link>https://huggingface.co/posts/darkc0de/635443238112929</link><description>ğŸ¤—ğŸ‘¨ğŸ»â€ğŸ“</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/darkc0de/635443238112929</guid></item><item><title>deepseek-ai/DeepSeek-R1-0528</title><link>https://huggingface.co/posts/AtAndDev/639250895656011</link><description>deepseek-ai/DeepSeek-R1-0528 This is the end See translation</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AtAndDev/639250895656011</guid></item><item><title>ğŸµ Dream come true for content creators! TIGER AI can extract voice, effects &amp; music from ANY audio file ğŸ¤¯</title><link>https://huggingface.co/posts/fdaudens/323840314242853</link><description>ğŸµ Dream come true for content creators! TIGER AI can extract voice, effects &amp; music from ANY audio file ğŸ¤¯ This lightweight model uses frequency band-split technology to separate speech like magic. Kudos to @ fffiloni for the amazing demo! fffiloni/TIGER-audio-extraction See translation</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/323840314242853</guid></item><item><title>ğŸ”¥ New benchmark &amp; dataset for Subject-to-Video generation</title><link>https://huggingface.co/posts/AdinaY/228294422537840</link><description>ğŸ”¥ New benchmark &amp; dataset for Subject-to-Video generation OPENS2V-NEXUS by Pekin University âœ¨ Fine-grained evaluation for subject consistency BestWishYsh/OpenS2V-Eval âœ¨ 5M-scale dataset: BestWishYsh/OpenS2V-5M âœ¨ New metrics â€“ automatic scores for identity, realism, and text match See translation</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/228294422537840</guid></item><item><title>ğŸ§   AI Brand Naming with 15 Specialized Theories</title><link>https://huggingface.co/posts/openfree/518842941778923</link><description>ğŸ§  AI Brand Naming with 15 Specialized Theories ğŸ¯ Core Features 15 Expert Theories for professional brand naming Bilingual Support Korean/English for global brands Unified Evaluation System creativity/memorability/relevance scores Real-time Visualization theory-specific custom designs openfree/Naming ğŸ”¬ Applied Theories Cognitive Theories (4) ğŸŸ¦ Square Theory - Semantic square structure with 4-word relationships ğŸ”Š Sound Symbolism - Psychological connections between phonemes and meaning ğŸ§  Cognitive Load - Minimized processing for instant recognition ğŸ‘ï¸ Gestalt Theory - Perceptual principles where whole exceeds parts Creative Theories (3) ğŸ”€ Conceptual Blending - Merging concepts to create new meanings ğŸ”§ SCAMPER Method - 7 creative transformation techniques ğŸŒ¿ Biomimicry - Nature-inspired wisdom from 3.8 billion years of evolution Strategic Theories (2) âœ… Jobs-to-be-Done - Customer-centric problem-solving focus ğŸ’­ Design Thinking - Human-centered innovation methodology Cultural Theories (3)...</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/518842941778923</guid></item><item><title>I am so happy  to share to all that Iâ€™ve just completed the first unit of the new MCP course on Hugging Face and earned my certificate! The AI acceleration track is intense and fast-paced, but Iâ€™m doing my best to keep up. Excited for whatâ€™s ahead!</title><link>https://huggingface.co/posts/lukmanaj/495766537273785</link><description>I am so happy to share to all that Iâ€™ve just completed the first unit of the new MCP course on Hugging Face and earned my certificate! The AI acceleration track is intense and fast-paced, but Iâ€™m doing my best to keep up. Excited for whatâ€™s ahead! See translation</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/lukmanaj/495766537273785</guid></item><item><title>I really like how this seven-stage pipeline was laid out in the Ultimate Guide to Fine-Tuning book.</title><link>https://huggingface.co/posts/hesamation/260011784391977</link><description>I really like how this seven-stage pipeline was laid out in the Ultimate Guide to Fine-Tuning book. It gives an overview, then goes into detail for each stage, even providing best practices. Itâ€™s 115 pages on arxiv, definitely worth a read. Check it out: https://arxiv.org/abs/2408.13296 See translation</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/260011784391977</guid></item><item><title>VEO 3 FLOW Full Tutorial - How To Use VEO3 in FLOW Guide :</title><link>https://huggingface.co/posts/MonsterMMORPG/279762403721253</link><description>VEO 3 FLOW Full Tutorial - How To Use VEO3 in FLOW Guide : https://youtu.be/AoEmQPU2gtg Tutorial link : https://youtu.be/AoEmQPU2gtg VEO 3 AI is rocking generative AI field right now. FLOW is the platform that lets you use VEO 3 with so many cool features. This is an official tutorial and guide made by Google team. I edited it slightly. I hope this be helpful. FLOW : https://labs.google/flow/about Veo 3 is Google DeepMindâ€™s most advanced video generation model to date. It allows users to create high-quality, cinematic video clips from simple text prompts, making it one of the most powerful AI tools for video creation. What sets Veo 3 apart is its ability to generate videos with native audio. This means that along with stunning visuals, Veo 3 can produce synchronized dialogue, ambient sounds, and background musicâ€”all from a single prompt. For filmmakers, this is a significant leap forward, as it eliminates the need for separate audio generation or complex syncing processes. Veo 3...</description><pubDate>Fri, 30 May 2025 09:25:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/279762403721253</guid></item></channel></rss>