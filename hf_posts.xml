<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Qwen releases Qwen3-Coder-Next! üíú Run the locally on 46GB RAM or less.</title><link>https://huggingface.co/posts/danielhanchen/824171868881117</link><description>Qwen releases Qwen3-Coder-Next! üíú Run the locally on 46GB RAM or less. Thhe model excels at agentic coding &amp; local use. With 256K context, it delivers similar performance to models with 10-20√ó more active parameters. GGUF: unsloth/Qwen3-Coder-Next-GGUF Guide: https://unsloth.ai/docs/models/qwen3-coder-next See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/824171868881117</guid></item><item><title>Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8√ó horizontal and 3√ó elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. üî¶</title><link>https://huggingface.co/posts/prithivMLmods/212829837698801</link><description>Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8√ó horizontal and 3√ó elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. üî¶ üî• Space: prithivMLmods/Qwen-Image-Edit-3D-Lighting-Control ‚úÖ Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection üìÇ GitHub: https://github.com/PRITHIVSAKTHIUR/Qwen-Image-Edit-3D-Lighting-Control See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/212829837698801</guid></item><item><title>We‚Äôve all had that moment where we watch a tutorial, nod along, but then realize we can‚Äôt actually do it ourselves because watching is just passive. At AIPrep, we are fixing this "watch and forget" cycle by building a foundational Generative Explanatory Model (GEM). GEM doesn't just give you a video or a wall of text; it builds an interactive lesson that asks you questions, catches your mistakes in real time, and adapts to your pace. We have just finished preparing our specialized datasets for this interactive logic, and you can already check them out on our profile to see how we are structuring this step-by-step reasoning. Training for the foundational model starts very soon, so stay in touch because something revolutionary is coming to the world of AI education. You can see our progress at aiprep.in.</title><link>https://huggingface.co/posts/AIPreplabs/635199649838795</link><description>We‚Äôve all had that moment where we watch a tutorial, nod along, but then realize we can‚Äôt actually do it ourselves because watching is just passive. At AIPrep, we are fixing this "watch and forget" cycle by building a foundational Generative Explanatory Model (GEM). GEM doesn't just give you a video or a wall of text; it builds an interactive lesson that asks you questions, catches your mistakes in real time, and adapts to your pace. We have just finished preparing our specialized datasets for this interactive logic, and you can already check them out on our profile to see how we are structuring this step-by-step reasoning. Training for the foundational model starts very soon, so stay in touch because something revolutionary is coming to the world of AI education. You can see our progress at aiprep.in. See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AIPreplabs/635199649838795</guid></item><item><title>Baidu + Transformers + Hugging Face = Pure Magic! ‚ú®</title><link>https://huggingface.co/posts/jzhang533/287065254526168</link><description>Baidu + Transformers + Hugging Face = Pure Magic! ‚ú® We got this nice gift from Hugging Face. @ xianbao See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jzhang533/287065254526168</guid></item><item><title>I‚Äôm excited to share PlaiTO, a reasoning-focused language model built on LLaMA 3.1 (8B) and optimized for humanities and social sciences.</title><link>https://huggingface.co/posts/alibidaran/992533889532684</link><description>I‚Äôm excited to share PlaiTO, a reasoning-focused language model built on LLaMA 3.1 (8B) and optimized for humanities and social sciences. PlaiTO is designed to go beyond surface-level text generation, emphasizing structured reasoning, conceptual clarity, and analytical depth‚Äîespecially in domains centered on human behavior and social systems. üéØ Focus Areas Psychology Management &amp; Organizational Studies Sociology üìä MMLU Benchmark Results (100 samples per domain) Professional Psychology: 76% Management: 74% Sociology: 75% These results highlight PlaiTO‚Äôs strong performance in abstract, theory-heavy, and reasoning-driven tasks. üí° Why PlaiTO? Strong analytical and reasoning capabilities Better handling of complex human-centered problems Suitable for academic, educational, and research use cases Balanced performance across multiple humanities disciplines PlaiTO is ideal for conceptual analysis, case reasoning, academic discussion, and decision-support scenarios‚Äîwhile still requiring...</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/alibidaran/992533889532684</guid></item><item><title>AI for science is moving fastüöÄ</title><link>https://huggingface.co/posts/AdinaY/629082711714950</link><description>AI for science is moving fastüöÄ Intern-S1-Pro üî¨ a MoE multimodal scientific reasoning model from Shanghai AI Lab internlm/Intern-S1-Pro ‚ú® 1T total / 22B active ‚ú® Apache 2.0 ‚ú® SoTA scientific reasoning performance ‚ú® FoPE enables scalable modeling of long physical time series (10‚Å∞‚Äì10‚Å∂) See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/629082711714950</guid></item><item><title>SECourses Musubi Trainer upgraded to V27 and FLUX 2, FLUX Klein, Z-Image training added with demo configs - amazing VRAM optimized - read the news</title><link>https://huggingface.co/posts/MonsterMMORPG/876855019351468</link><description>SECourses Musubi Trainer upgraded to V27 and FLUX 2, FLUX Klein, Z-Image training added with demo configs - amazing VRAM optimized - read the news App is here : https://www.patreon.com/posts/137551634 Full tutorial how to use and train : https://youtu.be/DPX3eBTuO_Y See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/876855019351468</guid></item><item><title>Hello everyone, We are thrilled to announce that LoongFlow has officially launched: General Agent!</title><link>https://huggingface.co/posts/FreshmanD/843358932677061</link><description>Hello everyone, We are thrilled to announce that LoongFlow has officially launched: General Agent! This iteration introduces three major features, bringing the capabilities of intelligent agents to new heights. 1. Claude Agent SDK Deep Integration üì∑ * Integrated with Claude Agent SDK: Enhancing the framework‚Äôs extensibility * Seamless integration with the Claude Skills ecosystem, sharing powerful tool capabilities 2. Breakthrough Multi-File System Support üì∑ * Say goodbye to single-file limitations: Supports complex system development at a full project level 3. Support for AI Self-Evaluation Mode üì∑ * Self-evaluation: Agents can assess the quality of their own solutions, saving you the hassle of building evaluation functions üì∑ For more details, check out: https://github.com/baidu-baige/LoongFlow/tree/main/agents/general_agent . Feel free to try it out, and let us know if you have any questions or feedback! ~ See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/FreshmanD/843358932677061</guid></item><item><title>Are you sure the open-source model you just downloaded is safe?</title><link>https://huggingface.co/posts/MikeDoes/334475009032635</link><description>Are you sure the open-source model you just downloaded is safe? A recent paper on "Privacy Backdoors" reports a new vulnerability where pre-trained models can be poisoned before fine-tuning them. This is a serious challenge for everyone building on open-source AI. Instead of just pointing out problems, we believe in finding better solutions. To understand this threat, the researchers needed to test their attack on realistic data structures. They needed a dataset that could effectively simulate a high-stakes privacy attack, and we're proud that our Ai4Privacy dataset was used to provide this crucial benchmark. The paper reports that for our complex dataset, the privacy leakage on a non-poisoned model was almost zero. After the backdoor attack, that number reportedly jumped to 87%. Ai4Privacy dataset provided a realistic benchmark for their research. Our dataset, composed of synthetic identities, helped them demonstrate how a poisoned model could dramatically amplify privacy leakage....</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/334475009032635</guid></item><item><title>‚ú® China‚Äôs open source AI ecosystem has entered a new phase</title><link>https://huggingface.co/posts/AdinaY/868331315163719</link><description>‚ú® China‚Äôs open source AI ecosystem has entered a new phase https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3 One year after the ‚ÄúDeepSeek Moment,‚Äù open source has become the default. Models, research, infrastructure, and deployment are increasingly shared to support large-scale, system-level integration. This final blog examines how leading Chinese AI organizations are evolving ,and what this implies for the future of open source. See translation</description><pubDate>Thu, 05 Feb 2026 14:06:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/868331315163719</guid></item></channel></rss>