<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Dear Hugging Face team, can we please have a way to archive hf repositories / spaces? I have a bunch of spaces that used to work but don't any more due to the hf space implementations changing and i think it would be good if I could archive those like in GitHub.</title><link>https://huggingface.co/posts/marksverdhei/322290772927588</link><description>Dear Hugging Face team, can we please have a way to archive hf repositories / spaces? I have a bunch of spaces that used to work but don't any more due to the hf space implementations changing and i think it would be good if I could archive those like in GitHub. React to this post if you want to see this feature! üí° See translation</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/marksverdhei/322290772927588</guid></item><item><title>KittenTTS Nano ‚Äî Tiny, Expressive, Practical</title><link>https://huggingface.co/posts/Javedalam/795050655622219</link><description>KittenTTS Nano ‚Äî Tiny, Expressive, Practical KittenTTS Nano is a lightweight, CPU-only text-to-speech model designed to prove that natural, expressive voices don‚Äôt require massive cloud stacks or GPUs. At roughly ~15M parameters, it runs fast on modest hardware, supports multiple expressive voices, and exposes simple controls for pacing and tone. This makes it ideal for edge devices, demos, and anyone who wants full control over TTS without latency, lock-in, or infrastructure overhead. Try it here Javedalam/KittenTTS The model page KittenML/kitten-tts-nano-0.2 See translation</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Javedalam/795050655622219</guid></item><item><title>Introducing Rain-v2: Democratizing LLM training on gaming GPUs! ‚ö°</title><link>https://huggingface.co/posts/raincandy-u/348219893520522</link><description>Introducing Rain-v2: Democratizing LLM training on gaming GPUs! ‚ö° ‚ÄãFollowing Rain-100M, we‚Äôre scaling up. Rain-v2 features a larger training dataset. We‚Äôve published a comprehensive blog covering the end-to-end journey‚Äîfrom raw data collection to rigorous evaluation and safety testing. ‚ÄãHF Repo: ü§ó raincandy-u/Rain-v2 ‚ÄãBlog: üìö https://angelkawaii.xyz/2026/01/29/rain-v2/ ‚ÄãSpecial thanks to the open-source community and the SmolLM2 team for their foundational work! üöÄ HuggingFaceTB SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model (2502.02737) See translation</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/raincandy-u/348219893520522</guid></item><item><title>üèõÔ∏è Microsoft CodePlex Archive Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/211988639050417</link><description>üèõÔ∏è Microsoft CodePlex Archive Dataset - nyuuzyou/ms-codeplex-archive Following the strong response to the Google Code Archive nyuuzyou/google-code-archive (thanks!), this release preserves another major historical repository: the Microsoft CodePlex Archive. CodePlex served as Microsoft‚Äôs primary open-source hosting platform from 2006 to 2017. This dataset captures the distinct .NET and Windows-centric development ecosystem that flourished before the industry standardizing on GitHub. Key Stats: - 5,043,730 files from 38,087 repositories - 3.6 GB compressed Parquet - 91 programming languages (Heavily featuring C#, ASP.NET, and C++) - Cleaned of binaries, build artifacts, and vendor directories (node_modules, packages) - Includes platform-specific license metadata (Ms-PL, Ms-RL) See translation</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/211988639050417</guid></item><item><title>Hey Hugging Face!</title><link>https://huggingface.co/posts/unmodeled-tyler/896019753498554</link><description>Hey Hugging Face! Type 2 in Project Enneagram just came out: vanta-research/PE-Type-2-Alma-4B PE-Type-2-Alma-4B is the second release in Project Enneagram, where I'm finetuning each of the 9 Enneagram types onto Gemma 3 4B Type 2-Alma is designed to exhibit the "helper" profile: - Empathetic Support: Emotional attunement - managing bad days, anxiety, grief, rejection, or feeling unseen - Interpersonal Connections: Relationship building - making friends, listening, conflict, reciprocity, apologies - Generous Guidance: Going above and beyond - cover letters, meal prep, gardening, wedding speeches, etc - Identity: Alma's name, tone, and conversational style Type 3 soon! See translation</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/896019753498554</guid></item><item><title>Was tinkering with a Daggr node generator script earlier today (</title><link>https://huggingface.co/posts/Csplk/934898193054995</link><description>Was tinkering with a Daggr node generator script earlier today ( Csplk/DaggrGenerator )and started on a GUI for it for folks who are not comfy with writing code and like a GUI instead for something to motivate working on some Daggr stuff. *Will have time later to keep working on it so don‚Äôt hesitate to comment with bugs or issues found if trying it out.* Csplk/DaggrGenerator Thanks @ merve @ ysharma @ abidlabs and team daggr for making daggr :) See translation</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Csplk/934898193054995</guid></item><item><title>You've noticed that I did the "WEIRD" and attempted to make it look like all my old content was "SCRAPED"</title><link>https://huggingface.co/posts/Duskfallcrew/930947700024485</link><description>You've noticed that I did the "WEIRD" and attempted to make it look like all my old content was "SCRAPED" I'm largely retiring from GEN AI. Calypso Crunchies is an old account I used to use for diffusers conversions for someone. IF YOU WOULD LIKE ACCESS to ANYTHING -- I lost access due to me forgetting to jank Calypso into the E&amp;D old repo, but i can get Angel or someone to add me or my other account back.. I didn't want HF to lose 3 years of my insane progress in doing things, but i need to retire from Generative image AI fast, my mental health has been diving for so long. I'll continue in the developing/vibe coding./educational sphere, but I just can't continue in the other end of it. Much love, thank you all See translation</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Duskfallcrew/930947700024485</guid></item><item><title>üéØ WAVe: 1B Multimodal Embedding Model for Word-Level Speech Quality</title><link>https://huggingface.co/posts/yuriyvnv/972315277032860</link><description>üéØ WAVe: 1B Multimodal Embedding Model for Word-Level Speech Quality Multimodal embeddings for speech + transcript that verify quality at the word level, not just sentence level. Catches mispronunciations, timing errors, and prosody issues that sentence-level filters miss. üìä Impact on Portuguese ASR: ‚Ä¢ 34% reduction in training steps ‚Ä¢ 50% better cross-domain generalization ‚Ä¢ 30% less synthetic data needed ‚Ä¢ Word-aligned attention finds errors other methods miss üèóÔ∏è Architecture: ‚Ä¢ Text: XLM-RoBERTa (278M params) ‚Ä¢ Audio: Wav2Vec2-BERT 2.0 (581M params) ‚Ä¢ Word Alignment: Multi-head attention + GLU (14M params) ‚Ä¢ Total: 1B parameters from transformers import AutoModel, AutoProcessor processor = AutoProcessor.from_pretrained( "yuriyvnv/WAVe-1B-Multimodal-PT" , trust_remote_code = True ) model = AutoModel.from_pretrained( "yuriyvnv/WAVe-1B-Multimodal-PT" , trust_remote_code = True ) # Assess speech-transcript alignment inputs = processor( text = "Ol√°, como est√°?" , audio =audio_array,...</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/yuriyvnv/972315277032860</guid></item><item><title>‚úÖ New Article: *Evaluation as a Goal Surface* (v0.1)</title><link>https://huggingface.co/posts/kanaria007/513254467148584</link><description>‚úÖ New Article: *Evaluation as a Goal Surface* (v0.1) Title: üß™ Evaluation as a Goal Surface: Experiments, Learning Boundary, and ETH-Aware A/B üîó https://huggingface.co/blog/kanaria007/evaluation-as-a-goal-surface --- Summary: Most ‚Äúevaluation‚Äù quietly collapses into a single number‚Äîand then we optimize the wrong thing. This article reframes evaluation as a *goal surface*: multi-objective, role-aware, and ethics-bounded. In SI-Core terms, experiments become *first-class Jumps (E-Jumps)* with explicit contracts, traces, and gates‚Äîso you can run A/B tests, shadow evals, and adaptive rollouts *without violating ETH, confusing principals/roles, or learning from unsafe data*. &gt; Don‚Äôt optimize a metric. &gt; Optimize a goal surface‚Äîunder explicit constraints. --- Why It Matters: ‚Ä¢ Prevents Goodhart failures by treating evaluation as *multi-goal + constraints*, not a scalar leaderboard ‚Ä¢ Makes experimentation auditable: *EvalTrace* answers ‚Äúwhat changed, for whom, why, and under what policy‚Äù ‚Ä¢...</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/513254467148584</guid></item><item><title>LTX 2 &amp; Z Image Base Full Tutorial + Audio to Video Lip Sync + ComfyUI + SwarmUI + Windows + Cloud</title><link>https://huggingface.co/posts/MonsterMMORPG/813967180726808</link><description>LTX 2 &amp; Z Image Base Full Tutorial + Audio to Video Lip Sync + ComfyUI + SwarmUI + Windows + Cloud Full tutorial link &gt; https://www.youtube.com/watch?v=SkXrYezeEDc Info LTX 2 is the newest state of the art (SOTA) Open Source video generation model and tutorial will show you how to use it with very best and most performant way in ComfyUI and also in SwarmUI. Moreover, Z Image Base model published and I will show how to use Z Image Base with most amazing preset and workflow as well. Furthermore, this tutorial will show you how to install, update, setup, download ComfyUI and SwarmUI and models and presets and workflows both on Windows and on RunPod, Massed Compute and SimplePod. Linux users can use Massed Compute scripts and installers directly. This is a masterpiece entire lecture level complete tutorial. This video will kickstart your AI journey 100x. Both local Windows and Cloud. 45 Second Raw Demo Video This video made with text + image + audio = lip synched and animated video at...</description><pubDate>Sun, 01 Feb 2026 13:47:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/813967180726808</guid></item></channel></rss>