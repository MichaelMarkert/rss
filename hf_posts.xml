<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>üåà‚ú® FLUX 'Every Text Imaginator'</title><link>https://huggingface.co/posts/ginipick/804980229974999</link><description>üåà‚ú® FLUX 'Every Text Imaginator' Multilingual Text-Driven Image Generation and Editing Demo: ginigen/Every-Text üìù What is FLUX Text Imaginator? FLUX Text Imaginator is an innovative tool that leverages cutting-edge FLUX diffusion models to create and edit images with perfectly integrated multilingual text. Unlike other image generation models, FLUX possesses exceptional capability to naturally incorporate text in various languages including Korean, English, Chinese, Japanese, Russian, French, Spanish and more into images! ‚ú® FLUX's Multilingual Text Processing Strengths üî§ Superior Multilingual Text Rendering: FLUX renders text with amazing accuracy, including non-English languages and special characters üá∞üá∑ Perfect Korean Language Support: Accurately represents complex Korean combined characters üà∂ Excellent East Asian Language Handling: Naturally expresses complex Chinese characters and Japanese text üîç Sophisticated Text Placement: Precise text positioning using &lt;text1&gt;, &lt;text2&gt;,...</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/804980229974999</guid></item><item><title>‚úÇÔ∏è AutoAbliteration</title><link>https://huggingface.co/posts/mlabonne/714992455492422</link><description>‚úÇÔ∏è AutoAbliteration I made a Colab notebook to automatically abliterate models. It's quite general, so you can do interesting stuff like blocking a given language in the model outputs. üíª Colab: https://colab.research.google.com/drive/1RmLv-pCMBBsQGXQIM8yF-OdCNyoylUR1?usp=sharing See translation</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mlabonne/714992455492422</guid></item><item><title>At Rapidata, we compared DeepL with LLMs like DeepSeek-R1, Llama, and Mixtral for translation quality using feedback from over 51,000 native speakers. Despite the costs, the performance makes it a valuable investment, especially in critical applications where translation quality is paramount. Now we can say that Europe is more than imposing regulations.</title><link>https://huggingface.co/posts/jasoncorkill/521063845119914</link><description>At Rapidata, we compared DeepL with LLMs like DeepSeek-R1, Llama, and Mixtral for translation quality using feedback from over 51,000 native speakers. Despite the costs, the performance makes it a valuable investment, especially in critical applications where translation quality is paramount. Now we can say that Europe is more than imposing regulations. Our dataset, based on these comparisons, is now available on Hugging Face. This might be useful for anyone working on AI translation or language model evaluation. Rapidata/Translation-deepseek-llama-mixtral-v-deepl See translation</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jasoncorkill/521063845119914</guid></item><item><title>RWKV7-G1 0.1B üî• Pure RNN reasoning model released by RWKV</title><link>https://huggingface.co/posts/AdinaY/946974056180555</link><description>RWKV7-G1 0.1B üî• Pure RNN reasoning model released by RWKV Model: BlinkDL/rwkv7-g1 paper: RWKV-7 "Goose" with Expressive Dynamic State Evolution (2503.14456) ‚ú® Apache2.0 ‚ú® Supports 100+ languages ‚ú® 0.1 B runs smoothly on low power devices ‚ú® 0.4B/1.5B/2.9B are coming soon!! See translation</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/946974056180555</guid></item><item><title>New 3D models from Tencent Hunyuan  are now available on the hub üî•</title><link>https://huggingface.co/posts/AdinaY/835178247040445</link><description>New 3D models from Tencent Hunyuan are now available on the hub üî• ‚ú® Hunyuan3D-2mv: multiview shape model for high quality generation ‚ú® Hunyuan3D-2mini: 0.6B lightweight model for efficient workflows Model: tencent/Hunyuan3D-2mv tencent/Hunyuan3D-2mini Demo: tencent/Hunyuan3D-2mv See translation</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/835178247040445</guid></item><item><title>My 1 year of work summarized.</title><link>https://huggingface.co/posts/etemiz/135866882319158</link><description>My 1 year of work summarized. TLDR: by carefully curating datasets we can fix misinformation in AI. Then we can use that to measure misinformation in other AI. https://huggingface.co/blog/etemiz/building-a-beneficial-ai See translation</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/135866882319158</guid></item><item><title>Big companies are now training huge AI models with tons of data and billions of parameters, and the future seems to be about quantization‚Äîmaking those models smaller by turning big numbers into simpler ones, like going from 32-bit to 8-bit without reducing accuracy by +/- 0.01%. There should be some standard unit of measurement for the ratio of model size reduction to accuracy lost.</title><link>https://huggingface.co/posts/ritvik77/148515751469332</link><description>Big companies are now training huge AI models with tons of data and billions of parameters, and the future seems to be about quantization‚Äîmaking those models smaller by turning big numbers into simpler ones, like going from 32-bit to 8-bit without reducing accuracy by +/- 0.01%. There should be some standard unit of measurement for the ratio of model size reduction to accuracy lost. What do you all thing about this ? See translation</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ritvik77/148515751469332</guid></item><item><title>üòä This program is designed to remove emojis from a given text. It uses a regular expression (regex) pattern to match and replace emojis with an empty string, effectively removing them from the text. The pattern includes a range of Unicode characters that correspond to various types of emojis, such as emoticons, symbols, and flags. By using this program, you can clean up text data by removing any emojis that may be present, which can be useful for text processing, analysis, or other applications where emojis are not desired. üíª</title><link>https://huggingface.co/posts/aifeifei798/845431141575759</link><description>üòä This program is designed to remove emojis from a given text. It uses a regular expression (regex) pattern to match and replace emojis with an empty string, effectively removing them from the text. The pattern includes a range of Unicode characters that correspond to various types of emojis, such as emoticons, symbols, and flags. By using this program, you can clean up text data by removing any emojis that may be present, which can be useful for text processing, analysis, or other applications where emojis are not desired. üíª import re def remove_emojis ( text ): # Define a broader emoji pattern emoji_pattern = re. compile ( "[" u"\U0001F600-\U0001F64F" # emoticons u"\U0001F300-\U0001F5FF" # symbols &amp; pictographs u"\U0001F680-\U0001F6FF" # transport &amp; map symbols u"\U0001F1E0-\U0001F1FF" # flags (iOS) u"\U00002702-\U000027B0" u"\U000024C2-\U0001F251" u"\U0001F900-\U0001F9FF" # supplemental symbols and pictographs u"\U0001FA00-\U0001FA6F" # chess symbols and more emojis...</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aifeifei798/845431141575759</guid></item><item><title>‚úÇÔ∏è Gemma 3 Abliterated</title><link>https://huggingface.co/posts/mlabonne/443122762320210</link><description>‚úÇÔ∏è Gemma 3 Abliterated I noticed that Gemma 3 was much more resilient to refusal removal than other models like Qwen 2.5. I experimented with different recipes and improved the abliteration technique I wrote about last year. It's still experimental but the refusal rate is super low in my tests. Enjoy! mlabonne/gemma-3-4b-it-abliterated mlabonne/gemma-3-12b-it-abliterated mlabonne/gemma-3-27b-it-abliterated See translation</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mlabonne/443122762320210</guid></item><item><title>üöÄ I'm thrilled to announce the launch of Arcee Conductor, a game-changing platform that's about to revolutionize the way you interact with AI models! ü§ñ As the pioneers of small language models (SLMs), we've been working tirelessly to bring you the most exciting innovation in the AI space.</title><link>https://huggingface.co/posts/abhishek/496057967241133</link><description>üöÄ I'm thrilled to announce the launch of Arcee Conductor, a game-changing platform that's about to revolutionize the way you interact with AI models! ü§ñ As the pioneers of small language models (SLMs), we've been working tirelessly to bring you the most exciting innovation in the AI space. Here's a quick TL;DR of what Arcee Conductor is all about: üåü Choice and flexibility: Get access to multiple models, including our powerful SLMs and third-party LLMs, to choose the best one for your specific use case ü§ñ Intelligent routing: Our platform evaluates which model is best-suited for each of your queries, ensuring you get the most accurate results üìà Cost savings: Reduce your AI costs with our affordable SLMs, while still having access to leading LLMs when needed üöÄ Easy to get started: Sign up now and try Arcee Conductor today, with 400 million tokens (a $200 value) on us! üéÅ üìä Proven track record: Our SLMs have already racked up 222K+ downloads on Hugging Face, with customers seeing...</description><pubDate>Thu, 20 Mar 2025 09:24:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abhishek/496057967241133</guid></item></channel></rss>