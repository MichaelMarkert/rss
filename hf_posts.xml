<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>âœ¨ DreamO Video: From Customized Images to Videos âœ¨</title><link>https://huggingface.co/posts/openfree/538970335354687</link><description>âœ¨ DreamO Video: From Customized Images to Videos âœ¨ Hello, AI creators! Today I'm introducing a truly special project. DreamO Video is an integrated framework that generates customized images based on reference images and transforms them into videos with natural movement. ğŸ¬âœ¨ openfree/DreamO-video ğŸ” Key Features Image Reference (IP): Maintain object appearance while applying to new backgrounds and situations ID Preservation: Retain facial features across various environments Style Transfer: Apply unique styles from reference images to other content ğŸï¸ Video Generation: Create natural 2-second videos from generated images ğŸ’¡ How to Use Upload Reference Images: One or two images (people, objects, landscapes, etc.) Select Task Type: Choose between IP (Image Preservation), ID (Face Feature Retention), or Style Enter Prompt: Describe your desired result (e.g., "a woman playing guitar on a cloud") Click Generate Image: âœ¨ Create customized AI images! Generate Video: Click the ğŸ¬ button on the...</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/538970335354687</guid></item><item><title>VLMS 2025 UPDATE ğŸ”¥</title><link>https://huggingface.co/posts/merve/544378273517703</link><description>VLMS 2025 UPDATE ğŸ”¥ We just shipped a blog on everything latest on vision language models, including ğŸ¤– GUI agents, agentic VLMs, omni models ğŸ“‘ multimodal RAG â¯ï¸ video LMs ğŸ¤ğŸ» smol models ..and more! https://huggingface.co/blog/vlms-2025 See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/544378273517703</guid></item><item><title>Today we launch Dione.</title><link>https://huggingface.co/posts/blaise-tk/108431169603656</link><description>Today we launch Dione. A few months ago it was just a wild idea I shared with @ bygimenez , now it's real. Dione (Beta) is here, the easiest way to discover and install open-source apps, especially AI ones. Think of it as the Steam of open source. Installing open-source tools is often a mess. Dione fixes that. Beautiful UI and workflow. Soon multi-platform, multilingual &amp; fully open-source. Users can even write and share their own installation scripts. This is just the beginning. ğŸš€ Join our exclusive Beta â†’ https://getdione.app/beta/join See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/blaise-tk/108431169603656</guid></item><item><title># ğŸŒŸ 3D Model to Video: Easy GLB Conversion Tool ğŸŒŸ</title><link>https://huggingface.co/posts/ginipick/766230066345476</link><description># ğŸŒŸ 3D Model to Video: Easy GLB Conversion Tool ğŸŒŸ demo link: ginigen/3D-VIDEO Hello there! Would you like to transform your 3D models into stunning animations? This space can help you! âœ¨ ## ğŸ” What Can It Do? This tool converts your uploaded GLB model into: 1. ğŸ® A transformed GLB file 2. ğŸ¬ An animated GIF preview 3. ğŸ“‹ A metadata JSON file ## âœ… Key Features * ğŸ–¥ï¸ Works in headless server environments (EGL + pyglet-headless â†’ pyrender fallback) * ğŸ” Objects in GIFs appear 3x larger (global scale Ã—3) * ğŸ¨ Clean interface with pastel background ## ğŸ® Animation Types * ğŸ”„ Rotate - Object rotates around the Y-axis * â¬†ï¸ Float - Object moves smoothly up and down * ğŸ’¥ Explode - Object moves sideways * ğŸ§© Assemble - Object returns to its original position * ğŸ’“ Pulse - Object changes in size * ğŸ”„ Swing - Object swings around the Z-axis ## ğŸ› ï¸ How to Use 1. Upload your GLB model ğŸ“¤ 2. Select your desired animation type ğŸ¬ 3. Adjust the duration and FPS â±ï¸ 4. Click the "Generate Animation" button â–¶ï¸ 5....</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/766230066345476</guid></item><item><title>11 Alignment and Optimization Algorithms for LLMs</title><link>https://huggingface.co/posts/Kseniase/849940009274643</link><description>11 Alignment and Optimization Algorithms for LLMs When we need to align models' behavior with the desired objectives, we rely on specialized algorithms that support helpfulness, accuracy, reasoning, safety, and alignment with user preferences. Much of a modelâ€™s usefulness comes from post-training optimization methods. Here are the main optimization algorithms (both classic and new) in one place: 1. PPO (Proximal Policy Optimization) -&gt; Proximal Policy Optimization Algorithms (1707.06347) Clips the probability ratio to prevent the new policy from diverging too far from the old one. It helps keep everything stable 2. DPO (Direct Preference Optimization) -&gt; Direct Preference Optimization: Your Language Model is Secretly a Reward Model (2305.18290) It's a non RL method, where an LM is an implicit reward model. It uses a simple loss to boost the preferred answerâ€™s probability over the less preferred one 3. GRPO (Group Relative Policy Optimization) -&gt; DeepSeekMath: Pushing the Limits of...</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/849940009274643</guid></item><item><title>this book actually exists for free, â€œthe little book of deep learningâ€. best to refresh your mind about DL basics:</title><link>https://huggingface.co/posts/hesamation/756119536681094</link><description>this book actually exists for free, â€œthe little book of deep learningâ€. best to refresh your mind about DL basics: &gt; foundations of machine learning &gt; how models train &gt; common layers (dropout, poolingâ€¦) &gt; basic intro to LLMs actually optimized for mobile. Book: https://fleuret.org/public/lbdl.pdf See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/756119536681094</guid></item><item><title>âœ¨ Weâ€™re live! Introducing TFrameX, the agentic framework for AI builders.</title><link>https://huggingface.co/posts/smirki/468999292160757</link><description>âœ¨ Weâ€™re live! Introducing TFrameX, the agentic framework for AI builders. After nights of development, weâ€™re finally open-sourcing TFrameX, a powerful AI agent communication and coordination library. TFrameX lets you: ğŸ¤– Run agents in dynamic flows ğŸ” Compose reusable patterns like Sequential, Parallel, Router, and more ğŸ§  Enable agent-to-agent collaboration and delegation âš¡ Build modular, complex multi-agent systems that just work ğŸ‘‰ GitHub: TFrameX https://github.com/TesslateAI/TFrameX But we didnâ€™t stop there. We also built a sleek visual builder to design, deploy, and debug your agent patterns without writing boilerplate! ğŸ§© Visual Studio for TFrameX: https://github.com/TesslateAI/Studio If youâ€™re building agent frameworks, LLM tools, or agentic apps, TFrameX gives you the tools to move fast and reason deeply. See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/smirki/468999292160757</guid></item><item><title>finally, a course that makes diffusion math much easier to grasp, well done ğŸ‘</title><link>https://huggingface.co/posts/Jaward/144425660093937</link><description>finally, a course that makes diffusion math much easier to grasp, well done ğŸ‘ https://diffusion.csail.mit.edu/ See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/144425660093937</guid></item><item><title>Automatic Multi-Modal Research Agent</title><link>https://huggingface.co/posts/VirtualOasis/965866013655862</link><description>Automatic Multi-Modal Research Agent I am thinking of building an Automatic Research Agent that can boost creativity! Input: Topics or data sources Processing: Automated deep research Output: multimodal results (such as reports, videos, audio, diagrams) &amp; multi-platform publishing. There is a three-stage process In the initial Stage, output for text-based content in markdown format allows for user review before transformation into various other formats, such as PDF or HTML. The second stage transforms the output into other modalities, like audio, video, diagrams, and translations into different languages. The final stage focuses on publishing multi-modal content across multiple platforms like X, GitHub, Hugging Face, YouTube, and podcasts, etc. See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/VirtualOasis/965866013655862</guid></item><item><title>Let's pipe some ğ—±ğ—®ğ˜ğ—® ğ—³ğ—¿ğ—¼ğ—º ğ˜ğ—µğ—² ğ˜„ğ—²ğ—¯ into our vector database, shall we?ğŸ¤ </title><link>https://huggingface.co/posts/as-cle-bert/400981312479742</link><description>Let's pipe some ğ—±ğ—®ğ˜ğ—® ğ—³ğ—¿ğ—¼ğ—º ğ˜ğ—µğ—² ğ˜„ğ—²ğ—¯ into our vector database, shall we?ğŸ¤  With ğ¢ğ§ğ ğğ¬ğ­-ğšğ§ğ²ğ­ğ¡ğ¢ğ§ğ  ğ¯ğŸ.ğŸ‘.ğŸ ( https://github.com/AstraBert/ingest-anything ) you can now scrape content simply starting from URLs, extract the text from it, chunk it and put it into your favorite LlamaIndex-compatible database!ğŸ•¸ï¸ You can do it thanks to ğ—°ğ—¿ğ—®ğ˜„ğ—¹ğ—²ğ—² by Apify, an open-source crawling library for python and javascript that handles all the data flow from the web: ingest-anything then combines it with ğ—•ğ—²ğ—®ğ˜‚ğ˜ğ—¶ğ—³ğ˜‚ğ—¹ğ—¦ğ—¼ğ˜‚ğ—½, ğ—£ğ—±ğ—³ğ—œğ˜ğ——ğ—¼ğ˜„ğ—» and ğ—£ğ˜†ğ— ğ˜‚ğ—£ğ—±ğ—³ to scrape HTML files, convert them to PDF and extract the text - hassle-free!ğŸ˜¸ Check the attached code snippet if you're curious of knowing how to get startedğŸ¬ PS: Don't tell anybody, but this release also has another gem... It supports OpenAI models for agentic chunking, following the new releases of ChonkieğŸ¦›âœ¨ If you don't want to miss out on the new features, leave us a little star on GitHub â¡ï¸ https://github.com/AstraBert/ingest-anything And join our discord community!...</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/400981312479742</guid></item></channel></rss>