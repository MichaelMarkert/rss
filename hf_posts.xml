<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.</title><link>https://huggingface.co/posts/etemiz/710778843328598</link><description>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really "free": they are costing you your freedom if you know what i mean. See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/710778843328598</guid></item><item><title>Image-to-Prompt⚡</title><link>https://huggingface.co/posts/ovi054/657358125503535</link><description>Image-to-Prompt⚡ ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 👉 Try it now: ovi054/image-to-prompt See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/657358125503535</guid></item><item><title>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:</title><link>https://huggingface.co/posts/fdaudens/770107969696647</link><description>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines &amp; specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup — just open-weight GPT-OSS models via Hugging Face If you’ve been wanting to try agents but weren’t sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/770107969696647</guid></item><item><title>Want to quickly try Gemma 3 270m? 💎💬</title><link>https://huggingface.co/posts/anakin87/751707976654130</link><description>Want to quickly try Gemma 3 270m? 💎💬 I made a simple Space to do that: anakin87/gemma-3-270m-it ⚡ Fast: Flash Attention, Zero GPU ⚙️ Configurable See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/anakin87/751707976654130</guid></item><item><title>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.🧪</title><link>https://huggingface.co/posts/prithivMLmods/284574267701705</link><description>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.🧪 🤗 Space: prithivMLmods/Tiny-VLMs-Lab ✦︎ Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. ✦︎ Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 ✦︎ GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or the...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/284574267701705</guid></item><item><title>suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source?</title><link>https://huggingface.co/posts/appvoid/589674942896129</link><description>suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source? keep in mind everybody will have access to it: scientists, governments, terrorists, average people, etc... See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/appvoid/589674942896129</guid></item><item><title>✅ New Article: *Memory as Structured Time*</title><link>https://huggingface.co/posts/kanaria007/576453037371058</link><description>✅ New Article: *Memory as Structured Time* Title: 🧠 History: Memory Loops as Civilization Structure 🔗 https://huggingface.co/blog/kanaria007/memory-loops-as-civilization-structure --- Summary: Memory is often treated as *storage and retrieval*. Structured Intelligence reframes it as *time‑shaping architecture*: * *Loops that preserve context and continuity* * *Rollback paths that enable reflection and correction* * *Patterns that turn experience into adaptive structure* &gt; Memory isn’t static — &gt; *it’s how intelligence edits time.* --- Why It Matters: • Reveals *how memory enables learning, identity, and adaptation* • Supports *AI that can reflect, revise, and self‑align* • Connects *personal cognition and collective history* as structural processes --- What’s Inside: • Memory as *recursive structural loop* • *Failure and recovery* as part of adaptive recall • How *history and record‑keeping mirror cognitive memory* • Implications for *resilient AI and social knowledge systems* --- 📖...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/576453037371058</guid></item><item><title>🔥Check out new SOTA Orpheus Auto-Continuations Generator🔥</title><link>https://huggingface.co/posts/asigalov61/289707289100732</link><description>🔥Check out new SOTA Orpheus Auto-Continuations Generator🔥 asigalov61/Orpheus-Music-Transformer Now you can generate good music with Orpheus without supervision!!! @ Timzoid @ John6666 @ alvanalrakib See translation</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/asigalov61/289707289100732</guid></item><item><title>🧬 DNA Diffusion Suite: AI-Powered Revolution in Life Science Research</title><link>https://huggingface.co/posts/openfree/904316268987326</link><description>🧬 DNA Diffusion Suite: AI-Powered Revolution in Life Science Research 🚀 Transformative Innovation Through AI Technology DNA Diffusion Suite is a next-generation platform that leverages cutting-edge Diffusion models to generate biologically meaningful DNA sequences. By reducing sequence design time from weeks to mere seconds, we're revolutionizing research productivity and accelerating scientific discovery. VIDraft/DNA-Diffusion 💡 Real-World Benefits of AI Technology 🎯 Research Acceleration Instant Hypothesis Testing: Pre-validate experimental designs with AI-generated sequence variants Cost Reduction: Test hundreds of sequences virtually before expensive synthesis Time Efficiency: 1000x faster sequence generation compared to manual design 🧠 Intelligent Sequence Optimization Cell-Type Specific Learning: AI trained on real ChIP-seq data from K562, GM12878, and HepG2 cells Context-Aware Generation: Fine-tune biological context with precision Guidance Scale control Automated Pattern...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/904316268987326</guid></item><item><title>✨ HairPick | Preview Your Perfect Hair Transformation in 360° ✨</title><link>https://huggingface.co/posts/ginipick/955296677233221</link><description>✨ HairPick | Preview Your Perfect Hair Transformation in 360° ✨ 🎊 Free Trial for Hugging Face Launch! Hurry! ⏰ Hello! Introducing an innovative AI service that helps you choose the perfect hairstyle without any regrets before visiting the salon! 🎯 Try It Now ginigen/Hair-Pick 🔄 What Makes HairPick Special? 360° Complete Preview! Other hair simulators only show the front view? 😑 HairPick is different! ✅ Front + 4 random angles = Total 5 multi-angle images generated ✅ Perfect check from side profile 👤 diagonal 📐 back view 👥! ✅ 100+ trendy hairstyle library 💇‍♀️ 💡 Highly Recommended For: 🎯 "I really don't want to fail this time!" → Check side volume and back lines thoroughly 🎯 "It's hard to explain exactly to my stylist" → Perfect communication with 360° result images! 🎯 "I have a profile photo/photoshoot coming up" → Preview your best look from every angle 🚀 Super Simple Usage (Just 1 Minute!) 1️⃣ One Selfie 📸 Take a front-facing photo in bright light (show your forehead and face...</description><pubDate>Sun, 17 Aug 2025 17:20:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/955296677233221</guid></item></channel></rss>