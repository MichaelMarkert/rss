<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possibleâ€”just look at the â€œTâ€ in ChatGPT, which comes from the Transformer architecture openly shared by Google.</title><link>https://huggingface.co/posts/clem/267300235555885</link><description>Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possibleâ€”just look at the â€œTâ€ in ChatGPT, which comes from the Transformer architecture openly shared by Google. Then came the myth that AI was too dangerous to share, and companies started optimizing for short-term revenue. That led many major AI labs and researchers to stop sharing and collaborating. With OAI and sama now saying they're willing to share open weights again, we have a real chance to return to a golden age of AI progress and democratizationâ€”powered by openness and collaboration, in the US and around the world. This is incredibly exciting. Letâ€™s go, open science and open-source AI! See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/267300235555885</guid></item><item><title>You can now run DeepSeek-V3-0324 on your own local device!</title><link>https://huggingface.co/posts/danielhanchen/465464088880734</link><description>You can now run DeepSeek-V3-0324 on your own local device! Run our Dynamic 2.42 and 2.71-bit DeepSeek GGUFs: unsloth/DeepSeek-V3-0324-GGUF You can run them on llama.cpp and other inference engines. See our guide here: https://docs.unsloth.ai/basics/tutorial-how-to-run-deepseek-v3-0324-locally See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/465464088880734</guid></item><item><title>âœ¨ High-Resolution Ghibli Style Image Generator âœ¨</title><link>https://huggingface.co/posts/aiqtech/202174985893140</link><description>âœ¨ High-Resolution Ghibli Style Image Generator âœ¨ ğŸŒŸ Introducing FLUX Ghibli LoRA Hello everyone! Today I'm excited to present a special LoRA model for FLUX Dev.1. This model leverages a LoRA trained on high-resolution Ghibli images for FLUX Dev.1 to easily create beautiful Ghibli-style images with stunning detail! ğŸ¨ space: aiqtech/FLUX-Ghibli-Studio-LoRA model: openfree/flux-chatgpt-ghibli-lora ğŸ”® Key Features Trained on High-Resolution Ghibli Images - Unlike other LoRAs, this one is trained on high-resolution images, delivering sharper and more beautiful results Powered by FLUX Dev.1 - Utilizing the latest FLUX model for faster generation and superior quality User-Friendly Interface - An intuitive UI that allows anyone to create Ghibli-style images with ease Diverse Creative Possibilities - Express various themes in Ghibli style, from futuristic worlds to fantasy elements ğŸ–¼ï¸ Sample Images Include "Ghibli style" in your prompts Try combining nature, fantasy elements, futuristic...</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aiqtech/202174985893140</guid></item><item><title>DeepGit: Your GitHub Gold Digger! ğŸ’°ğŸš€</title><link>https://huggingface.co/posts/zamal/271014113300033</link><description>DeepGit: Your GitHub Gold Digger! ğŸ’°ğŸš€ Hey Hugging Face gang! Meet DeepGitâ€”my open-source sidekick that rips through GitHub to snag repos that fit you. Done with dead-end searches? Me too. Built it with LangGraph and some dope tricks: Embeddings grab the good stuff (HF magic, baby!) Re-ranking nails the best picks Snoops docs, code, and buzz in one slick flow Drops a clean list of hidden gems ğŸ’ Unearth that sneaky ML lib or Python gemâ€”run python app.py or langgraph dev and boom! Peek it at https://github.com/zamalali/DeepGit . Fork it, tweak it, love itâ€”Dockerâ€™s in, HF vibes are strong. Drop a ğŸŒŸ or a crazy ideaâ€”Iâ€™m pumped to jam with you all! ğŸª‚ See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/zamal/271014113300033</guid></item><item><title>HF's new system makes me feel like they are not transparent on their pricing and making me feel they are not trustworthy.</title><link>https://huggingface.co/posts/OFT/611311806757189</link><description>HF's new system makes me feel like they are not transparent on their pricing and making me feel they are not trustworthy. See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/OFT/611311806757189</guid></item><item><title>ğŸ‰ Thrilled to share our #CVPR2025 accepted work:</title><link>https://huggingface.co/posts/ZhiyuanthePony/617713430689574</link><description>ğŸ‰ Thrilled to share our #CVPR2025 accepted work: Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data (2503.21694) ğŸ”¥ â€‹Key Innovations: 1ï¸âƒ£ First to adapt SD for â€‹direct textured mesh generation (1-2s inference) 2ï¸âƒ£ Novel teacher-student framework leveraging multi-view diffusion models ([MVDream]( https://arxiv.org/abs/2308.16512 ) &amp; [RichDreamer]( https://arxiv.org/abs/2311.16918) ) 3ï¸âƒ£ â€‹Parameter-efficient tuning - â€‹only +2.6% params over base SD 4ï¸âƒ£ â€‹3D data-free training liberates model from dataset constraints ğŸ’¡ Why matters? â†’ A novel â€‹3D-Data-Free paradigm â†’ Outperforms data-driven methods on creative concept generation â†’ Unlocks web-scale text corpus for 3D content creation ğŸŒ Project: https://theericma.github.io/TriplaneTurbo/ ğŸ® Demo: ZhiyuanthePony/TriplaneTurbo ğŸ’» Code: https://github.com/theEricMa/TriplaneTurbo See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZhiyuanthePony/617713430689574</guid></item><item><title>Hi all,</title><link>https://huggingface.co/posts/hanzla/237314499914963</link><description>Hi all, Last week, I open sourced Free Search API. It allows sourcing results from top search engines (including google, bing) for free. It uses searxng instances for this purpose. I was overwhelmed by community's response and I am glad for all the support and suggestions. So today, I have pushed several improvements that make this API more stable. These improvements include 1) Parallel scrapping of search results for faster response 2) Markdown formatting of search results 3) Prioritizing SearXNG instances that have faster google response time 4) Update/Get endpoints for searxng instances. Github: https://github.com/HanzlaJavaid/Free-Search/tree/main Try the deployed version: https://freesearch.replit.app/docs I highly appreciate PRs, issues, stars, and any kind of feedback. Let's join hands, and make it real big! See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hanzla/237314499914963</guid></item><item><title>AutoGLM æ²‰æ€ğŸ’« FREE AI Agent released by ZhipuAI</title><link>https://huggingface.co/posts/AdinaY/863826405061849</link><description>AutoGLM æ²‰æ€ğŸ’« FREE AI Agent released by ZhipuAI âœ¨ Think &amp; Act simultaneously âœ¨ Based on a fully self-developed stack: GLM-4 for general, GLM-Z1 for inference, and GLM-Z1-Rumination for rumination âœ¨ Will openly share these models on April 14 ğŸ¤¯ Preview versionğŸ‘‰ https://autoglm-research.zhipuai.cn/?channel=autoglm_android See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/863826405061849</guid></item><item><title>AReal-Boba ğŸ”¥ a fully open RL Frameworks released by AntGroup, an affiliate company of Alibaba.</title><link>https://huggingface.co/posts/AdinaY/252351292657061</link><description>AReal-Boba ğŸ”¥ a fully open RL Frameworks released by AntGroup, an affiliate company of Alibaba. inclusionAI/areal-boba-67e9f3fa5aeb74b76dcf5f0a âœ¨ 7B/32B - Apache2.0 âœ¨ Outperform on math reasoning âœ¨ Replicating QwQ-32B with 200 data under $200 âœ¨ All-in-one: weights, datasets, code &amp; tech report See translation</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/252351292657061</guid></item><item><title>â€¼ï¸ huggingface_hub's v0.30.0 is out with our biggest update of the past two years!</title><link>https://huggingface.co/posts/Wauplin/747413191251683</link><description>â€¼ï¸ huggingface_hub's v0.30.0 is out with our biggest update of the past two years! Full release notes: https://github.com/huggingface/huggingface_hub/releases/tag/v0.30.0 . ğŸš€ Ready. Xet. Go! Xet is a groundbreaking new protocol for storing large objects in Git repositories, designed to replace Git LFS. Unlike LFS, which deduplicates files, Xet operates at the chunk levelâ€”making it a game-changer for AI builders collaborating on massive models and datasets. Our Python integration is powered by [xet-core]( https://github.com/huggingface/xet-core ), a Rust-based package that handles all the low-level details. You can start using Xet today by installing the optional dependency: pip install -U huggingface_hub[hf_xet] With that, you can seamlessly download files from Xet-enabled repositories! And donâ€™t worryâ€”everything remains fully backward-compatible if youâ€™re not ready to upgrade yet. Blog post: https://huggingface.co/blog/xet-on-the-hub Docs:...</description><pubDate>Wed, 02 Apr 2025 05:23:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Wauplin/747413191251683</guid></item></channel></rss>