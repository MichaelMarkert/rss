<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>12 Foundational AI Model Types</title><link>https://huggingface.co/posts/Kseniase/795992300839975</link><description>12 Foundational AI Model Types Let‚Äôs refresh some fundamentals today to stay fluent in the what we all work with. Here are some of the most popular model types that shape the vast world of AI (with examples in the brackets): 1. LLM - Large Language Model (GPT, LLaMA) -&gt; Large Language Models: A Survey (2402.06196) + history of LLMs: https://www.turingpost.com/t/The%20History%20of%20LLMs It's trained on massive text datasets to understand and generate human language. They are mostly build on Transformer architecture, predicting the next token. LLMs scale by increasing overall parameter count across all components (layers, attention heads, MLPs, etc.) 2. SLM - Small Language Model (TinyLLaMA, Phi models, SmolLM) A Survey of Small Language Models (2410.20011) Lightweight LM optimized for efficiency, low memory use, fast inference, and edge use. SLMs work using the same principles as LLMs 3. VLM - Vision-Language Model (CLIP, Flamingo) -&gt; An Introduction to Vision-Language Modeling...</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/795992300839975</guid></item><item><title>Having an insanely good medical LLM is pointless if it won‚Äôt answer your questions!</title><link>https://huggingface.co/posts/drwlf/878228510592624</link><description>Having an insanely good medical LLM is pointless if it won‚Äôt answer your questions! So we‚Äôve made 2 notebook for abliterating any model in order to achieve a good model that will actually help you! The notebooks are made using @ mlabonne ‚Äòs abliteration logic and datasets! Feel free to use them and happy training üòä https://github.com/dralexlup/LLM-Abliteration See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/drwlf/878228510592624</guid></item><item><title>üöÄ Videoxity is live on Hugging Face! üéûÔ∏è</title><link>https://huggingface.co/posts/zamal/148346638153657</link><description>üöÄ Videoxity is live on Hugging Face! üéûÔ∏è A powerful, modular toolkit for intelligent video manipulation and scene editing. With Videoxity, you can: üñºÔ∏è Auto-caption keyframes with BLIP üß† Filter scenes using natural language (e.g. ‚Äúremove dog scenes‚Äù) ‚úÇÔ∏è Seamlessly trim videos with FFmpeg üìä Generate frame-based summaries Powered by Groq LLM + LangChain, OpenCV, BLIP, and SentenceTransformers, Videoxity bridges vision and language to give developers full control over video content. üîß Built for developers. Feedback welcome! üëâ Try it out here fau/videoxity See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/zamal/148346638153657</guid></item><item><title>RoboBrain 2.0üî• OPEN embedded brain model by BAAIBeijing</title><link>https://huggingface.co/posts/AdinaY/444223242188874</link><description>RoboBrain 2.0üî• OPEN embedded brain model by BAAIBeijing BAAI/RoboBrain2.0-7B ‚ú® 7B - Apache 2.0 / 32B coming soon ‚ú® Supports multiple images, long videos, and high-resolution visuals ‚ú® Spatial + temporal reasoning ‚ú® Real-time memory &amp; scene graphs See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/444223242188874</guid></item><item><title>As part of Duality AI‚Äôs recent Kaggle competition, we‚Äôve released a free, fully customizable cloud scenario designed to help you create targeted datasets with YOLO-compatible labels.</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/946731855039439</link><description>As part of Duality AI‚Äôs recent Kaggle competition, we‚Äôve released a free, fully customizable cloud scenario designed to help you create targeted datasets with YOLO-compatible labels. The cloud simulation lets you customize the: üì∏ camera distance üéûÔ∏è film grain variation üñºÔ∏èbackground objects, ‚ûï and more! Create the dataset that you need by following this link: https://falcon.duality.ai/secure/scenarios/edit/cca0bc47-265a-4f67-843f-a434b63271b3?utm_source=huggingface&amp;utm_medium=social&amp;utm_campaign=general I‚Äôve attached an instructional video we used for the competition, but this feature is free for anyone who has an account. https://vimeo.com/1091271731?share=copy See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/946731855039439</guid></item><item><title>Super excited to launch Hugging Face Sheets: Spreadsheets meet AI and unstructured data.</title><link>https://huggingface.co/posts/dvilasuero/324662497616161</link><description>Super excited to launch Hugging Face Sheets: Spreadsheets meet AI and unstructured data. A few months ago, we started imagining new ways to build and transform datasets with the latest open-source models. Today, I'm thrilled to introduce our first step in this direction. In a nutshell: üìÅ Effortlessly run prompts and models over your data. üåê Agentic search for accuracy and real-time information. üñºÔ∏è Familiar, minimalistic interface for interacting with data. üéØ Human feedback 2.0: Your input directly improves generated data. üíØ Access hundreds of open models and leading inference providers. Go to this space to try it out! aisheets/sheets Leave your questions below, we're just getting started! See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dvilasuero/324662497616161</guid></item><item><title>Inspired by Hugging Face's official MCP server, I've developed a complementary tool that exposes my semantic search API to enhance discovery across the HF platform.</title><link>https://huggingface.co/posts/davanstrien/750748889354716</link><description>Inspired by Hugging Face's official MCP server, I've developed a complementary tool that exposes my semantic search API to enhance discovery across the HF platform. Key capabilities: - AI-powered semantic search for models and datasets - Parameter count analysis via safetensors metadata - Trending content discovery - Find similar models/datasets functionality - 11 tools total for enhanced ecosystem navigation The semantic search goes beyond simple keyword matching, understanding context and relationships between different models and datasets. Example query: "Find around 10 reasoning Hugging Face datasets published in 2025 focusing on topics other than maths and science. Show a link and a short summary for each dataset." (results in video!) https://github.com/davanstrien/hub-semantic-search-mcp See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/davanstrien/750748889354716</guid></item><item><title>Agents &amp; MCP Hackathon Day 8</title><link>https://huggingface.co/posts/azettl/866417641952211</link><description>Agents &amp; MCP Hackathon Day 8 Today I added arXiv, GitHub, SEC EDGAR to the research agent. I also improved the speech bubbles of the agent so you can see exactly what is going on. As tomorrow is the last day, please try the roundtable and let me know if you miss something and I will try to add it. Also, please like the space if you find my MCP useful. Agents-MCP-Hackathon/consilium_mcp See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/azettl/866417641952211</guid></item><item><title>Snooping on HF is the best because sometimes you just discover that someone (in this case, Earth Species Project) is about to drop terabytes of sick (high quality animal sounds) data...</title><link>https://huggingface.co/posts/cgeorgiaw/953713233096323</link><description>Snooping on HF is the best because sometimes you just discover that someone (in this case, Earth Species Project) is about to drop terabytes of sick (high quality animal sounds) data... EarthSpeciesProject/NatureLM-audio-training See translation</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/cgeorgiaw/953713233096323</guid></item><item><title>Ultimate ComfyUI &amp; SwarmUI on RunPod Tutorial with Addition RTX 5000 Series GPUs &amp; 1-Click to Setup :</title><link>https://huggingface.co/posts/MonsterMMORPG/478306591921253</link><description>Ultimate ComfyUI &amp; SwarmUI on RunPod Tutorial with Addition RTX 5000 Series GPUs &amp; 1-Click to Setup : https://youtu.be/R02kPf9Y3_w Tutorial Video : https://youtu.be/R02kPf9Y3_w If you want to use ComfyUI or SwarmUI with ComfyUI backend on RunPod cloud platform, this is the ultimate tutorial that you will find to step by step install ComfyUI and SwarmUI on RunPod and use each one of them. RunPod is a great platform to scale your AI generation or if you are a GPU poor, rent the very best GPUs and leverage the AI in your profession. ComfyUI is the ultimate ecosystem right now for Image and Video generation models and with SwarmUI interface leveraging ComfyUI, you can become master for gen AI. So learn how to install ComfyUI on RunPod step by step and run it. Then learn how to install SwarmUI on RunPod step by step and learn how to use it. Then learn how to give installed ComfyUI backend to SwarmUI and leverage its features and ultimate performance and optimizations. Moreover, the...</description><pubDate>Wed, 11 Jun 2025 05:23:57 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/478306591921253</guid></item></channel></rss>