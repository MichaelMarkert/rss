<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.</title><link>https://huggingface.co/posts/etemiz/710778843328598</link><description>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really "free": they are costing you your freedom if you know what i mean. See translation</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/710778843328598</guid></item><item><title>Image-to-Prompt‚ö°</title><link>https://huggingface.co/posts/ovi054/657358125503535</link><description>Image-to-Prompt‚ö° ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 üëâ Try it now: ovi054/image-to-prompt See translation</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/657358125503535</guid></item><item><title>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.üß™</title><link>https://huggingface.co/posts/prithivMLmods/284574267701705</link><description>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.üß™ ü§ó Space/App: prithivMLmods/Tiny-VLMs-Lab ‚ú¶Ô∏é Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. ‚ú¶Ô∏é Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 ‚ú¶Ô∏é GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or...</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/284574267701705</guid></item><item><title>Want to quickly try Gemma 3 270m? üíéüí¨</title><link>https://huggingface.co/posts/anakin87/751707976654130</link><description>Want to quickly try Gemma 3 270m? üíéüí¨ I made a simple Space to do that: anakin87/gemma-3-270m-it ‚ö° Fast: Flash Attention, Zero GPU ‚öôÔ∏è Configurable See translation</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/anakin87/751707976654130</guid></item><item><title>suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source?</title><link>https://huggingface.co/posts/appvoid/589674942896129</link><description>suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source? keep in mind everybody will have access to it: scientists, governments, terrorists, average people, etc... See translation</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/appvoid/589674942896129</guid></item><item><title>‚úÖ New Article: *Memory as Structured Time*</title><link>https://huggingface.co/posts/kanaria007/576453037371058</link><description>‚úÖ New Article: *Memory as Structured Time* Title: üß† History: Memory Loops as Civilization Structure üîó https://huggingface.co/blog/kanaria007/memory-loops-as-civilization-structure --- Summary: Memory is often treated as *storage and retrieval*. Structured Intelligence reframes it as *time‚Äëshaping architecture*: * *Loops that preserve context and continuity* * *Rollback paths that enable reflection and correction* * *Patterns that turn experience into adaptive structure* &gt; Memory isn‚Äôt static ‚Äî &gt; *it‚Äôs how intelligence edits time.* --- Why It Matters: ‚Ä¢ Reveals *how memory enables learning, identity, and adaptation* ‚Ä¢ Supports *AI that can reflect, revise, and self‚Äëalign* ‚Ä¢ Connects *personal cognition and collective history* as structural processes --- What‚Äôs Inside: ‚Ä¢ Memory as *recursive structural loop* ‚Ä¢ *Failure and recovery* as part of adaptive recall ‚Ä¢ How *history and record‚Äëkeeping mirror cognitive memory* ‚Ä¢ Implications for *resilient AI and social knowledge systems* --- üìñ...</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/576453037371058</guid></item><item><title>benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :(</title><link>https://huggingface.co/posts/etemiz/891816438009932</link><description>benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :( See translation</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/891816438009932</guid></item><item><title>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:</title><link>https://huggingface.co/posts/fdaudens/770107969696647</link><description>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines &amp; specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup ‚Äî just open-weight GPT-OSS models via Hugging Face If you‚Äôve been wanting to try agents but weren‚Äôt sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/770107969696647</guid></item><item><title>üî•Check out new SOTA Orpheus Auto-Continuations Generatorüî•</title><link>https://huggingface.co/posts/asigalov61/289707289100732</link><description>üî•Check out new SOTA Orpheus Auto-Continuations Generatorüî• asigalov61/Orpheus-Music-Transformer Now you can generate good music with Orpheus without supervision!!! @ Timzoid @ John6666 @ alvanalrakib See translation</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/asigalov61/289707289100732</guid></item><item><title>üß¨ Breaking news in Clinical AI: Introducing the OpenMed NER Model Discovery App on Hugging Face üî¨</title><link>https://huggingface.co/posts/MaziyarPanahi/751516664507693</link><description>üß¨ Breaking news in Clinical AI: Introducing the OpenMed NER Model Discovery App on Hugging Face üî¨ OpenMed is back! üî• Finding the right biomedical NER model just became as precise as a PCR assay! I'm thrilled to unveil my comprehensive OpenMed Named Entity Recognition Model Discovery App that puts 384 specialized biomedical AI models at your fingertips. üéØ Why This Matters in Healthcare AI: Traditional clinical text mining required hours of manual model evaluation. My Discovery App instantly connects researchers, clinicians, and data scientists with the exact NER models they need for their biomedical entity extraction tasks. üî¨ What You Can Discover: ‚úÖ Pharmacological Models - Extract "chemical compounds", "drug interactions", and "pharmaceutical" entities from clinical notes ‚úÖ Genomics &amp; Proteomics - Identify "DNA sequences", "RNA transcripts", "gene variants", "protein complexes", and "cell lines" ‚úÖ Pathology &amp; Disease Detection - Recognize "pathological formations", "cancer types",...</description><pubDate>Mon, 18 Aug 2025 05:28:24 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MaziyarPanahi/751516664507693</guid></item></channel></rss>