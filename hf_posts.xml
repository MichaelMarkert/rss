<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Happy birthday to me!!!</title><link>https://huggingface.co/posts/Reality123b/635291729211142</link><description>Happy birthday to me!!! See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reality123b/635291729211142</guid></item><item><title>We have updated our transcription model:</title><link>https://huggingface.co/posts/hypothetical/242547767593660</link><description>We have updated our transcription model: TheStageAI/thewhisper-large-v3-turbo ‚Äì 6.00 WER on the English Open ASR Leaderboard ‚Äì 4.74 WER on the Multilingual Open ASR Leaderboard ‚Äì Beats NVIDIA Parakeet (6.34 WER) and Whisper-large-v3-turbo (7.8 WER) ‚Äì Strong improvements in Arabic, Hindi, Chinese ‚Äì Maintains quality with background and environmental noise ‚Äì Optimized inference engines for NVIDIA and Apple ‚Äì Hugging Face Transformers interface for easy use ‚Äì Best-in-class speed on NVIDIA GPUs and power efficiency on Apple devices ‚Äì NVIDIA Jetson Thor support See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hypothetical/242547767593660</guid></item><item><title>Qwen just released two new model series: Qwen3-VL-Embedding &amp; Qwen3-VL-Reranker üöÄ</title><link>https://huggingface.co/posts/AdinaY/677909506898469</link><description>Qwen just released two new model series: Qwen3-VL-Embedding &amp; Qwen3-VL-Reranker üöÄ ‚ú® 2B / 8B - Apache2.0 ‚ú® 30+ languages ‚ú® Supported text, images, screenshots, videos, and arbitrary multimodal combinations Qwen3-VL-Embedding: Flexible vector sizes (64‚Äì2048) https://huggingface.co/collections/Qwen/qwen3-vl-embedding Qwen3-VL-Reranker: Built for recall&gt;rerank pipelines https://huggingface.co/collections/Qwen/qwen3-vl-reranker See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/677909506898469</guid></item><item><title>New GRPO + TRL free Colab notebook out! üî•</title><link>https://huggingface.co/posts/sergiopaniego/609901844144152</link><description>New GRPO + TRL free Colab notebook out! üî• Fine-tune 7B+ models on T4 GPUs thanks to a ton of memory optimizations for GRPO 7B model uses only 9.2 GB VRAM (~7√ó reduction) ü§Ø Try the notebook here üëâ https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_trl_lora_qlora.ipynb See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/609901844144152</guid></item><item><title>üéâ Exciting News ‚Äî NVIDIA Cosmos is celebrating its 1st birthday and has hit 5 MILLION downloads! üéâ</title><link>https://huggingface.co/posts/tsungyi/951918573083601</link><description>üéâ Exciting News ‚Äî NVIDIA Cosmos is celebrating its 1st birthday and has hit 5 MILLION downloads! üéâ In just one year, the Cosmos ecosystem has grown rapidly: üß† Cosmos Reason and Cosmos Predict have surpassed 2 MILLION downloads each on @ HuggingFace , topping physical AI leaderboards üîÑ Cosmos Transfer is enabling adaptation across domains and tasks üîÆ Cosmos Cookbook is the go-to hub for recipes from developers and partners like Uber and IntBot. Thank you to our amazing developer community for making this possible. Here's to pushing the boundaries of world foundation models together! üßëüèª‚Äçüç≥Read the Cosmos Cookbook: https://nvda.ws/4qevli8 üìö Explore Models &amp; Datasets: https://huggingface.co/collections/nvidia/nvidia-cosmos-2 See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tsungyi/951918573083601</guid></item><item><title>New family of 1B models just dropped!</title><link>https://huggingface.co/posts/mlabonne/713929804806596</link><description>New family of 1B models just dropped! &gt; LiquidAI/LFM2.5-1.2B-Base : 10T ‚Üí 28T tokens &gt; LiquidAI/LFM2.5-1.2B-Instruct : new large-scale multi-stage RL &gt; LiquidAI/LFM2.5-1.2B-JP : our most polite model &gt; LiquidAI/LFM2.5-VL-1.6B : multi-image multilingual &gt; LiquidAI/LFM2.5-Audio-1.5B : 8x times faster, no quality loss Super proud of this release ü§ó See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mlabonne/713929804806596</guid></item><item><title>I‚Äôve built two Firefox extensions for my personal workflow:</title><link>https://huggingface.co/posts/JLouisBiz/620644523229509</link><description>I‚Äôve built two Firefox extensions for my personal workflow: 1. **Quick Edit in Emacs** I manage over 3,500 web pages locally. With this extension, I can now click anywhere on a webpage and instantly jump into Emacs to edit the exact page (or annotate any other page I'm working on). 2. **Describe Images (and soon Videos) on the Web** Using the right-click menu, I can generate descriptions for images I come across online. These descriptions are stored and reused for my own image collections or web pages. I‚Äôm planning to add the same functionality for videos soon. What makes this possible is running LLMs locally on my own machine ‚Äî I‚Äôve been experimenting with models like **Mistral Vibe** and others. This lets me automate description generation and text processing entirely offline, keeping everything fast, private, and fully under my control. See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JLouisBiz/620644523229509</guid></item><item><title>Atom-80B is out!:</title><link>https://huggingface.co/posts/unmodeled-tyler/111185407753079</link><description>Atom-80B is out!: vanta-research/atom-80b I'm excited to share the new Atom-80B from VANTA Research! A few days ago we released the largest model-to-date from our portfolio, which was Atom-27B. We've quickly scaled up to the new Qwen3 Next 80B architecture, bringing our friendly, curious, and collaborative Atom persona to cutting edge lightweight, high parameter inference. Atom is designed to work and think alongside you through curious exploration. Using Atom collaboratively in your work can help spark your own creativity or curiosity. Give it a try! See translation</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/111185407753079</guid></item><item><title>Scaling Physical AI: SAM 3D, NVIDIA Cosmos, and Unreal Engine!</title><link>https://huggingface.co/posts/mindchain/396197878979681</link><description>Scaling Physical AI: SAM 3D, NVIDIA Cosmos, and Unreal Engine! The "Sim-to-Real" gap is officially history. In early 2026, we are no longer just rendering data; we are simulating reality. By bridging Meta‚Äôs SAM 3D, Unreal Engine, and the NVIDIA Cosmos suite, we‚Äôve built an autonomous pipeline for Physical AI that evolves itself. The 2026 Tech Stack: SAM 3D: Generates high-fidelity digital twins from 2D photos in seconds. Unreal Engine + MCP: The AI "Director" orchestrates environments via the Model Context Protocol, providing perfect Ground Truth. NeMo Data Designer: The orchestration hub on GitHub. Following NVIDIA‚Äôs acquisition of Gretel in early 2025, its leading generative privacy and tabular tech are now fully integrated here. NVIDIA Cosmos Transfer: Neural rendering that adds hyper-realism to Unreal Engine outputs. NVIDIA Cosmos Predict: Predicts physically accurate motion (falling, sliding) without manual animation. NVIDIA Cosmos Reason: The automated supervisor checking...</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mindchain/396197878979681</guid></item><item><title>‚úÖ New Article: *PoC Architecture for Education &amp; Developmental Support*</title><link>https://huggingface.co/posts/kanaria007/141065277072114</link><description>‚úÖ New Article: *PoC Architecture for Education &amp; Developmental Support* Title: üéì Building an SI-Core Wrapped Learning Companion - PoC architecture for education and developmental support üîó https://huggingface.co/blog/kanaria007/poc-architecture-for-education-development-support --- Summary: Most ‚ÄúAI tutors‚Äù are built as *LLM-first* systems. This article flips the default: * The LLM is treated as an *untrusted proposal engine* * *SI-Core owns* observation, consent, ethics, memory, and rollback * Teachers and guardians get *real oversight*, not just chat transcripts Scoped intentionally to *one subject √ó a small cohort (10‚Äì30 learners)*, this is a PoC you can actually ship‚Äîand audit. &gt; Don‚Äôt ask: ‚ÄúCan an AI replace teachers?‚Äù &gt; Prove: ‚ÄúCan we make an AI companion *safe, explainable, and governable* for real learners?‚Äù --- Why It Matters (for AI on real stacks): ‚Ä¢ *Consent &amp; accommodations* are first-class (especially for minors / neurodivergent learners) ‚Ä¢ *Ethics decisions are...</description><pubDate>Sat, 10 Jan 2026 05:26:55 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/141065277072114</guid></item></channel></rss>