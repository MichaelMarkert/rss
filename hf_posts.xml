<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Christmas came early this year</title><link>https://huggingface.co/posts/csabakecskemeti/277521964775652</link><description>Christmas came early this year See translation</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/277521964775652</guid></item><item><title>ğŸ‰ I am excited to share news of a project my brother, Umar Butler, and I have been working on for what feels like an eternity now.</title><link>https://huggingface.co/posts/abdurrahmanbutler/994710514786612</link><description>ğŸ‰ I am excited to share news of a project my brother, Umar Butler, and I have been working on for what feels like an eternity now. ğˆğ§ğ­ğ«ğ¨ğğ®ğœğ¢ğ§ğ  ğŒğ‹ğ„ğ â€” ğ­ğ¡ğ ğŒğšğ¬ğ¬ğ¢ğ¯ğ ğ‹ğğ ğšğ¥ ğ„ğ¦ğ›ğğğğ¢ğ§ğ  ğğğ§ğœğ¡ğ¦ğšğ«ğ¤. A suite of 10 high-quality English legal IR datasets, designed by legal experts to set a new standard for comparing embedding models. Whether youâ€™re exploring legal RAG on your home computer, or running enterprise-scale retrieval, apples-to-apples evaluation is crucial. Thatâ€™s why weâ€™ve open-sourced everything - including our 7 brand-new, hand-crafted retrieval datasets. All of these datasets are now live on Hugging Face. Any guesses which embedding model leads on legal retrieval? ğ‡ğ¢ğ§ğ­: itâ€™s not OpenAI or Google - they place 7th and 9th on our leaderboard. To do well on MLEB, embedding models must demonstrate both extensive legal domain knowledge and strong legal reasoning skills. https://huggingface.co/blog/isaacus/introducing-mleb See translation</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abdurrahmanbutler/994710514786612</guid></item><item><title>MLEB  is the largest, most diverse, and most comprehensive benchmark for legal text embedding models.</title><link>https://huggingface.co/posts/adlumal/955872232459431</link><description>MLEB is the largest, most diverse, and most comprehensive benchmark for legal text embedding models. https://huggingface.co/blog/isaacus/introducing-mleb See translation</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/adlumal/955872232459431</guid></item><item><title>The Secret to FREE, Local AI Image Generation is Finally Here</title><link>https://huggingface.co/posts/MonsterMMORPG/932213585157202</link><description>The Secret to FREE, Local AI Image Generation is Finally Here Tutorial video : https://youtu.be/c3gEoAyL2IE ğŸ¨ Stop struggling with complex AI image generation! In this tutorial, I reveal the ultimate, one-click solution to creating stunning, photorealistic, and stylized AI art LOCALLY on your own computerâ€”for FREE. Tired of confusing workflows, endless command lines, and expensive subscriptions? Forget everything you know about Stable Diffusion and ComfyUI's complexity. I'm introducing you to SwarmUI, the revolutionary tool that leverages the power of ComfyUI's backend with an incredibly simple, user-friendly interface. This isn't just another AI tutorial. This is a complete, all-in-one guide that takes you from ZERO to AI Art PRO in minutes. I provide a one-click installer that sets up everything you need, including pre-configured presets for achieving breathtaking realism and incredible stylization. ğŸ”¥ In This Video, You Will Discover: The Easiest AI Art Install Ever: A step-by-...</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/932213585157202</guid></item><item><title>I just set up the new Ollama integration in VS Code, so I wanted to test it. I hooked up glm-4.6, and asked it to build a full stack Ollama chat interface.</title><link>https://huggingface.co/posts/unmodeled-tyler/140461476722015</link><description>I just set up the new Ollama integration in VS Code, so I wanted to test it. I hooked up glm-4.6, and asked it to build a full stack Ollama chat interface. In only 3 prompts, glm-4.6 built the app, and debugged it successfully. One prompt for the build, two for debugging -&gt; fully functional app. I was genuinely impressed! It's really cool to see how powerful open source tools have become. The future is exciting and I'm here for it! See translation</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/140461476722015</guid></item><item><title>AutoRound keeps evolving its LLM quantization algorithm! ğŸš€</title><link>https://huggingface.co/posts/wenhuach/917073841450527</link><description>AutoRound keeps evolving its LLM quantization algorithm! ğŸš€ After enhancing W2A16 quantization, we now offer a fast algorithm to generate mixed bits/data-type schemes (~2mins for 8B models), great for MXFP4 and W2A16. Learn more: https://github.com/intel/auto-round/blob/main/docs/step_by_step.md#autoscheme See translation</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wenhuach/917073841450527</guid></item><item><title>There are two very interesting reasoning models from</title><link>https://huggingface.co/posts/mike-ravkine/370448674179433</link><description>There are two very interesting reasoning models from ServiceNow-AI that I think are flying under everyone's radar - lets take a closer look at ServiceNow-AI/Apriel-1.5-15b-Thinker (#10 on the ReasonScape rankings) and ServiceNow-AI/Apriel-Nemotron-15b-Thinker (landing just below its brother at #12). A rather interesting attribute of these models is I have absolutely no idea what they are fine-tuned from, other then some kind of pre-small Mistrals! The non-nemo 15b looks like Mistral Pixtral 12B, but with 8 more layers while the nemo 15b analogously looks like Mistral NeMo 12B but with 10 more layers and a smaller max context length. The performance trade-offs between these two models are quite clear: the Nemotron provides ~30% shorter answers but at the expense of totally collapsing under difficulty on 4 of the 12 tasks ... which all just happen to have "Math" in common, so it's pretty easy to point the finger at exactly what the price for the lower reasoning token usage is here. In...</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mike-ravkine/370448674179433</guid></item><item><title>Bee-8B ğŸ open 8B Multimodal LLM built on high quality data, released by</title><link>https://huggingface.co/posts/AdinaY/881278132358680</link><description>Bee-8B ğŸ open 8B Multimodal LLM built on high quality data, released by TencentHunyuan Paper: Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs (2510.13795) Model: Open-Bee/bee-8b-68ecbf10417810d90fbd9995 âœ¨ Trained on Honey-Data-15M, a 15M-sample SFT corpus with dual-level CoT reasoning âœ¨ Backed by HoneyPipe, a transparent &amp; reproducible open data curation suite See translation</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/881278132358680</guid></item><item><title>Now you can try all the latest state-of-the-art multimodal vision-language models from the Qwen3-VL series demo on Hugging Face Spaces â€” including 4B, 8B, and 30B (Instruct, 4B-Thinking) variants. Iâ€™ve also uploaded the weights for the Abliterated variants of these models, up to 30B parameters. Check out the Spaces and model links below! ğŸ¤—ğŸ”¥</title><link>https://huggingface.co/posts/prithivMLmods/967861422994938</link><description>Now you can try all the latest state-of-the-art multimodal vision-language models from the Qwen3-VL series demo on Hugging Face Spaces â€” including 4B, 8B, and 30B (Instruct, 4B-Thinking) variants. Iâ€™ve also uploaded the weights for the Abliterated variants of these models, up to 30B parameters. Check out the Spaces and model links below! ğŸ¤—ğŸ”¥ âœ¨ Qwen3-VL[4B,8B]: prithivMLmods/Qwen3-VL-Outpost âœ¨ Qwen3-VL-30B-A3B-Demo: prithivMLmods/Qwen3-VL-HF-Demo âœ¨ Collection: prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 Qwen3-VL Abliterated Model Collection [ Version 1.0 ] âœ¨ Qwen3-VL-8B-Instruct-abliterated: prithivMLmods/Qwen3-VL-8B-Instruct-abliterated âœ¨ Qwen3-VL-4B-Instruct-abliterated: prithivMLmods/Qwen3-VL-4B-Instruct-abliterated âœ¨ Qwen3-VL-8B-Thinking-abliterated: prithivMLmods/Qwen3-VL-8B-Thinking-abliterated âœ¨ Qwen3-VL-4B-Thinking-abliterated: prithivMLmods/Qwen3-VL-4B-Thinking-abliterated âœ¨ Qwen3-VL-30B-A3B-Instruct-abliterated: prithivMLmods/Qwen3-VL-30B-A3B-Instruct-...</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/967861422994938</guid></item><item><title>ğŸ‘‹ Hey i have Just uploaded 2 new datasets for code and scientific reasoning models:</title><link>https://huggingface.co/posts/nick007x/296214873413452</link><description>ğŸ‘‹ Hey i have Just uploaded 2 new datasets for code and scientific reasoning models: 1. ArXiv Papers (4.6TB) A massive scientific corpus with papers and metadata across all domains.Perfect for training models on academic reasoning, literature review, and scientific knowledge mining. ğŸ”—Link: nick007x/arxiv-papers 2. GitHub Code 2025 (1 TB)a comprehensive code dataset for code generation and analysis tasks. mostly contains GitHub's high quality top 1 million repos above 2 stars ğŸ”—Link: nick007x/github-code-2025 See translation</description><pubDate>Sat, 18 Oct 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nick007x/296214873413452</guid></item></channel></rss>