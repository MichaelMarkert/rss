<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>✨ DreamO Video: From Customized Images to Videos ✨</title><link>https://huggingface.co/posts/openfree/538970335354687</link><description>✨ DreamO Video: From Customized Images to Videos ✨ Hello, AI creators! Today I'm introducing a truly special project. DreamO Video is an integrated framework that generates customized images based on reference images and transforms them into videos with natural movement. 🎬✨ openfree/DreamO-video 🔍 Key Features Image Reference (IP): Maintain object appearance while applying to new backgrounds and situations ID Preservation: Retain facial features across various environments Style Transfer: Apply unique styles from reference images to other content 🎞️ Video Generation: Create natural 2-second videos from generated images 💡 How to Use Upload Reference Images: One or two images (people, objects, landscapes, etc.) Select Task Type: Choose between IP (Image Preservation), ID (Face Feature Retention), or Style Enter Prompt: Describe your desired result (e.g., "a woman playing guitar on a cloud") Click Generate Image: ✨ Create customized AI images! Generate Video: Click the 🎬 button on the...</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/538970335354687</guid></item><item><title>VLMS 2025 UPDATE 🔥</title><link>https://huggingface.co/posts/merve/544378273517703</link><description>VLMS 2025 UPDATE 🔥 We just shipped a blog on everything latest on vision language models, including 🤖 GUI agents, agentic VLMs, omni models 📑 multimodal RAG ⏯️ video LMs 🤏🏻 smol models ..and more! https://huggingface.co/blog/vlms-2025 See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/544378273517703</guid></item><item><title>Today we launch Dione.</title><link>https://huggingface.co/posts/blaise-tk/108431169603656</link><description>Today we launch Dione. A few months ago it was just a wild idea I shared with @ bygimenez , now it's real. Dione (Beta) is here, the easiest way to discover and install open-source apps, especially AI ones. Think of it as the Steam of open source. Installing open-source tools is often a mess. Dione fixes that. Beautiful UI and workflow. Soon multi-platform, multilingual &amp; fully open-source. Users can even write and share their own installation scripts. This is just the beginning. 🚀 Join our exclusive Beta → https://getdione.app/beta/join See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/blaise-tk/108431169603656</guid></item><item><title># 🌟 3D Model to Video: Easy GLB Conversion Tool 🌟</title><link>https://huggingface.co/posts/ginipick/766230066345476</link><description># 🌟 3D Model to Video: Easy GLB Conversion Tool 🌟 demo link: ginigen/3D-VIDEO Hello there! Would you like to transform your 3D models into stunning animations? This space can help you! ✨ ## 🔍 What Can It Do? This tool converts your uploaded GLB model into: 1. 🎮 A transformed GLB file 2. 🎬 An animated GIF preview 3. 📋 A metadata JSON file ## ✅ Key Features * 🖥️ Works in headless server environments (EGL + pyglet-headless → pyrender fallback) * 🔍 Objects in GIFs appear 3x larger (global scale ×3) * 🎨 Clean interface with pastel background ## 🎮 Animation Types * 🔄 Rotate - Object rotates around the Y-axis * ⬆️ Float - Object moves smoothly up and down * 💥 Explode - Object moves sideways * 🧩 Assemble - Object returns to its original position * 💓 Pulse - Object changes in size * 🔄 Swing - Object swings around the Z-axis ## 🛠️ How to Use 1. Upload your GLB model 📤 2. Select your desired animation type 🎬 3. Adjust the duration and FPS ⏱️ 4. Click the "Generate Animation" button ▶️ 5....</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/766230066345476</guid></item><item><title>11 Alignment and Optimization Algorithms for LLMs</title><link>https://huggingface.co/posts/Kseniase/849940009274643</link><description>11 Alignment and Optimization Algorithms for LLMs When we need to align models' behavior with the desired objectives, we rely on specialized algorithms that support helpfulness, accuracy, reasoning, safety, and alignment with user preferences. Much of a model’s usefulness comes from post-training optimization methods. Here are the main optimization algorithms (both classic and new) in one place: 1. PPO (Proximal Policy Optimization) -&gt; Proximal Policy Optimization Algorithms (1707.06347) Clips the probability ratio to prevent the new policy from diverging too far from the old one. It helps keep everything stable 2. DPO (Direct Preference Optimization) -&gt; Direct Preference Optimization: Your Language Model is Secretly a Reward Model (2305.18290) It's a non RL method, where an LM is an implicit reward model. It uses a simple loss to boost the preferred answer’s probability over the less preferred one 3. GRPO (Group Relative Policy Optimization) -&gt; DeepSeekMath: Pushing the Limits of...</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/849940009274643</guid></item><item><title>this book actually exists for free, “the little book of deep learning”. best to refresh your mind about DL basics:</title><link>https://huggingface.co/posts/hesamation/756119536681094</link><description>this book actually exists for free, “the little book of deep learning”. best to refresh your mind about DL basics: &gt; foundations of machine learning &gt; how models train &gt; common layers (dropout, pooling…) &gt; basic intro to LLMs actually optimized for mobile. Book: https://fleuret.org/public/lbdl.pdf See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/756119536681094</guid></item><item><title>✨ We’re live! Introducing TFrameX, the agentic framework for AI builders.</title><link>https://huggingface.co/posts/smirki/468999292160757</link><description>✨ We’re live! Introducing TFrameX, the agentic framework for AI builders. After nights of development, we’re finally open-sourcing TFrameX, a powerful AI agent communication and coordination library. TFrameX lets you: 🤖 Run agents in dynamic flows 🔁 Compose reusable patterns like Sequential, Parallel, Router, and more 🧠 Enable agent-to-agent collaboration and delegation ⚡ Build modular, complex multi-agent systems that just work 👉 GitHub: TFrameX https://github.com/TesslateAI/TFrameX But we didn’t stop there. We also built a sleek visual builder to design, deploy, and debug your agent patterns without writing boilerplate! 🧩 Visual Studio for TFrameX: https://github.com/TesslateAI/Studio If you’re building agent frameworks, LLM tools, or agentic apps, TFrameX gives you the tools to move fast and reason deeply. See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/smirki/468999292160757</guid></item><item><title>finally, a course that makes diffusion math much easier to grasp, well done 👍</title><link>https://huggingface.co/posts/Jaward/144425660093937</link><description>finally, a course that makes diffusion math much easier to grasp, well done 👍 https://diffusion.csail.mit.edu/ See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/144425660093937</guid></item><item><title>Automatic Multi-Modal Research Agent</title><link>https://huggingface.co/posts/VirtualOasis/965866013655862</link><description>Automatic Multi-Modal Research Agent I am thinking of building an Automatic Research Agent that can boost creativity! Input: Topics or data sources Processing: Automated deep research Output: multimodal results (such as reports, videos, audio, diagrams) &amp; multi-platform publishing. There is a three-stage process In the initial Stage, output for text-based content in markdown format allows for user review before transformation into various other formats, such as PDF or HTML. The second stage transforms the output into other modalities, like audio, video, diagrams, and translations into different languages. The final stage focuses on publishing multi-modal content across multiple platforms like X, GitHub, Hugging Face, YouTube, and podcasts, etc. See translation</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/VirtualOasis/965866013655862</guid></item><item><title>Let's pipe some 𝗱𝗮𝘁𝗮 𝗳𝗿𝗼𝗺 𝘁𝗵𝗲 𝘄𝗲𝗯 into our vector database, shall we?🤠</title><link>https://huggingface.co/posts/as-cle-bert/400981312479742</link><description>Let's pipe some 𝗱𝗮𝘁𝗮 𝗳𝗿𝗼𝗺 𝘁𝗵𝗲 𝘄𝗲𝗯 into our vector database, shall we?🤠 With 𝐢𝐧𝐠𝐞𝐬𝐭-𝐚𝐧𝐲𝐭𝐡𝐢𝐧𝐠 𝐯𝟏.𝟑.𝟎 ( https://github.com/AstraBert/ingest-anything ) you can now scrape content simply starting from URLs, extract the text from it, chunk it and put it into your favorite LlamaIndex-compatible database!🕸️ You can do it thanks to 𝗰𝗿𝗮𝘄𝗹𝗲𝗲 by Apify, an open-source crawling library for python and javascript that handles all the data flow from the web: ingest-anything then combines it with 𝗕𝗲𝗮𝘂𝘁𝗶𝗳𝘂𝗹𝗦𝗼𝘂𝗽, 𝗣𝗱𝗳𝗜𝘁𝗗𝗼𝘄𝗻 and 𝗣𝘆𝗠𝘂𝗣𝗱𝗳 to scrape HTML files, convert them to PDF and extract the text - hassle-free!😸 Check the attached code snippet if you're curious of knowing how to get started🎬 PS: Don't tell anybody, but this release also has another gem... It supports OpenAI models for agentic chunking, following the new releases of Chonkie🦛✨ If you don't want to miss out on the new features, leave us a little star on GitHub ➡️ https://github.com/AstraBert/ingest-anything And join our discord community!...</description><pubDate>Tue, 13 May 2025 05:23:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/400981312479742</guid></item></channel></rss>