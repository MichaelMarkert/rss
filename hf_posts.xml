<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>I run 20 AI coding agents locally on my desktop workstation at 400+ tokens/sec with MiniMax-M2. Itâ€™s a Sonnet drop-in replacement in my Cursor, Claude Code, Droid, Kilo and Cline peak at 11k tok/sec input and 433 tok/s output, can generate 1B+ tok/m.All with 196k context window. I'm running it for 6 days now with this config.</title><link>https://huggingface.co/posts/mitkox/488545088120873</link><description>I run 20 AI coding agents locally on my desktop workstation at 400+ tokens/sec with MiniMax-M2. Itâ€™s a Sonnet drop-in replacement in my Cursor, Claude Code, Droid, Kilo and Cline peak at 11k tok/sec input and 433 tok/s output, can generate 1B+ tok/m.All with 196k context window. I'm running it for 6 days now with this config. Today max performance was stable at 490.2 tokens/sec across 48 concurrent clients and MiniMax M2. Z8 Fury G5, Xeon 3455, 4xA6K. Aibrix 0.5.0, vLLM 0.11.2, See translation</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mitkox/488545088120873</guid></item><item><title>I am now being charged for paused and unstarted spaces out of the blue.</title><link>https://huggingface.co/posts/nroggendorff/660079914865865</link><description>I am now being charged for paused and unstarted spaces out of the blue. I think this is it, folks. o7 The unstarted spaces I can get behind. I would've appreciated a warning email first, but whatever. However, every time I restart the active usage goes up, despite all of my spaces being moved to CPU (free), and being paused. See translation</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/660079914865865</guid></item><item><title>SceneWeaver â€” AI-Powered Background Generation &amp; Image Composition ğŸ¨âœ¨</title><link>https://huggingface.co/posts/DawnC/810522223628641</link><description>SceneWeaver â€” AI-Powered Background Generation &amp; Image Composition ğŸ¨âœ¨ Transform ordinary portraits into professional studio shots with just one click! What can SceneWeaver do? - ğŸ“¸ Upload any portrait photo and instantly generate stunning, professional-quality backgrounds - ğŸ­ Smart Subject Detection â€” Automatically identifies and extracts people, pets, or objects from your photos, even handling tricky cases like dark clothing and cartoon characters. - ğŸŒ„ Creative Scene Library â€” Choose from 24 professionally curated backgrounds spanning offices, nature landscapes, urban settings, artistic styles, and seasonal themes, or describe your own custom vision. - âš™ï¸ Professional Results â€” Delivers studio-quality compositions in seconds, saving hours of manual editing work while maintaining natural lighting and color harmony. What's next? ğŸ¬ Enhanced context-aware generation ğŸ¨ Batch processing for multiple style variations ğŸ”§ Higher resolution output support ğŸŒ Accessible cloud deployment Current...</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/810522223628641</guid></item><item><title>I wanted to call attention to Arli Ai's success in applying my recent modifications to refusal ablation to a MoE model successfully. Nice work,</title><link>https://huggingface.co/posts/grimjim/634931502597925</link><description>I wanted to call attention to Arli Ai's success in applying my recent modifications to refusal ablation to a MoE model successfully. Nice work, @ OwenArli ! ArliAI/GLM-4.5-Air-Derestricted Ablation on a MoE model is no small thing; I expect preserving norms/magnitudes during intervention better respects routing compared to naive refusal ablation. (I would have tagged their org, but that feature seems to be broken at the moment.) See translation</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/grimjim/634931502597925</guid></item><item><title>Hey everyone! ğŸ‘‹</title><link>https://huggingface.co/posts/Reubencf/751562087510582</link><description>Hey everyone! ğŸ‘‹ I am thrilled to present MCP-1st-Birthday/Reuben_OS my submission for the Hugging Face MCP 1st Birthday Hackathon (Creative Track). ReubenOS is a virtual cloud-based operating system designed specifically to act as a backend for Claude Desktop via the Model Context Protocol (MCP). It gives Claude a persistent environment to work in! âœ¨ Key Features * ğŸ“± Flutter IDE: Claude can write Flutter code and I can view/execute the files directly in the ReubenOS dashboard. * ğŸµ AI Audio Studio: Integrated with ElevenLabs to generate songs and voiceovers from text prompts within Claude. * ğŸ”’ Secure File System: A passkey-protected file system (private &amp; public folders) to store code, JSON, and documents. * ğŸ§  Gemini Integration: Access Google's Gemini model directly inside the OS. * ğŸ“ Quiz Engine: Ask Claude to "Create a Python quiz," and it deploys a graded interactive quiz to the web instantly. See translation</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reubencf/751562087510582</guid></item><item><title>Introducing the advanced sketch-board editor "Nano-Banana-Pro-Sketch-Board" powered by the Gemini 2.5 Flash Image and Gemini 3 Pro Preview Image models through the Gemini API. This version includes more features than the Nano-Banana-AIO app for drawing and prompt-based concept transformation of freestyle sketches. ğŸ”¥ğŸŒ</title><link>https://huggingface.co/posts/prithivMLmods/585236174284354</link><description>Introducing the advanced sketch-board editor "Nano-Banana-Pro-Sketch-Board" powered by the Gemini 2.5 Flash Image and Gemini 3 Pro Preview Image models through the Gemini API. This version includes more features than the Nano-Banana-AIO app for drawing and prompt-based concept transformation of freestyle sketches. ğŸ”¥ğŸŒ âœ¨Nano-Banana-Pro-Sketch-Board: prithivMLmods/Nano-Banana-Pro-Sketch-Board âœ¨Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection âœ¨Github: https://github.com/PRITHIVSAKTHIUR/Nano-Banana-Pro-Sketch-Board âœ¨Model-Garden: https://tinyurl.com/4xxs9dvy Some Other Relevant Apps [OSS] â­Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast-Fusion â­Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast â­Photo-Mate-i2i: prithivMLmods/Photo-Mate-i2i â­Kontext-Photo-Mate-v2: prithivMLmods/Kontext-Photo-Mate-v2 Note: The Nano-Banana-Pro-Sketch-Board demo requires a Gemini API key for the...</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/585236174284354</guid></item><item><title>Both cat and  dog has RL, vision, hearing abilities like a human.  And they acted - run and jump - better than Optimus. Why can human own  cat and dog? Maybe we have better LLM model in brain than that of cat and dog?</title><link>https://huggingface.co/posts/John1604/431236892313740</link><description>Both cat and dog has RL, vision, hearing abilities like a human. And they acted - run and jump - better than Optimus. Why can human own cat and dog? Maybe we have better LLM model in brain than that of cat and dog? çŒ«å’Œç‹—éƒ½æ‹¥æœ‰åƒäººç±»ä¸€æ ·çš„å¼ºåŒ–å­¦ä¹ èƒ½åŠ›ã€è§†è§‰å’Œå¬è§‰ã€‚è€Œä¸”å®ƒä»¬è·‘è·³ç­‰æ–¹é¢çš„è¡¨ç°ç”šè‡³æ¯”æ“å¤©æŸ±è¿˜è¦å‡ºè‰²ã€‚ä¸ºä»€ä¹ˆäººç±»å¯ä»¥é¥²å…»çŒ«å’Œç‹—å‘¢ï¼Ÿæˆ–è®¸æˆ‘ä»¬çš„å¤§è„‘æ‹¥æœ‰æ¯”çŒ«ç‹—æ›´ä¼˜ç§€çš„å¤§è¯­è¨€æ¨¡å‹ï¼Ÿ See translation</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/John1604/431236892313740</guid></item><item><title>Interested in RL training environments?</title><link>https://huggingface.co/posts/sergiopaniego/841067327080467</link><description>Interested in RL training environments? We just released a beginner-friendly walkthrough notebook! Train a model to play Wordle using TRL + OpenEnv (TextArena) + GRPO + vLLM. happy learning! ğŸŒ± Notebook: https://github.com/huggingface/trl/blob/main/examples/notebooks/openenv_wordle_grpo.ipynb OpenEnv guide in TRL: https://huggingface.co/docs/trl/main/en/openenv See translation</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/841067327080467</guid></item><item><title>6 Essential Reads on Spatial Intelligence</title><link>https://huggingface.co/posts/Kseniase/693757616060963</link><description>6 Essential Reads on Spatial Intelligence In AI, spatial intelligence is basically the modelâ€™s â€œsense of spaceâ€ â€“ its ability to understand where things are, how they relate, and how they move. It lets an AI models navigate a room, interpret a scene, or figure out how objects fit together, like giving it a built-in mental map. For example, world models can't live without spatial intelligence. Here are 6 good reads to explore what spatial intelligence is and how it's evolving: 1. From Words to Worlds: Spatial Intelligence is AIâ€™s Next Frontier by Fei-Fei Li â†’ https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence Fei-Fei Li, the godmother of AI, is a key figure in spatial intelligence, since her work in computer vision, especially ImageNet, helped AI learn to recognize and understand objects in space. She's recently started a blog, and this post, in particular, argues that true intelligence requires grounding in space, understanding geometry, motion and...</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/693757616060963</guid></item><item><title>Introducing the japanese-trending-words dataset: a dataset consisting 593 words from Japanâ€™s annual trending word rankings (æµè¡Œèªå¤§è³) from 2006-2025. This dataset provides the top 30 words from each year and its meaning in Japanese and english. This resource is awesome for NLP tasks understanding recent Japanese culture and history.</title><link>https://huggingface.co/posts/ronantakizawa/796142001232258</link><description>Introducing the japanese-trending-words dataset: a dataset consisting 593 words from Japanâ€™s annual trending word rankings (æµè¡Œèªå¤§è³) from 2006-2025. This dataset provides the top 30 words from each year and its meaning in Japanese and english. This resource is awesome for NLP tasks understanding recent Japanese culture and history. ronantakizawa/japanese-trending-words #japanese #japanesedataset #trending See translation</description><pubDate>Tue, 25 Nov 2025 13:36:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/796142001232258</guid></item></channel></rss>