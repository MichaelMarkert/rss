<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>AI will bring us "a country of yes-men on servers" instead of one of "Einsteins sitting in a data center" if we continue on current trends.</title><link>https://huggingface.co/posts/fdaudens/198644025808355</link><description>AI will bring us "a country of yes-men on servers" instead of one of "Einsteins sitting in a data center" if we continue on current trends. Must-read by @ thomwolf deflating overblown AI promises and explaining what real scientific breakthroughs require. https://thomwolf.io/blog/scientific-ai.html See translation</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/198644025808355</guid></item><item><title>ğŸš€ New smolagents update: Safer Local Python Execution! ğŸ¦¾ğŸ</title><link>https://huggingface.co/posts/albertvillanova/159056887588114</link><description>ğŸš€ New smolagents update: Safer Local Python Execution! ğŸ¦¾ğŸ With the latest release, we've added security checks to the local Python interpreter: every evaluation is now analyzed for dangerous builtins, modules, and functions. ğŸ”’ Here's why this matters &amp; what you need to know! ğŸ§µğŸ‘‡ 1ï¸âƒ£ Why is local execution risky? âš ï¸ AI agents that run arbitrary Python code can unintentionally (or maliciously) access system files, run unsafe commands, or exfiltrate data. 2ï¸âƒ£ New Safety Layer in smolagents ğŸ›¡ï¸ We now inspect every return value during execution: âœ… Allowed: Safe built-in types (e.g., numbers, strings, lists) â›” Blocked: Dangerous functions/modules (e.g., os.system, subprocess, exec, shutil) 3ï¸âƒ£ Immediate Benefits ğŸ’¡ - Prevent agents from accessing unsafe builtins - Block unauthorized file or network access - Reduce accidental security vulnerabilities 4ï¸âƒ£ Security Disclaimer âš ï¸ ğŸš¨ Despite these improvements, local Python execution is NEVER 100% safe. ğŸš¨ If you need true isolation, use a remote...</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/albertvillanova/159056887588114</guid></item><item><title>10,000+ models based on Deepseek R1 have been publicly shared on Hugging Face! Which ones are your favorite ones:</title><link>https://huggingface.co/posts/clem/304267654005363</link><description>10,000+ models based on Deepseek R1 have been publicly shared on Hugging Face! Which ones are your favorite ones: https://huggingface.co/models?sort=trending&amp;search=r1 . Truly game-changer! See translation</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/304267654005363</guid></item><item><title>ğŸš€ Duality is super excited to announce that our Kaggle competition is LIVE! Synthetic-to-Real Object Detection Challenge is LIVE! ğŸš¦</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/233802872800595</link><description>ğŸš€ Duality is super excited to announce that our Kaggle competition is LIVE! Synthetic-to-Real Object Detection Challenge is LIVE! ğŸš¦ Want to master AI training, learn industry-proven synthetic data workflows, and compete for public recognition and cash prizes? ğŸ‘‰ Join our Synthetic-to-Real Object Detection Challenge on Kaggle! https://www.kaggle.com/competitions/synthetic-2-real-object-detection-challenge/overview Compete to build the top-performing model capable of detecting real-world objectsâ€”trained entirely on synthetic data. Master these industry-proven methods for faster, more targeted, and diverse dataset creation, and set yourself apart, unlocking today's most exciting AI opportunities. Ready to test your skills? ğŸ† The Challenge Train an object detection model using synthetic images created with Falconâ€”Duality AI's cutting-edge digital twin simulation softwareâ€”then evaluate your model on real-world imagery. The Twist? ğŸ“ˆ Boost your modelâ€™s accuracy by creating and refining your...</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/233802872800595</guid></item><item><title>QwQ-32B is amazing!</title><link>https://huggingface.co/posts/onekq/433851020584240</link><description>QwQ-32B is amazing! It ranks below o1-preview, but beats DeepSeek v3 and all Gemini models. onekq-ai/WebApp1K-models-leaderboard Now we have such a powerful model that can fit into a single GPU, can someone finetune a web app model to push SOTA of my leaderboard? ğŸ¤— See translation</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/433851020584240</guid></item><item><title>I was chatting with</title><link>https://huggingface.co/posts/clem/381394695080482</link><description>I was chatting with @ peakji , one of the cofounders of Manu AI, who told me he was on Hugging Face (very cool!). He shared an interesting insight which is that agentic capabilities might be more of an alignment problem rather than a foundational capability issue. Similar to the difference between GPT-3 and InstructGPT, some open-source foundation models are simply trained to 'answer everything in one response regardless of the complexity of the question' - after all, that's the user preference in chatbot use cases. Just a bit of post-training on agentic trajectories can make an immediate and dramatic difference. As a thank you to the community, he shared 100 invite code first-come first serve, just use â€œHUGGINGFACEâ€ to get access! See translation</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/381394695080482</guid></item><item><title>Hi there ğŸ‘‹! Check this project for mapping features in OpenStreetMap with Computer Vision:</title><link>https://huggingface.co/posts/daavoo/348063789486715</link><description>Hi there ğŸ‘‹! Check this project for mapping features in OpenStreetMap with Computer Vision: â­-&gt; https://github.com/mozilla-ai/osm-ai-helper And a live demo showing how to map new swimming pools ğŸŠ: ğŸ—ºï¸ -&gt; mozilla-ai/osm-ai-helper See translation</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/daavoo/348063789486715</guid></item><item><title>ğŸ“¢ For those who interested in quick extraction of emotion causes in dialogues, below is a notebook that adopts the pre-trained Flan-T5 model on FRIENDS dataset powered by bulk-chain framework:</title><link>https://huggingface.co/posts/nicolay-r/947679817144983</link><description>ğŸ“¢ For those who interested in quick extraction of emotion causes in dialogues, below is a notebook that adopts the pre-trained Flan-T5 model on FRIENDS dataset powered by bulk-chain framework: https://gist.github.com/nicolay-r/c8cfe7df1bef0c14f77760fa78ae5b5c Why it might be intersted to check? The provided supports batching mode for a quck inference. In the case of Flan-T5-base that would be the quickest option via LLM. ğŸ“Š Evaluation results are available in model card: nicolay-r/flan-t5-emotion-cause-thor-base See translation</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/947679817144983</guid></item><item><title>Stoked to announce we've partnered with JFrog to continue improving safety on the Hub! ğŸ¸</title><link>https://huggingface.co/posts/mcpotato/157940161703448</link><description>Stoked to announce we've partnered with JFrog to continue improving safety on the Hub! ğŸ¸ Their model scanner brings new scanning capabilities to the table, aimed at reducing alert fatigue. More on that in our blog post: https://huggingface.co/blog/jfrog See translation</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mcpotato/157940161703448</guid></item><item><title>I just released a fully automated evaluation framework for your RAG applications!ğŸ“ˆ</title><link>https://huggingface.co/posts/as-cle-bert/983515572081803</link><description>I just released a fully automated evaluation framework for your RAG applications!ğŸ“ˆ GitHub ğŸ‘‰ https://github.com/AstraBert/diRAGnosis PyPi ğŸ‘‰ https://pypi.org/project/diragnosis/ It's called ğğ¢ğ‘ğ€ğ†ğ§ğ¨ğ¬ğ¢ğ¬ and is a lightweight framework that helps you ğ—±ğ—¶ğ—®ğ—´ğ—»ğ—¼ğ˜€ğ—² ğ˜ğ—µğ—² ğ—½ğ—²ğ—¿ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ—»ğ—°ğ—² ğ—¼ğ—³ ğ—Ÿğ—Ÿğ— ğ˜€ ğ—®ğ—»ğ—± ğ—¿ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹ ğ—ºğ—¼ğ—±ğ—²ğ—¹ğ˜€ ğ—¶ğ—» ğ—¥ğ—”ğ—š ğ—®ğ—½ğ—½ğ—¹ğ—¶ğ—°ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ˜€. You can launch it as an application locally (it's Docker-ready!ğŸ‹) or, if you want more flexibility, you can integrate it in your code as a python packageğŸ“¦ The workflow is simple: ğŸ§  You choose your favorite LLM provider and model (supported, for now, are Mistral AI, Groq, Anthropic, OpenAI and Cohere) ğŸ§  You pick the embedding models provider and the embedding model you prefer (supported, for now, are Mistral AI, Hugging Face, Cohere and OpenAI) ğŸ“„ You prepare and provide your documents âš™ï¸ Documents are ingested into a Qdrant vector database and transformed into a synthetic question dataset with the help of LlamaIndex ğŸ“Š The LLM is evaluated for the faithfulness and...</description><pubDate>Sun, 09 Mar 2025 05:16:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/983515572081803</guid></item></channel></rss>