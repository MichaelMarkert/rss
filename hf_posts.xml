<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Going forward, I will be adopting the term Magnitude-Preserving Orthogonal Ablation (MPOA) for my recent work in mitigating model damage from abliteration. The technique potentially unlocks reasoning capacity previously occupied with safety refusal processing.</title><link>https://huggingface.co/posts/grimjim/803126534676334</link><description>Going forward, I will be adopting the term Magnitude-Preserving Orthogonal Ablation (MPOA) for my recent work in mitigating model damage from abliteration. The technique potentially unlocks reasoning capacity previously occupied with safety refusal processing. For details, start here: https://huggingface.co/blog/grimjim/norm-preserving-biprojected-abliteration Showcase results: grimjim/gemma-3-12b-it-norm-preserved-biprojected-abliterated (outperforms base instruct on UGI Leaderboard NatInt) (The existing name, while technically accurate, was a bit of a mouthful.) See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/grimjim/803126534676334</guid></item><item><title>Proud to share the results of our engineering team‚Äôs recent work at</title><link>https://huggingface.co/posts/branikita/874837305207313</link><description>Proud to share the results of our engineering team‚Äôs recent work at Robonine : ‚Ä¢ Together, we applied advanced topology optimization to redesign critical brackets of the manipulator, achieving a 57‚Äì76% reduction in structural deflection. ‚Ä¢ Our updated model also demonstrated a major stress decrease ‚Äî from 93 MPa down to 25 MPa ‚Äî all while staying within the allowed weight increase. ‚Ä¢ Although we didn‚Äôt fully reach the target tip deviation of 0.3 mm (best achieved: 0.41 mm), the project gave us valuable insights and a solid foundation for the next design iteration. See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/874837305207313</guid></item><item><title>Who wants a TRL sticker? üôã</title><link>https://huggingface.co/posts/sergiopaniego/332334875092196</link><description>Who wants a TRL sticker? üôã https://github.com/huggingface/trl See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/332334875092196</guid></item><item><title>Running large language models efficiently is more than just raw GPU power. The latest guide breaks down the essential math to determine if your LLM workload is compute-bound or memory-bound.</title><link>https://huggingface.co/posts/flozi00/635605102777732</link><description>Running large language models efficiently is more than just raw GPU power. The latest guide breaks down the essential math to determine if your LLM workload is compute-bound or memory-bound. We apply these principles to a real-world example: Qwen's 32B parameter model on the new NVIDIA RTX PRO 6000 Blackwell Edition. In this guide, you will learn how to: Calculate your GPU's operational intensity (Ops:Byte Ratio) Determine your model's arithmetic intensity Identify whether your workload is memory-bound or compute-bound Read the full guide here: https://flozi.net/en/guides/ai/llm-inference-math See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/flozi00/635605102777732</guid></item><item><title>we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments</title><link>https://huggingface.co/posts/sergiopaniego/565991505089039</link><description>we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments train a model to interact with a browser (üéÆ BrowserGym Env), play Wordle (üéÆ Wordle Env) and moooore! TRL (GRPO + vLLM) + OpenEnv! ‚ö°Ô∏è üìù go play with them: https://github.com/huggingface/trl/tree/main/examples/scripts/openenv üìù examples list: https://huggingface.co/docs/trl/main/en/example_overview#scripts See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/565991505089039</guid></item><item><title>Made a demo for multimodal understanding of Qwen3-VL space for tasks including point annotation, detection, captioning, guided text inferences, and more. Find the demo link below. ü§ó‚ÜóÔ∏è</title><link>https://huggingface.co/posts/prithivMLmods/902988810263838</link><description>Made a demo for multimodal understanding of Qwen3-VL space for tasks including point annotation, detection, captioning, guided text inferences, and more. Find the demo link below. ü§ó‚ÜóÔ∏è ‚Æû Space[Demo]: prithivMLmods/Qwen3-VL-HF-Demo ‚Æû Model Used: Qwen/Qwen3-VL-4B-Instruct ‚Æû Collection: https://huggingface.co/collections/prithivMLmods/multimodal-implementations ‚Æû GitHub: https://github.com/PRITHIVSAKTHIUR/Qwen-3VL-Multimodal-Understanding To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/902988810263838</guid></item><item><title>Transforming Ideas Into Art: My New AI Speed Painting Demo</title><link>https://huggingface.co/posts/wang12390/386545539363465</link><description>Transforming Ideas Into Art: My New AI Speed Painting Demo I‚Äôm excited to share my latest AI speed painting demonstration, showcasing how quickly and smoothly AI can transform a simple idea into a fully rendered artwork. This video highlights the power of real-time AI brushwork, dynamic color composition, and fluid scene construction ‚Äî all generated using my custom Miragic Speed Painting engine. What This Demo Shows - Ultra-fast painting generation from start to finish - Smooth, natural brushstrokes that feel hand-drawn - Stable composition and color consistency - A cinematic visual style suitable for creative projects - No diffusion-style noise or randomness ‚Äî just pure painting Speed painting is perfect for: - Content creators and video editors - Graphic designers and social media marketers - Artists exploring quick concepts - Businesses needing fast creative assets - Anyone who wants beautiful visuals‚Ä¶ without waiting minutes or hours Watch the Video I‚Äôve attached the full speed...</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wang12390/386545539363465</guid></item><item><title>We‚Äôve officially kicked off the ERNIE AI Developer Challenge!</title><link>https://huggingface.co/posts/jzhang533/559250209683939</link><description>We‚Äôve officially kicked off the ERNIE AI Developer Challenge! We want to create something interesting with you all, so we partnered with Unsloth, LLaMA-Factory, Novita AI, D-Robotics, and CAMEL-AI to empower your creativity. Come build with us: https://baiduernieai.devpost.com/?utm_source=ERNIE-HF&amp;utm_medium=ERNIE-HF&amp;utm_campaign=ERNIE+AI+Developer+Challenge See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jzhang533/559250209683939</guid></item><item><title>üéâ Wow. Congratulations</title><link>https://huggingface.co/posts/ZennyKenny/159598235519685</link><description>üéâ Wow. Congratulations @ bfirsh and the Replicate team on the CloudFlare acquisition! ‚úåÔ∏è You've really built an incredible ecosystem and product offering and should be super proud. See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/159598235519685</guid></item><item><title>&gt;&gt;&gt; We're writing a new book,  &lt;Planetary Causal Inference&gt;, on how to model counterfactuals at planetary scale by combining satellite imagery + other global data with local studies and RCTs. Forthcoming in 2026+.</title><link>https://huggingface.co/posts/cjerzak/918588861809536</link><description>&gt;&gt;&gt; We're writing a new book, &lt;Planetary Causal Inference&gt;, on how to model counterfactuals at planetary scale by combining satellite imagery + other global data with local studies and RCTs. Forthcoming in 2026+. &gt;&gt;&gt; Book info: https://planetarycausalinference.org/book-launch &gt;&gt;&gt; All datasets used in the book will be openly available on our lab‚Äôs Hugging Face hub: theaidevlab See translation</description><pubDate>Thu, 20 Nov 2025 13:33:22 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/cjerzak/918588861809536</guid></item></channel></rss>