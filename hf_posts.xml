<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Colox, a reasoning AI model. I am currently working on a model smarter than GPT o1 that thinks before it speaks. It is coming tomorrow in the afternoon.</title><link>https://huggingface.co/posts/retronic/114797173531800</link><description>Colox, a reasoning AI model. I am currently working on a model smarter than GPT o1 that thinks before it speaks. It is coming tomorrow in the afternoon. See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/retronic/114797173531800</guid></item><item><title>We did it. Kokoro TTS (v1.0) can now run 100% locally in your browser w/ WebGPU acceleration. Real-time text-to-speech without a server. âš¡ï¸</title><link>https://huggingface.co/posts/Xenova/620657830533509</link><description>We did it. Kokoro TTS (v1.0) can now run 100% locally in your browser w/ WebGPU acceleration. Real-time text-to-speech without a server. âš¡ï¸ Generate 10 seconds of speech in ~1 second for $0. What will you build? ğŸ”¥ webml-community/kokoro-webgpu The most difficult part was getting the model running in the first place, but the next steps are simple: âœ‚ï¸ Implement sentence splitting, allowing for streamed responses ğŸŒ Multilingual support (only phonemization left) Who wants to help? See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Xenova/620657830533509</guid></item><item><title>Wanted: Peak Data. I'm collecting audio data to train another TTS model:</title><link>https://huggingface.co/posts/hexgrad/846477530846098</link><description>Wanted: Peak Data. I'm collecting audio data to train another TTS model: + AVM data: ChatGPT Advanced Voice Mode audio &amp; text from source + Professional audio: Permissive (CC0, Apache, MIT, CC-BY) This audio should *impress* most native speakers, not just barely pass their audio Turing tests. Professional-caliber means S or A-tier, not your average bloke off the street. Traditional TTS may not make the cut. Absolutely no low-fi microphone recordings like Common Voice. The bar is much higher than last time, so there are no timelines yet and I expect it may take longer to collect such mythical data. Raising the bar means evicting quite a bit of old data, and voice/language availability may decrease. The theme is *quality* over quantity. I would rather have 1 hour of A/S-tier than 100 hours of mid data. I have nothing to offer but the north star of a future Apache 2.0 TTS model, so prefer data that you *already have* and costs you *nothing extra* to send. Additionally, *all* the new...</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hexgrad/846477530846098</guid></item><item><title>I wrote an article about G2P:</title><link>https://huggingface.co/posts/hexgrad/562263062112849</link><description>I wrote an article about G2P: https://hf.co/blog/hexgrad/g2p G2P is an underrated piece of small TTS models, like offensive linemen who do a bunch of work and get no credit. Instead of relying on explicit G2P, larger speech models implicitly learn this task by eating many thousands of hours of audio data. They often use a 500M+ parameter LLM at the front to predict latent audio tokens over a learned codebook, then decode these tokens into audio. Kokoro instead relies on G2P preprocessing, is 82M parameters, and thus needs less audio to learn. Because of this, we can cherrypick high fidelity audio for training data, and deliver solid speech for those voices. In turn, this excellent audio quality &amp; lack of background noise helps explain why Kokoro is very competitive in single-voice TTS Arenas. See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hexgrad/562263062112849</guid></item><item><title>ğŸŒŸ 3D Llama Studio - AI 3D Generation Platform</title><link>https://huggingface.co/posts/ginipick/845644282975973</link><description>ğŸŒŸ 3D Llama Studio - AI 3D Generation Platform ğŸ“ Project Overview 3D Llama Studio is an all-in-one AI platform that generates high-quality 3D models and stylized images from text or image inputs. âœ¨ Key Features Text/Image to 3D Conversion ğŸ¯ Generate 3D models from detailed text descriptions or reference images Intuitive user interface Text to Styled Image Generation ğŸ¨ Customizable image generation settings Adjustable resolution, generation steps, and guidance scale Supports both English and Korean prompts ğŸ› ï¸ Technical Features Gradio-based web interface Dark theme UI/UX Real-time image generation and 3D modeling ğŸ’« Highlights User-friendly interface Real-time preview Random seed generation High-resolution output support (up to 2048x2048) ğŸ¯ Applications Product design Game asset creation Architectural visualization Educational 3D content ğŸ”— Try It Now! Experience 3D Llama Studio: ginigen/3D-LLAMA #AI #3DGeneration #MachineLearning #ComputerVision #DeepLearning See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/845644282975973</guid></item><item><title>VectorFlow âš¡: Transform Images into Professional Vector Graphics</title><link>https://huggingface.co/posts/openfree/664271513735189</link><description>VectorFlow âš¡: Transform Images into Professional Vector Graphics Convert your raster images (JPG, PNG, WEBP) into high-quality vector graphics (SVG, AI) with our easy-to-use tool! Perfect for designers, artists, and anyone needing vector conversions. ğŸ¯ Key Features: Dual format support: SVG and AI output Real-time preview for both formats Advanced customization options Clean, user-friendly interface Batch processing ready ğŸ› ï¸ Advanced Controls: Color/B&amp;W mode selection Speckle filtering Color precision adjustment Layer management Curve fitting options ğŸ’« Why VectorFlow? No installation needed Free to use Professional-grade output Simple yet powerful ğŸ”§ Technical Details: Built with Gradio Powered by VTracer Optimized SVG generation AI format support ğŸ‘‰ Try it now: openfree/VectorFlow #computervision #vectorgraphics #imageprocessing #svg #design #ai See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/664271513735189</guid></item><item><title>SmolLM2 paper is out! ğŸ˜Š</title><link>https://huggingface.co/posts/burtenshaw/638294801973727</link><description>SmolLM2 paper is out! ğŸ˜Š ğŸ˜ Why do I love it? Because it facilitates teaching and learning! Over the past few months I've engaged with (no joke) thousands of students based on SmolLM. - People have inferred, fine-tuned, aligned, and evaluated this smol model. - People used they're own machines and they've used free tools like colab, kaggle, and spaces. - People tackled use cases in their job, for fun, in their own language, and with their friends. upvote the paper SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model (2502.02737) See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/638294801973727</guid></item><item><title>Introducing ğ—¼ğ—½ğ—²ğ—» ğ——ğ—²ğ—²ğ—½-ğ—¥ğ—²ğ˜€ğ—²ğ—®ğ—¿ğ—°ğ—µ by Hugging Face! ğŸ’¥</title><link>https://huggingface.co/posts/m-ric/410805194640777</link><description>Introducing ğ—¼ğ—½ğ—²ğ—» ğ——ğ—²ğ—²ğ—½-ğ—¥ğ—²ğ˜€ğ—²ğ—®ğ—¿ğ—°ğ—µ by Hugging Face! ğŸ’¥ OpenAI's latest agentic app Deep Research seems really good... But it's closed, as usual. â±ï¸ So with a team of cracked colleagues, we set ourselves a 24hours deadline to replicate and open-source Deep Research! â±ï¸ â¡ï¸ We built open-Deep-Research, an entirely open agent that can: navigate the web autonomously, scroll and search through pages, download and manipulate files, run calculation on data... We aimed for the best performance: are the agent's answers really rigorous? On GAIA benchmark, Deep Research had 67% accuracy on the validation set. â¡ï¸ open Deep Research is at 55% (powered by o1), it is: - the best pass@1 solution submitted - the best open solution ğŸ’ªğŸ’ª And it's only getting started ! Please jump in, drop PRs, and let's bring it to the top ! Read the blog post ğŸ‘‰ https://huggingface.co/blog/open-deep-research See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/m-ric/410805194640777</guid></item><item><title>Amazing Gradio Batch Processing APP For Newest SOTA Background Remover Open Source Model BiRefNet HR (High Resolution) Published For Windows, RunPod, Massed Compute, and Kaggle</title><link>https://huggingface.co/posts/MonsterMMORPG/594321967336207</link><description>Amazing Gradio Batch Processing APP For Newest SOTA Background Remover Open Source Model BiRefNet HR (High Resolution) Published For Windows, RunPod, Massed Compute, and Kaggle Installers and APP : https://www.patreon.com/posts/121679760 BiRefNet : Bilateral Reference for High-Resolution Dichotomous Image Segmentation BiRefNet recently got some amazing updates and now it has high resolution model (2048x2048) and other speed and VRAM optimizations We have upgraded our existing Gradio APP, added new model and new features Official repo is here : https://github.com/ZhengPeng7/BiRefNet We have published 1-Click installers for Windows, RunPod, Massed Compute and a free Kaggle Account notebook Works great even on free Kaggle account Check out the below attached images to learn more See translation</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/594321967336207</guid></item><item><title>I am presenting Decoder-Only Transformer (DOT) Policy a simple Behavioral Control policy that outperforms SOTA models on two simple benchmark tasks:</title><link>https://huggingface.co/posts/IliaLarchenko/621814832633058</link><description>I am presenting Decoder-Only Transformer (DOT) Policy a simple Behavioral Control policy that outperforms SOTA models on two simple benchmark tasks: âœ… PushT (pushing an object to a goal) â€“ 84% success on keypoints, 74% on images (previous best: 75% / 69%) âœ… ALOHA Insert (precise bimanual insertion) â€“ 30% success (previous best: ~21%) The best part? DOT is much smaller (sometimes 100 times less parameters) than previous SOTA models, trains faster, and avoids complexity: ğŸš« No generative models (Diffusion, VAE, GANs) ğŸš« No discretization/tokenization of actions ğŸš« No reinforcement learning or multi-stage training âœ… Just learns from human demos, plain and simple This is still early â€” more complex real-life tasks need testing, and no guarantees it will actually work well there, but I think it's interesting to share. Sometimes, simpler approaches can be just as effective (or even better) than complex ones. ğŸ”— Open-source code and detailed description:...</description><pubDate>Sat, 08 Feb 2025 05:07:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/IliaLarchenko/621814832633058</guid></item></channel></rss>