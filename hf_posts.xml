<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Today, we're unveiling two new open-source AI robots! HopeJR for $3,000 &amp; Reachy Mini for $300 ğŸ¤–ğŸ¤–ğŸ¤–</title><link>https://huggingface.co/posts/clem/522668354429256</link><description>Today, we're unveiling two new open-source AI robots! HopeJR for $3,000 &amp; Reachy Mini for $300 ğŸ¤–ğŸ¤–ğŸ¤– Let's go open-source AI robotics! See translation</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/522668354429256</guid></item><item><title>deepseek-ai/DeepSeek-R1-0528</title><link>https://huggingface.co/posts/AtAndDev/639250895656011</link><description>deepseek-ai/DeepSeek-R1-0528 This is the end See translation</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AtAndDev/639250895656011</guid></item><item><title>VisionScout Major Update: Enhanced Precision Through Multi-Modal AI Integration</title><link>https://huggingface.co/posts/DawnC/538322807718464</link><description>VisionScout Major Update: Enhanced Precision Through Multi-Modal AI Integration I'm excited to share significant improvements to VisionScout that substantially enhance accuracy and analytical capabilities. â­ï¸ Key Enhancements - CLIP Zero-Shot Landmark Detection: The system now identifies famous landmarks and architectural features without requiring specific training data, expanding scene understanding beyond generic object detection. - Places365 Environmental Classification: Integration of MIT's Places365 model provides robust scene baseline classification across 365 categories, significantly improving lighting analysis accuracy and overall scene identification precision. - Enhanced Multi-Modal Fusion: Advanced algorithms now dynamically combine insights from YOLOv8, CLIP, and Places365 to optimize accuracy across diverse scenarios. - Refined LLM Narratives: Llama 3.2 integration continues to transform analytical data into fluent, contextually rich descriptions while maintaining...</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/538322807718464</guid></item><item><title>VEO 3 FLOW Full Tutorial - How To Use VEO3 in FLOW Guide :</title><link>https://huggingface.co/posts/MonsterMMORPG/279762403721253</link><description>VEO 3 FLOW Full Tutorial - How To Use VEO3 in FLOW Guide : https://youtu.be/AoEmQPU2gtg Tutorial link : https://youtu.be/AoEmQPU2gtg VEO 3 AI is rocking generative AI field right now. FLOW is the platform that lets you use VEO 3 with so many cool features. This is an official tutorial and guide made by Google team. I edited it slightly. I hope this be helpful. FLOW : https://labs.google/flow/about Veo 3 is Google DeepMindâ€™s most advanced video generation model to date. It allows users to create high-quality, cinematic video clips from simple text prompts, making it one of the most powerful AI tools for video creation. What sets Veo 3 apart is its ability to generate videos with native audio. This means that along with stunning visuals, Veo 3 can produce synchronized dialogue, ambient sounds, and background musicâ€”all from a single prompt. For filmmakers, this is a significant leap forward, as it eliminates the need for separate audio generation or complex syncing processes. Veo 3...</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/279762403721253</guid></item><item><title>ğŸ¤—ğŸ‘¨ğŸ»â€ğŸ“</title><link>https://huggingface.co/posts/darkc0de/635443238112929</link><description>ğŸ¤—ğŸ‘¨ğŸ»â€ğŸ“</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/darkc0de/635443238112929</guid></item><item><title>introducing: VLM vibe eval ğŸª­</title><link>https://huggingface.co/posts/merve/470654136703534</link><description>introducing: VLM vibe eval ğŸª­ visionLMsftw/VLMVibeEval vision LMs are saturated over benchmarks, so we built vibe eval ğŸ’¬ &gt; compare different models with refreshed in-the-wild examples in different categories ğŸ¤  &gt; submit your favorite model for eval no numbers -- just vibes! See translation</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/470654136703534</guid></item><item><title>ğŸ™ï¸ Voice Clone AI Podcast Generator: Create Emotionally Rich Podcasts with Your Own Voice!</title><link>https://huggingface.co/posts/openfree/308586070731874</link><description>ğŸ™ï¸ Voice Clone AI Podcast Generator: Create Emotionally Rich Podcasts with Your Own Voice! ğŸš€ Project Introduction Hello! Today we're excited to introduce an AI-powered solo podcast generator that creates high-quality voice cloning with authentic emotional expression. Transform any PDF document, web URL, or keyword into a professional podcast with just a few clicks! ğŸ“šâ¡ï¸ğŸ§ VIDraft/Voice-Clone-Podcast âœ¨ Key Features 1. ğŸ¯ Multiple Input Methods URL: Simply paste any blog or article link PDF: Upload research papers or documents directly Keyword: Enter a topic and AI searches for the latest information to create content 2. ğŸ­ Emotionally Expressive Voice Cloning Powered by Chatterbox TTS: ğŸ¤ Voice Cloning: Learn and replicate your unique voice perfectly ğŸ“¢ Natural intonation and emotional expression ğŸŒŠ Customizable emotion intensity with Exaggeration control âš¡ Seamless handling of long texts with automatic chunking 3. ğŸ¤– State-of-the-Art LLM Script Generation Professional-grade English dialogue...</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/308586070731874</guid></item><item><title>Just made a demo for Cosmos-Reason1, a physical AI model that understands physical common sense and generates appropriate embodied decisions in natural language through long chain-of-thought reasoning. Also added video understanding support to it. ğŸ¤—ğŸš€</title><link>https://huggingface.co/posts/prithivMLmods/678739858093880</link><description>Just made a demo for Cosmos-Reason1, a physical AI model that understands physical common sense and generates appropriate embodied decisions in natural language through long chain-of-thought reasoning. Also added video understanding support to it. ğŸ¤—ğŸš€ âœ¦ Try the demo here : https://huggingface.co/spaces/prithivMLmods/Cosmos-Reason1 â¤¹ Model Page : nvidia/Cosmos-Reason1-7B â¤¹ Multimodal Implementations : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 â¤¹ GitHub : https://github.com/PRITHIVSAKTHIUR/Nvidia-Cosmos-Reason1-Demo To know more about it, visit the model card !! See translation</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/678739858093880</guid></item><item><title>ğŸ‘ Congrats</title><link>https://huggingface.co/posts/jeffboudier/548880163054097</link><description>ğŸ‘ Congrats @ jinanz adding TimesFM times series forecasting to Transformers! Learn how to use TimesFM in this blog post by the Nutanix team: https://huggingface.co/blog/Nutanix/introducing-timesfm-for-time-series-forcasting See translation</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jeffboudier/548880163054097</guid></item><item><title>I am so happy  to share to all that Iâ€™ve just completed the first unit of the new MCP course on Hugging Face and earned my certificate! The AI acceleration track is intense and fast-paced, but Iâ€™m doing my best to keep up. Excited for whatâ€™s ahead!</title><link>https://huggingface.co/posts/lukmanaj/495766537273785</link><description>I am so happy to share to all that Iâ€™ve just completed the first unit of the new MCP course on Hugging Face and earned my certificate! The AI acceleration track is intense and fast-paced, but Iâ€™m doing my best to keep up. Excited for whatâ€™s ahead! See translation</description><pubDate>Fri, 30 May 2025 17:20:34 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/lukmanaj/495766537273785</guid></item></channel></rss>