<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>I got 370 tokens/sec of Qwen3-30B-A3B 2507 on my desktop Z8 GPU workstation. My target is 400 t/s, and the last 10 % always tastes like victory!</title><link>https://huggingface.co/posts/mitkox/340947617819121</link><description>I got 370 tokens/sec of Qwen3-30B-A3B 2507 on my desktop Z8 GPU workstation. My target is 400 t/s, and the last 10 % always tastes like victory! See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mitkox/340947617819121</guid></item><item><title>Qwen3-30B-A3B-Thinking-2507 ğŸ”¥ latest step in scaling thinking capabilities from  Alibaba Qwen team.</title><link>https://huggingface.co/posts/AdinaY/263963364371914</link><description>Qwen3-30B-A3B-Thinking-2507 ğŸ”¥ latest step in scaling thinking capabilities from Alibaba Qwen team. Qwen/Qwen3-30B-A3B-Thinking-2507-FP8 âœ¨ 30B total / 3B active - Apache 2.0 âœ¨ Native 256K context âœ¨ SOTA coding, alignment, agentic reasoning See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/263963364371914</guid></item><item><title>past week in open AI was insane ğŸ”¥ here's some of picks, find more here</title><link>https://huggingface.co/posts/merve/514822650680483</link><description>past week in open AI was insane ğŸ”¥ here's some of picks, find more here merve/releases-july-25-688768ca47fe3693407e02d1 ğŸ’¬ LLMs &amp; VLMs &gt; Qwen/Qwen3-235B-A22B-Thinking-2507 had a new update (OS) &gt; Qwen/Qwen3-Coder-480B-A35B-Instruct is out with 480B total 35B active params ğŸ¤¯ (OS) &gt; AllenAI dropped an update to allenai/olmOCR-7B-0725 ğŸ“ &gt; InternLM released internlm/Intern-S1 - 235B Qwen3 MoE + 6B InternViT encoder (OS) &gt; OmniSVG/OmniSVG is a new SVG generation VLM (OS) ğŸ–¼ï¸ image/video/3D generation &gt; WanAI released Wan2.2 series - both T2V and I2V 14B models for high-quality video generation (OS) multimodalart/wan-22-688767e313337b434ed55112 &gt; Tencent dropped tencent/HunyuanWorld-1 - image-to-3D scene generation model See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/514822650680483</guid></item><item><title>Skywork UniPic ğŸ”¥a unified autoregressive multimodal model for image understanding, generation, &amp; editing, by Skywork å¤©å·¥</title><link>https://huggingface.co/posts/AdinaY/618670304840857</link><description>Skywork UniPic ğŸ”¥a unified autoregressive multimodal model for image understanding, generation, &amp; editing, by Skywork å¤©å·¥ Skywork/skywork-unipic-6888c0789cdb82457b2acf32 âœ¨ 1.5 B - MIT License âœ¨ Runs on RTX 4090 âœ¨ Truly unified architecture See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/618670304840857</guid></item><item><title>ğŸš€ Optimum: The Last v1 Release ğŸš€</title><link>https://huggingface.co/posts/IlyasMoutawwakil/721004690541036</link><description>ğŸš€ Optimum: The Last v1 Release ğŸš€ Optimum v1.27 marks the final major release in the v1 series. As we close this chapter, we're laying the groundwork for a more modular and community-driven future: - Optimum v2: A lightweight core package for porting Transformers, Diffusers, or Sentence-Transformers to specialized AI hardware/software/accelerators.. - Optimumâ€‘ONNX: A dedicated package where the ONNX/ONNX Runtime ecosystem lives and evolves, faster-moving and decoupled from the Optimum core. ğŸ¯ Why this matters: - A clearer governance path for ONNX, fostering stronger community collaboration and improved developer experience.. - Enable innovation at a faster pace in a more modular, open-source environment. ğŸ’¡ What this means: - More transparency, broader participation, and faster development driven by the community and key actors in the ONNX ecosystem (PyTorch, Microsoft, Joshua Lochner ğŸ‘€, ...) - A cleaner, more maintainable core Optimum, focused on extending HF libraries to special AI...</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/IlyasMoutawwakil/721004690541036</guid></item><item><title>We've crossed 1 million repositories backed by Xet storage on Hugging Face! ğŸš€ğŸš€ğŸš€</title><link>https://huggingface.co/posts/jsulz/651298897017923</link><description>We've crossed 1 million repositories backed by Xet storage on Hugging Face! ğŸš€ğŸš€ğŸš€ You can follow along our progress converting the Hub from Git LFS to Xet at jsulz/ready-xet-go We have a lot of repos left to migrate, which means I have plenty of time to add more animations ğŸ¤ª See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jsulz/651298897017923</guid></item><item><title>Qwen just released Qwen3-30B-A3B-Instruct-2507 ğŸ”¥ an upgrade to the non-thinking mode model</title><link>https://huggingface.co/posts/AdinaY/246049488455702</link><description>Qwen just released Qwen3-30B-A3B-Instruct-2507 ğŸ”¥ an upgrade to the non-thinking mode model Qwen/Qwen3-30B-A3B-Instruct-2507 âœ¨ 30B MoE / 3.3B active - Apache 2.0 âœ¨ Strong gains in reasoning, math, coding, &amp; multilingual tasks âœ¨ Native support for 256K long-context inputs See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/246049488455702</guid></item><item><title>When you're looking for data, what's your focus (use the reactions below to vote):</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/147929225613950</link><description>When you're looking for data, what's your focus (use the reactions below to vote): ğŸš€ Getting as many images as you can ğŸ¤¯ Getting the right type of images (framing, domain, lighting, etc) I know both are very important, but I'm curious what people would put as #1 See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/147929225613950</guid></item><item><title>We just released TRL v0.20 with major multimodal upgrades!</title><link>https://huggingface.co/posts/sergiopaniego/236970560808195</link><description>We just released TRL v0.20 with major multimodal upgrades! ğŸ‘ï¸ VLM support for GRPO (highly requested by the community!) ğŸï¸ New GSPO trainer (from @ Qwen , released last week, VLM-ready) ğŸ™ New MPO trainer (multimodal by design, as in the paper) ğŸ“ Full release notes here: https://github.com/huggingface/trl/releases/tag/v0.20.0 See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/236970560808195</guid></item><item><title>â˜€ï¸ Build a Website Chatbot in Minutesâ€”No Fine-Tuning Required!</title><link>https://huggingface.co/posts/dmoxy/897711395009147</link><description>â˜€ï¸ Build a Website Chatbot in Minutesâ€”No Fine-Tuning Required! We just released Workflow #4 in our Summer of Workflows series: ğŸ’¬ Website Chatbot Workflow ğŸ¬ See It In Action: https://youtu.be/OPBIctfXDY4 Crawl your site, index it with ApertureDB, and deploy a RAG chatbot in minutes. âœ… No-code setup âœ… Supports LLM providers OpenAI, Together &amp; Groq âœ… Comes with a demo UI + API access âœ… Uses your actual content for smart answers This workflow supports #OpenAI, Together and Groq and integrates with AIMon to prevent hallucinations and provide guardrails for RAGâ€”an important step for real world use cases. Perfect for docs, blogs, product sitesâ€”anything you want users to talk to. ğŸ‘‰ Try It Now! https://cloud.aperturedata.io/signup Let us know what you thinkâ€”weâ€™re building a new one each week! Read the docs: https://shorturl.at/ZY2yh Explore the code: https://shorturl.at/hgMfU Additional Resources: https://shorturl.at/bUny3 See translation</description><pubDate>Fri, 01 Aug 2025 09:31:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dmoxy/897711395009147</guid></item></channel></rss>