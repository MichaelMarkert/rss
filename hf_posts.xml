<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>An assembly of 18 European companies, labs, and universities have banded together to launch üá™üá∫ EuroBERT! It's a state-of-the-art multilingual encoder for 15 European languages, designed to be finetuned for retrieval, classification, etc.</title><link>https://huggingface.co/posts/tomaarsen/782540332014764</link><description>An assembly of 18 European companies, labs, and universities have banded together to launch üá™üá∫ EuroBERT! It's a state-of-the-art multilingual encoder for 15 European languages, designed to be finetuned for retrieval, classification, etc. üá™üá∫ 15 Languages: English, French, German, Spanish, Chinese, Italian, Russian, Polish, Portuguese, Japanese, Vietnamese, Dutch, Arabic, Turkish, Hindi 3Ô∏è‚É£ 3 model sizes: 210M, 610M, and 2.1B parameters - very very useful sizes in my opinion ‚û°Ô∏è Sequence length of 8192 tokens! Nice to see these higher sequence lengths for encoders becoming more common. ‚öôÔ∏è Architecture based on Llama, but with bi-directional (non-causal) attention to turn it into an encoder. Flash Attention 2 is supported. üî• A new Pareto frontier (stronger *and* smaller) for multilingual encoder models üìä Evaluated against mDeBERTa, mGTE, XLM-RoBERTa for Retrieval, Classification, and Regression (after finetuning for each task separately): EuroBERT punches way above its weight. üìù...</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tomaarsen/782540332014764</guid></item><item><title>Honored to be named among their 12 pioneers and power players in the news industry in the 2025 Tech Trends Report from Future Today Strategy Group.</title><link>https://huggingface.co/posts/fdaudens/473088205866195</link><description>Honored to be named among their 12 pioneers and power players in the news industry in the 2025 Tech Trends Report from Future Today Strategy Group. Incredible group to be part of - each person is doing groundbreaking work at the intersection of AI and journalism. Worth following them all: they're consistently sharing practical insights on building the future of news. Take the time to read this report, it's packed with insights as always. The news &amp; information section's #1 insight hits hard: "The most substantive economic impact of AI to date has been licensing payouts for a handful of big publishers. The competition will start shifting in the year ahead to separate AI 'haves' that have positioned themselves to grow from the 'have-nots.'" This AI-driven divide is something I've been really concerned about. Now is the time to build more than ever! üëâ Full report here: https://ftsg.com/wp-content/uploads/2025/03/FTSG_2025_TR_FINAL_LINKED.pdf See translation</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/473088205866195</guid></item><item><title>We distill a more accurate and concise dataset from DeepSeek R1, and also provide a distillation pipeline code repository.ü§ó</title><link>https://huggingface.co/posts/JingzeShi/246281295432423</link><description>We distill a more accurate and concise dataset from DeepSeek R1, and also provide a distillation pipeline code repository.ü§ó Dataset: SmallDoge/SmallThoughts Code: https://github.com/SmallDoges/small-thoughts See translation</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JingzeShi/246281295432423</guid></item><item><title>I was chatting with</title><link>https://huggingface.co/posts/clem/381394695080482</link><description>I was chatting with @ peakji , one of the cofounders of Manu AI, who told me he was on Hugging Face (very cool!). He shared an interesting insight which is that agentic capabilities might be more of an alignment problem rather than a foundational capability issue. Similar to the difference between GPT-3 and InstructGPT, some open-source foundation models are simply trained to 'answer everything in one response regardless of the complexity of the question' - after all, that's the user preference in chatbot use cases. Just a bit of post-training on agentic trajectories can make an immediate and dramatic difference. As a thank you to the community, he shared 100 invite code first-come first serve, just use ‚ÄúHUGGINGFACE‚Äù to get access! See translation</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/381394695080482</guid></item><item><title>Spatial sound experience! SonicOrbit features AI beat detection to auto-sync your rhythm.</title><link>https://huggingface.co/posts/Bils/172618670261897</link><description>Spatial sound experience! SonicOrbit features AI beat detection to auto-sync your rhythm. Bils/SonicOrbit See translation</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Bils/172618670261897</guid></item><item><title>5 New implementations of Diffusion Models</title><link>https://huggingface.co/posts/Kseniase/475779328543857</link><description>5 New implementations of Diffusion Models Diffusion models are widely used for image and video generation but remain underexplored in text generation, where autoregressive models (ARMs) dominate. Unlike ARMs, which produce tokens sequentially, diffusion models iteratively refine noise through denoising steps, offering greater flexibility and speed. Recent advancements show a shift toward using diffusion models in place of, or alongside, ARMs. Researchers also combine strengths from both methods and integrate autoregressive concepts into diffusion. Here are 5 new implementations of diffusion models: 1. Mercury family of diffusion LLMs (dLLMs) by Inception Labs -&gt; https://www.inceptionlabs.ai/news It applies diffusion to text and code data, enabling sequence generation 10x faster than today's top LLMs. Now available Mercury Coder can run at over 1,000 tokens/sec on NVIDIA H100s. 2. Diffusion of Thoughts (DoT) -&gt; Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language...</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/475779328543857</guid></item><item><title>Regardless of X being down or not, so glad I can rely on HF Posts for AI news ‚ù§Ô∏èü§ó</title><link>https://huggingface.co/posts/BrigitteTousi/858963061028741</link><description>Regardless of X being down or not, so glad I can rely on HF Posts for AI news ‚ù§Ô∏èü§ó See translation</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/BrigitteTousi/858963061028741</guid></item><item><title>Lightweight (nanoGPT)  implementation of hybrid norm - an intuitive normalization method that combines the strength of both pre-norm (i.e QKV-norm in MHA) and post-norm in the feed-forward network.</title><link>https://huggingface.co/posts/Jaward/141543803186613</link><description>Lightweight (nanoGPT) implementation of hybrid norm - an intuitive normalization method that combines the strength of both pre-norm (i.e QKV-norm in MHA) and post-norm in the feed-forward network. Code: https://github.com/Jaykef/ai-algorithms/blob/main/hybrid_normalization.ipynb See translation</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/141543803186613</guid></item><item><title>Genetic counselors help patients get üß¨ tests and understand their results. They need to study inheritance of several conditions, statistics, and patient care ü§ì‚öïÔ∏è. I compiled 225 multiple-choice questions for the ABGC exam into a dataset:</title><link>https://huggingface.co/posts/monsoon-nlp/510481079927870</link><description>Genetic counselors help patients get üß¨ tests and understand their results. They need to study inheritance of several conditions, statistics, and patient care ü§ì‚öïÔ∏è. I compiled 225 multiple-choice questions for the ABGC exam into a dataset: monsoon-nlp/genetic-counselor-multiple-choice Llama 3.1 8B Instruct gets a 51% score. I'm also creating a dataset of real-world open-ended questions (starting with Reddit) and am open to contributors See translation</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/monsoon-nlp/510481079927870</guid></item><item><title>üôã‚Äç‚ôÄÔ∏è Happy Monday! Duality AI has released another dataset for pose estimation</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/338565450730801</link><description>üôã‚Äç‚ôÄÔ∏è Happy Monday! Duality AI has released another dataset for pose estimation duality-robotics/pose_estimation5.1 It's once again 100% ‚ú®FREE‚ú® Access the full-size dataset by creating an EDU account here- https://falcon.duality.ai/secure/documentation/pose-colab?sidebarMode=learn Or check it out in the linked HuggingFace dataset Why train a model in pose estimation? Many functions require pose estimation, such as... ü§ñDefining the orientation of an object on a conveyer belt for pick and place operations with a robotic arm, ü§ñ Replicating an object's pose for AR and VR application overlays, ü§ñ Localizing and mapping an environment for path navigation, ü§ñ ...and more! What makes this dataset useful for training a model? üí†Duality AI's digital twins are not generated by AI, but are instead crafted by 3D artists. This allows the training from this data to transfer into real-world applicability. Read more about our techniques for bridging the Sim2Real gap here: https://www.duality.ai/blog/ml-...</description><pubDate>Tue, 11 Mar 2025 17:20:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/338565450730801</guid></item></channel></rss>