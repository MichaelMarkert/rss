<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams üìù</title><link>https://huggingface.co/posts/openfree/682363513025265</link><description>Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams üìù openfree/Korean-Exam-Leaderboard ## üìä What is this leaderboard? This leaderboard evaluates the performance of various AI models on 22 Korean civil service and professional qualification exams. All scores are converted to a 100-point scale to show how well different LLMs can solve actual Korean civil service and professional qualification tests! ## üèÜ Current Top Performers - **OpenAI/GPT-o1**: Bar Exam 52.5 points ü•á - **OpenAI/GPT-4.5**: Bar Exam 49.33 points ü•à - **OpenAI/GPT-4o**: Bar Exam 49.11 points ü•â - **deepseek-ai/DeepSeek-R1**: Bar Exam 47.33 points ## üìã Exams Being Evaluated The leaderboard includes various Korean civil service and professional qualification exams: - Korean Bar Exam - Senior Civil Service Grade 5 - Judicial Service Grade 5 - National Assembly Grade 5 - Judicial Scrivener - Police Executive Candidate - And more exams! ## ü§ñ Models Being Evaluated We are testing a variety of...</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/682363513025265</guid></item><item><title>üëã Hi all!</title><link>https://huggingface.co/posts/hanzla/334929914214979</link><description>üëã Hi all! For any AI agent, internet search üîé is an important tool. However, with APIs like Tavily and Exa, it becomes really difficult to keep up with the cost. In some cases, these Internet APIs cost more than the LLM. To solve, this, I am making a playwright wrapper API on top of publicly available searXNG instances. This will enable agent applications to fetch internet results for free. Currently, I have set up a basic GitHub repo, and I will continue developing advanced search features, such as image search üñºÔ∏è Github: https://github.com/HanzlaJavaid/Free-Search/tree/main üöÄ Try the deployed version: https://freesearch.replit.app/docs If you find this useful, consider starring ‚≠êÔ∏è the GitHub repository to support further development! See translation</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hanzla/334929914214979</guid></item><item><title>8 types of RoPE</title><link>https://huggingface.co/posts/Kseniase/498106595218801</link><description>8 types of RoPE As we always use Transformers, it's helpful to understand RoPE‚ÄîRotary Position Embedding. Since token order matters, RoPE encodes it by rotating token embeddings based on their position, so the model knows how to interpret which token comes first, second, and so on. Here are 8 types of RoPE that can be implemented in different cases: 1. Original RoPE -&gt; RoFormer: Enhanced Transformer with Rotary Position Embedding (2104.09864) Encodes token positions by rotating token embeddings in the complex plane via a position-based rotation matrix, thereby providing the self-attention mechanism with relative positional info. 2. LongRoPE -&gt; LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens (2402.13753) Extends the context window of pre-trained LLMs to 2048k tokens, leveraging non-uniformities in positional interpolation with an efficient search. 3. LongRoPE2 -&gt; LongRoPE2: Near-Lossless LLM Context Window Scaling (2502.20082) Extends the effective context window of...</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/498106595218801</guid></item><item><title>Folks, let's get ready.ü•≥ We will be busy soon.  üòÖü§óhttps://github.com/huggingface/transformers/pull/36878</title><link>https://huggingface.co/posts/onekq/812629409559433</link><description>Folks, let's get ready.ü•≥ We will be busy soon. üòÖü§óhttps://github.com/huggingface/transformers/pull/36878 See translation</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/812629409559433</guid></item><item><title>So many open releases at Hugging Face past week ü§Ø recapping all here ‚§µÔ∏è</title><link>https://huggingface.co/posts/merve/746832157330905</link><description>So many open releases at Hugging Face past week ü§Ø recapping all here ‚§µÔ∏è merve/march-21-releases-67dbe10e185f199e656140ae üëÄ Multimodal &gt; Mistral AI released a 24B vision LM, both base and instruction FT versions, sota üî• (OS) &gt; with IBM we released SmolDocling, a sota 256M document parser with Apache 2.0 license (OS) &gt; SpatialLM is a new vision LM that outputs 3D bounding boxes, comes with 0.5B (QwenVL based) and 1B (Llama based) variants &gt; SkyWork released SkyWork-R1V-38B, new vision reasoning model (OS) üí¨ LLMs &gt; NVIDIA released new Nemotron models in 49B and 8B with their post-training dataset &gt; LG released EXAONE, new reasoning models in 2.4B, 7.8B and 32B &gt; Dataset: Glaive AI released a new reasoning dataset of 22M+ examples &gt; Dataset: NVIDIA released new helpfulness dataset HelpSteer3 &gt; Dataset: OpenManusRL is a new agent dataset based on ReAct framework (OS) &gt; Open-R1 team released OlympicCoder, new competitive coder model in 7B and 32B &gt; Dataset: GeneralThought-430K is a new...</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/746832157330905</guid></item><item><title>Today I decided to cancel my PRO subscription for Hugging Face. I had a lot of fun with it but with the current changes to API and allowed limits I think it isn't worth it anymore. So I just turned everything off and cancelled my subscription. It feels like one of these movies scenes where you see an old computerlab and someone putting big white sheets over it and closing the door behind him.  I am not going, I am not gone, but watching through the glass window of the door that I just closed.</title><link>https://huggingface.co/posts/OFT/371302061549874</link><description>Today I decided to cancel my PRO subscription for Hugging Face. I had a lot of fun with it but with the current changes to API and allowed limits I think it isn't worth it anymore. So I just turned everything off and cancelled my subscription. It feels like one of these movies scenes where you see an old computerlab and someone putting big white sheets over it and closing the door behind him. I am not going, I am not gone, but watching through the glass window of the door that I just closed. See translation</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/OFT/371302061549874</guid></item><item><title>I shared my view on Qwen vs DeepSeek (student vs genius), and I forgot to mention this: they are neighbors in the same city.</title><link>https://huggingface.co/posts/onekq/124053264899473</link><description>I shared my view on Qwen vs DeepSeek (student vs genius), and I forgot to mention this: they are neighbors in the same city. https://en.wikipedia.org/wiki/Hangzhou See translation</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/124053264899473</guid></item><item><title>Implemented a custom multimodal GRPO trainer that scales for Small VLMs, supports cpu and gpu with vllm + flash attention. Using SmolVLM-256M-Instruct reference &amp; reward model, wasn‚Äôt trained for long btw, still got some sparks of ‚Äúthinking‚Äù:)</title><link>https://huggingface.co/posts/Jaward/890536870890791</link><description>Implemented a custom multimodal GRPO trainer that scales for Small VLMs, supports cpu and gpu with vllm + flash attention. Using SmolVLM-256M-Instruct reference &amp; reward model, wasn‚Äôt trained for long btw, still got some sparks of ‚Äúthinking‚Äù:) Code: https://github.com/Jaykef/ai-algorithms/blob/main/grpo_multimodal_reasoner.ipynb See translation</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/890536870890791</guid></item><item><title>I am doing a workflow research for a company and our Ultimate Image Processing tool is being extremely helpful. You can auto zoom / crop into desired aspect ratio with using prompts (like a shoe) via SAM2 that we have in our batch processing app.</title><link>https://huggingface.co/posts/MonsterMMORPG/579577092717485</link><description>I am doing a workflow research for a company and our Ultimate Image Processing tool is being extremely helpful. You can auto zoom / crop into desired aspect ratio with using prompts (like a shoe) via SAM2 that we have in our batch processing app. Gradio based App link : https://www.patreon.com/posts/120352012 See translation</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/579577092717485</guid></item><item><title>I'm collecting llama-bench results for inference with a llama 3.1 8B q4 and q8 reference models on varoius GPUs. The results are average of 5 executions.</title><link>https://huggingface.co/posts/csabakecskemeti/287842366376256</link><description>I'm collecting llama-bench results for inference with a llama 3.1 8B q4 and q8 reference models on varoius GPUs. The results are average of 5 executions. The system varies (different motherboard and CPU ... but that probably that has little effect on the inference performance). https://devquasar.com/gpu-gguf-inference-comparison/ the exact models user are in the page I'd welcome results from other GPUs is you have access do anything else you've need in the post. Hopefully this is useful information everyone. See translation</description><pubDate>Mon, 24 Mar 2025 13:31:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/287842366376256</guid></item></channel></rss>