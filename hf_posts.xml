<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Inference for generative ai models looks like a mine field, but there’s a simple protocol for picking the best inference:</title><link>https://huggingface.co/posts/burtenshaw/697123415535373</link><description>Inference for generative ai models looks like a mine field, but there’s a simple protocol for picking the best inference: 🌍 95% of users &gt;&gt; If you’re using open (large) models and need fast online inference, then use Inference providers on auto mode, and let it choose the best provider for the model. https://huggingface.co/docs/inference-providers/index 👷 fine-tuners/ bespoke &gt;&gt; If you’ve got custom setups, use Inference Endpoints to define a configuration from AWS, Azure, GCP. https://endpoints.huggingface.co/ 🦫 Locals &gt;&gt; If you’re trying to stretch everything you can out of a server or local machine, use Llama.cpp, Jan, LMStudio or vLLM. https://huggingface.co/settings/local-apps#local-apps 🪟 Browsers &gt;&gt; If you need open models running right here in the browser, use transformers.js. https://github.com/huggingface/transformers.js Let me know what you’re using, and if you think it’s more complex than this. See translation</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/697123415535373</guid></item><item><title>🎉 Dhanishtha 2.0 Preview is Now Open Source!</title><link>https://huggingface.co/posts/Abhaykoul/404767027882987</link><description>🎉 Dhanishtha 2.0 Preview is Now Open Source! The world's first Intermediate Thinking Model is now available to everyone! Dhanishtha 2.0 Preview brings revolutionary intermediate thinking capabilities to the open-source community. Unlike traditional reasoning models that think once, Dhanishtha can think, answer, rethink, answer again, and continue rethinking as needed using multiple blocks between responses. 🚀 Key Features - Intermediate thinking: Think → Answer → Rethink → Answer → Rethink if needed... - Token efficient: Uses up to 79% fewer tokens than DeepSeek R1 on similar queries - Transparent thinking: See the model's reasoning process in real-time - Open source: Freely available for research and development HelpingAI/Dhanishtha-2.0-preview https://helpingai.co/chat See translation</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Abhaykoul/404767027882987</guid></item><item><title>🎰 DNA CASINO: Hit the Genetic Jackpot! 🧬</title><link>https://huggingface.co/posts/openfree/646247384264829</link><description>🎰 DNA CASINO: Hit the Genetic Jackpot! 🧬 🎲 When Biotech Meets Vegas = ?? Hey there! Today I'm thrilled to introduce something truly extraordinary. We've transformed DNA-Diffusion into a full-blown casino slot machine - welcome to DNA CASINO! 🎊 🎯 What's This All About? 🧬 Generate 200bp DNA Regulatory Sequences: AI-powered generation of cell-type specific synthetic biology sequences 🎰 Slot Machine UI: Watch each nucleotide (A,T,C,G) spin like real casino reels! 🔬 Real-time Protein Analysis: Instantly translate generated DNA to protein and get AI-powered structure/function analysis 💫 Key Features 1️⃣ Choose Your Cell Type (Like Casino Chips!) 🟢 K562 - Leukemia cell line 🔵 GM12878 - Lymphoblastoid cell line 🟡 HepG2 - Liver cancer cell line 2️⃣ Pull the Lever to Begin! Just like a real slot machine - pull the lever or hit SPIN and watch 200 nucleotides whirl in spectacular fashion! 🎪 3️⃣ AI-Powered Protein Analysis DNA → Protein translation Structure/function prediction via...</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/646247384264829</guid></item><item><title>A few months ago, I shared that I was building with</title><link>https://huggingface.co/posts/blaise-tk/599826348587266</link><description>A few months ago, I shared that I was building with @ deeivihh something like "the Steam for open source apps"... 🚀 Today, I’m excited to announce that Dione is now open source and live in public beta! Our mission is simple: make it easier to discover, use, and contribute to open source applications. 🔗 GitHub: https://github.com/dioneapp/dioneapp 💬 Join the community: https://discord.gg/JDFJp33vrM Want to give it a try? I’d love your feedback! 👀 See translation</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/blaise-tk/599826348587266</guid></item><item><title>🔥 HuggingFace Heatmap Leaderboard</title><link>https://huggingface.co/posts/aiqtech/840192921912390</link><description>🔥 HuggingFace Heatmap Leaderboard Visualizing AI ecosystem activity at a glance aiqtech/Heatmap-Leaderboard 🎯 Introduction A leaderboard that visualizes the vibrant HuggingFace community activity through heatmaps. ✨ Key Features 📊 Real-time Tracking - Model/dataset/app releases from AI labs and developers 🏆 Auto Ranking - Rankings based on activity over the past year 🎨 Responsive UI - Unique colors per organization, mobile optimized ⚡ Auto Updates - Hourly data refresh for latest information 🌍 Major Participants Big Tech: OpenAI, Google, Meta, Microsoft, Apple, NVIDIA AI Startups: Anthropic, Mistral, Stability AI, Cohere, DeepSeek Chinese Companies: Tencent, Baidu, ByteDance, Qwen HuggingFace Official: HuggingFaceH4, HuggingFaceM4, lerobot, etc. Active Developers: prithivMLmods, lllyasviel, multimodalart and many more 🚀 Value Trend Analysis 📈 Real-time open source contribution insights Inspiration 💪 Learn from other developers' activity patterns Ecosystem Growth 🌱 Visualize AI...</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aiqtech/840192921912390</guid></item><item><title>Gemma 3n finetuning is now 1.5x faster and uses 50% less VRAM in Unsloth!</title><link>https://huggingface.co/posts/danielhanchen/374907101016508</link><description>Gemma 3n finetuning is now 1.5x faster and uses 50% less VRAM in Unsloth! Click "Use this model" and click "Google Colab"! unsloth/gemma-3n-E4B-it unsloth/gemma-3n-E2B-it https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma3N_(4B)-Conversational.ipynb See translation</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/374907101016508</guid></item><item><title>‼️Sentence Transformers v5.0 is out! The biggest update yet introduces Sparse Embedding models, encode methods improvements, Router module for asymmetric models &amp; much more. Sparse + Dense = 🔥 hybrid search performance! Details:</title><link>https://huggingface.co/posts/tomaarsen/190568030432786</link><description>‼️Sentence Transformers v5.0 is out! The biggest update yet introduces Sparse Embedding models, encode methods improvements, Router module for asymmetric models &amp; much more. Sparse + Dense = 🔥 hybrid search performance! Details: 1️⃣ Sparse Encoder Models Brand new support for sparse embedding models that generate high-dimensional embeddings (30,000+ dims) where &lt;1% are non-zero: - Full SPLADE, Inference-free SPLADE, and CSR architecture support - 4 new modules, 12 new losses, 9 new evaluators - Integration with @ elastic-co , @ opensearch-project , @ NAVER LABS Europe, @ qdrant , @ IBM , etc. - Decode interpretable embeddings to understand token importance - Hybrid search integration to get the best of both worlds 2️⃣ Enhanced Encode Methods &amp; Multi-Processing - Introduce encode_query &amp; encode_document automatically use predefined prompts - No more manual pool management - just pass device list directly to encode() - Much cleaner and easier to use than the old multi-process approach...</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tomaarsen/190568030432786</guid></item><item><title>I played around with the new RXTX paper (XX^T) and was able to train nanogpt with 4x4 RXTX matmuls in both attention layer and optimizer🤕</title><link>https://huggingface.co/posts/Jaward/639375924369190</link><description>I played around with the new RXTX paper (XX^T) and was able to train nanogpt with 4x4 RXTX matmuls in both attention layer and optimizer🤕 It just works (well I had to add some guardrails) but still saves 5% of memory usage: The Patch: - Computes attention scores with a 4x4 blockwise RXTX matmuls (no pytorch dot prod) - Handles arbitrary sequence lengths by padding to the nearest multiple of 4. - An RXTX variant of shampoo with params reshaped into 4x4 blocks during each optimizer step. - Uses 5% less ops Code: https://github.com/Jaykef/ai-algorithms/blob/main/nanogpt-rxtx.ipynb Paper: https://arxiv.org/pdf/2505.09814 See translation</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/639375924369190</guid></item><item><title>The full Celestia 3 science-reasoning dataset is here!</title><link>https://huggingface.co/posts/sequelbox/523631078445392</link><description>The full Celestia 3 science-reasoning dataset is here! - 91k high-quality synthetic science prompts answered by DeepSeek-R1-0528 - subjects include physics, biology, chemistry, computer science, Earth science, astronomy, and information theory - one of the reasoning datasets powering the upcoming Shining Valiant 3 :) coming soon! GET IT NOW, FOR EVERYONE: sequelbox/Celestia3-DeepSeek-R1-0528 SUPPORT OUR RELEASES: sequelbox/SupportOpenSource with love, allegra See translation</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sequelbox/523631078445392</guid></item><item><title>Check out new symbolic music AI front end and CLI training app</title><link>https://huggingface.co/posts/asigalov61/301808424415801</link><description>Check out new symbolic music AI front end and CLI training app https://webchatappai.github.io/midi-gen/ https://github.com/WebChatAppAi/Orpheus-Midi-Model-Maker @ Timzoid @ Csplk @ not-lain @ victor @ bartowski @ John6666 See translation</description><pubDate>Wed, 02 Jul 2025 17:22:09 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/asigalov61/301808424415801</guid></item></channel></rss>