<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>New family of 1B models just dropped!</title><link>https://huggingface.co/posts/mlabonne/713929804806596</link><description>New family of 1B models just dropped! &gt; LiquidAI/LFM2.5-1.2B-Base : 10T ‚Üí 28T tokens &gt; LiquidAI/LFM2.5-1.2B-Instruct : new large-scale multi-stage RL &gt; LiquidAI/LFM2.5-1.2B-JP : our most polite model &gt; LiquidAI/LFM2.5-VL-1.6B : multi-image multilingual &gt; LiquidAI/LFM2.5-Audio-1.5B : 8x times faster, no quality loss Super proud of this release ü§ó See translation</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mlabonne/713929804806596</guid></item><item><title>üéâ Exciting News ‚Äî NVIDIA Cosmos is celebrating its 1st birthday and has hit 5 MILLION downloads! üéâ</title><link>https://huggingface.co/posts/tsungyi/951918573083601</link><description>üéâ Exciting News ‚Äî NVIDIA Cosmos is celebrating its 1st birthday and has hit 5 MILLION downloads! üéâ In just one year, the Cosmos ecosystem has grown rapidly: üß† Cosmos Reason and Cosmos Predict have surpassed 2 MILLION downloads each on @ HuggingFace , topping physical AI leaderboards üîÑ Cosmos Transfer is enabling adaptation across domains and tasks üîÆ Cosmos Cookbook is the go-to hub for recipes from developers and partners like Uber and IntBot. Thank you to our amazing developer community for making this possible. Here's to pushing the boundaries of world foundation models together! üßëüèª‚Äçüç≥Read the Cosmos Cookbook: https://nvda.ws/4qevli8 üìö Explore Models &amp; Datasets: https://huggingface.co/collections/nvidia/nvidia-cosmos-2 See translation</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tsungyi/951918573083601</guid></item><item><title>New Book: No-Blackbox, Secure, Efficient AI and LLM Solutions</title><link>https://huggingface.co/posts/vincentg64/731522720644742</link><description>New Book: No-Blackbox, Secure, Efficient AI and LLM Solutions https://mltblog.com/4aRwvM5 Large language models and modern AI is often presented as technology that needs deep neural networks (DNNs) with billions of Blackbox parameters, expensive and time consuming training, along with GPU farms, yet prone to hallucinations. This book presents alternatives that rely on explainable AI, featuring new algorithms based on radically different technology with trustworthy, auditable, fast, accurate, secure, replicable Enterprise AI. Most of the material is proprietary and made from scratch, showcasing the culmination of decades of research away from standard models to establish a new framework in machine learning and AI technology. I discuss an efficient DNN architecture based on a new type of universal functions in chapter 4, with DNN distillation and protection via watermarking in chapter 5. Then, in chapter 6, I discuss non-DNN alternatives that yield exact interpolation on the training...</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/vincentg64/731522720644742</guid></item><item><title>üéâ OpenMed 2025 Year in Review: 6 Months of Open Medical AI</title><link>https://huggingface.co/posts/MaziyarPanahi/255552518498714</link><description>üéâ OpenMed 2025 Year in Review: 6 Months of Open Medical AI I'm thrilled to share what the OpenMed community has accomplished since our July 2025 launch! üìä The Numbers 29,700,000 downloads Thank you! üôè - 481 total models (475 medical NER models + 6 fine-tuned LLMs) - 475 medical NER models in [OpenMed]( OpenMed ) organization - 6 fine-tuned LLMs in [openmed-community]( openmed-community ) - 551,800 PyPI downloads of the [openmed package]( https://pypi.org/project/openmed/ ) - 707 followers on HuggingFace (you!) - 97 GitHub stars on the [toolkit repo]( https://github.com/maziyarpanahi/openmed ) üèÜ Top Models by Downloads 1. [OpenMed-NER-PharmaDetect-SuperClinical-434M]( OpenMed/OpenMed-NER-PharmaDetect-SuperClinical-434M ) ‚Äî 147,305 downloads 2. [OpenMed-NER-ChemicalDetect-ElectraMed-33M]( OpenMed/OpenMed-NER-ChemicalDetect-ElectraMed-33M ) ‚Äî 126,785 downloads 3. [OpenMed-NER-BloodCancerDetect-TinyMed-65M]( OpenMed/OpenMed-NER-BloodCancerDetect-TinyMed-65M ) ‚Äî 126,465 downloads üî¨ Model...</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MaziyarPanahi/255552518498714</guid></item><item><title>We can't build more private AI if we can't measure privacy intelligence.</title><link>https://huggingface.co/posts/MikeDoes/265606187790986</link><description>We can't build more private AI if we can't measure privacy intelligence. That's why we're highlighting the Priv-IQ benchmark, a new, solution-oriented framework for evaluating LLMs on eight key privacy competencies, from visual privacy to knowledge of privacy law. The direct connection to our work is clear: the researchers relied on samples from the Ai4Privacy dataset to build out questions for Privacy Risk Assessment and Multilingual Entity Recognition. This is the power of open-source collaboration. We provide the data building blocks, and researchers construct powerful new evaluation tools on top of them. It's a win-win for the entire ecosystem when we can all benefit from transparent, data-driven benchmarks that help push for better, safer AI. Kudos to Sakib Shahriar and Rozita A. Dara for this important contribution. Read the paper to see the results: https://www.proquest.com/docview/3170854914?pq-origsite=gscholar&amp;fromopenview=true&amp;sourcetype=Scholarly%20Journals #OpenSource...</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/265606187790986</guid></item><item><title>Assertions are  sanity checks for your API.</title><link>https://huggingface.co/posts/dhruv3006/531790411219507</link><description>Assertions are sanity checks for your API. In Voiden, assertions are reusable blocks . How it works : 1. Type /assertion-block 2. Run the request Ctrl + Enter ) 3. Check the Response Panel to see if it passed or broke Quick confidence. Zero guesswork. Download Voiden here : https://voiden.md/ See translation</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/531790411219507</guid></item><item><title>Scaling Physical AI: SAM 3D, NVIDIA Cosmos, and Unreal Engine!</title><link>https://huggingface.co/posts/mindchain/396197878979681</link><description>Scaling Physical AI: SAM 3D, NVIDIA Cosmos, and Unreal Engine! The "Sim-to-Real" gap is officially history. In early 2026, we are no longer just rendering data; we are simulating reality. By bridging Meta‚Äôs SAM 3D, Unreal Engine, and the NVIDIA Cosmos suite, we‚Äôve built an autonomous pipeline for Physical AI that evolves itself. The 2026 Tech Stack: SAM 3D: Generates high-fidelity digital twins from 2D photos in seconds. Unreal Engine + MCP: The AI "Director" orchestrates environments via the Model Context Protocol, providing perfect Ground Truth. NeMo Data Designer: The orchestration hub on GitHub. Following NVIDIA‚Äôs acquisition of Gretel in early 2025, its leading generative privacy and tabular tech are now fully integrated here. NVIDIA Cosmos Transfer: Neural rendering that adds hyper-realism to Unreal Engine outputs. NVIDIA Cosmos Predict: Predicts physically accurate motion (falling, sliding) without manual animation. NVIDIA Cosmos Reason: The automated supervisor checking...</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mindchain/396197878979681</guid></item><item><title>Genuine recommendation: You should really use this AutoHotKey macro. Save the file as</title><link>https://huggingface.co/posts/Nymbo/966932912375733</link><description>Genuine recommendation: You should really use this AutoHotKey macro. Save the file as macros.ahk and run it. Before sending a prompt to your coding agent, press Ctrl + Alt + 1 and paste your prompt to any regular chatbot. Then send the output to the agent. This is the actual, boring, real way to "10x your prompting". Use the other number keys to avoid repeating yourself over and over again. I use this macro prolly 100-200 times per day. AutoHotKey isn't as new or hype as a lot of other workflows, but there's a reason it's still widely used after 17 years. Don't overcomplicate it. ; Requires AutoHotkey v1 .1 + ; All macros are `Ctrl + Alt + &lt;variable&gt;` ^! 1 :: Send, Please help me more clearly articulate what I mean with this message (write the message in a code block): return ^! 2 :: Send, Please make the following changes: return ^! 3 :: Send, It seems you got cut off by the maximum response limit. Please continue by picking up where you left off. return In my experience the past...</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Nymbo/966932912375733</guid></item><item><title>Have extra processing power in downtime?  Have old devices you haven't used in years?  I recommend primarily Folding@home to do protein folding on your GPUs, but also BOINC, particularly on Android and Apple devices, because of the lower power usage.  I've been doing this, and get about 14,000 hours a week in, primarily for mapping cancer markers on BOINC on an Aiyara cluster of Androids.  I also hold a sign out by the highway encouraging people to join BOINC.  It was Dylan Bucci, a young promoter of BOINC on school's computers, who wished before he died to get as many people on as possible to do this, and in his honor, the Dylan Bucci challenge was implemented.  No reason to wait for a challenge.  If you care about such things, there is an associated cryptocurrency for such processing, but it's worth it to save lives.</title><link>https://huggingface.co/posts/Fishtiks/265029484620174</link><description>Have extra processing power in downtime? Have old devices you haven't used in years? I recommend primarily Folding@home to do protein folding on your GPUs, but also BOINC, particularly on Android and Apple devices, because of the lower power usage. I've been doing this, and get about 14,000 hours a week in, primarily for mapping cancer markers on BOINC on an Aiyara cluster of Androids. I also hold a sign out by the highway encouraging people to join BOINC. It was Dylan Bucci, a young promoter of BOINC on school's computers, who wished before he died to get as many people on as possible to do this, and in his honor, the Dylan Bucci challenge was implemented. No reason to wait for a challenge. If you care about such things, there is an associated cryptocurrency for such processing, but it's worth it to save lives. I look forward to AI-related endeavors like this, and only know of NATIX Drive&amp;, Acurast, and HYRA AI, all of which use Androids I'd rather devote to BOINC. However, they...</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Fishtiks/265029484620174</guid></item><item><title>This isn't really related, but... do people generally prefer dark themes or light themes?</title><link>https://huggingface.co/posts/paulpham157/603963052902251</link><description>This isn't really related, but... do people generally prefer dark themes or light themes? See translation</description><pubDate>Thu, 08 Jan 2026 17:31:05 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/paulpham157/603963052902251</guid></item></channel></rss>