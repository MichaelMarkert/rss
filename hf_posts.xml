<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>🏯 Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! ✨</title><link>https://huggingface.co/posts/ginipick/807578740801859</link><description>🏯 Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! ✨ Hello AI enthusiasts! 🙋‍♀️ Today I'm introducing a truly magical project: Open Ghibli Studio 🎨 ginigen/FLUX-Open-Ghibli-Studio 🌟 What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! 🏞️✨ 🔧 How Does It Work? 📸 Upload your photo 🤖 Florence-2 AI analyzes the image and generates a description ✏️ "Ghibli style" is added to the description 🎭 Magic transformation happens using the FLUX.1 model and Ghibli LoRA! ⚙️ Customization Options Want more control? Adjust these in the advanced settings: 🎲 Set a seed (for reproducible results) 📏 Adjust image dimensions 🔍 Guidance scale (prompt adherence) 🔄 Number of generation steps 💫 Ghibli style intensity 🚀 Try It Now! Click the "Transform to Ghibli Style" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? 🌈 🌿 Note: For best results,...</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/807578740801859</guid></item><item><title>🔥 'Open Meme Studio': Your Creative Meme Factory 🎭✨</title><link>https://huggingface.co/posts/openfree/925352420925810</link><description>🔥 'Open Meme Studio': Your Creative Meme Factory 🎭✨ Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. 🚀 VIDraft/Open-Meme-Studio 🎯 Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! 🛠️ Features You'll Love 📸 Transform and reinterpret existing meme templates 🎭 Freely change expressions and poses 👓 Add props (sunglasses, hats, etc.) 🏞️ Change backgrounds and composite characters 🎨 Apply various artistic styles 💪 Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/925352420925810</guid></item><item><title>Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possible—just look at the “T” in ChatGPT, which comes from the Transformer architecture openly shared by Google.</title><link>https://huggingface.co/posts/clem/267300235555885</link><description>Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possible—just look at the “T” in ChatGPT, which comes from the Transformer architecture openly shared by Google. Then came the myth that AI was too dangerous to share, and companies started optimizing for short-term revenue. That led many major AI labs and researchers to stop sharing and collaborating. With OAI and sama now saying they're willing to share open weights again, we have a real chance to return to a golden age of AI progress and democratization—powered by openness and collaboration, in the US and around the world. This is incredibly exciting. Let’s go, open science and open-source AI! See translation</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/267300235555885</guid></item><item><title>✨ High-Resolution Ghibli Style Image Generator ✨</title><link>https://huggingface.co/posts/aiqtech/202174985893140</link><description>✨ High-Resolution Ghibli Style Image Generator ✨ 🌟 Introducing FLUX Ghibli LoRA Hello everyone! Today I'm excited to present a special LoRA model for FLUX Dev.1. This model leverages a LoRA trained on high-resolution Ghibli images for FLUX Dev.1 to easily create beautiful Ghibli-style images with stunning detail! 🎨 space: aiqtech/FLUX-Ghibli-Studio-LoRA model: openfree/flux-chatgpt-ghibli-lora 🔮 Key Features Trained on High-Resolution Ghibli Images - Unlike other LoRAs, this one is trained on high-resolution images, delivering sharper and more beautiful results Powered by FLUX Dev.1 - Utilizing the latest FLUX model for faster generation and superior quality User-Friendly Interface - An intuitive UI that allows anyone to create Ghibli-style images with ease Diverse Creative Possibilities - Express various themes in Ghibli style, from futuristic worlds to fantasy elements 🖼️ Sample Images Include "Ghibli style" in your prompts Try combining nature, fantasy elements, futuristic...</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aiqtech/202174985893140</guid></item><item><title>You can now run DeepSeek-V3-0324 on your own local device!</title><link>https://huggingface.co/posts/danielhanchen/465464088880734</link><description>You can now run DeepSeek-V3-0324 on your own local device! Run our Dynamic 2.42 and 2.71-bit DeepSeek GGUFs: unsloth/DeepSeek-V3-0324-GGUF You can run them on llama.cpp and other inference engines. See our guide here: https://docs.unsloth.ai/basics/tutorial-how-to-run-deepseek-v3-0324-locally See translation</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/465464088880734</guid></item><item><title>DeepGit: Your GitHub Gold Digger! 💰🚀</title><link>https://huggingface.co/posts/zamal/271014113300033</link><description>DeepGit: Your GitHub Gold Digger! 💰🚀 Hey Hugging Face gang! Meet DeepGit—my open-source sidekick that rips through GitHub to snag repos that fit you. Done with dead-end searches? Me too. Built it with LangGraph and some dope tricks: Embeddings grab the good stuff (HF magic, baby!) Re-ranking nails the best picks Snoops docs, code, and buzz in one slick flow Drops a clean list of hidden gems 💎 Unearth that sneaky ML lib or Python gem—run python app.py or langgraph dev and boom! Peek it at https://github.com/zamalali/DeepGit . Fork it, tweak it, love it—Docker’s in, HF vibes are strong. Drop a 🌟 or a crazy idea—I’m pumped to jam with you all! 🪂 See translation</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/zamal/271014113300033</guid></item><item><title>🎉 Thrilled to share our #CVPR2025 accepted work:</title><link>https://huggingface.co/posts/ZhiyuanthePony/617713430689574</link><description>🎉 Thrilled to share our #CVPR2025 accepted work: Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data (2503.21694) 🔥 ​Key Innovations: 1️⃣ First to adapt SD for ​direct textured mesh generation (1-2s inference) 2️⃣ Novel teacher-student framework leveraging multi-view diffusion models ([MVDream]( https://arxiv.org/abs/2308.16512 ) &amp; [RichDreamer]( https://arxiv.org/abs/2311.16918) ) 3️⃣ ​Parameter-efficient tuning - ​only +2.6% params over base SD 4️⃣ ​3D data-free training liberates model from dataset constraints 💡 Why matters? → A novel ​3D-Data-Free paradigm → Outperforms data-driven methods on creative concept generation → Unlocks web-scale text corpus for 3D content creation 🌐 Project: https://theericma.github.io/TriplaneTurbo/ 🎮 Demo: ZhiyuanthePony/TriplaneTurbo 💻 Code: https://github.com/theEricMa/TriplaneTurbo See translation</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZhiyuanthePony/617713430689574</guid></item><item><title>AReal-Boba 🔥 a fully open RL Frameworks released by AntGroup, an affiliate company of Alibaba.</title><link>https://huggingface.co/posts/AdinaY/252351292657061</link><description>AReal-Boba 🔥 a fully open RL Frameworks released by AntGroup, an affiliate company of Alibaba. inclusionAI/areal-boba-67e9f3fa5aeb74b76dcf5f0a ✨ 7B/32B - Apache2.0 ✨ Outperform on math reasoning ✨ Replicating QwQ-32B with 200 data under $200 ✨ All-in-one: weights, datasets, code &amp; tech report See translation</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/252351292657061</guid></item><item><title>HF's new system makes me feel like they are not transparent on their pricing and making me feel they are not trustworthy.</title><link>https://huggingface.co/posts/OFT/611311806757189</link><description>HF's new system makes me feel like they are not transparent on their pricing and making me feel they are not trustworthy. See translation</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/OFT/611311806757189</guid></item><item><title>Curious how Duality AI crafts synthetic data that can bridge the sim2real gap?</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/493599242742163</link><description>Curious how Duality AI crafts synthetic data that can bridge the sim2real gap? We just published an article here on HuggingFace outlining our process, with bonus dataset releases! Read it here: https://huggingface.co/blog/DualityAI-RebekahBogdanoff/training-yolov8-with-synthetic-data-from-falcon See translation</description><pubDate>Wed, 02 Apr 2025 13:31:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/493599242742163</guid></item></channel></rss>