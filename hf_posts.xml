<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>We're kick-starting the process of Transformers v5, with</title><link>https://huggingface.co/posts/lysandre/194539610907979</link><description>We're kick-starting the process of Transformers v5, with @ ArthurZ and @ cyrilvallez ! v5 should be significant: we're using it as a milestone for performance optimizations, saner defaults, and a much cleaner code base worthy of 2025. Fun fact: v4.0.0-rc-1 came out on Nov 19, 2020, nearly five years ago! See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/lysandre/194539610907979</guid></item><item><title>I‚Äôve built my blocker for AI-generated content. It‚Äôs a local AI running on my laptop with a browser extension that classifies and scrubs synthetic content from my eyeballs. I‚Äôm too old for this synthetic noise.</title><link>https://huggingface.co/posts/mitkox/209940111097655</link><description>I‚Äôve built my blocker for AI-generated content. It‚Äôs a local AI running on my laptop with a browser extension that classifies and scrubs synthetic content from my eyeballs. I‚Äôm too old for this synthetic noise. TL;DR I‚Äôm going full John Connor on the AI content apocalypse Think of it as an on device AI ad-blocker, but for: Em-dash overdose. Seriously, why is everything suddenly revolutionary‚Äîdisruptive‚Äîlife-changing? AI influencers‚Äô auto-generated posts and images, auto-posted, all hands-free. Fake news, fake images, fake people... puff. Surprisingly, it works. I suppose it will block some human-generated content. However, I would rather read a 2007 Myspace blog than another ‚Äú10 Growth Hacks Powered By ChatGPT‚Äù post. See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mitkox/209940111097655</guid></item><item><title>I'm a Hugging Face Fellow now, guys!ü§ó‚ù§Ô∏è</title><link>https://huggingface.co/posts/prithivMLmods/245628043869780</link><description>I'm a Hugging Face Fellow now, guys!ü§ó‚ù§Ô∏è With the same passion, trust, and momentum to contribute to the community, I‚Äôm excited to do some amazing things to wrap up Q3 and Q4 of 2025. And importantly, I‚Äôve been lucky enough to receive some knowledge and guidance from @ merve to build open-source demos and stuff. Thank you for the belief. Thank you ‚Äî much love. Long live open source! ‚Äî Prithiv See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/245628043869780</guid></item><item><title>The open source Synthetic Data SDK from MOSTLY AI:</title><link>https://huggingface.co/posts/ZennyKenny/754070932382171</link><description>The open source Synthetic Data SDK from MOSTLY AI: mostlyai offers the ability to generate realistic, privacy-safe synthetic data with just a few lines of Python. Try it out yourself in a No Code UI in the SDK Demo Space: mostlyai/synthetic-sdk-demo See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/754070932382171</guid></item><item><title>My team at</title><link>https://huggingface.co/posts/aposadasn/143665230984018</link><description>My team at arclabmit created a robotic teleoperation and learning software for controlling robots, recording datasets, and training physical AI models, which is compatible with lerobot . This work was part of a paper we published to ICCR Kyoto 2025. Check out or code here: https://github.com/ARCLab-MIT/beavr-bot/tree/main Our work aims to solve two key problems in the world of robotic manipulation: 1. The lack of a well-developed, open-source, accessible teleoperation system that can work out of the box. 2. No performant end-to-end control, recording, and learning platform for robots that is completely hardware agnostic. If you are curious to learn more or have any questions please feel free to reach out! Paper: BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots (2508.09606) See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aposadasn/143665230984018</guid></item><item><title>Search is such a fundamental part of content discovery, yet ends up overlooked or poorly implemented in so many apps we use every day.</title><link>https://huggingface.co/posts/salma-remyx/227310661152992</link><description>Search is such a fundamental part of content discovery, yet ends up overlooked or poorly implemented in so many apps we use every day. We built hundreds of Docker images for arXiv papers with a codebase - it's tough to find what you're looking for unless you happen to have the arXiv id handy using DockerHub's search. So we added full text search over these resources so that you're that much closer to testing a new promising idea. More resources to be indexed soon! Full Demo: https://www.youtube.com/watch?v=GjYReWbQZw8 Try it here!: https://engine.remyx.ai/resources Join us at Experiment 2025!: https://experiment.remyx.ai See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/227310661152992</guid></item><item><title>ü§ñ As AI-generated content is shared in movies/TV/across the web, there's one simple low-hanging fruit üçá to help know what's real: Visible watermarks. With the Gradio team, I've made sure it's trivially easy to add this disclosure to images, video, chatbot text. See how:</title><link>https://huggingface.co/posts/meg/340948346361550</link><description>ü§ñ As AI-generated content is shared in movies/TV/across the web, there's one simple low-hanging fruit üçá to help know what's real: Visible watermarks. With the Gradio team, I've made sure it's trivially easy to add this disclosure to images, video, chatbot text. See how: https://huggingface.co/blog/watermarking-with-gradio Thanks to the code collab in particular from @ abidlabs and Yuvraj Sharma. See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/meg/340948346361550</guid></item><item><title>‚úÖ New Article: *Earth under the Cosmic Intelligence Model ‚Äî Methodological Spec*</title><link>https://huggingface.co/posts/kanaria007/892789765870102</link><description>‚úÖ New Article: *Earth under the Cosmic Intelligence Model ‚Äî Methodological Spec* Title: üìù CIM‚ÄìEarth: A Methodology to Validate Earth Against the Cosmic Intelligence Model üîó https://huggingface.co/blog/kanaria007/cim-earth-spec --- Summary: This article is not a prediction, but a *methodological specification*. It outlines how the *Cosmic Intelligence Model (CIM)* can be mapped onto Earth, using only structural metrics and recomputation procedures. All numbers are placeholders ‚Äî the emphasis is on reproducibility, auditability, and clarity of method. &gt; Not a forecast, but a framework. &gt; Not results, but the path to results. --- Why It Matters: ‚Ä¢ Demonstrates how CIM can be applied consistently to real civilizations ‚Ä¢ Provides receiver-side recomputation rules for future empirical releases ‚Ä¢ Keeps theory transparent, auditable, and open to refinement --- What‚Äôs Inside: ‚Ä¢ Recap of CIM metrics (R_A, SEV, EAI, etc.) ‚Ä¢ Structural mapping procedure for Earth (Spec-only) ‚Ä¢ Guidelines for...</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/892789765870102</guid></item><item><title>a ton of image/video generation models and LLMs from big labs üî•</title><link>https://huggingface.co/posts/merve/630809926693212</link><description>a ton of image/video generation models and LLMs from big labs üî• &gt; Meta released facebook/mobilellm-r1-68c4597b104fac45f28f448e , smol LLMs for on-device use üí¨ &gt; Tencent released tencent/SRPO , high res image generation model and tencent/POINTS-Reader , cutting edge OCR üìù &gt; ByteDance released bytedance-research/HuMo , video generation from any input ‚èØÔ∏è find more models, datasets, demos here merve/sep-11-releases-68c7dbfa26bea8cd921fa0ac See translation</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/630809926693212</guid></item><item><title>6 Recent &amp; free sources to master Reinforcement Learning</title><link>https://huggingface.co/posts/Kseniase/121549643934542</link><description>6 Recent &amp; free sources to master Reinforcement Learning Almost every week new research and resources on RL come out. Knowledge needs to be constantly refreshed and updated with the latest trends. So today, we‚Äôre sharing 6 free sources to help you stay on track with RL: 1. A Survey of Continual Reinforcement Learning ‚Üí https://arxiv.org/abs/2506.21872 Covers continual RL (CRL): how agents can keep learning and adapt to new tasks without forgetting past ones. It analyses methods, benchmarks, evaluation metrics &amp;challenges 2. The Deep Reinforcement Learning course by Hugging Face ‚Üí https://huggingface.co/learn/deep-rl-course/unit0/introduction This is a popular free course, regularly updated. Includes community interaction, exercises, leaderboards, etc. 3. Reinforcement Learning Specialization (Coursera, University of Alberta) ‚Üí https://www.coursera.org/specializations/reinforcement-learning A 4-course series introducing foundational RL, implementing different algorithms, culminating...</description><pubDate>Wed, 17 Sep 2025 13:29:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/121549643934542</guid></item></channel></rss>