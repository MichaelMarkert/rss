<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>XBai o4 claims to beat Claude Opus 4 and o3-mini, and they provide verifiable proof. My skepticism circuits overloaded, but my local AI FOMO module screamed louder.</title><link>https://huggingface.co/posts/mitkox/604222926195865</link><description>XBai o4 claims to beat Claude Opus 4 and o3-mini, and they provide verifiable proof. My skepticism circuits overloaded, but my local AI FOMO module screamed louder. I've thrown this 33B monoblock LLM onto a single GPU and used Roo Code for someâ€¦ letâ€™s call it â€œvibe testingâ€. Itâ€™s terrifyingly competent. As an architect, itâ€™s the best open-weight model Iâ€™ve touched this side of 2025. See translation</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mitkox/604222926195865</guid></item><item><title>Wan 2.2 &amp; FLUX Krea Full Tutorial - Automated Install - Ready Perfect Presets - SwarmUI with ComfyUI - Install Wan 2.2 and FLUX Krea with literally 1-click and use our pre-made most amazing quality presets :</title><link>https://huggingface.co/posts/MonsterMMORPG/425722660691765</link><description>Wan 2.2 &amp; FLUX Krea Full Tutorial - Automated Install - Ready Perfect Presets - SwarmUI with ComfyUI - Install Wan 2.2 and FLUX Krea with literally 1-click and use our pre-made most amazing quality presets : https://youtu.be/8MvvuX4YPeo https://youtu.be/8MvvuX4YPeo Video Chapters 0:00 Introduction: The Ultimate Wan 2.2 Tutorial with Optimized Presets 1:03 Free Prompt Generation Tool &amp; Introducing the New FLUX Krea Dev Model 2:01 How SwarmUI &amp; ComfyUI Enable Video Generation on Low-End Hardware 2:46 Quick Start Guide: Downloading the Latest SwarmUI &amp; ComfyUI Installers 3:10 Step-by-Step: How to Update or Perform a Fresh Installation of ComfyUI 3:51 Step-by-Step: How to Update or Perform a Fresh Installation of SwarmUI 4:18 Essential Setup: Configuring the SwarmUI Backend for ComfyUI 4:53 One-Click Setup: Downloading All Required Wan 2.2 Models Automatically 5:46 Importing the Ultimate SwarmUI Presets Pack for Best Results 6:22 Wan 2.2 Image-to-Video Generation: A Complete Step-by-...</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/425722660691765</guid></item><item><title>Qwen Image â€“ The Latest Image Generation ModelğŸ”¥</title><link>https://huggingface.co/posts/prithivMLmods/372876915549424</link><description>Qwen Image â€“ The Latest Image Generation ModelğŸ”¥ Below are some samples generated using the Qwen Image Diffusion Model. Qwen-Image, a 20B MMDiT model for next-generation text-to-image generation, preserves typographic details, layout coherence, and contextual harmony with stunning accuracy. It is especially strong at creating stunning graphic posters with native text. The model is now open-source. [ ğš€ğš ğšğš—-ğ™¸ğš–ğšŠğšğš : Qwen/Qwen-Image ] â¤· Try the Qwen Image demo here: prithivMLmods/Qwen-Image-Diffusion , Qwen/Qwen-Image &amp; more ... â¤· Qwen-Image Technical Report : Qwen-Image Technical Report (2508.02324) â¤· Qwen Image [GitHub] : https://github.com/QwenLM/Qwen-Image Even more impressively, it demonstrates a strong ability to understand images. The model supports a wide range of vision-related tasks such as object detection, semantic segmentation, depth and edge (Canny) estimation, novel view synthesis, and image super-resolution. While each task is technically distinct, they can all be viewed...</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/372876915549424</guid></item><item><title>Trainable selective sampling and sparse attention kernels are indispensable in the era of context engineering. We hope our work will be helpful to everyone! ğŸ¤—</title><link>https://huggingface.co/posts/JingzeShi/527939367728783</link><description>Trainable selective sampling and sparse attention kernels are indispensable in the era of context engineering. We hope our work will be helpful to everyone! ğŸ¤— Trainable Dynamic Mask Sparse Attention (2508.02124) See translation</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/JingzeShi/527939367728783</guid></item><item><title>Just included example scripts for aligning models using GSPO (including VLM example) ğŸ™†â€â™‚ï¸ğŸ™†â€â™‚ï¸</title><link>https://huggingface.co/posts/sergiopaniego/720514750677796</link><description>Just included example scripts for aligning models using GSPO (including VLM example) ğŸ™†â€â™‚ï¸ğŸ™†â€â™‚ï¸ GSPO is the latest RL alignment algo by @Alibaba_Qwen and it's already supported in the latest TRL v0.20 release. Super-easy-to-get-started example scripts below, GO run them!ğŸ‘©â€ğŸ’»ğŸ‘©â€ğŸ’» ğŸ§‘â€ğŸ¨ Script: https://github.com/huggingface/trl/blob/main/examples/scripts/gspo.py ğŸ¦„ VLM script: https://github.com/huggingface/trl/blob/main/examples/scripts/gspo_vlm.py ğŸ§© More TRL examples: https://huggingface.co/docs/trl/main/en/example_overview ğŸ§™â€â™‚ï¸ GSPO paper: Group Sequence Policy Optimization (2507.18071) See translation</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/720514750677796</guid></item><item><title>Extended the ICM paper to show cross-model capability transfer - used Qwen3's mathematical reasoning to improve Gemma3 without any human supervision.</title><link>https://huggingface.co/posts/codelion/145733180850232</link><description>Extended the ICM paper to show cross-model capability transfer - used Qwen3's mathematical reasoning to improve Gemma3 without any human supervision. Key results: Qwen3-0.6B: 63.2 â†’ 66.0 on MATH-500 (+4%) Gemma3-1B: 41.0 â†’ 45.6 on MATH-500 (+11%) The method extracts coherent reasoning patterns from one model via Internal Coherence Maximization, converts them to DPO training data, and uses that to improve a completely different model architecture. This goes beyond the original ICM paper which only improved models using their own labels. We're showing you can transfer capabilities between any models - imagine extracting capabilities from strong models to improve your local ones. Models available: codelion/Qwen3-0.6B-ICM-DPO codelion/gemma-3-1b-it-ICM-DPO Complete collection with code and datasets: codelion/internal-coherence-maximization-687a1bd1c1f5f1d6f76e9b3b Full methodology and results: https://huggingface.co/blog/codelion/internal-coherence-maximization Planning to extend this...</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/145733180850232</guid></item><item><title>12 Powerful World Models</title><link>https://huggingface.co/posts/Kseniase/651523050744942</link><description>12 Powerful World Models World models are one of the most challenging areas in AI, pushing the boundaries of reasoning, perception, and planning. They're gen AI systems that help models and agents learn internal representations of real-world environments. Today, we invite you to take a look at 12 standout examples: 1. WorldVLA â†’ WorldVLA: Towards Autoregressive Action World Model (2506.21539) This autoregressive world model integrates action prediction and visual world modeling in a single framework, allowing each to enhance the other. It introduces an attention masking strategy to reduce action prediction errors 2. SimuRA â†’ https://arxiv.org/abs/2507.23773 A generalized world model that uses a language-based world model to simulate and plan actions before execution, enabling more general and flexible reasoning 3. PAN (Physical, Agentic, and Nested) world models â†’ Critiques of World Models (2507.05169) Has a hybrid architecture that combines discrete concept-based reasoning (via...</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/651523050744942</guid></item><item><title>Introducing Completionist, an open-source command-line tool that automates synthetic dataset generation.</title><link>https://huggingface.co/posts/mrs83/268112975581936</link><description>Introducing Completionist, an open-source command-line tool that automates synthetic dataset generation. It works by iterating over an existing HF dataset and by using a LLM to create completions. - Problem: You need a fast way to create custom datasets for fine-tuning or RAG, but you want the flexibility to use different LLM backends or your own infrastructure. - Solution: Completionist connects with any OpenAI-compatible endpoint, including Ollama and LM Studio, or a Hugging Face inference endpoint. A simple CLI like Completionist gives you the possibility to take full control of your synthetic data generation workflow. ğŸ‘‰ Check out Completionist on GitHub: https://github.com/ethicalabs-ai/completionist Synthetic Dataset Example: ethicalabs/kurtis-mental-health-v2-sft-reasoning See translation</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mrs83/268112975581936</guid></item><item><title>ğŸš€ Dhanishtha-2.0-preview-0825 Is Here</title><link>https://huggingface.co/posts/Abhaykoul/625756342268823</link><description>ğŸš€ Dhanishtha-2.0-preview-0825 Is Here The Intermediate Thinking Model just leveled up again. With sharper reasoning, better tool use, and expanded capabilities, Dhanishtha-2.0-preview-0825 is now live and ready to impress. ğŸ§  What Makes Dhanishtha Special? Unlike typical CoT models that only thinks one time, Dhanishtha thinks iteratively: &gt; Think â†’ Answer â†’ Rethink â†’ Improve â†’ Rethink again if needed. ğŸ”— Try it now: HelpingAI/Dhanishtha-2.0-preview-0825 ğŸ” Dhanishtha NSFW Preview For those exploring more expressive and immersive roleplay scenarios, weâ€™re also releasing: HelpingAI/Dhanishtha-nsfw A specialized version tuned for adult-themed interactions and character-driven roleplay. ğŸ”— Explore it here: HelpingAI/Dhanishtha-nsfw ğŸ’¬ You can also try all of these live at chat.helpingai.co See translation</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Abhaykoul/625756342268823</guid></item><item><title>ğŸ§¬ We just published our comprehensive analysis of OpenEvolve - an open-source evolutionary coding agent that automatically optimizes algorithms using LLMs!</title><link>https://huggingface.co/posts/codelion/631631354493607</link><description>ğŸ§¬ We just published our comprehensive analysis of OpenEvolve - an open-source evolutionary coding agent that automatically optimizes algorithms using LLMs! Our key findings from 29 experiments across 10 models: - Gemini Flash 2.5 achieved 2.04x speedup across 30 benchmark tasks - Open models like Gemma 3 27B (1.63x) and Qwen3-Coder 480B (1.41x) rivaled proprietary models - The system discovered entirely new algorithms - not just code optimizations! - One task evolved from DFS to BFS to Union-Find approaches - Specialized coding models outperformed much larger general models 200 iterations beat 100 iterations by 24% - Ensembles surprisingly failed due to conflicting optimization strategies Most fascinating: watching models evolve code step-by-step, like transforming matrix operations from basic eigendecomposition to vectorized one-liners with 32x speedup. Our systematic experimental approach reveals that open-source evolutionary coding is becoming seriously competitive with...</description><pubDate>Tue, 05 Aug 2025 13:45:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/631631354493607</guid></item></channel></rss>