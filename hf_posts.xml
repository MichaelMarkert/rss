<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>🚀 Llama-4 Model-Based Agentic AI System Released!</title><link>https://huggingface.co/posts/openfree/652290136793730</link><description>🚀 Llama-4 Model-Based Agentic AI System Released! 🔥 Introducing the Latest Llama-4 Models Hello AI enthusiasts! Today we're excited to introduce our free API service powered by the cutting-edge Llama-4-Maverick-17B and Llama-4-Scout-17B models! These state-of-the-art models will upgrade your AI experience with remarkable stability and speed. Link1: openfree/Llama-4-Maverick-17B-Research Link2: openfree/Llama-4-Scout-17B-Research 🧠 The Innovation of Agentic AI: Deep Research Feature The standout feature of our service is the revolutionary "Deep Research" functionality! This innovative Agentic AI system includes: 🔍 Optimized Keyword Extraction: LLM automatically generates the most effective keywords for searches 🌐 Real-time Web Search: Collects the latest information through the SerpHouse API 📊 Intelligent Information Analysis: Precise analysis utilizing the LLM's reasoning capabilities based on collected information 📝 Contextualized Response Generation: Provides accurate answers...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/652290136793730</guid></item><item><title>🎨 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition 🌏✨</title><link>https://huggingface.co/posts/seawolf2357/883323339740165</link><description>🎨 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition 🌏✨ Hello creators! Today I'm introducing a special image generator that combines the beautiful aesthetics of Studio Ghibli with multilingual text integration! 😍 seawolf2357/Ghibli-Multilingual-Text-rendering ✨ Key Features Ghibli-Style Image Generation - High-quality animation-style images based on FLUX.1 Multilingual Text Rendering - Support for Korean, Japanese, English, and all languages! 🇰🇷🇯🇵🇬🇧 Automatic Image Editing with Simple Prompts - Just input your desired text and you're done! Two Stylistic Variations Provided - Get two different results from a single prompt Full Hugging Face Spaces Support - Deploy and share instantly! 🚀 How Does It Work? Enter a prompt describing your desired image (e.g., "a cat sitting by the window") Input the text you want to add (any language works!) Select the text position, size, and color Two different versions are automatically generated! 💯...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/883323339740165</guid></item><item><title>🏯 Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! ✨</title><link>https://huggingface.co/posts/ginipick/807578740801859</link><description>🏯 Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! ✨ Hello AI enthusiasts! 🙋‍♀️ Today I'm introducing a truly magical project: Open Ghibli Studio 🎨 ginigen/FLUX-Open-Ghibli-Studio 🌟 What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! 🏞️✨ 🔧 How Does It Work? 📸 Upload your photo 🤖 Florence-2 AI analyzes the image and generates a description ✏️ "Ghibli style" is added to the description 🎭 Magic transformation happens using the FLUX.1 model and Ghibli LoRA! ⚙️ Customization Options Want more control? Adjust these in the advanced settings: 🎲 Set a seed (for reproducible results) 📏 Adjust image dimensions 🔍 Guidance scale (prompt adherence) 🔄 Number of generation steps 💫 Ghibli style intensity 🚀 Try It Now! Click the "Transform to Ghibli Style" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? 🌈 🌿 Note: For best results,...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/807578740801859</guid></item><item><title>🔥 'Open Meme Studio': Your Creative Meme Factory 🎭✨</title><link>https://huggingface.co/posts/openfree/925352420925810</link><description>🔥 'Open Meme Studio': Your Creative Meme Factory 🎭✨ Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. 🚀 VIDraft/Open-Meme-Studio 🎯 Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! 🛠️ Features You'll Love 📸 Transform and reinterpret existing meme templates 🎭 Freely change expressions and poses 👓 Add props (sunglasses, hats, etc.) 🏞️ Change backgrounds and composite characters 🎨 Apply various artistic styles 💪 Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/925352420925810</guid></item><item><title>✨ High-Resolution Ghibli Style Image Generator ✨</title><link>https://huggingface.co/posts/aiqtech/202174985893140</link><description>✨ High-Resolution Ghibli Style Image Generator ✨ 🌟 Introducing FLUX Ghibli LoRA Hello everyone! Today I'm excited to present a special LoRA model for FLUX Dev.1. This model leverages a LoRA trained on high-resolution Ghibli images for FLUX Dev.1 to easily create beautiful Ghibli-style images with stunning detail! 🎨 space: aiqtech/FLUX-Ghibli-Studio-LoRA model: openfree/flux-chatgpt-ghibli-lora 🔮 Key Features Trained on High-Resolution Ghibli Images - Unlike other LoRAs, this one is trained on high-resolution images, delivering sharper and more beautiful results Powered by FLUX Dev.1 - Utilizing the latest FLUX model for faster generation and superior quality User-Friendly Interface - An intuitive UI that allows anyone to create Ghibli-style images with ease Diverse Creative Possibilities - Express various themes in Ghibli style, from futuristic worlds to fantasy elements 🖼️ Sample Images Include "Ghibli style" in your prompts Try combining nature, fantasy elements, futuristic...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aiqtech/202174985893140</guid></item><item><title>Huge week for</title><link>https://huggingface.co/posts/jsulz/745335361364732</link><description>Huge week for xet-team as Llama 4 is the first major model on Hugging Face uploaded with Xet providing the backing! Every byte downloaded comes through our infrastructure. Using Xet on Hugging Face is the fastest way to download and iterate on open source models and we've proved it with Llama 4 giving a boost of ~25% across all models. We expect builders on the Hub to see even more improvements, helping power innovation across the community. With the models on our infrastructure, we can peer in and see how well our dedupe performs across the Llama 4 family. On average, we're seeing ~25% dedupe, providing huge savings to the community who iterate on these state-of-the-art models. The attached image shows a few selected models and how they perform on Xet. Thanks to the meta-llama team for launching on Xet! See translation</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jsulz/745335361364732</guid></item><item><title>Meta has unveiled its  Llama 4 🦙 family of models, featuring native multimodality and mixture-of-experts architecture. Two model families are available now:</title><link>https://huggingface.co/posts/merterbak/558288701198389</link><description>Meta has unveiled its Llama 4 🦙 family of models, featuring native multimodality and mixture-of-experts architecture. Two model families are available now: Models🤗: meta-llama/llama-4-67f0c30d9fe03840bc9d0164 Blog Post: https://ai.meta.com/blog/llama-4-multimodal-intelligence/ HF's Blog Post: https://huggingface.co/blog/llama4-release - 🧠 Native Multimodality - Process text and images in a unified architecture - 🔍 Mixture-of-Experts - First Llama models using MoE for incredible efficiency - 📏 Super Long Context - Up to 10M tokens - 🌐 Multilingual Power - Trained on 200 languages with 10x more multilingual tokens than Llama 3 (including over 100 languages with over 1 billion tokens each) 🔹 Llama 4 Scout - 17B active parameters (109B total) - 16 experts architecture - 10M context window - Fits on a single H100 GPU - Beats Gemma 3, Gemini 2.0 Flash-Lite, and Mistral 3.1 🔹 Llama 4 Maverick - 17B active parameters (400B total) - 128 experts architecture - It can fit perfectly on DGX...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merterbak/558288701198389</guid></item><item><title>JOURNEY TO 1 MILLION DEVELOPERS</title><link>https://huggingface.co/posts/abidlabs/192598522318521</link><description>JOURNEY TO 1 MILLION DEVELOPERS 5 years ago, we launched Gradio as a simple Python library to let researchers at Stanford easily demo computer vision models with a web interface. Today, Gradio is used by &gt;1 million developers each month to build and share AI web apps. This includes some of the most popular open-source projects of all time, like Automatic1111, Fooocus, Oobabooga’s Text WebUI, Dall-E Mini, and LLaMA-Factory. How did we get here? How did Gradio keep growing in the very crowded field of open-source Python libraries? I get this question a lot from folks who are building their own open-source libraries. This post distills some of the lessons that I have learned over the past few years: 1. Invest in good primitives, not high-level abstractions 2. Embed virality directly into your library 3. Focus on a (growing) niche 4. Your only roadmap should be rapid iteration 5. Maximize ways users can consume your library's outputs 1. Invest in good primitives, not high-level...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/192598522318521</guid></item><item><title>The best researchers from Yale, Stanford, Google DeepMind, and Microsoft laid out all we know about Agents in a 264-page paper [book],</title><link>https://huggingface.co/posts/hesamation/410985277524863</link><description>The best researchers from Yale, Stanford, Google DeepMind, and Microsoft laid out all we know about Agents in a 264-page paper [book], Here are some of their key findings: They build a mapping of different agent components, such as perception, memory, and world modelling, to different regions of the human brain and compare them: - brain is much more energy-efficient - no genuine experience in agents - brain learns continuously, agent is static An agent is broken down to: - Perception: the agent's input mechanism. can be improved with multi-modality, feedback mechanisms (e.g., human corrections), etc. - Cognition: learning, reasoning, planning, memory. LLMs are key in this part. - Action: agent's output and tool use. Agentic memory is represented as: - Sensory memory or short-term holding of inputs which is not emphasized much in agents. - Short-term memory which is the LLM context window - Long-term memory which is the external storage such as RAG or knowledge graphs. The memory in...</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/410985277524863</guid></item><item><title>Hi  🤗HF Community,</title><link>https://huggingface.co/posts/ritvik77/384830286585456</link><description>Hi 🤗HF Community, I would be incredibly grateful for an opportunity to contribute — in any capacity — and learn alongside researchers here. Is there any possibility I could collaborate or assist with any of your research works ? I’m happy to support ongoing projects, contribute to data analysis, code, documentation, or anything that adds value. Thank you for your time and consideration! Warm regards, Ritvik Gaur See translation</description><pubDate>Mon, 07 Apr 2025 09:25:36 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ritvik77/384830286585456</guid></item></channel></rss>