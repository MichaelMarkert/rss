<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸŒ¾ NH Prediction: AI System for Korean Agricultural Price Forecasting ğŸŒ¾</title><link>https://huggingface.co/posts/openfree/102455854917725</link><description>ğŸŒ¾ NH Prediction: AI System for Korean Agricultural Price Forecasting ğŸŒ¾ ğŸ“Š Project Introduction Price volatility in agricultural markets has significant impacts from producers to consumers! NH Prediction is an innovative system that utilizes cutting-edge AI technology to predict Korean agricultural wholesale prices based on extensive data spanning 40 years. ğŸš€ VIDraft/NH-Prediction ginipick/NH-Korea ğŸ§  VIDraft's 14 Enhanced Prediction Models The VIDraft research team has developed 14 advanced prediction models by reinforcing existing forecasting approaches: ğŸ”® VID-SARIMA Series: Precisely models seasonality and trends (up to 99.99% accuracy) âš–ï¸ VID-ETS Series: Captures multiplicative/additive variation patterns ğŸ“ˆ VID-Holt/Holt-Winters: Simultaneous analysis of linear trends and seasonality ğŸ“‰ VID-MovingAverage/WeightedMA: Noise removal and medium-term trend identification ğŸ” VID-Fourier+LR: Hybrid approach capturing complex periodicity âœ¨ Key Features ğŸŒŸ Item-Specific Optimization:...</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/102455854917725</guid></item><item><title>ğŸ§¬ Hey everyone! Just released **OpenEvolve** - an open-source implementation of Google DeepMind's AlphaEvolve system.</title><link>https://huggingface.co/posts/codelion/735622263233891</link><description>ğŸ§¬ Hey everyone! Just released **OpenEvolve** - an open-source implementation of Google DeepMind's AlphaEvolve system. It's an evolutionary coding agent that uses LLMs to discover and optimize algorithms. I successfully replicated DeepMind's results on circle packing (99.97% match!) and evolved a random search into a simulated annealing algorithm. âœ¨ Key features: - Evolves entire codebases (not just single functions) - Works with any OpenAI-compatible API - LLM ensemble approach for better results - Multi-objective optimization ğŸ‘‰ Check it out: GitHub: https://github.com/codelion/openevolve Blog post: https://huggingface.co/blog/codelion/openevolve Would love to hear your thoughts or answer any questions about it! See translation</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/735622263233891</guid></item><item><title>ByteDance is absolutely cooking latelyğŸ”¥</title><link>https://huggingface.co/posts/AdinaY/709690582361356</link><description>ByteDance is absolutely cooking latelyğŸ”¥ BAGEL ğŸ¥¯ 7B active parameter open multimodal foundation model by Bytedance Seed team. ByteDance-Seed/BAGEL-7B-MoT âœ¨ Apache 2.0 âœ¨ Outperforms top VLMs (Qwen2.5-VL &amp; InternVL-2.5) âœ¨ Mixture-of-Transformer-Experts + dual encoders âœ¨ Trained on trillions of interleaved tokens See translation</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/709690582361356</guid></item><item><title>Video link :</title><link>https://huggingface.co/posts/MonsterMMORPG/454841394174188</link><description>Video link : https://youtu.be/gFMUChHgXYk VEO 3 AI Video Generation is Literally Insane with Perfect Audio! - 60 User Generated Wild Examples - Finally We can Expect Native Audio Supported Open Source Video Gen Models Video link : https://youtu.be/gFMUChHgXYk Google Unveils Veo 3: A Game-Changing AI Video Generator with Native Audio Published May 21, 2025 At Google I/O 2025, held on May 20â€“21 in Mountain View, California, Google announced the launch of Veo 3, its latest AI-powered video generation model, marking a significant leap in creative technology. This third-generation model, succeeding Veo 2, introduces groundbreaking features, most notably its ability to generate high-quality videos with integrated audio, including dialogue, sound effects, and ambient noise. Alongside Veo 3, Google introduced Flow, a new AI-driven video editing suite designed to empower filmmakers and content creators. Hereâ€™s an in-depth look at Veo 3, its capabilities, and its potential to reshape AI...</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/454841394174188</guid></item><item><title>Heyo</title><link>https://huggingface.co/posts/jsulz/285043040409517</link><description>Heyo @ RichardErkhov the xet-team at Hugging face was wondering if you wanted to join the fun and jump over to Xet storage. ğŸ¤— We've been onboarding folks https://huggingface.co/blog/xet-on-the-hub know the backend can scale (Llama 4 and Qwen 3 are on Xet), is great for working with quants (see xet-team/quantization-dedup ), and we're pushing on inviting impactful orgs and users on the Hub. You fit the bill. We'd love to onboard you, get some feedback, and create some excitement ğŸ‰ The steps are pretty straightforward - join the waitlist at hf.co/join/xet and we'll take care of the rest. The system is fully backward compatible, so you shouldn't notice a thing. BUT to get the best experience when uploading/downloading, make sure you have hf_xet installed alongside the latest huggingface_hub What do you think? See translation</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jsulz/285043040409517</guid></item><item><title>Despite the emergence of combining LLM and DiT architectures for T2I synthesis, its design remains severely understudied.</title><link>https://huggingface.co/posts/sayakpaul/592772325865027</link><description>Despite the emergence of combining LLM and DiT architectures for T2I synthesis, its design remains severely understudied. This was done long ago and got into CVPR25 -- super excited to finally share it now, along with the data and code â™¥ï¸ We explore several architectural choices that affect this design. We provide an open &amp; reproducible training recipe that works at scale. Works like Playground v3 have already explored a deep fusion between an LLM and a DiT, sharing their representations through layerwise attention. They exhibit excellent performance on T2I. Despite its compelling results and other performance virtues, it remains unexplored, which is what we want to improve in our work. Specifically, we take a pre-trained LLM (Gemma-2B) and trainable DiT, and set out to explore what makes a "good deep fusion" between the two for T2I. We explore several key questions in the work, such as: Q1: How should we do attention? We considered several alternatives. PixArt-Alpha like attention...</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sayakpaul/592772325865027</guid></item><item><title>Yesterday, we dropped a new conversational viewer for datasets on the hub! ğŸ’¬</title><link>https://huggingface.co/posts/cfahlgren1/983652211807712</link><description>Yesterday, we dropped a new conversational viewer for datasets on the hub! ğŸ’¬ Actually being able to view and inspect your data is extremely important. This is a big step in making data more accessible and actionable for everyone. Here's some datasets you can try it out on: â€¢ mlabonne/FineTome-100k â€¢ Salesforce/APIGen-MT-5k â€¢ open-thoughts/OpenThoughts2-1M â€¢ allenai/tulu-3-sft-mixture Any other good ones? See translation</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/cfahlgren1/983652211807712</guid></item><item><title>hey hey</title><link>https://huggingface.co/posts/reach-vb/415173057781918</link><description>hey hey @ mradermacher - VB from Hugging Face here, we'd love to onboard you over to our optimised xet backend! ğŸ’¥ as you know we're in the process of upgrading our storage backend to xet (which helps us scale and offer blazingly fast upload/ download speeds too): https://huggingface.co/blog/xet-on-the-hub and now that we are certain that the backend can scale with even big models like Llama 4/ Qwen 3 - we;re moving to the next phase of inviting impactful orgs and users on the hub over as you are a big part of the open source ML community - we would love to onboard you next and create some excitement about it in the community too! in terms of actual steps - it should be as simple as one of the org admins to join hf.co/join/xet - we'll take care of the rest. p.s. you'd need to have a the latest hf_xet version of huggingface_hub lib but everything else should be the same: https://huggingface.co/docs/hub/storage-backends#using-xet-storage p.p.s. this is fully backwards compatible so...</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/reach-vb/415173057781918</guid></item><item><title>Playing with Veo3 this morning. Share your prompt if you want me to create videos for you (bonus point if they funnily reference HF/open-source). These videos are "a cat on the moon rapping "I love Hugging Face""!</title><link>https://huggingface.co/posts/clem/670042306060895</link><description>Playing with Veo3 this morning. Share your prompt if you want me to create videos for you (bonus point if they funnily reference HF/open-source). These videos are "a cat on the moon rapping "I love Hugging Face""! See translation</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/670042306060895</guid></item><item><title>Meet our new agentic model : ğ——ğ—²ğ˜ƒğ˜€ğ˜ğ—¿ğ—®ğ—¹</title><link>https://huggingface.co/posts/Jofthomas/656021086131496</link><description>Meet our new agentic model : ğ——ğ—²ğ˜ƒğ˜€ğ˜ğ—¿ğ—®ğ—¹ Devstral is an open-source LLM built software engineering tasks built under a collaboration between Mistral AI and All Hands AI ğŸ™Œ. ğ—ğ—²ğ˜† ğ—³ğ—²ğ—®ğ˜ğ˜‚ğ—¿ğ—²ğ˜€ : â€¢ ğŸ¤– ğ—”ğ—´ğ—²ğ—»ğ˜ğ˜€ : perfect for Agentic coding â€¢ ğŸƒ ğ—¹ğ—¶ğ—´ğ—µğ˜ğ˜„ğ—²ğ—¶ğ—´ğ—µğ˜: Devstral is a ğŸ®ğŸ°ğ—• parameter based on Mistral small. â€¢ Â©ï¸ ğ—”ğ—½ğ—®ğ—°ğ—µğ—² ğŸ®.ğŸ¬, meaning fully open-source ! â€¢ ğŸ“„ A ğŸ­ğŸ®ğŸ´ğ—¸ context window. ğŸ“šBlog : https://mistral.ai/news/devstral âš¡API : The model is also available on our API under the name ğ—±ğ—²ğ˜ƒğ˜€ğ˜ğ—¿ğ—®ğ—¹-ğ˜€ğ—ºğ—®ğ—¹ğ—¹-ğŸ®ğŸ±ğŸ¬ğŸ± ğŸ¤— repo : mistralai/Devstral-Small-2505 Can't wait to see what you will build with it ! See translation</description><pubDate>Thu, 22 May 2025 13:34:33 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jofthomas/656021086131496</guid></item></channel></rss>