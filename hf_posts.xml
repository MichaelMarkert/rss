<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>So, Koreans are also doing great progress behind Chinese,</title><link>https://huggingface.co/posts/Ujjwal-Tyagi/869541950904709</link><description>So, Koreans are also doing great progress behind Chinese, Their two open source ai models that are actually good in coding. upstage/Solar-Open-100B skt/A.X-K1 See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Ujjwal-Tyagi/869541950904709</guid></item><item><title>Inspired by the heroes of day zero quants (</title><link>https://huggingface.co/posts/marksverdhei/460500590246249</link><description>Inspired by the heroes of day zero quants ( @ TheBloke @ danielhanchen @ shimmyshimmer @ bartowski ), I decided to join the race by releasing the first FP8 quant of glm-4.7-flash! Not as easy as i expected, but I'm happy i was still able to have it working within a few hours after the original model was released! Interested in feedback if anyone wants to try it out! marksverdhei/GLM-4.7-Flash-FP8 Note: If my PR to vLLM isn't merged yet you might have to use my fork. Cheers! ü§ó See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/marksverdhei/460500590246249</guid></item><item><title>VividFlow: Complete AI Image Transformation Platform üé¨üé®‚ú®</title><link>https://huggingface.co/posts/DawnC/976121143006478</link><description>VividFlow: Complete AI Image Transformation Platform üé¨üé®‚ú® Three powerful creative tools in one streamlined workspace. VividFlow combines professional video generation, intelligent background replacement, and artistic style transfer to transform your images with precision and creativity. üé≠ Triple Creative Powers - Cinematic Video Generation transforms static images into smooth motion sequences from 0.5 to 5 seconds. Eight curated motion categories cover portraits, products, landscapes, and artistic content with precision-tuned templates. - Intelligent Background Replacement generates photorealistic scenes from 24 professionally crafted presets spanning studios, natural environments, urban settings, and seasonal atmospheres. Advanced edge refinement handles complex subjects, while the built-in Touch Up tool eliminates artifacts through AI-powered inpainting for flawless results. - Artistic Style Transfer converts photographs into stunning interpretations across six distinct styles...</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/976121143006478</guid></item><item><title>Run GLM-4.7-Flash locally on your device with 24GB RAM!üî•</title><link>https://huggingface.co/posts/danielhanchen/143027024579647</link><description>Run GLM-4.7-Flash locally on your device with 24GB RAM!üî• It's the best performing 30B model on SWE-Bench and GPQA. With 200K context, it excels at coding, agents, chat &amp; reasoning. GGUF: unsloth/GLM-4.7-Flash-GGUF Guide: https://unsloth.ai/docs/models/glm-4.7-flash See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/143027024579647</guid></item><item><title>Z.ai just released a powerful lightweight option of GLM 4.7</title><link>https://huggingface.co/posts/AdinaY/893023705771972</link><description>Z.ai just released a powerful lightweight option of GLM 4.7 ‚ú® 30B total/3B active - MoE zai-org/GLM-4.7-Flash See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/893023705771972</guid></item><item><title>Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI!</title><link>https://huggingface.co/posts/projectlosangeles/732365874551092</link><description>Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI! projectlosangeles/Orpheus-Karaoke See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/projectlosangeles/732365874551092</guid></item><item><title>Interesting paper: PhysRVG</title><link>https://huggingface.co/posts/efecelik/213200184330880</link><description>Interesting paper: PhysRVG The core idea: instead of treating physics as a soft condition the model can work around during optimization, enforce it strictly via reinforcement learning. The paper focuses on rigid body dynamics - collisions, pendulums, free fall, rolling. PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models (2601.11087) See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/efecelik/213200184330880</guid></item><item><title>üòé My new personal website is live! Check out</title><link>https://huggingface.co/posts/ZennyKenny/848353801795401</link><description>üòé My new personal website is live! Check out https://kennethhamilton.me to chat with an LLM about my professional skills and personal projects. üôà Think of it like a really, really vain version of ChatGPT. See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/848353801795401</guid></item><item><title>üèõÔ∏è Google Code Archive Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/331224318760046</link><description>üèõÔ∏è Google Code Archive Dataset - nyuuzyou/google-code-archive Expanding beyond the modern code series, this release presents a massive historical snapshot from the Google Code Archive. This dataset captures the open-source landscape from 2006 to 2016, offering a unique time capsule of software development patterns during the era before GitHub's dominance. Key Stats: - 65,825,565 files from 488,618 repositories - 47 GB compressed Parquet storage - 454 programming languages (Heavily featuring Java, PHP, and C++) - Extensive quality filtering (excluding vendor code and build artifacts) - Rich historical metadata: original repo names, file paths, and era-specific licenses This is one of those releases that I'm most interested in getting feedback on. Would you like to see more old code datasets? See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/331224318760046</guid></item><item><title>NEW MODEL:</title><link>https://huggingface.co/posts/unmodeled-tyler/422829843470899</link><description>NEW MODEL: vanta-research/mox-small-1 Mox-Small-1 has landed on the Hub! Finetuned from the fantastic Olmo3.1 32B architecture by AllenAI, Mox-Small-1 was trained using the same datasets and methodology as Mox-Tiny-1, making this model our second addition to the Mox-1 family of models. Mox-1 is designed to prioritize clarity, honesty, and genuine utility over blind agreement. These models are perfect for when you want to be challenged in a constructive, helpful way. By utilizing Olmo3.1 32B's architecture, Mox-Small-1 brings greater conversational depth and reasoning quality to the Mox-1 model family. Check it out! See translation</description><pubDate>Wed, 21 Jan 2026 13:50:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/422829843470899</guid></item></channel></rss>