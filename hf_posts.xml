<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>made a few improvements on custom grpo trainer:</title><link>https://huggingface.co/posts/Jaward/982484477481896</link><description>made a few improvements on custom grpo trainer: - added sequence similarity reward (seems to work) - improved vllm support (5x inference speed) - adjusted reward scores (this helped with format/accuracy) - can now push to hf hub (already pushed mine lol: Jaward/smollm2_360m_grpo_gsm8k_reasoner ) Code: https://github.com/Jaykef/ai-algorithms/blob/main/smollm2_360M_135M_grpo_gsm8k.ipynb See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/982484477481896</guid></item><item><title>Dropping some of the custom fine-tunes based on SigLIP2,</title><link>https://huggingface.co/posts/prithivMLmods/305640045790864</link><description>Dropping some of the custom fine-tunes based on SigLIP2, with a single-label classification problem type! üåÄüß§ - AI vs Deepfake vs Real : prithivMLmods/AI-vs-Deepfake-vs-Real-Siglip2 - Deepfake Detect : prithivMLmods/Deepfake-Detect-Siglip2 - Fire Detection : prithivMLmods/Fire-Detection-Siglip2 - Deepfake Quality Assess : prithivMLmods/Deepfake-Quality-Assess-Siglip2 - Guard Against Unsafe Content : prithivMLmods/Guard-Against-Unsafe-Content-Siglip2 üå†Collection : prithivMLmods/siglip2-custom-67bcdb2de8fe96b99fb4e19e See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/305640045790864</guid></item><item><title>Dear HF Community!</title><link>https://huggingface.co/posts/lingvanex-mt/205421793754165</link><description>Dear HF Community! Our company open-sourced machine translation models for 12 rare languages under MIT license. You can use them freely with OpenNMT translation framework. Each model is about 110 mb and has an excellent performance, ( about 40000 characters / s on Nvidia RTX 3090 ) Download models there https://huggingface.co/lingvanex You can test translation quality there: https://lingvanex.com/translate/ See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/lingvanex-mt/205421793754165</guid></item><item><title>Introducing a new architecture, MedIT One ‚Äì a single-token transformer with LSTM-like recurrence.</title><link>https://huggingface.co/posts/mkurman/255930071052172</link><description>Introducing a new architecture, MedIT One ‚Äì a single-token transformer with LSTM-like recurrence. It is extremely fast in training and inference, but we lack funding for large-scale training. Enjoy üçì https://github.com/MedITSolutionsKurman/medit-one See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mkurman/255930071052172</guid></item><item><title>create amazing audio ads in just a few steps</title><link>https://huggingface.co/posts/Bils/313728910739163</link><description>create amazing audio ads in just a few steps Bils/AIPromoStudio See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Bils/313728910739163</guid></item><item><title>üìä Introducing "Hugging Face Dataset Spotlight" üìä</title><link>https://huggingface.co/posts/davanstrien/119757489156561</link><description>üìä Introducing "Hugging Face Dataset Spotlight" üìä I'm excited to share the first episode of our AI-generated podcast series focusing on nice datasets from the Hugging Face Hub! This first episode explores mathematical reasoning datasets: - SynthLabsAI/Big-Math-RL-Verified : Over 250,000 rigorously verified problems spanning multiple difficulty levels and mathematical domains - open-r1/OpenR1-Math-220k : 220,000 math problems with multiple reasoning traces, verified for accuracy using Math Verify and Llama-3.3-70B models. - facebook/natural_reasoning : 1.1 million general reasoning questions carefully deduplicated and decontaminated from existing benchmarks, showing superior scaling effects when training models like Llama3.1-8B-Instruct. Plus a bonus segment on bespokelabs/bespoke-manim ! https://www.youtube.com/watch?v=-TgmRq45tW4 See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/davanstrien/119757489156561</guid></item><item><title>9 types of "Chain-of-..." approaches:</title><link>https://huggingface.co/posts/Kseniase/433849056207490</link><description>9 types of "Chain-of-..." approaches: Chain-of-Thought (CoT) prompting enhances reasoning in AI models by breaking down complex problems into step-by-step logical sequences. It continues proving its effectiveness, especially in top-performing reasoning models. However, there are other similar methods, that expand CoT and can be used for different purposes. Here are 9 of them: 1. Chain-of-Action-Thought (COAT) -&gt; Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search (2502.02508) Helps model decide when to keep thinking, double-check their work, or try a different approach, using special guiding tokens. 2. Chain of Draft (CoD) -&gt; Chain of Draft: Thinking Faster by Writing Less (2502.18600) It helps model generate short but meaningful reasoning steps, cutting costs and making processing faster 3. Chain-of-Agents -&gt; Chain of Agents: Large Language Models Collaborating on Long-Context Tasks (2406.02818) Uses multi-agent...</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/433849056207490</guid></item><item><title>We're using RLHF on diffusion models, right? Just making sure..</title><link>https://huggingface.co/posts/nroggendorff/209736816535732</link><description>We're using RLHF on diffusion models, right? Just making sure.. See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/209736816535732</guid></item><item><title>üìö Historical Russian Technical Journal Images Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/326966093381385</link><description>üìö Historical Russian Technical Journal Images Dataset - nyuuzyou/journals –°ollection of digitized pages from vintage Russian technical journals featuring: - 7.47k high-quality images - Machine-generated descriptions in Russian - Valuable historical technical content for image-to-text applications Content descriptions are dedicated to the public domain under the CC0 1.0 license, allowing unrestricted use without attribution. See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/326966093381385</guid></item><item><title>What if AI becomes as ubiquitous as the internet, but runs locally and transparently on our devices?</title><link>https://huggingface.co/posts/fdaudens/113970261627099</link><description>What if AI becomes as ubiquitous as the internet, but runs locally and transparently on our devices? Fascinating TED talk by @ thomwolf on open source AI and its future impact. Imagine this for AI: instead of black box models running in distant data centers, we get transparent AI that runs locally on our phones and laptops, often without needing internet access. If the original team moves on? No problem - resilience is one of the beauties of open source. Anyone (companies, collectives, or individuals) can adapt and fix these models. This is a compelling vision of AI's future that solves many of today's concerns around AI transparency and centralized control. Watch the full talk here: https://www.ted.com/talks/thomas_wolf_what_if_ai_just_works See translation</description><pubDate>Sun, 02 Mar 2025 17:16:54 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/113970261627099</guid></item></channel></rss>