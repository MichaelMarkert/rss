<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>🔥 Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities 🚀</title><link>https://huggingface.co/posts/openfree/174131256400578</link><description>🔥 Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities 🚀 openfree/qwen3-30b-a3b-research openfree/qwen3-235b-a22b-research Hello AI researchers! 👋 Today I'm introducing a powerful chatbot implementation with real-time web search capabilities. ✨ Key Features 🧠 Chatbot based on qwen3-30b-a3b and llama4-maverick models 🔍 LLM-based optimal keyword extraction 🌐 Real-time web search using SerpHouse API 💬 Streaming responses for natural conversation experience 🛠️ Technology Stack Gradio: Implementation of intuitive web interface Fireworks.ai API: Access to high-performance LLM models SerpHouse API: Collection of real-time search results 🌟 Application Areas Question answering systems requiring up-to-date information Providing current information beyond training data Delivering reliable information with accurate sources Add real-time search capabilities to your AI applications with this project! 🎉 Leave your questions or suggestions in the comments! Let's...</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/174131256400578</guid></item><item><title>🔮 Mistral Perflexity AI - Local LLM Space with Web Search Capabilities 🌐</title><link>https://huggingface.co/posts/ginipick/917789522887291</link><description>🔮 Mistral Perflexity AI - Local LLM Space with Web Search Capabilities 🌐 Hello AI enthusiasts! Today I'm excited to introduce my special Hugging Face space! 🚀 ginigen/Mistral-Perflexity ✨ Key Features Powerful Model: Using Private-BitSix-Mistral-Small-3.1-24B-Instruct-2503, optimized through 6-bit quantization to run smoothly on local 4090 GPUs! 💪 Web Search Integration: Leveraging the Brave Search API to provide real-time web search results for user queries! 🔍 Customizable Responses: Shape AI personality and response format through system messages ⚙️ Multilingual Support: Perfect handling of both English and Korean! 🇺🇸🇰🇷 🛠️ Technical Highlights GGUF Format: Optimized quantized model with excellent memory efficiency Flash Attention: Applied optimization technology for faster inference speeds 8K Context Window: Capable of handling lengthy conversations and complex queries Streaming Responses: Watch text being generated in real-time 💡 Use Cases Complex Q&amp;A requiring real-time...</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/917789522887291</guid></item><item><title>VisionScout — Now with Scene Understanding! 🚀</title><link>https://huggingface.co/posts/DawnC/822045713383062</link><description>VisionScout — Now with Scene Understanding! 🚀 I'm excited to share a major update to VisionScout, my interactive vision tool that combines powerful object detection with emerging scene understanding capabilities! 👀🔍 What can VisionScout do today? 🖼️ Upload any image and detect 80 object types using YOLOv8. 🔄 Instantly switch between Nano, Medium, and XLarge models depending on speed vs. accuracy needs. 🎯 Filter specific classes (people, vehicles, animals, etc.) to focus only on what matters to you. 📊 View detailed statistics on detected objects, confidence levels, and spatial distribution. ⭐️ NEW: Scene understanding layer now added! - Automatically interprets the scene based on detected objects. - Uses a combination of rule-based reasoning and CLIP-powered semantic validation. - Outputs descriptions, possible activities, and even safety concerns. What’s coming next? 🔎 Expanding YOLO’s object categories. 🎥 Adding video processing and multi-frame object tracking. ⚡ Faster real-time...</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/822045713383062</guid></item><item><title>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me!</title><link>https://huggingface.co/posts/fdaudens/694548457778636</link><description>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me! Just tested it with Steve Jobs' Stanford speech and was speechless (pun intended). The video isn’t sped up. 3 things that floored me: - Transcription took just 10 seconds for a 15-min file - Got a CSV with perfect timestamps, punctuation &amp; capitalization - Stunning accuracy (correctly captured "Reed College" and other specifics) NVIDIA also released a demo where you can click any transcribed segment to play it instantly. The improvement is significant: number 1 on the ASR Leaderboard, 6% error rate (best in class) with complete commercial freedom (cc-by-4.0 license). Time to update those Whisper pipelines! H/t @ Steveeeeeeen for the finding! Model: nvidia/parakeet-tdt-0.6b-v2 Demo: nvidia/parakeet-tdt-0.6b-v2 ASR Leaderboard: hf-audio/open_asr_leaderboard See translation</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/694548457778636</guid></item><item><title>10 new Chain-of-Thoughts (CoT) methods</title><link>https://huggingface.co/posts/Kseniase/864305548620639</link><description>10 new Chain-of-Thoughts (CoT) methods CoT has long been one of the hottest techniques in AI thanks to its effectiveness and compelling core idea: encouraging models to solve complex problems through explicit intermediate reasoning steps. But usually researchers modify original CoT approach, finding tips that further improve LLMs' reasoning. That's what we're going to talk about today. Here's a list of 10 latest enhanced CoT approaches: 1. Chain-of-Defensive-Thought -&gt; Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption (2504.20769) Provides a few structured, defensive reasoning exemplars to improve the robustness of LLMs 2. Hybrid-CoT -&gt; AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization (2504.21659) Proposes using Adaptive Hybrid Reasoning Model (AdaR1) that combines Long- and Short-CoT, and applying bi-level preference training to select effective reasoning styles 3. Semantic-level...</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/864305548620639</guid></item><item><title>Our ICEdit's video is below~</title><link>https://huggingface.co/posts/sanaka87/102647382067427</link><description>Our ICEdit's video is below~ 🔥 🔥🔥Huggingface DEMO: RiverZ/ICEdit 🌐 Project Website: https://river-zhang.github.io/ICEdit-gh-pages/ 🏠 GitHub Repository: https://github.com/River-Zhang/ICEdit/blob/main/scripts/gradio_demo.py 🤗 Huggingface: sanaka87/ICEdit-MoE-LoRA 📄 arxiv Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) See translation</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sanaka87/102647382067427</guid></item><item><title>🚀 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer～</title><link>https://huggingface.co/posts/RiverZ/535015681556179</link><description>🚀 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer～ 🎨 Daily Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) 🔓 Code is now open source! 🔥 Huggingface DEMO: RiverZ/ICEdit 🌐 Project Website: https://river-zhang.github.io/ICEdit-gh-pages/ 🏠 GitHub Repository: https://github.com/River-Zhang/ICEdit/blob/main/scripts/gradio_demo.py 🤗 Huggingface: sanaka87/ICEdit-MoE-LoRA 📄 arxiv Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) 🔥 Why it’s cool: - Achieves high-quality, multi-task image editing. - Uses only 1% of the training parameters and 0.1% of the training data compared to existing methods — extremely efficient - Beats several commercial models on background preservation, ID control, and consistency - Open-...</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/RiverZ/535015681556179</guid></item><item><title>FinSightX: Your AI Financial Co-Pilot</title><link>https://huggingface.co/posts/Raahulthakur/638579217973846</link><description>FinSightX: Your AI Financial Co-Pilot FinSightX is a multi-agent financial assistant powered by language models. Designed for analysts, investors, and fintech developers, it combines insights from multiple domains into a single, sleek Streamlit interface. Features Equity Analyst Agent → Ask questions about stocks, indicators, performance. Macro Strategist Agent → Get macroeconomic insights using language models. News Summarizer Agent → Summarizes market headlines instantly. Quant Backtester Agent → Run basic backtests using bt. Regulatory Radar Agent → Monitor policy shifts and alerts. Client Advisor Agent → Assist with client queries or hypothetical portfolios. Tech Stack transformers, sentence-transformers torch, scikit-learn, neuralprophet bt for strategy backtesting chromadb for vector storage Streamlit + FastAPI for UI/backend Developed and maintained by @ Raahul-Thakur Live Space: Raahulthakur/FinsightX Built using open-source tools and financial domain knowledge....</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Raahulthakur/638579217973846</guid></item><item><title>HELLO GUYS 🚀 Just released my first MCP: VUDA – Visual UI Debug Agent</title><link>https://huggingface.co/posts/samihalawa/966135943196710</link><description>HELLO GUYS 🚀 Just released my first MCP: VUDA – Visual UI Debug Agent Ever been stuck debugging buttons that don’t work? Broken flows? Inconsistent UI behavior? VUDA sees it, clicks it, fixes it. An automated visual debug agent that inspects, validates, and repairs your UI — like magic 🧠✨ Better that any other playwright / puppeteer. 🔧 Install now via Smithery: npx -y @ smithery /cli@latest install @ samihalawa /visual-ui-debug-agent-mcp --client cursor ⸻ Want a shorter alt for social media too? See translation</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/samihalawa/966135943196710</guid></item><item><title>Just published a tutorial that shows how to properly install ComfyUI, SwarmUI, use installed ComfyUI as a backend in SwarmUI with absolutely maximum best performance such as out of the box Sage Attention, Flash Attention, RTX 5000 Series support and more. Also how to upscale images with max quality</title><link>https://huggingface.co/posts/MonsterMMORPG/846082369642024</link><description>Just published a tutorial that shows how to properly install ComfyUI, SwarmUI, use installed ComfyUI as a backend in SwarmUI with absolutely maximum best performance such as out of the box Sage Attention, Flash Attention, RTX 5000 Series support and more. Also how to upscale images with max quality Tutorial Link https://youtu.be/fTzlQ0tjxj0 Tutorial Information If you want to generate the very best AI videos and images on your Windows computer locally this is the tutorial that you were looking for. Literally 1-click to install most powerful and advanced generative AI interface SwarmUI (with Flash Attention, Sage Attention, Triton, DeepSpeed, xFormers, RTX 5000 series perfect compatibility) and download the very best AI image and video generation models with ultra advanced model downloader Gradio app. SwarmUI utilizes the famous and most powerful, advanced, performant and optimized ComfyUI as a backend. So SwarmUI is the ultimate generative AI tool at the moment with vast amount of...</description><pubDate>Mon, 05 May 2025 09:25:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/846082369642024</guid></item></channel></rss>