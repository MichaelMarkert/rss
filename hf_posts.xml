<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.🧪</title><link>https://huggingface.co/posts/prithivMLmods/284574267701705</link><description>Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.🧪 🤗 Space/App: prithivMLmods/Tiny-VLMs-Lab ✦︎ Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. ✦︎ Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 ✦︎ GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or...</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/284574267701705</guid></item><item><title>When you ask ChatGPT, Claude, or Gemini a really tough question,</title><link>https://huggingface.co/posts/RakshitAralimatti/207934490136479</link><description>When you ask ChatGPT, Claude, or Gemini a really tough question, you might notice that little "thinking..." moment before it answers. But what does it actually mean when an LLM is “thinking”? Imagine a chess player pausing before their next move not because they don’t know how to play, but because they’re running through possibilities, weighing options, and choosing the best one. LLMs do something similar… except they’re not really thinking like us. Here’s the surprising part :- You might think these reasoning skills come from futuristic architectures or alien neural networks. In reality, most reasoning LLMs still use the same transformer decoder-only architecture as other models The real magic? It’s in how they’re trained and what data they learn from. Can AI actually think, or is it just insanely good at faking it? I broke it down in a simple, 4-minute Medium read. Bet you’ll walk away with at least one “aha!” moment. 🚀 Read here - https://lnkd.in/edZ8Ceyg See translation</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/RakshitAralimatti/207934490136479</guid></item><item><title>Qwen's latest Image Edit model has been implemented with lightx2v's LoRA for 8-step lightning fast inferencing. Still a WIP, so YMMV.</title><link>https://huggingface.co/posts/LPX55/307818881554669</link><description>Qwen's latest Image Edit model has been implemented with lightx2v's LoRA for 8-step lightning fast inferencing. Still a WIP, so YMMV. https://huggingface.co/spaces/LPX55/Qwen-Image-Edit-Lightning-Fast See translation</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/LPX55/307818881554669</guid></item><item><title>✨ HairPick | Preview Your Perfect Hair Transformation in 360° ✨</title><link>https://huggingface.co/posts/ginipick/955296677233221</link><description>✨ HairPick | Preview Your Perfect Hair Transformation in 360° ✨ 🎊 Free Trial for Hugging Face Launch! Hurry! ⏰ Hello! Introducing an innovative AI service that helps you choose the perfect hairstyle without any regrets before visiting the salon! 🎯 Try It Now ginigen/Hair-Pick 🔄 What Makes HairPick Special? 360° Complete Preview! Other hair simulators only show the front view? 😑 HairPick is different! ✅ Front + 4 random angles = Total 5 multi-angle images generated ✅ Perfect check from side profile 👤 diagonal 📐 back view 👥! ✅ 100+ trendy hairstyle library 💇‍♀️ 💡 Highly Recommended For: 🎯 "I really don't want to fail this time!" → Check side volume and back lines thoroughly 🎯 "It's hard to explain exactly to my stylist" → Perfect communication with 360° result images! 🎯 "I have a profile photo/photoshoot coming up" → Preview your best look from every angle 🚀 Super Simple Usage (Just 1 Minute!) 1️⃣ One Selfie 📸 Take a front-facing photo in bright light (show your forehead and face...</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/955296677233221</guid></item><item><title>benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :(</title><link>https://huggingface.co/posts/etemiz/891816438009932</link><description>benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :( See translation</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/891816438009932</guid></item><item><title>Added plug-and-play support for Qwen Image LoRA!  🤗⚡</title><link>https://huggingface.co/posts/prithivMLmods/366249407896156</link><description>Added plug-and-play support for Qwen Image LoRA! 🤗⚡ Try it here: ✦︎ Qwen-Image (with LoRA): prithivMLmods/Qwen-Image-Diffusion ✦︎ Collection: prithivMLmods/image-gen-apps-diffusion-lastupdated-08-18-68a2f4c5ef3e5e394eacc20a See translation</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/366249407896156</guid></item><item><title>🤖 AI-Generated 6-Nation Military Simulator in a Single HTML File</title><link>https://huggingface.co/posts/openfree/413087646131051</link><description>🤖 AI-Generated 6-Nation Military Simulator in a Single HTML File 🚀 Project Highlight A full-scale military strategy simulator that runs in a single HTML file! This AI-generated wargame implements real military equipment and tactical doctrines from 6 nations (🇰🇷,🇰🇵,🇺🇸,🇷🇺,🇺🇦,🇨🇳) using pure JavaScript only, without any external libraries. openfree/WAR-Game-Simul 💡 Amazing Achievement of AI Auto-Generation 📁 Single File Magic One-Click Launch: Just open the HTML file and play instantly Zero Dependencies: No npm, webpack, or external libraries Pure Vanilla JS: Implemented with Canvas API only, no frameworks All-in-One: Rendering, physics engine, AI, and UI in a single file 🎮 Advanced Features AI Implemented ✅ Perlin Noise terrain generation algorithm ✅ Marching Squares contour rendering ✅ Lanchester combat equations ✅ A* pathfinding algorithm ✅ Real-time Line of Sight (LOS) calculations ✅ 40-second battlefield sound loop 🎖️ Implemented Military Systems 🔥 Real Weapon Systems from 6...</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/413087646131051</guid></item><item><title>Want to quickly try Gemma 3 270m? 💎💬</title><link>https://huggingface.co/posts/anakin87/751707976654130</link><description>Want to quickly try Gemma 3 270m? 💎💬 I made a simple Space to do that: anakin87/gemma-3-270m-it ⚡ Fast: Flash Attention, Zero GPU ⚙️ Configurable See translation</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/anakin87/751707976654130</guid></item><item><title>Image-to-Prompt⚡</title><link>https://huggingface.co/posts/ovi054/657358125503535</link><description>Image-to-Prompt⚡ ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 👉 Try it now: ovi054/image-to-prompt See translation</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/657358125503535</guid></item><item><title>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.</title><link>https://huggingface.co/posts/etemiz/710778843328598</link><description>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really "free": they are costing you your freedom if you know what i mean. See translation</description><pubDate>Tue, 19 Aug 2025 13:33:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/710778843328598</guid></item></channel></rss>