<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™</title><link>https://huggingface.co/posts/prithivMLmods/223082724733311</link><description>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™ ‚óè Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC ‚óè Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection ‚óè Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo ‚óè Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- ‚óè FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 ‚óè FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC ‚óè Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC ‚óè Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast ‚óè Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/223082724733311</guid></item><item><title>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! üî•</title><link>https://huggingface.co/posts/danielhanchen/963278821580490</link><description>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! üî• Has 1M context window &amp; best in class performance for SWE-Bench, reasoning &amp; chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF üíö Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/963278821580490</guid></item><item><title>Great News !</title><link>https://huggingface.co/posts/Reubencf/239576255947718</link><description>Great News ! Reubencf/Nano_Banana_Editor Now supports black-forest-labs/FLUX.1-Kontext-dev and Qwen/Qwen-Image-Edit-2509 Just log in with Huggingface and try it out See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reubencf/239576255947718</guid></item><item><title>ü§Ø ü§Ø Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ü§Ø ü§Ø</title><link>https://huggingface.co/posts/YatharthS/190514854652270</link><description>ü§Ø ü§Ø Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! ü§Ø ü§Ø Github link: https://github.com/ysharma3501/MiraTTS Model link: https://github.com/ysharma3501/MiraTTS Blog explaining llm tts models: https://huggingface.co/blog/YatharthS/llm-tts-models See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/190514854652270</guid></item><item><title>Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on.</title><link>https://huggingface.co/posts/ronantakizawa/412513789590360</link><description>Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on. #github #developers ronantakizawa/github-top-developers See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/412513789590360</guid></item><item><title>New Preview Model:</title><link>https://huggingface.co/posts/unmodeled-tyler/439099944779481</link><description>New Preview Model: unmodeled-tyler/vanta-research-loux-preview VANTA Research is excited to announce a small lab preview of our new 675B fine tune, Loux-Large. Loux is an AI model with a sophisticated, rebellious edge designed to assist and collaborate with engineers, builders, and people working on technical projects. If you enjoy working with Loux and would like full access, let us know by liking the space or opening a discussion in the community! See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/439099944779481</guid></item><item><title>üö® Phare LLM benchmark V2: Reasoning models don't guarantee better security</title><link>https://huggingface.co/posts/davidberenstein1957/505419805971375</link><description>üö® Phare LLM benchmark V2: Reasoning models don't guarantee better security Read the full blog here: https://huggingface.co/blog/davidberenstein1957/phare-llm-benchmark-v2 See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/davidberenstein1957/505419805971375</guid></item><item><title>Finch üí∞ an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance &amp; accounting work.</title><link>https://huggingface.co/posts/AdinaY/236108821864145</link><description>Finch üí∞ an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance &amp; accounting work. FinWorkBench/Finch ‚ú® Built from real enterprise data (Enron + financial institutions), not synthetic tasks ‚ú® Tests end-to-end finance workflows ‚ú® Multimodal &amp; cross-file reasoning ‚ú® Expert annotated (700+ hours) and genuinely challenging hard See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/236108821864145</guid></item><item><title>Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models üî•</title><link>https://huggingface.co/posts/victor/750233862472141</link><description>Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models üî• https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe See translation</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/victor/750233862472141</guid></item><item><title>üçì One of the coolest parts about being an early Strawberry user has been the opportunity to build on the app at the ground floor.</title><link>https://huggingface.co/posts/ZennyKenny/672558817086708</link><description>üçì One of the coolest parts about being an early Strawberry user has been the opportunity to build on the app at the ground floor. The platform already has a ton of great integrations that let you interact with your external apps directly with tools, but I wanted to add the ability to do stuff in Slack as well. üí™ So I took the base Anthropic Slack MCP server, added a whole bunch of new tools, and generalized it as an HTTP-based SSE-server and deployed it in like 2 minutes with Railway so that Strawberry could make use of it (as can Claude or any other MCP client). Now, you can Chat with your Strawberry Companion (or Claude, or whatever) and do things like: ‚û°Ô∏è Get caught up across all of your Slack channels after a long weekend or noisy incident without having to read 20 threads in 10 different channels ‚û°Ô∏è Create, read, and edit Canvases, Messages, and Channels ‚û°Ô∏è Take any resources or content that you're using in your Chat and inject it directly into Slack without copy / paste üòé I'm...</description><pubDate>Thu, 18 Dec 2025 13:39:37 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/672558817086708</guid></item></channel></rss>