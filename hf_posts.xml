<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>üöÄ Gemma3-R1984-27B: Next Generation Agentic AI Platform</title><link>https://huggingface.co/posts/openfree/214646053127729</link><description>üöÄ Gemma3-R1984-27B: Next Generation Agentic AI Platform Model Path: VIDraft/Gemma-3-R1984-27B Space: VIDraft/Gemma-3-R1984-27B git clone VIDraft/Gemma-3-R1984-27B üí´ A New Frontier in AI Innovation Gemma3-R1984-27B is a powerful agentic AI platform built on Google's Gemma-3-27B model. It integrates state-of-the-art deep research via web search with multimodal file processing capabilities and handles long contexts up to 8,000 tokens. Designed for local deployment on independent servers using NVIDIA A100 GPUs, it provides high security and prevents data leakage. üîì Uncensored and Unrestricted AI Experience Gemma3-R1984-27B comes with all censorship restrictions removed, allowing users to operate any persona without limitations. The model perfectly implements various roles and characters according to users' creative requests, providing unrestricted responses that transcend the boundaries of conventional AI. This unlimited interaction opens infinite possibilities across research, creative...</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/214646053127729</guid></item><item><title>üß† PROMPT FOR CONVERTING ANY MODEL IN REASONING "THINKING" MODELüî•ü§ñ</title><link>https://huggingface.co/posts/luigi12345/612317420621834</link><description>üß† PROMPT FOR CONVERTING ANY MODEL IN REASONING "THINKING" MODELüî•ü§ñ Convert any model to Deepseek R1 like "thinking" model. üí≠ You 're now a thinking-first LLM. For all inputs: 1 . Start with &lt;thinking&gt; - Break down problems step - by - step - Consider multiple approaches - Calculate carefully - Identify errors - Evaluate critically - Explore edge cases - Check knowledge accuracy - Cite sources when possible 2 . End with &lt;/thinking&gt; 3 . Then respond clearly based on your thinking. The &lt;thinking&gt; section is invisible to users and helps you produce better answers. For math: show all work and verify For coding: reason through logic and test edge cases For facts: verify information and consider reliability For creative tasks: explore options before deciding For analysis: examine multiple interpretations Example: &lt;thinking&gt; [ Step - by - step analysis] [Multiple perspectives] [Self-critique] [Final conclusion] &lt;/thinking&gt; [Clear, concise response to user] See translation</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/luigi12345/612317420621834</guid></item><item><title>üöÄ First Benchmark of</title><link>https://huggingface.co/posts/jasoncorkill/659246791111385</link><description>üöÄ First Benchmark of @ OpenAI 's 4o Image Generation Model! We've just completed the first-ever (to our knowledge) benchmarking of the new OpenAI 4o image generation model, and the results are impressive! In our tests, OpenAI 4o image generation absolutely crushed leading competitors, including @ black-forest-labs , @ google , @ xai-org , Ideogram, Recraft, and @ deepseek-ai , in prompt alignment and coherence! They hold a gap of more than 20% to the nearest competitor in terms of Bradley-Terry score, the biggest we have seen since the beginning of the benchmark! The benchmarks are based on 200k human responses collected through our API. However, the most challenging part wasn't the benchmarking itself, but generating and downloading the images: - 5 hours to generate 1000 images (no API available yet) - Just 10 minutes to set up and launch the benchmark - Over 200,000 responses rapidly collected While generating the images, we faced some hurdles that meant that we had to leave out...</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jasoncorkill/659246791111385</guid></item><item><title>This is truly an inspirational story please help us spread the word,</title><link>https://huggingface.co/posts/giux78/831597804891353</link><description>This is truly an inspirational story please help us spread the word, @ clem , @ thomwolf and everyone who supports open source AI. A few weeks ago, @ mmuffo94 and @ cittiberto from indigo_ai launched the Chatbot Arena for the Italian language: https://indigo.ai/it/chatbot-arena-italia/ . To our surprise, among the top-ranked models is mii-llm/maestrale-chat-v0.4-beta a carefully fine-tuned version of mistralai/Mistral-7B-v0.1 , developed by @ efederici and @ mferraretto from https://huggingface.co/mii-llm , and released nearly a year ago. At this very moment, as shown in the screenshot, mii-llm/maestrale-chat-v0.4-beta is ranked 8th right between ChatGPT-4.5 and ChatGPT-4o. It's likely that for several months, the best Italian speaking LLM has been an open source 7B model created by open source contributors and hardly anyone knew it. See translation</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/giux78/831597804891353</guid></item><item><title>What happens when you combine the Chain of Thought (CoT) reasoning capabilities of LLMs with a heuristic-guided tree search algorithm? In the Tree of Thoughts (ToT) paper, the authors (Yao et al.) have coupled GPT-4 with tree search algorithms to attack a few tasks on which left-to-right CoT struggles. And the results are impressive. For example, on the "Game of 24" task, while GPT-4 with CoT prompting only managed to solve 4% of tasks, ToT achieved a success rate of 74%.</title><link>https://huggingface.co/posts/sadhaklal/924148356658805</link><description>What happens when you combine the Chain of Thought (CoT) reasoning capabilities of LLMs with a heuristic-guided tree search algorithm? In the Tree of Thoughts (ToT) paper, the authors (Yao et al.) have coupled GPT-4 with tree search algorithms to attack a few tasks on which left-to-right CoT struggles. And the results are impressive. For example, on the "Game of 24" task, while GPT-4 with CoT prompting only managed to solve 4% of tasks, ToT achieved a success rate of 74%. I've written a blog post that makes the ToT paper easy to understand and implement by taking you through all the details in a step-by-step manner: https://huggingface.co/blog/sadhaklal/tree-of-thoughts If you are interested in the topics of algorithmic AI, tree search, reasoning, planning, or "System 2" thinking, then you may find this blog post useful. See translation</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sadhaklal/924148356658805</guid></item><item><title>üî• It's out! We published the dataset for our evaluation of</title><link>https://huggingface.co/posts/jasoncorkill/503307901294516</link><description>üî• It's out! We published the dataset for our evaluation of @ OpenAI 's new 4o image generation model. Rapidata/OpenAI-4o_t2i_human_preference Yesterday we published the first large evaluation of the new model, showing that it absolutely leaves the competition in the dust. We have now made the results and data available here! Please check it out and ‚ù§Ô∏è ! See translation</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jasoncorkill/503307901294516</guid></item><item><title>üî• ULTRA VIDEO COMPRESSION (300MB ‚Üí 3MB!)</title><link>https://huggingface.co/posts/luigi12345/403914274386316</link><description>üî• ULTRA VIDEO COMPRESSION (300MB ‚Üí 3MB!) ffmpeg - i input .mp4 -vcodec libx264 -crf 28 -vf "pad=ceil(iw/2)*2:ceil(ih/2)*2" -y output.mp4 -i ‚Üí Input ‚ö°Ô∏è -vcodec libx264 ‚Üí H.264 codec ‚ö°Ô∏è -crf 28 ‚Üí Compression (lower = better quality) ‚ö°Ô∏è-vf pad=... ‚Üí Even dimensions ‚ö°Ô∏è -y ‚Üí Overwrite See translation</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/luigi12345/403914274386316</guid></item><item><title>Very interesting security section by</title><link>https://huggingface.co/posts/clem/920824763998544</link><description>Very interesting security section by @ yjernite @ lvwerra @ reach-vb @ dvilasuero &amp; the team replicating R1. Broadly applicable to most open-source models &amp; some to APIs (but APIs have a lot more additional risks because you're not in control of the underlying system): https://huggingface.co/blog/open-r1/update-4#is-it-safe See translation</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/920824763998544</guid></item><item><title>did a small emotive classified test dataset for all the tts tuners out there</title><link>https://huggingface.co/posts/MrDragonFox/457878757157673</link><description>did a small emotive classified test dataset for all the tts tuners out there MrDragonFox/Elise 3h total mit - single speaker voice dataset is a copy of an existing one just added the emotional tags over 1200 samples - should be good enough to test if emotional tags stick in your finetune See translation</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MrDragonFox/457878757157673</guid></item><item><title>Want to ramp up your AI skills and start breaking bigger stories? With the Journalists on Hugging Face community, we're launching our first learn-together course!</title><link>https://huggingface.co/posts/fdaudens/253707357021654</link><description>Want to ramp up your AI skills and start breaking bigger stories? With the Journalists on Hugging Face community, we're launching our first learn-together course! We'll build AI classifiers that process months of data in minutes. How? - Work through an interactive version of an excellent course developed by Ben Welsh and Derek Willis - Share findings and get help in our dedicated community channel - Build working classifiers you can use in your reporting today No coding background needed - if you can write a ChatGPT or Claude prompt, you can do this. Journalists are already using these techniques to break stories, from uncovering hidden real estate deals to tracking unusual campaign spending. Join us‚Äîit might give you your next big story! Thanks to Ben and Derek for letting me adapt their excellent course into this interactive version! - Check out the course: JournalistsonHF/first-llm-classifier - Join our Slack community to learn together:...</description><pubDate>Sat, 29 Mar 2025 05:19:50 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/253707357021654</guid></item></channel></rss>