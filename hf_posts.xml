<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>13 Outstanding MCP Servers</title><link>https://huggingface.co/posts/Kseniase/251572743842280</link><description>13 Outstanding MCP Servers MCP is redefining how AI assistants connect to the world of data and tools, so no wonder MCP servers are in high demand now. That’s why we’ve curated 13 cool MCP servers to upgrade your workflow: 1. Hugging Face Official MCP Server -&gt; https://github.com/evalstate/hf-mcp-server Provides an access and interaction with Hugging Face models, datasets, and Gradio Spaces for dynamic tool integration and configuration across environments. 2. Browser MCP -&gt; https://browsermcp.io/ An MCP server +Chrome extension. It allows to automate your browser with AI apps like VS Code, Claude, Cursor, and Windsurf. 3. Bright Data MCP -&gt; https://github.com/brightdata/brightdata-mcp This one is for working with data in real-time: searching the web, navigating websites, taking action and retrieving data. 4. JSON MCP -&gt; https://github.com/VadimNastoyashchy/json-mcp Interact with JSON files: split, merge, find specific data, and validate content within them. 5. Octagon Deep Research...</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/251572743842280</guid></item><item><title>**Build Claude Code from Scratch Together**</title><link>https://huggingface.co/posts/YerbaPage/620116280773759</link><description>**Build Claude Code from Scratch Together** I'm building a minimal, open-source AI agent that runs in the terminal to help with programming tasks. Think of a simplified, from-scratch version of the Claude Code agent 💻. You can check out the basic framework I've already started here: [github.com/YerbaPage/Terminal-Agent]( https://github.com/YerbaPage/Terminal-Agent ) 🔥 To be clear, the goal isn't to create a perfect, commercial-grade tool. This is a for-fun project geared towards research and exploration. The main idea is to build a **flexible and minimal framework** that helps us understand the modules and functionalities of sophisticated agents like Claude Code. It's a playground to explore how we can enable agents to handle more complex tasks effectively. I'm looking for a few people who'd be interested in exploring this together. We could experiment with ideas like adding a to-do list manager to improve planning or finding better ways for the agent to manage its memory like some...</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/620116280773759</guid></item><item><title>Hey all</title><link>https://huggingface.co/posts/zamal/249688504470467</link><description>Hey all Finally it's happening. DeepGit lite is back now, running on cpu only devices. Just smartly search across Github and spin up conversational agents in the background and have grounded conversation with repositories Try it out now!!!! zamal/DeepGit See translation</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/zamal/249688504470467</guid></item><item><title>🧠 MathX-5M by XenArcAI — Scalable Math Reasoning for Smarter LLMs</title><link>https://huggingface.co/posts/Parveshiiii/373499845630863</link><description>🧠 MathX-5M by XenArcAI — Scalable Math Reasoning for Smarter LLMs Introducing MathX-5M, a high-quality, instruction-tuned dataset built to supercharge mathematical reasoning in large language models. With 5 million rigorously filtered examples, it spans everything from basic arithmetic to advanced calculus—curated from public sources and enhanced with synthetic data. 🔍 Key Highlights: - Step-by-step reasoning with verified answers - Covers algebra, geometry, calculus, logic, and more - RL-validated correctness and multi-stage filtering - Ideal for fine-tuning, benchmarking, and educational AI 📂 - XenArcAI/MathX-5M See translation</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Parveshiiii/373499845630863</guid></item><item><title>Transformers are getting old! It’s been 8 whole years since the architecture that powers almost all language models.</title><link>https://huggingface.co/posts/ProCreations/317763668973922</link><description>Transformers are getting old! It’s been 8 whole years since the architecture that powers almost all language models. Read here for newer alternatives and variants of transformers: https://huggingface.co/blog/ProCreations/transformers-are-getting-old See translation</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ProCreations/317763668973922</guid></item><item><title>Layer-wise and Pruned versions of cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition</title><link>https://huggingface.co/posts/eaddario/837008676792926</link><description>Layer-wise and Pruned versions of cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition * Tesor-wise: eaddario/Dolphin-Mistral-24B-Venice-Edition-GGUF * Pruned: eaddario/Dolphin-Mistral-24B-Venice-Edition-pruned-GGUF Summary in the model's card and test results in the ./scores directory. Questions/feedback is always welcomed. See translation</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eaddario/837008676792926</guid></item><item><title>Is 100% Pass Rate on HumanEval possible? Yes! ✅</title><link>https://huggingface.co/posts/YerbaPage/727846915147423</link><description>Is 100% Pass Rate on HumanEval possible? Yes! ✅ Meet MGDebugger if you are tired of LLMs failing on complex bugs 🤔 Our MGDebugger, just hit 100% accuracy on HumanEval using the DeepSeek-R1 model. 🚀 ✨ Demo: learnmlf/MGDebugger 📝 Paper: From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging (2410.01215) 💻 Code: https://github.com/YerbaPage/MGDebugger HumanEval may be retired, we're ready for the next challenge In more complex scenarios! You may also take look at this repo for a collection of awesome repo-level coding tasks! 🖥️ https://github.com/YerbaPage/Awesome-Repo-Level-Code-Generation See translation</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/727846915147423</guid></item><item><title>🚀 We just released the WASM Agent Blueprint!</title><link>https://huggingface.co/posts/stefan-french/381121888136998</link><description>🚀 We just released the WASM Agent Blueprint! It shows how to run Python-based AI agents directly in your browser using WebAssembly (WASM) via Pyodide and the OpenAI Agents SDK. There are no installs, it runs straight in your browser. Try it out and explore the code 👉 https://github.com/mozilla-ai/wasm-agents-blueprint See translation</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/stefan-french/381121888136998</guid></item><item><title>𝗚𝗿𝗮𝗱𝗶𝗼 𝗔𝗴𝗲𝗻𝘁𝘀 &amp; 𝗠𝗖𝗣 𝗛𝗮𝗰𝗸𝗮𝘁𝗵𝗼𝗻 - 𝗙𝗶𝗻𝗮𝗹 𝗗𝗮𝘆</title><link>https://huggingface.co/posts/azettl/767271507427519</link><description>𝗚𝗿𝗮𝗱𝗶𝗼 𝗔𝗴𝗲𝗻𝘁𝘀 &amp; 𝗠𝗖𝗣 𝗛𝗮𝗰𝗸𝗮𝘁𝗵𝗼𝗻 - 𝗙𝗶𝗻𝗮𝗹 𝗗𝗮𝘆 Submission deadline is in 10 minutes, so here's where Consilium ended up after a week of building. What started as a simple idea, "𝘞𝘩𝘢𝘵 𝘪𝘧 𝘮𝘶𝘭𝘵𝘪𝘱𝘭𝘦 𝘈𝘐 𝘮𝘰𝘥𝘦𝘭𝘴 𝘤𝘰𝘶𝘭𝘥 𝘥𝘪𝘴𝘤𝘶𝘴𝘴 𝘢𝘯𝘥 𝘳𝘦𝘢𝘤𝘩 𝘤𝘰𝘯𝘴𝘦𝘯𝘴𝘶𝘴?" turned into a full multi-AI expert platform with live research integration. 𝗙𝗶𝗻𝗮𝗹 𝗳𝗲𝗮𝘁𝘂𝗿𝗲𝘀: - Custom Gradio roundtable component with real-time speech bubbles - MCP server mode - Multiple AI models: Mistral Large, DeepSeek-R1, Meta-Llama-3.3-70B, QwQ-32B - Research Agent with 5 sources: Web Search, Wikipedia, arXiv, GitHub, SEC EDGAR - Different decision protocols and role assignments 𝗖𝘂𝗿𝗿𝗲𝗻𝘁 𝘀𝘁𝗮𝘁𝘂𝘀: 25 likes 👍 and some really good user feedback in the Discord channel. People are actually testing it on real decisions, which feels great. Also met some really awesome people during this week 🙌. ➡️ 𝗧𝗿𝘆 𝗶𝘁: Agents-MCP-Hackathon/consilium_mcp Thanks to everyone who tested and gave feedback during the week ❤️. Win or lose, this was a fun deep dive into...</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/azettl/767271507427519</guid></item><item><title>🚀 For those who interested in summarization of the long textual reports in medical domain  📝🩺,</title><link>https://huggingface.co/posts/nicolay-r/221275408085007</link><description>🚀 For those who interested in summarization of the long textual reports in medical domain 📝🩺, @ Xiaolihai and I delighted to share that we experiment with distillation tuning adaptation for Qwen-2.5 0.5B. We use reports from the MultiClinSum dataset and pass it through 72B version to retrieve report explanations in order to initiate ditillation tuning for 0.5B model. We experiment with passages written in English, French, Portuguese, and Spanish. 🔑 We find that using distil-technique results in 2-4% performance increment on fine-tuning and similar improvements for reports in English. For the other it results in systems that perform similar to the convential tuning (standard) (see result below). Github: https://github.com/nicolay-r/distil-tuning-llm model: nicolay-r/qwen25-05b-multiclinsum-distil See translation</description><pubDate>Mon, 07 Jul 2025 17:21:56 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/221275408085007</guid></item></channel></rss>