<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SigLIP2 Image Classification  ğŸ§¤</title><link>https://huggingface.co/posts/prithivMLmods/550891236404805</link><description>SigLIP2 Image Classification ğŸ§¤ &gt; https://huggingface.co/blog/prithivMLmods/siglip2-finetune-image-classification See translation</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/550891236404805</guid></item><item><title>Hi there!</title><link>https://huggingface.co/posts/Undi95/824593315166092</link><description>Hi there! If you want to create your own thinking model or do a better MistralThinker, I just uploaded my entire dataset made on Deepseek R1 and the axolotl config. (well I made them public) Axolotl config : Undi95/MistralThinker-v1.1 The dataset : Undi95/R1-RP-ShareGPT3 You can also read all I did on those two discord screenshot from two days ago, I'm a little lazy to rewrite all kek. Hope you will use them! See translation</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Undi95/824593315166092</guid></item><item><title>Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months!</title><link>https://huggingface.co/posts/clem/866977064333227</link><description>Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months! Nvidia's org: https://huggingface.co/nvidia Enterprise hub: https://huggingface.co/enterprise See translation</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/866977064333227</guid></item><item><title>ğŸš€ Big news for AI agents! With the latest release of smolagents, you can now securely execute Python code in sandboxed Docker or E2B environments. ğŸ¦¾ğŸ”’</title><link>https://huggingface.co/posts/albertvillanova/674737128301579</link><description>ğŸš€ Big news for AI agents! With the latest release of smolagents, you can now securely execute Python code in sandboxed Docker or E2B environments. ğŸ¦¾ğŸ”’ Here's why this is a game-changer for agent-based systems: ğŸ§µğŸ‘‡ 1ï¸âƒ£ Security First ğŸ” Running AI agents in unrestricted Python environments is risky! With sandboxing, your agents are isolated, preventing unintended file access, network abuse, or system modifications. 2ï¸âƒ£ Deterministic &amp; Reproducible Runs ğŸ“¦ By running agents in containerized environments, you ensure that every execution happens in a controlled and predictable settingâ€”no more environment mismatches or dependency issues! 3ï¸âƒ£ Resource Control &amp; Limits ğŸš¦ Docker and E2B allow you to enforce CPU, memory, and execution time limits, so rogue or inefficient agents donâ€™t spiral out of control. 4ï¸âƒ£ Safer Code Execution in Production ğŸ­ Deploy AI agents confidently, knowing that any generated code runs in an ephemeral, isolated environment, protecting your host machine and...</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/albertvillanova/674737128301579</guid></item><item><title>Iâ€™m super excited to work with</title><link>https://huggingface.co/posts/burtenshaw/281561952705692</link><description>Iâ€™m super excited to work with @ mlabonne to build the first practical example in the reasoning course. ğŸ”— https://huggingface.co/reasoning-course Here's a quick walk through of the first drop of material that works toward the use case: - a fundamental introduction to reinforcement learning. Answering questions like, â€˜what is a reward?â€™ and â€˜how do we create an environment for a language model?â€™ - Then it focuses on Deepseek R1 by walking through the paper and highlighting key aspects. This is an old school way to learn ML topics, but it always works. - Next, it takes to you Transformers Reinforcement Learning and demonstrates potential reward functions you could use. This is cool because it uses Marimo notebooks to visualise the reward. - Finally, Maxime walks us through a real training notebook that uses GRPO to reduce generation length. Iâ€™m really into this because it works and Maxime took the time to validate it share assets and logging from his own runs for you to compare with....</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/281561952705692</guid></item><item><title>Extremely bullish on</title><link>https://huggingface.co/posts/andito/495335597913303</link><description>Extremely bullish on @ CohereForAI 's Aya Vision (8B &amp; 32B) - new SOTA open-weight VLMs - 8B wins up to 81% of the time in its class, better than Gemini Flash - 32B beats Llama 3.2 90B! - Covers 23 languages, excels in image captioning, VQA &amp; more - Integrated on transformers from Day 0! Efficient multimodal models are here to stay!!ğŸ”¥ Check out their blog! https://huggingface.co/blog/aya-vision See translation</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/andito/495335597913303</guid></item><item><title>I just released a fully automated evaluation framework for your RAG applications!ğŸ“ˆ</title><link>https://huggingface.co/posts/as-cle-bert/983515572081803</link><description>I just released a fully automated evaluation framework for your RAG applications!ğŸ“ˆ GitHub ğŸ‘‰ https://github.com/AstraBert/diRAGnosis PyPi ğŸ‘‰ https://pypi.org/project/diragnosis/ It's called ğğ¢ğ‘ğ€ğ†ğ§ğ¨ğ¬ğ¢ğ¬ and is a lightweight framework that helps you ğ—±ğ—¶ğ—®ğ—´ğ—»ğ—¼ğ˜€ğ—² ğ˜ğ—µğ—² ğ—½ğ—²ğ—¿ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ—»ğ—°ğ—² ğ—¼ğ—³ ğ—Ÿğ—Ÿğ— ğ˜€ ğ—®ğ—»ğ—± ğ—¿ğ—²ğ˜ğ—¿ğ—¶ğ—²ğ˜ƒğ—®ğ—¹ ğ—ºğ—¼ğ—±ğ—²ğ—¹ğ˜€ ğ—¶ğ—» ğ—¥ğ—”ğ—š ğ—®ğ—½ğ—½ğ—¹ğ—¶ğ—°ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ˜€. You can launch it as an application locally (it's Docker-ready!ğŸ‹) or, if you want more flexibility, you can integrate it in your code as a python packageğŸ“¦ The workflow is simple: ğŸ§  You choose your favorite LLM provider and model (supported, for now, are Mistral AI, Groq, Anthropic, OpenAI and Cohere) ğŸ§  You pick the embedding models provider and the embedding model you prefer (supported, for now, are Mistral AI, Hugging Face, Cohere and OpenAI) ğŸ“„ You prepare and provide your documents âš™ï¸ Documents are ingested into a Qdrant vector database and transformed into a synthetic question dataset with the help of LlamaIndex ğŸ“Š The LLM is evaluated for the faithfulness and...</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/983515572081803</guid></item><item><title>New amazing updates arrived to our ultimate Wan 2.1 (1-Click Install) Gradio APP</title><link>https://huggingface.co/posts/MonsterMMORPG/739966885386928</link><description>New amazing updates arrived to our ultimate Wan 2.1 (1-Click Install) Gradio APP Source : https://www.patreon.com/posts/123105403 Tutorial video : https://youtu.be/hnAhveNy-8s Please checkout the screenshots See translation</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/739966885386928</guid></item><item><title>Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949</link><description>Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free! duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset Access the full size dataset by creating an EDU account here- https://falcon.duality.ai/secure/documentation/ex3-dataset?sidebarMode=learn Or check it out in the linked HuggingFace dataset! What makes this dataset unique, useful, and capable of bridging the Sim2Real gap? ğŸ’  The digital twins are not generated by AI, but instead crafted by 3D artists to be INDISTINGUISHABLE from the physical-world objects. This allows the training from this data to transfer into real-world applicability ğŸ’  The simulation software, called FalconEditor, can easily create thousands of images with varying lighting, posing, occlusions, backgrounds, camera positions, and more. This enables robust model training. ğŸ’  The labels are created along with the data. This not only saves large amounts of time, but also ensures the...</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949</guid></item><item><title>AI will bring us "a country of yes-men on servers" instead of one of "Einsteins sitting in a data center" if we continue on current trends.</title><link>https://huggingface.co/posts/fdaudens/198644025808355</link><description>AI will bring us "a country of yes-men on servers" instead of one of "Einsteins sitting in a data center" if we continue on current trends. Must-read by @ thomwolf deflating overblown AI promises and explaining what real scientific breakthroughs require. https://thomwolf.io/blog/scientific-ai.html See translation</description><pubDate>Fri, 07 Mar 2025 05:20:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/198644025808355</guid></item></channel></rss>