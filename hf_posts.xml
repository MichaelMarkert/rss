<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams üìù</title><link>https://huggingface.co/posts/openfree/682363513025265</link><description>Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams üìù openfree/Korean-Exam-Leaderboard ## üìä What is this leaderboard? This leaderboard evaluates the performance of various AI models on 22 Korean civil service and professional qualification exams. All scores are converted to a 100-point scale to show how well different LLMs can solve actual Korean civil service and professional qualification tests! ## üèÜ Current Top Performers - **OpenAI/GPT-o1**: Bar Exam 52.5 points ü•á - **OpenAI/GPT-4.5**: Bar Exam 49.33 points ü•à - **OpenAI/GPT-4o**: Bar Exam 49.11 points ü•â - **deepseek-ai/DeepSeek-R1**: Bar Exam 47.33 points ## üìã Exams Being Evaluated The leaderboard includes various Korean civil service and professional qualification exams: - Korean Bar Exam - Senior Civil Service Grade 5 - Judicial Service Grade 5 - National Assembly Grade 5 - Judicial Scrivener - Police Executive Candidate - And more exams! ## ü§ñ Models Being Evaluated We are testing a variety of...</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/682363513025265</guid></item><item><title>Folks, let's get ready.ü•≥ We will be busy soon.  üòÖü§óhttps://github.com/huggingface/transformers/pull/36878</title><link>https://huggingface.co/posts/onekq/812629409559433</link><description>Folks, let's get ready.ü•≥ We will be busy soon. üòÖü§óhttps://github.com/huggingface/transformers/pull/36878 See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/812629409559433</guid></item><item><title>The Hugging Face Agents Course now includes three major agent frameworks!</title><link>https://huggingface.co/posts/burtenshaw/105046709529701</link><description>The Hugging Face Agents Course now includes three major agent frameworks! üîó https://huggingface.co/agents-course This includes LlamaIndex, LangChain, and our very own smolagents. We've worked to integrate the three frameworks in distinctive ways so that learners can reflect on when and where to use each. This also means that you can follow the course if you're already familiar with one of these frameworks, and soak up some of the fundamental knowledge in earlier units. Hopefully, this makes the agents course as open to as many people as possible. See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/105046709529701</guid></item><item><title>JFK declassified documents datasets</title><link>https://huggingface.co/posts/zlatinb/969200508438848</link><description>JFK declassified documents datasets Hello, I've prepared two datasets (raw and cleaned) of the recently declassified documents related to the assassination of President John F. Kennedy. Raw zlatinb/jfk-2025-raw Cleaned zlatinb/jfk-2025-cleaned The 2182 documents cover a vast range of topics, so it may be interesting to train on them to generate insights. See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/zlatinb/969200508438848</guid></item><item><title>Finally, the ground truth / AlexNet‚Äôs original source code is available to all.</title><link>https://huggingface.co/posts/Jaward/142231502952502</link><description>Finally, the ground truth / AlexNet‚Äôs original source code is available to all. Context: AlexNet had a historic win in the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC), reducing error rate from 26% (previous best) to 15.3%. It‚Äôs a deep CNN with 8 layers (5 convolutional + 3 fully connected), pioneering the use of ReLU activations for faster training, dropout for regularization, and GPU acceleration for large-scale learning. This moment marked the beginning of the deep learning revolution, inspiring architectures like VGG, ResNet, and modern transformers. Code: https://github.com/computerhistory/AlexNet-Source-Code See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/142231502952502</guid></item><item><title>Should we assemble affordable open-source robots at Hugging Face for the community. Would you buy them? At what price?</title><link>https://huggingface.co/posts/clem/968928866217294</link><description>Should we assemble affordable open-source robots at Hugging Face for the community. Would you buy them? At what price? See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/968928866217294</guid></item><item><title>Hey üëã Want to build your own personal timeline algorithm?</title><link>https://huggingface.co/posts/stefan-french/995663487518303</link><description>Hey üëã Want to build your own personal timeline algorithm? ‚≠êÔ∏è -&gt; https://github.com/mozilla-ai/byota üî• Try the live demo mozilla-ai/byota üßê Read more about it https://huggingface.co/blog/mozilla-ai/build-your-own-timeline-algorithm See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/stefan-french/995663487518303</guid></item><item><title>FlexWorld üî• an open framework that generates 3D scenes from a single image!</title><link>https://huggingface.co/posts/AdinaY/812841775665112</link><description>FlexWorld üî• an open framework that generates 3D scenes from a single image! Model: GSAI-ML/FlexWorld Paper: FlexWorld: Progressively Expanding 3D Scenes for Flexiable-View Synthesis (2503.13265) ‚ú® 360¬∞ rotation &amp; zooming ‚ú® High quality novel views powered by video-to-video diffusion model ‚ú® Progressive 3D expansion See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/812841775665112</guid></item><item><title>Squeezing Tensor Bits: the quest for smaller LLMs</title><link>https://huggingface.co/posts/eaddario/966662987888563</link><description>Squeezing Tensor Bits: the quest for smaller LLMs An area of personal interest is finding ways to optimize the inference performance of LLMs when deployed in resource-constrained environments like commodity hardware, desktops, laptops, mobiles, edge devices, etc. The method that I'm using to produce these experimental versions, for example eaddario/DeepSeek-R1-Distill-Llama-8B-GGUF is explained in https://medium.com/@eaddario/squeezing-tensor-bits-the-quest-for-smaller-llms-86b23bd052ca At a high level it involves using a custom version of the llama-quantize tool to selectively quantize different tensors at different levels. On average a 10% or more reduction with little loss of quality is possible. There‚Äôre two PRs to merge these changes back into the core project but until then, the modified version will be available on GitHub https://github.com/EAddario/llama.cpp/tree/quantize Would love to hear if you can achieve smaller sizes at higher quality! See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eaddario/966662987888563</guid></item><item><title>Managed to get my hands on a 5090FE, it's beefy</title><link>https://huggingface.co/posts/csabakecskemeti/458514085783723</link><description>Managed to get my hands on a 5090FE, it's beefy | llama 8B Q8_0 | 7.95 GiB | 8.03 B | CUDA | 99 | pp512 | 12207.44 ¬± 481.67 | | llama 8B Q8_0 | 7.95 GiB | 8.03 B | CUDA | 99 | tg128 | 143.18 ¬± 0.18 | Comparison with others GPUs http://devquasar.com/gpu-gguf-inference-comparison/ See translation</description><pubDate>Sun, 23 Mar 2025 09:20:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/458514085783723</guid></item></channel></rss>