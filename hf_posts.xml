<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.</title><link>https://huggingface.co/posts/etemiz/710778843328598</link><description>gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really "free": they are costing you your freedom if you know what i mean. See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/710778843328598</guid></item><item><title>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:</title><link>https://huggingface.co/posts/fdaudens/770107969696647</link><description>Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines &amp; specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup ‚Äî just open-weight GPT-OSS models via Hugging Face If you‚Äôve been wanting to try agents but weren‚Äôt sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/770107969696647</guid></item><item><title>No, I did not create those bots that just got banned today.</title><link>https://huggingface.co/posts/nroggendorff/812423234168314</link><description>No, I did not create those bots that just got banned today. See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/812423234168314</guid></item><item><title>Update on</title><link>https://huggingface.co/posts/ovi054/459497213356295</link><description>Update on ovi054/Qwen-Image-LORA ‚ö° You can now load a Qwen LoRA in this space as follows: 1. Model ID: flymy-ai/qwen-image-realism-lora 2. Model link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora 3. Specific file link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /blob/m ain/flymy_realism.safetensors 4. Direct download link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /resolve/m ain/flymy_realism.safetensors You can also use an external .safetensors download link (if Hugging Face doesn‚Äôt block it). It is useful if a model repository contains multiple weights and you want to load a specific one. üëâ Try it now: ovi054/Qwen-Image-LORA See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/459497213356295</guid></item><item><title>Image-to-Prompt‚ö°</title><link>https://huggingface.co/posts/ovi054/657358125503535</link><description>Image-to-Prompt‚ö° ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 üëâ Try it now: ovi054/image-to-prompt See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/657358125503535</guid></item><item><title>Liquid just released two 450M and 1.6B param VLMs!</title><link>https://huggingface.co/posts/mlabonne/575026837446793</link><description>Liquid just released two 450M and 1.6B param VLMs! They're super fast and leverage SigLIP2 NaFlex encoders to handle native resolutions without distortion. It's ideal for on-device deployment in constrained environments like phones. It's available today on Hugging Face, with an inference and a fine-tuning Colab notebooks. LiquidAI/LFM2-VL-450M LiquidAI/LFM2-VL-1.6B See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mlabonne/575026837446793</guid></item><item><title>Want to quickly try Gemma 3 270m? üíéüí¨</title><link>https://huggingface.co/posts/anakin87/751707976654130</link><description>Want to quickly try Gemma 3 270m? üíéüí¨ I made a simple Space to do that: anakin87/gemma-3-270m-it ‚ö° Fast: Flash Attention, Zero GPU ‚öôÔ∏è Configurable See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/anakin87/751707976654130</guid></item><item><title>üî• Wild Fire Tracker with Gradio MCP</title><link>https://huggingface.co/posts/space-sue/968839932309229</link><description>üî• Wild Fire Tracker with Gradio MCP Just finished this fire/smoke detection space that watches video feeds and alerts when it spots danger. Uses computer vision to analyze frames every 10 seconds. Agents-MCP-Hackathon/wild-fire-tracker What it does: -Detects fire &amp; smoke in real-time -Works with webcam, video files, or RTSP streams -Shows confidence scores + color-coded alerts - Has both web UI and API integration Looking for feedback on: -Detection accuracy -What features would be most useful -Real-world use cases you'd want Would love to hear thoughts from anyone working in fire monitoring, emergency response, or just interested in computer vision projects! Try it out and let me know what you think. See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/space-sue/968839932309229</guid></item><item><title>‚úÖ New Article: *Philosophy of Science as Structured Cognition*</title><link>https://huggingface.co/posts/kanaria007/826776352207938</link><description>‚úÖ New Article: *Philosophy of Science as Structured Cognition* Title: üî¨ Epistemic Architecture: Structured Intelligence and the Meta-Structure of Scientific Reasoning üîó https://huggingface.co/blog/kanaria007/structured-philosophy-of-science --- Summary: Science is often described as *method* or *accumulated knowledge*. Structured Intelligence reframes it as *epistemic architecture*: * Hypotheses as *jumpable structures* * Experiments as *self‚Äëauditing loops* * Theories as *reusable, ethically constrained models* &gt; Science isn‚Äôt just discovery ‚Äî &gt; *it‚Äôs the structured evolution of understanding.* --- Why It Matters: ‚Ä¢ Makes *reasoning paths explicit and auditable* ‚Ä¢ Connects *scientific method with cognitive architecture* ‚Ä¢ Enables *AI systems to model knowledge growth transparently* --- What‚Äôs Inside: ‚Ä¢ Science as *structured jumps and self‚Äëcorrections* ‚Ä¢ Comparison of *linear method vs recursive architecture* ‚Ä¢ Structural conditions for *reproducibility and paradigm shifts* ‚Ä¢...</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/826776352207938</guid></item><item><title>If you are interested safety and adversarial perspective in deep reinforcement learning, I will leave this repository here:</title><link>https://huggingface.co/posts/ezgikorkmaz/616130439361444</link><description>If you are interested safety and adversarial perspective in deep reinforcement learning, I will leave this repository here: Link: https://github.com/EzgiKorkmaz/adversarial-reinforcement-learning See translation</description><pubDate>Sat, 16 Aug 2025 13:29:58 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ezgikorkmaz/616130439361444</guid></item></channel></rss>