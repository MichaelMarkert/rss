<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>9 new policy optimization techniques</title><link>https://huggingface.co/posts/Kseniase/659752309280422</link><description>9 new policy optimization techniques Reinforcement Learning (RL) won't stuck in the same old PPO loop - in the last two months alone, researchers have introduced a new wave of techniques, reshaping how we train and fine-tune LLMs, VLMs, and agents. Here are 9 fresh policy optimization techniques worth knowing: 1. GSPO: Group Sequence Policy Optimization â†’ Group Sequence Policy Optimization (2507.18071) Shifts from token-level to sequence-level optimization, clipping, and rewarding to capture the full picture and increase stability compared to GRPO. GSPO-token variation also allows token-level fine-tuning. 2. LAPO: Length-Adaptive Policy Optimization â†’ LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization (2507.15758) A two-stage RL framework that trains models to adaptively control reasoning length by learning typical solution lengths for shorter and more efficient reasoning. 3. HBPO: Hierarchical Budget Policy Optimization â†’ Hierarchical Budget Policy...</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/659752309280422</guid></item><item><title>Explore OCR, Captioning, and Visual Understanding with Cutting-Edge Models on Hugging Face. ğŸ¤—ğŸ§ª</title><link>https://huggingface.co/posts/prithivMLmods/591329511468798</link><description>Explore OCR, Captioning, and Visual Understanding with Cutting-Edge Models on Hugging Face. ğŸ¤—ğŸ§ª Iâ€™ve put together a collection of Google Colab notebooks to experiment with some of the most exciting models available on the Hugging Face Hub focused on OCR, image captioning, and visual understanding tasks. [Image-to-Text] / [Image-Text-to-Text] &gt; ğŸ“– OCR-ReportLab-Notebooks : prithivMLmods/OCR-ReportLab-Notebooks These notebooks are built for quick prototyping and run on free T4 GPUs, making them perfect for experimentation, testing ideas, or just exploring whatâ€™s possible with modern vision-language models. Note: The experimental notebooks are compiled with models that fit within the T4 GPU (free-tier) limits. More models along with their notebooks will be added over time. See translation</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/591329511468798</guid></item><item><title>ğ—™ğ—¶ğ—¿ğ˜€ğ˜ ğ—šğ—£ğ—”ğ—œ ğ— ğ—¼ğ—±ğ—²ğ—¹ ğ˜„ğ—¶ğ˜ğ—µ ğ—˜ğ—¨ ğ——ğ—®ğ˜ğ—® ğ—§ğ—¿ğ—®ğ—»ğ˜€ğ—½ğ—®ğ—¿ğ—²ğ—»ğ—°ğ˜† ğ—§ğ—²ğ—ºğ—½ğ—¹ğ—®ğ˜ğ—²? ğŸ‡ªğŸ‡º</title><link>https://huggingface.co/posts/yjernite/544574162514620</link><description>ğ—™ğ—¶ğ—¿ğ˜€ğ˜ ğ—šğ—£ğ—”ğ—œ ğ— ğ—¼ğ—±ğ—²ğ—¹ ğ˜„ğ—¶ğ˜ğ—µ ğ—˜ğ—¨ ğ——ğ—®ğ˜ğ—® ğ—§ğ—¿ğ—®ğ—»ğ˜€ğ—½ğ—®ğ—¿ğ—²ğ—»ğ—°ğ˜† ğ—§ğ—²ğ—ºğ—½ğ—¹ğ—®ğ˜ğ—²? ğŸ‡ªğŸ‡º With the release of the EU data transparency template this week, we finally got to see one of the most meaningful artifacts to come out of the AI Act implementation so far (haven't you heard? AI's all about the data! ğŸ“ŠğŸ“š) The impact of the template will depend on how effectively it establishes a minimum meaningful transparency standard for companies that don't otherwise offer any transparency into their handling of e.g. personal data or (anti?-)competitive practices in commercial licensing - we'll see how those play out as new models are released after August 2nd ğŸ‘€ In the meantime, I wanted to see how the template works for a fully open-source + commercially viable model, so I filled it out for the SmolLM3 - which my colleagues at Hugging Face earlier this month ğŸ¤— ICYMI, it's fully open-source with 3B parameters and performance matching the best similar-size models (I've switched all my local apps from Qwen3 to it, you should...</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/yjernite/544574162514620</guid></item><item><title>ğŸ›¡ï¸ At Ai4Privacy, our goal is to empower researchers to build a safer AI ecosystem. Today, we're highlighting crucial research that does just that by exposing a new vulnerability.</title><link>https://huggingface.co/posts/MikeDoes/228428153197540</link><description>ğŸ›¡ï¸ At Ai4Privacy, our goal is to empower researchers to build a safer AI ecosystem. Today, we're highlighting crucial research that does just that by exposing a new vulnerability. The paper "Forget to Flourish" details a new model poisoning technique. It's a reminder that as we fine-tune LLMs, our anonymization and privacy strategies must evolve to counter increasingly sophisticated threats. We're proud that the Ai4Privacy dataset was instrumental in this study. It served two key purposes: Provided a Realistic Testbed: It gave the researchers access to a diverse set of synthetic and realistic PII samples in a safe, controlled environment. Enabled Impactful Benchmarking: It allowed them to measure the actual effectiveness of their data extraction attack, proving it could compromise specific, high-value information. This work reinforces our belief that progress in AI security is a community effort. By providing robust tools for benchmarking, we can collectively identify weaknesses and...</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/228428153197540</guid></item><item><title>ğŸ¤¯ 241B VLM with apache-2.0 license</title><link>https://huggingface.co/posts/merve/838684266814336</link><description>ğŸ¤¯ 241B VLM with apache-2.0 license internlm/Intern-S1 internlm released Intern-S1: multimodal reasoning model based on 235B MoE Qwen3 and 6B InternViT ğŸ˜ benchmarks look great (ğŸ‘‘ best model âœ… best open model) See translation</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/838684266814336</guid></item><item><title>We just released TRL v0.20 with major multimodal upgrades!</title><link>https://huggingface.co/posts/sergiopaniego/236970560808195</link><description>We just released TRL v0.20 with major multimodal upgrades! ğŸ‘ï¸ VLM support for GRPO (highly requested by the community!) ğŸï¸ New GSPO trainer (from @ Qwen , released last week, VLM-ready) ğŸ™ New MPO trainer (multimodal by design, as in the paper) ğŸ“ Full release notes here: https://github.com/huggingface/trl/releases/tag/v0.20.0 See translation</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/236970560808195</guid></item><item><title>NEW EXPERIMENTAL RELEASE: DAG Reasoning is here!</title><link>https://huggingface.co/posts/sequelbox/481535699199098</link><description>NEW EXPERIMENTAL RELEASE: DAG Reasoning is here! - Our first Experimental Reasoning Modality release: create structured, analytical Directed Acyclic Graphs to provide insight into your queries and situations! - Multi-step analysis identifies causal relationships, produces confidence measurements, and forms a single structured graph object. - DAG Reasoning Format provides clear, readable JSON containing structured, useful information; easy to use for creating visualizations, doing analysis, or further conversation with your assistant. - Trained in a variety of subjects for flexible analysis: programming, science, business, economics, finance, law, logistics, management, and more! Our first DAG Reasoning release is Qwen 3, starting off with 8B and 14B! Get 8B: sequelbox/Qwen3-8B-DAG-Reasoning Get 14B: sequelbox/Qwen3-14B-DAG-Reasoning You can also get the DAG Reasoning dataset, to train your own models to use DAG Reasoning Format: sequelbox/DAG-Reasoning-DeepSeek-R1-0528 Support our...</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sequelbox/481535699199098</guid></item><item><title>Hugging Face just made life easier with the new hf CLI!</title><link>https://huggingface.co/posts/ImranzamanML/854877876171123</link><description>Hugging Face just made life easier with the new hf CLI! huggingface-cli to hf With renaming the CLI, there are new features added like hf jobs. We can now run any script or Docker image on dedicated Hugging Face infrastructure with a simple command. It's a good addition for running experiments and jobs on the fly. To get started, just run: pip install -U huggingface_hub List of hf CLI Commands Main Commands hf auth: Manage authentication (login, logout, etc.). hf cache: Manage the local cache directory. hf download: Download files from the Hub. hf jobs: Run and manage Jobs on the Hub. hf repo: Manage repos on the Hub. hf upload: Upload a file or a folder to the Hub. hf version: Print information about the hf version. hf env: Print information about the environment. Authentication Subcommands (hf auth) login: Log in using a Hugging Face token. logout: Log out of your account. whoami: See which account you are logged in as. switch: Switch between different stored access...</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ImranzamanML/854877876171123</guid></item><item><title>Just dropped!</title><link>https://huggingface.co/posts/smirki/773357866668514</link><description>Just dropped! Tesslate/UIGEN-X-32B-0727 Runs Locally and Crushes It. Reasoning for UI, Mobile, Software and Frontend design. Specifically trained for modern web and mobile development across frameworks like React (Next.js, Remix, Gatsby, Vite), Vue (Nuxt, Quasar), Angular (Angular CLI, Ionic), and SvelteKit, along with Solid.js, Qwik, Astro, and static site tools like 11ty and Hugo. Styling options include Tailwind CSS, CSS-in-JS (Styled Components, Emotion), and full design systems like Carbon and Material UI. We cover UI libraries for every framework React (shadcn/ui, Chakra, Ant Design), Vue (Vuetify, PrimeVue), Angular, and Svelte plus headless solutions like Radix UI. State management spans Redux, Zustand, Pinia, Vuex, NgRx, and universal tools like MobX and XState. For animation, we support Framer Motion, GSAP, and Lottie, with icons from Lucide, Heroicons, and more. Beyond web, we enable React Native, Flutter, and Ionic for mobile, and Electron, Tauri, and Flutter Desktop for...</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/smirki/773357866668514</guid></item><item><title>ğŸ“¢ For those who planning to start a PhD or research in the UK ğŸ‡¬ğŸ‡§ (including AI field in particular) but facing ATAS (Academic Technology Approval Scheme) issues.</title><link>https://huggingface.co/posts/nicolay-r/579222924328271</link><description>ğŸ“¢ For those who planning to start a PhD or research in the UK ğŸ‡¬ğŸ‡§ (including AI field in particular) but facing ATAS (Academic Technology Approval Scheme) issues. Excited to share the ultimate guide for dealing with ATAS refusals and how to write effective rebuttal letters. ğŸ¬ https://youtu.be/bfknM3n-SHs ğŸ” From the video you will find: 1. Why appealing an ATAS decision matters even if your visa is approved 2. Which docments to use in understanding the principles behind sponsorship decisions 3. Key tips for proper rebuttal letter structuring See translation</description><pubDate>Tue, 29 Jul 2025 17:25:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/579222924328271</guid></item></channel></rss>