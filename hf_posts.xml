<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>🔮 Mistral Perflexity AI - Local LLM Space with Web Search Capabilities 🌐</title><link>https://huggingface.co/posts/ginipick/917789522887291</link><description>🔮 Mistral Perflexity AI - Local LLM Space with Web Search Capabilities 🌐 Hello AI enthusiasts! Today I'm excited to introduce my special Hugging Face space! 🚀 ginigen/Mistral-Perflexity ✨ Key Features Powerful Model: Using Private-BitSix-Mistral-Small-3.1-24B-Instruct-2503, optimized through 6-bit quantization to run smoothly on local 4090 GPUs! 💪 Web Search Integration: Leveraging the Brave Search API to provide real-time web search results for user queries! 🔍 Customizable Responses: Shape AI personality and response format through system messages ⚙️ Multilingual Support: Perfect handling of both English and Korean! 🇺🇸🇰🇷 🛠️ Technical Highlights GGUF Format: Optimized quantized model with excellent memory efficiency Flash Attention: Applied optimization technology for faster inference speeds 8K Context Window: Capable of handling lengthy conversations and complex queries Streaming Responses: Watch text being generated in real-time 💡 Use Cases Complex Q&amp;A requiring real-time...</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/917789522887291</guid></item><item><title>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me!</title><link>https://huggingface.co/posts/fdaudens/694548457778636</link><description>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me! Just tested it with Steve Jobs' Stanford speech and was speechless (pun intended). The video isn’t sped up. 3 things that floored me: - Transcription took just 10 seconds for a 15-min file - Got a CSV with perfect timestamps, punctuation &amp; capitalization - Stunning accuracy (correctly captured "Reed College" and other specifics) NVIDIA also released a demo where you can click any transcribed segment to play it instantly. The improvement is significant: number 1 on the ASR Leaderboard, 6% error rate (best in class) with complete commercial freedom (cc-by-4.0 license). Time to update those Whisper pipelines! H/t @ Steveeeeeeen for the finding! Model: nvidia/parakeet-tdt-0.6b-v2 Demo: nvidia/parakeet-tdt-0.6b-v2 ASR Leaderboard: hf-audio/open_asr_leaderboard See translation</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/694548457778636</guid></item><item><title>HOW TO ADD MCP SUPPORT TO ANY 🤗 SPACE</title><link>https://huggingface.co/posts/abidlabs/810486848644944</link><description>HOW TO ADD MCP SUPPORT TO ANY 🤗 SPACE Gradio now supports MCP! If you want to convert an existing Space, like this one hexgrad/Kokoro-TTS , so that you can use it with Claude Desktop / Cursor / Cline / TinyAgents / or any LLM that supports MCP, here's all you need to do: 1. Duplicate the Space (in the Settings Tab) 2. Upgrade the Gradio sdk_version to 5.28 (in the README.md ) 3. Set mcp_server=True in launch() 4. (Optionally) add docstrings to the function so that the LLM knows how to use it, like this: def generate ( text, speed= 1 ): """ Convert text to speech audio. Parameters: text (str): The input text to be converted to speech. speed (float, optional): Playback speed of the generated speech. That's it! Now your LLM will be able to talk to you 🤯 See translation</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/810486848644944</guid></item><item><title>🎨 Renoir Studio: Impressionist Masterpieces Reborn Through AI ✨</title><link>https://huggingface.co/posts/ginipick/692850049335646</link><description>🎨 Renoir Studio: Impressionist Masterpieces Reborn Through AI ✨ 🌟 Experience Renoir's Magical Brushstrokes with AI! 🔗 Try it now: ginigen/flux-lora-renoir 🔗 Model page: openfree/pierre-auguste-renoir 🔗 Collection: openfree/painting-art-ai-681453484ec15ef5978bbeb1 Hello, AI art enthusiasts! 💖 Today I'm introducing a special model - Pierre-Auguste Renoir Studio. Create your own beautiful artwork in the style of the 19th century French Impressionist master! 🖼️ ✨ Why Renoir's Style? Renoir is famous for his luminous colors and soft brushstrokes. His works feature: 🌞 Warm sunshine and dancing light 👨‍👩‍👧‍👦 The beauty of everyday life and joyful moments 🌸 Vibrant nature and portraits of beautiful women 🎭 Lively Parisian social gatherings and outdoor scenes 🔬 Technical Features This model was developed as a flux-based learning model trained on a curated collection of high-resolution masterpieces from renowned global artists. The LoRA fine-tuning process leveraged exceptional quality open-...</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/692850049335646</guid></item><item><title>One of the biggest challenges I've been facing since I started developing [𝐏𝐝𝐟𝐈𝐭𝐃𝐨𝐰𝐧](</title><link>https://huggingface.co/posts/as-cle-bert/299436064475061</link><description>One of the biggest challenges I've been facing since I started developing [𝐏𝐝𝐟𝐈𝐭𝐃𝐨𝐰𝐧]( https://github.com/AstraBert/PdfItDown ) was handling correctly the conversion of files like Excel sheets and CSVs: table conversion was bad and messy, almost unusable for downstream tasks🫣 That's why today I'm excited to introduce 𝐫𝐞𝐚𝐝𝐞𝐫𝐬, the new feature of PdfItDown v1.4.0!🎉 With 𝘳𝘦𝘢𝘥𝘦𝘳𝘴, you can choose among three (for now👀) flavors of text extraction and conversion to PDF: - 𝗗𝗼𝗰𝗹𝗶𝗻𝗴, which does a fantastic work with presentations, spreadsheets and word documents🦆 - 𝗟𝗹𝗮𝗺𝗮𝗣𝗮𝗿𝘀𝗲 by LlamaIndex, suitable for more complex and articulated documents, with mixture of texts, images and tables🦙 - 𝗠𝗮𝗿𝗸𝗜𝘁𝗗𝗼𝘄𝗻 by Microsoft, not the best at handling highly structured documents, by extremly flexible in terms of input file format (it can even convert XML, JSON and ZIP files!)✒️ You can use this new feature in your python scripts (check the attached code snippet!😉) and in the command line interface as well!🐍...</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/299436064475061</guid></item><item><title>I’m excited to share that I’ve completed the Hugging Face Agents Course and earned my certificate.</title><link>https://huggingface.co/posts/lukmanaj/906857593942972</link><description>I’m excited to share that I’ve completed the Hugging Face Agents Course and earned my certificate. Over the past few months, I explored how to build intelligent, autonomous agents using cutting-edge tools like smolagents, LlamaIndex, and LangGraph. The course covered everything from the fundamentals of agents to advanced topics like fine-tuning for function-calling, observability, evaluation, and even agents in games. Some key content included: 1. Introduction to AI Agents 2. Agentic RAG use cases 3. Multi-framework implementation: smolagents, LlamaIndex, and LangGraph 4. Building, testing, and certifying a complete agent project This was a hands-on, practical experience that deepened my understanding of how to design reliable, tool-using LLM agents. Looking forward to leveraging these skills in real-world applications in healthcare, logistics, and beyond. Many thanks to the Hugging Face team for putting this together. Let’s build safe and useful agents! See translation</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/lukmanaj/906857593942972</guid></item><item><title>The capabilities of the new Qwen 3 models are fascinating, and I am watching that space!</title><link>https://huggingface.co/posts/sometimesanotion/274970281216191</link><description>The capabilities of the new Qwen 3 models are fascinating, and I am watching that space! My experience, however, is that context management is vastly more important with them. If you use a client with a typical session log with rolling compression, a Qwen 3 model will start to generate the same messages over and over. I don't think that detracts from them. They're optimized for a more advanced MCP environment. I honestly think the 8B is optimal for home use, given proper RAG/CAG. In typical session chats, Lamarck and Chocolatine are still my daily drives. I worked hard to give Lamarck v0.7 a sprinkling of CoT from both DRT and Deepseek R1. While those models got surpassed on the leaderboards, in practice, I still really enjoy their output. My projects are focusing on application and context management, because that's where the payoff in improved quality is right now. But should there be a mix of finetunes to make just the right mix of - my recipes are standing by. See translation</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sometimesanotion/274970281216191</guid></item><item><title>VisionScout — Now with Scene Understanding! 🚀</title><link>https://huggingface.co/posts/DawnC/822045713383062</link><description>VisionScout — Now with Scene Understanding! 🚀 I'm excited to share a major update to VisionScout, my interactive vision tool that combines powerful object detection with emerging scene understanding capabilities! 👀🔍 What can VisionScout do today? 🖼️ Upload any image and detect 80 object types using YOLOv8. 🔄 Instantly switch between Nano, Medium, and XLarge models depending on speed vs. accuracy needs. 🎯 Filter specific classes (people, vehicles, animals, etc.) to focus only on what matters to you. 📊 View detailed statistics on detected objects, confidence levels, and spatial distribution. ⭐️ NEW: Scene understanding layer now added! - Automatically interprets the scene based on detected objects. - Uses a combination of rule-based reasoning and CLIP-powered semantic validation. - Outputs descriptions, possible activities, and even safety concerns. What’s coming next? 🔎 Expanding YOLO’s object categories. 🎥 Adding video processing and multi-frame object tracking. ⚡ Faster real-time...</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/822045713383062</guid></item><item><title>🚀 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer～</title><link>https://huggingface.co/posts/RiverZ/535015681556179</link><description>🚀 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer～ 🎨 Daily Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) 🔓 Code is now open source! 🔥 Huggingface DEMO: RiverZ/ICEdit 🌐 Project Website: https://river-zhang.github.io/ICEdit-gh-pages/ 🏠 GitHub Repository: https://github.com/River-Zhang/ICEdit/blob/main/scripts/gradio_demo.py 🤗 Huggingface: sanaka87/ICEdit-MoE-LoRA 📄 arxiv Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) 🔥 Why it’s cool: - Achieves high-quality, multi-task image editing. - Uses only 1% of the training parameters and 0.1% of the training data compared to existing methods — extremely efficient - Beats several commercial models on background preservation, ID control, and consistency - Open-...</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/RiverZ/535015681556179</guid></item><item><title>🖼️ OpenClipart SVG Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/253978208604387</link><description>🖼️ OpenClipart SVG Dataset - nyuuzyou/openclipart Collection of 178,604 Public Domain Scalable Vector Graphics (SVG) clipart images featuring: - Comprehensive metadata: title, description, artist name, tags, original page URL, and more. - Contains complete SVG XML content (minified) for direct use or processing. - All images explicitly released into the public domain under the CC0 license. - Organized in a single train split with 178,604 entries. See translation</description><pubDate>Sun, 04 May 2025 05:22:04 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/253978208604387</guid></item></channel></rss>