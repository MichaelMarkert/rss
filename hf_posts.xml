<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸš€ Llama-4 Model-Based Agentic AI System Released!</title><link>https://huggingface.co/posts/openfree/652290136793730</link><description>ğŸš€ Llama-4 Model-Based Agentic AI System Released! ğŸ”¥ Introducing the Latest Llama-4 Models Hello AI enthusiasts! Today we're excited to introduce our free API service powered by the cutting-edge Llama-4-Maverick-17B and Llama-4-Scout-17B models! These state-of-the-art models will upgrade your AI experience with remarkable stability and speed. Link1: openfree/Llama-4-Maverick-17B-Research Link2: openfree/Llama-4-Scout-17B-Research ğŸ§  The Innovation of Agentic AI: Deep Research Feature The standout feature of our service is the revolutionary "Deep Research" functionality! This innovative Agentic AI system includes: ğŸ” Optimized Keyword Extraction: LLM automatically generates the most effective keywords for searches ğŸŒ Real-time Web Search: Collects the latest information through the SerpHouse API ğŸ“Š Intelligent Information Analysis: Precise analysis utilizing the LLM's reasoning capabilities based on collected information ğŸ“ Contextualized Response Generation: Provides accurate answers...</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/652290136793730</guid></item><item><title>ğŸ¨ Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition ğŸŒâœ¨</title><link>https://huggingface.co/posts/seawolf2357/883323339740165</link><description>ğŸ¨ Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition ğŸŒâœ¨ Hello creators! Today I'm introducing a special image generator that combines the beautiful aesthetics of Studio Ghibli with multilingual text integration! ğŸ˜ seawolf2357/Ghibli-Multilingual-Text-rendering âœ¨ Key Features Ghibli-Style Image Generation - High-quality animation-style images based on FLUX.1 Multilingual Text Rendering - Support for Korean, Japanese, English, and all languages! ğŸ‡°ğŸ‡·ğŸ‡¯ğŸ‡µğŸ‡¬ğŸ‡§ Automatic Image Editing with Simple Prompts - Just input your desired text and you're done! Two Stylistic Variations Provided - Get two different results from a single prompt Full Hugging Face Spaces Support - Deploy and share instantly! ğŸš€ How Does It Work? Enter a prompt describing your desired image (e.g., "a cat sitting by the window") Input the text you want to add (any language works!) Select the text position, size, and color Two different versions are automatically generated! ğŸ’¯...</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/883323339740165</guid></item><item><title>ğŸ¯ Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! âœ¨</title><link>https://huggingface.co/posts/ginipick/807578740801859</link><description>ğŸ¯ Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! âœ¨ Hello AI enthusiasts! ğŸ™‹â€â™€ï¸ Today I'm introducing a truly magical project: Open Ghibli Studio ğŸ¨ ginigen/FLUX-Open-Ghibli-Studio ğŸŒŸ What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! ğŸï¸âœ¨ ğŸ”§ How Does It Work? ğŸ“¸ Upload your photo ğŸ¤– Florence-2 AI analyzes the image and generates a description âœï¸ "Ghibli style" is added to the description ğŸ­ Magic transformation happens using the FLUX.1 model and Ghibli LoRA! âš™ï¸ Customization Options Want more control? Adjust these in the advanced settings: ğŸ² Set a seed (for reproducible results) ğŸ“ Adjust image dimensions ğŸ” Guidance scale (prompt adherence) ğŸ”„ Number of generation steps ğŸ’« Ghibli style intensity ğŸš€ Try It Now! Click the "Transform to Ghibli Style" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? ğŸŒˆ ğŸŒ¿ Note: For best results,...</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/807578740801859</guid></item><item><title>ğŸ”¥ 'Open Meme Studio': Your Creative Meme Factory ğŸ­âœ¨</title><link>https://huggingface.co/posts/openfree/925352420925810</link><description>ğŸ”¥ 'Open Meme Studio': Your Creative Meme Factory ğŸ­âœ¨ Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. ğŸš€ VIDraft/Open-Meme-Studio ğŸ¯ Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! ğŸ› ï¸ Features You'll Love ğŸ“¸ Transform and reinterpret existing meme templates ğŸ­ Freely change expressions and poses ğŸ‘“ Add props (sunglasses, hats, etc.) ğŸï¸ Change backgrounds and composite characters ğŸ¨ Apply various artistic styles ğŸ’ª Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/925352420925810</guid></item><item><title>âœ¨ High-Resolution Ghibli Style Image Generator âœ¨</title><link>https://huggingface.co/posts/aiqtech/202174985893140</link><description>âœ¨ High-Resolution Ghibli Style Image Generator âœ¨ ğŸŒŸ Introducing FLUX Ghibli LoRA Hello everyone! Today I'm excited to present a special LoRA model for FLUX Dev.1. This model leverages a LoRA trained on high-resolution Ghibli images for FLUX Dev.1 to easily create beautiful Ghibli-style images with stunning detail! ğŸ¨ space: aiqtech/FLUX-Ghibli-Studio-LoRA model: openfree/flux-chatgpt-ghibli-lora ğŸ”® Key Features Trained on High-Resolution Ghibli Images - Unlike other LoRAs, this one is trained on high-resolution images, delivering sharper and more beautiful results Powered by FLUX Dev.1 - Utilizing the latest FLUX model for faster generation and superior quality User-Friendly Interface - An intuitive UI that allows anyone to create Ghibli-style images with ease Diverse Creative Possibilities - Express various themes in Ghibli style, from futuristic worlds to fantasy elements ğŸ–¼ï¸ Sample Images Include "Ghibli style" in your prompts Try combining nature, fantasy elements, futuristic...</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/aiqtech/202174985893140</guid></item><item><title>Huge week for</title><link>https://huggingface.co/posts/jsulz/745335361364732</link><description>Huge week for xet-team as Llama 4 is the first major model on Hugging Face uploaded with Xet providing the backing! Every byte downloaded comes through our infrastructure. Using Xet on Hugging Face is the fastest way to download and iterate on open source models and we've proved it with Llama 4 giving a boost of ~25% across all models. We expect builders on the Hub to see even more improvements, helping power innovation across the community. With the models on our infrastructure, we can peer in and see how well our dedupe performs across the Llama 4 family. On average, we're seeing ~25% dedupe, providing huge savings to the community who iterate on these state-of-the-art models. The attached image shows a few selected models and how they perform on Xet. Thanks to the meta-llama team for launching on Xet! See translation</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jsulz/745335361364732</guid></item><item><title>Iâ€™ve been diving into the iRoPE architecture from Llama 4â€”a game-changer for long-context models! It interleaves local attention (with RoPE) for short contexts and global attention (with inference-time temp scaling) for long-range reasoning, aiming for infinite context. Iâ€™m going to try writing iRoPEâ€”who wants to help?</title><link>https://huggingface.co/posts/wassemgtk/755158543554585</link><description>Iâ€™ve been diving into the iRoPE architecture from Llama 4â€”a game-changer for long-context models! It interleaves local attention (with RoPE) for short contexts and global attention (with inference-time temp scaling) for long-range reasoning, aiming for infinite context. Iâ€™m going to try writing iRoPEâ€”who wants to help? Code: https://github.com/wassemgtk/iRoPE-try/blob/main/iRoPE.ipynb See translation</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wassemgtk/755158543554585</guid></item><item><title>The best researchers from Yale, Stanford, Google DeepMind, and Microsoft laid out all we know about Agents in a 264-page paper [book],</title><link>https://huggingface.co/posts/hesamation/410985277524863</link><description>The best researchers from Yale, Stanford, Google DeepMind, and Microsoft laid out all we know about Agents in a 264-page paper [book], Here are some of their key findings: They build a mapping of different agent components, such as perception, memory, and world modelling, to different regions of the human brain and compare them: - brain is much more energy-efficient - no genuine experience in agents - brain learns continuously, agent is static An agent is broken down to: - Perception: the agent's input mechanism. can be improved with multi-modality, feedback mechanisms (e.g., human corrections), etc. - Cognition: learning, reasoning, planning, memory. LLMs are key in this part. - Action: agent's output and tool use. Agentic memory is represented as: - Sensory memory or short-term holding of inputs which is not emphasized much in agents. - Short-term memory which is the LLM context window - Long-term memory which is the external storage such as RAG or knowledge graphs. The memory in...</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/410985277524863</guid></item><item><title>Llama 4 is out...</title><link>https://huggingface.co/posts/AtAndDev/141454132915403</link><description>Llama 4 is out...</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AtAndDev/141454132915403</guid></item><item><title>ExLlamaV3 is out. And it introduces EXL3 - a new SOTA quantization format!</title><link>https://huggingface.co/posts/sr-rai/596076021766754</link><description>ExLlamaV3 is out. And it introduces EXL3 - a new SOTA quantization format! "The conversion process is designed to be simple and efficient and requires only an input model (in HF format) and a target bitrate. By computing Hessians on the fly and thanks to a fused Viterbi kernel, the quantizer can convert a model in a single step, taking a couple of minutes for smaller models, up to a few hours for larger ones (70B+) (on a single RTX 4090 or equivalent GPU.)" Repo: https://github.com/turboderp-org/exllamav3 See translation</description><pubDate>Tue, 08 Apr 2025 05:22:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sr-rai/596076021766754</guid></item></channel></rss>