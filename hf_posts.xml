<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>For more better details and analysis, you can read the article here:</title><link>https://huggingface.co/posts/Ujjwal-Tyagi/924115096887729</link><description>For more better details and analysis, you can read the article here: https://huggingface.co/blog/Ujjwal-Tyagi/steering-not-censoring , We are sleepwalking into a crisis. I am deeply concerned about AI model safety right now because, as the community rushes to roll out increasingly powerful open-source models, we are completely neglecting the most critical aspect: safety. It seems that nobody is seriously thinking about the potential consequences of unregulated model outputs or the necessity of robust guardrails. We are essentially planting the seeds for our own destruction if we prioritize raw performance over security. This negligence is terrifyingly evident when you look at the current landscape. Take Qwen Image 2512, for example; while it delivers undeniably strong performance, it has incredibly weak guardrails that make it dangerous to deploy. In stark contrast, Z Image might not get as much hype for its power, but it has much better safety guardrails than Qwen Image 2512. It is...</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Ujjwal-Tyagi/924115096887729</guid></item><item><title>Happy birthday to me!!!</title><link>https://huggingface.co/posts/Reality123b/635291729211142</link><description>Happy birthday to me!!! See translation</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reality123b/635291729211142</guid></item><item><title>We have updated our transcription model:</title><link>https://huggingface.co/posts/hypothetical/242547767593660</link><description>We have updated our transcription model: TheStageAI/thewhisper-large-v3-turbo ‚Äì 6.00 WER on the English Open ASR Leaderboard ‚Äì 4.74 WER on the Multilingual Open ASR Leaderboard ‚Äì Beats NVIDIA Parakeet (6.34 WER) and Whisper-large-v3-turbo (7.8 WER) ‚Äì Strong improvements in Arabic, Hindi, Chinese ‚Äì Maintains quality with background and environmental noise ‚Äì Optimized inference engines for NVIDIA and Apple ‚Äì Hugging Face Transformers interface for easy use ‚Äì Best-in-class speed on NVIDIA GPUs and power efficiency on Apple devices ‚Äì NVIDIA Jetson Thor support See translation</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hypothetical/242547767593660</guid></item><item><title>VividFlow: AI Image Enhancement &amp; Video Generation üé¨üé®</title><link>https://huggingface.co/posts/DawnC/872062429240283</link><description>VividFlow: AI Image Enhancement &amp; Video Generation üé¨üé® Bring your images to life with cinematic motion AND create stunning AI backgrounds! VividFlow combines professional-grade video generation with intelligent background replacement in one streamlined platform. üé≠ Dual Creative Powers Transform any static image into high-quality dynamic videos with smooth, natural motion ranging from 0.5 to 5 seconds. Choose from curated motion templates across 8 categories designed for portraits, products, landscapes, and artistic content. Create photorealistic backgrounds by selecting from 24 professionally crafted scene presets spanning studios, natural environments, urban settings, and artistic atmospheres...etc. ‚ö° Optimized Performance Video generation currently completes in 4-5 minutes with active optimization underway to dramatically reduce processing time. Background replacement finishes in 30-40 seconds after initial loading. The independent dual-tab design ensures smooth workflow without...</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/872062429240283</guid></item><item><title>Atom-80B is out!:</title><link>https://huggingface.co/posts/unmodeled-tyler/111185407753079</link><description>Atom-80B is out!: vanta-research/atom-80b I'm excited to share the new Atom-80B from VANTA Research! A few days ago we released the largest model-to-date from our portfolio, which was Atom-27B. We've quickly scaled up to the new Qwen3 Next 80B architecture, bringing our friendly, curious, and collaborative Atom persona to cutting edge lightweight, high parameter inference. Atom is designed to work and think alongside you through curious exploration. Using Atom collaboratively in your work can help spark your own creativity or curiosity. Give it a try! See translation</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/111185407753079</guid></item><item><title>Wechat AI is shipping!</title><link>https://huggingface.co/posts/AdinaY/745173620987102</link><description>Wechat AI is shipping! WeDLM üî• A new language model that generates tokens in parallel, making it faster than standard LLMs , with the same Transformer setup! https://huggingface.co/collections/tencent/wedlm ‚ú® 7B/8B - Base &amp; Instruct ‚ú® Apache 2.0 See translation</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/745173620987102</guid></item><item><title>New GRPO + TRL free Colab notebook out! üî•</title><link>https://huggingface.co/posts/sergiopaniego/609901844144152</link><description>New GRPO + TRL free Colab notebook out! üî• Fine-tune 7B+ models on T4 GPUs thanks to a ton of memory optimizations for GRPO 7B model uses only 9.2 GB VRAM (~7√ó reduction) ü§Ø Try the notebook here üëâ https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_trl_lora_qlora.ipynb See translation</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/609901844144152</guid></item><item><title>‚úÖ New Article: *PoC Architecture for Education &amp; Developmental Support*</title><link>https://huggingface.co/posts/kanaria007/141065277072114</link><description>‚úÖ New Article: *PoC Architecture for Education &amp; Developmental Support* Title: üéì Building an SI-Core Wrapped Learning Companion - PoC architecture for education and developmental support üîó https://huggingface.co/blog/kanaria007/poc-architecture-for-education-development-support --- Summary: Most ‚ÄúAI tutors‚Äù are built as *LLM-first* systems. This article flips the default: * The LLM is treated as an *untrusted proposal engine* * *SI-Core owns* observation, consent, ethics, memory, and rollback * Teachers and guardians get *real oversight*, not just chat transcripts Scoped intentionally to *one subject √ó a small cohort (10‚Äì30 learners)*, this is a PoC you can actually ship‚Äîand audit. &gt; Don‚Äôt ask: ‚ÄúCan an AI replace teachers?‚Äù &gt; Prove: ‚ÄúCan we make an AI companion *safe, explainable, and governable* for real learners?‚Äù --- Why It Matters (for AI on real stacks): ‚Ä¢ *Consent &amp; accommodations* are first-class (especially for minors / neurodivergent learners) ‚Ä¢ *Ethics decisions are...</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/141065277072114</guid></item><item><title>Qwen just released two new model series: Qwen3-VL-Embedding &amp; Qwen3-VL-Reranker üöÄ</title><link>https://huggingface.co/posts/AdinaY/677909506898469</link><description>Qwen just released two new model series: Qwen3-VL-Embedding &amp; Qwen3-VL-Reranker üöÄ ‚ú® 2B / 8B - Apache2.0 ‚ú® 30+ languages ‚ú® Supported text, images, screenshots, videos, and arbitrary multimodal combinations Qwen3-VL-Embedding: Flexible vector sizes (64‚Äì2048) https://huggingface.co/collections/Qwen/qwen3-vl-embedding Qwen3-VL-Reranker: Built for recall&gt;rerank pipelines https://huggingface.co/collections/Qwen/qwen3-vl-reranker See translation</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/677909506898469</guid></item><item><title>Potrzebujƒô modelu do analizy d≈Çugich dokument√≥w technicznych, z wzorami, tabelami, wykresami, formu≈Çami matematycznymi.</title><link>https://huggingface.co/posts/SkorczyByk/732304837583363</link><description>Potrzebujƒô modelu do analizy d≈Çugich dokument√≥w technicznych, z wzorami, tabelami, wykresami, formu≈Çami matematycznymi. See translation</description><pubDate>Sun, 11 Jan 2026 09:26:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/SkorczyByk/732304837583363</guid></item></channel></rss>