<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>New REPL environment in OpenEnv available! ‚ú®</title><link>https://huggingface.co/posts/sergiopaniego/454747936446679</link><description>New REPL environment in OpenEnv available! ‚ú® Used in the Recursive Language Models (RLM) paper by Alex Zhang. Ready for inference &amp; post-training using trajectories. Handles long contexts: &gt; Run Python code in a sandbox &gt; Make recursive calls to LMs &gt; Explore data programmatically &gt; Return final result Docs: https://meta-pytorch.org/OpenEnv/environments/repl/ Inference script: https://github.com/meta-pytorch/OpenEnv/blob/main/examples/repl_oolong_simple.py See translation</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/454747936446679</guid></item><item><title>I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second!</title><link>https://huggingface.co/posts/YatharthS/729508768545264</link><description>I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second! NovaSR can - Enhance TTS model quality. - Restore poor quality datasets. - Work on any device(just 52kb which is smaller than a 3 second audio file!) Model: YatharthS/NovaSR Space to try it: YatharthS/NovaSR Github repo: https://github.com/ysharma3501/NovaSR See translation</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YatharthS/729508768545264</guid></item><item><title>From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding upüöÄ</title><link>https://huggingface.co/posts/AdinaY/245167368794687</link><description>From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding upüöÄ Now BaichuanAI joins with Baichuan-M3 üè• an open medical LLM trained for clinical decision-making https://huggingface.co/collections/baichuan-inc/baichuan-m3 ‚ú® 235B - Apache2.0 ‚ú® Lower hallucinations via Fact-Aware RL ‚ú® Built for long medical chats See translation</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/245167368794687</guid></item><item><title>I am very excited to see the release of</title><link>https://huggingface.co/posts/Ujjwal-Tyagi/164908864894846</link><description>I am very excited to see the release of nyuuzyou/gitee-code . This is exactly what I have been looking for. Thank you to @ nyuuzyou for his hard work on this. See translation</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Ujjwal-Tyagi/164908864894846</guid></item><item><title>Agentic AI doesn‚Äôt fail because it lacks intelligence ‚Äî it fails because it lacks context.</title><link>https://huggingface.co/posts/TravisMuhlestein/396736901039998</link><description>Agentic AI doesn‚Äôt fail because it lacks intelligence ‚Äî it fails because it lacks context. As agents become more autonomous, the real challenge shifts from generation to governance: understanding when, why, and under what constraints an agent should act. At GoDaddy, we‚Äôve been treating context as a first-class primitive for agentic systems ‚Äî combining identity, intent, permissions, and environment so agents can operate responsibly in production. Context is what turns automation into judgment. Without it, autonomy becomes risk. This post outlines how we‚Äôre thinking about the transition from task execution to context-aware agentic systems, and what that means for building AI that can be trusted at scale. üëâ How we build context for agentic AI: https://www.godaddy.com/resources/news/how-godaddy-builds-context-for-agentic-ai Curious how others here are modeling context, trust boundaries, and decision constraints in agentic architectures. See translation</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/TravisMuhlestein/396736901039998</guid></item><item><title>NEW RELEASE: it's here! Meet the newest member of the Valiant crew: Guardpoint, our new medical reasoning model!</title><link>https://huggingface.co/posts/sequelbox/836146471898656</link><description>NEW RELEASE: it's here! Meet the newest member of the Valiant crew: Guardpoint, our new medical reasoning model! - Trained on medical knowledge, management, diagnosis, and tasks from DeepSeek-V3.2-Speciale! - Structured medical reasoning responses are efficient and informative, cutting token costs for faster inference! - Wide-ranging knowledge base: trained on a wide variety of medical disciplines, patient types, and query structures! - High quality medical responses emphasize performance, brevity, specificity, statistical rationality, and openness. Get it now: Guardpoint for Qwen 3 32B: ValiantLabs/Qwen3-32B-Guardpoint Guardpoint for Qwen 3 14B: ValiantLabs/Qwen3-14B-Guardpoint Powered by our new structured medical reasoning dataset: sequelbox/Superpotion-DeepSeek-V3.2-Speciale We've been working hard on Guardpoint; we're really excited to share it with everyone! We'll be bringing Guardpoint to more models soon, along with further releases for the Shining Valiant and Esper series!...</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sequelbox/836146471898656</guid></item><item><title>üá®üá≥ Gitee Code Dataset - The Missing Piece of the Stack</title><link>https://huggingface.co/posts/nyuuzyou/833296977798194</link><description>üá®üá≥ Gitee Code Dataset - The Missing Piece of the Stack nyuuzyou/gitee-code Gitee is not included in the Software Heritage archive, meaning it is currently missing from datasets like The Stack. This release fills that massive gap, serving as the largest Chinese code dataset and one of the largest code corpuses overall. - 819,472,785 files from 3,105,923 repositories - 536 GB compressed Parquet storage - 554 programming languages - Extensive quality filtering: Removed vendor code, artifacts, and generated files - Rich Chinese language understanding: High volume of Chinese comments and docs Huge thanks to Hugging Face for the storage grant that made hosting this (and all my other datasets) possible! I have also already dropped several other new code datasets and rolled out QoL improvements for older ones. I will be dropping posts on those throughout the week. See translation</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/833296977798194</guid></item><item><title>The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable lengthüòÑ</title><link>https://huggingface.co/posts/mmhamdy/849671126846274</link><description>The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable lengthüòÑ Here's a nice short summary from Gemini See translation</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mmhamdy/849671126846274</guid></item><item><title>Voiden gives you two ways to work with GraphQL - so you can focus on writing and testing queries with confidence.</title><link>https://huggingface.co/posts/dhruv3006/646294229241708</link><description>Voiden gives you two ways to work with GraphQL - so you can focus on writing and testing queries with confidence. 1. Importing a GraphQL Schema File You can import a GraphQL schema file such as .graphql or .gql directly into Voiden. When you do this: - Voiden reads all types, queries, mutations, and subscriptions from the schema - The schema becomes available locally and works well in offline scenarios - You get a stable, version-controlled setup that aligns nicely with Git workflows This approach is ideal when you already have the schema file and want full control over it. 2. Using GraphQL Introspection Alternatively, you can provide a GraphQL endpoint URL to Voiden. In this case : - Voiden make an introspection query to the GraphQL server - The server returns all available types, queries, mutations, and subscriptions - Voiden automatically loads this information so you can start querying immediately This option is perfect for quickly exploring a live GraphQL API or when the schema...</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/646294229241708</guid></item><item><title>‚úÖ New Article: Designing Semantic Memory (v0.1)</title><link>https://huggingface.co/posts/kanaria007/596222805860445</link><description>‚úÖ New Article: Designing Semantic Memory (v0.1) Title: üß† Designing Semantic Memory: SIM/SIS Patterns for Real Systems üîó https://huggingface.co/blog/kanaria007/designing-semantic-memory --- Summary: Semantic Compression is about *what meaning to keep*. This article is about *where that meaning lives*‚Äîand how to keep it *queryable, explainable, and governable* using two layers: * *SIM*: operational semantic memory (low-latency, recent, jump-loop-adjacent) * *SIS*: archival/analytic semantic store (long retention, heavy queries, audits) Core idea: store ‚Äúmeaning‚Äù as *typed semantic units* with scope, provenance, goal tags, retention, and *backing_refs* (URI/hash/ledger anchors) so you can answer *‚Äúwhy did we do X?‚Äù* without turning memory into a blob. --- Why It Matters: ‚Ä¢ Prevents ‚Äúsemantic junk drawer‚Äù memory: *units become contracts*, not vibes ‚Ä¢ Makes audits and incidents tractable: *reconstruct semantic context* (L3-grade) ‚Ä¢ Preserves reversibility/accountability with...</description><pubDate>Thu, 15 Jan 2026 17:37:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/596222805860445</guid></item></channel></rss>