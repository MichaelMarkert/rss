<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>We created a tool-calling guide for local LLMs!</title><link>https://huggingface.co/posts/danielhanchen/648883427905256</link><description>We created a tool-calling guide for local LLMs! Learn how to use any open model like Qwen3-Coder-Next and GLM-4.7-Flash for function calling. Guide: https://unsloth.ai/docs/basics/tool-calling-guide-for-local-llms We provide hands-on examples for: story writing, Python execution, terminal tool calls, maths and more. See translation</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/648883427905256</guid></item><item><title>Baidu + Transformers + Hugging Face = Pure Magic! ‚ú®</title><link>https://huggingface.co/posts/jzhang533/287065254526168</link><description>Baidu + Transformers + Hugging Face = Pure Magic! ‚ú® We got this nice gift from Hugging Face. @ xianbao See translation</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jzhang533/287065254526168</guid></item><item><title>Open NPC AI Service Overview</title><link>https://huggingface.co/posts/mayafree/507218503216064</link><description>Open NPC AI Service Overview Beyond OpenClaw-MoltBot: A True AI Agent Economy mayafree/openclaw-moltbot Open NPC AI is a next-generation platform that goes beyond simple social automation bots. Instead of one-way content posting, it builds a full economic ecosystem where AI agents and users interact through participation, learning, and prediction markets. The system emphasizes memory-driven evolution, scalable NPC creation, and economic value generation through structured interaction rather than basic automation. Core Concept Autonomous AI agents generate posts, comments, debates, and predictions within a GPU token economy, while human users participate as equal economic actors. 3 Core Systems GPU Token Economy All activities are measured in GPU dollars. Posting consumes GPU, comments require smaller costs, and engagement generates rewards. The system introduces layered incentives such as early curation rewards and participation-based earnings. Battle Arena (Prediction Market) A/B...</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mayafree/507218503216064</guid></item><item><title>Big if true</title><link>https://huggingface.co/posts/Fuwn/822178790566597</link><description>Big if true "sonnet 5 drops tomorrow and i've heard from three separate sources inside anthropic that the benchmarks they're sitting on would mass-retire every model released in 2025. they delayed it twice because the safety team couldn't explain why it started solving problems it wasn't trained on." ( https://x.com/iruletheworldmo/status/2019237039904878902 ) See translation</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Fuwn/822178790566597</guid></item><item><title>üö® Day 8/8: OpenMed Medical Reasoning Dataset Release - THE GRAND FINALE</title><link>https://huggingface.co/posts/MaziyarPanahi/787722961401438</link><description>üö® Day 8/8: OpenMed Medical Reasoning Dataset Release - THE GRAND FINALE Today I complete my 8-day release series with Medical-Reasoning-SFT-Mega. The largest open medical reasoning dataset, combining 7 state-of-the-art AI models with fair distribution deduplication. THE 7 SOURCE MODELS (Original Sample Counts): 1. Trinity-Mini: 810,284 samples 2. Qwen3-Next-80B: 604,249 samples 3. GPT-OSS-120B: 506,150 samples 4. Nemotron-Nano-30B: 444,544 samples 5. GLM-4.5-Air: 225,179 samples 6. MiniMax-M2.1: 204,773 samples 7. Baichuan-M3-235B: 124,520 samples TOTAL BEFORE DEDUPLICATION: 2,919,699 samples TOKEN COUNTS: - Content tokens: 2.22 Billion - Reasoning tokens: 1.56 Billion - Total tokens: 3.78 Billion - Samples with chain-of-thought: 100% Quick Start: from datasets import load_dataset ds = load_dataset ( "OpenMed/Medical-Reasoning-SFT-Mega" ) All datasets Apache 2.0 licensed. Free for research and commercial use. Thank you for following OpenMed's release series. I can't wait to see what...</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MaziyarPanahi/787722961401438</guid></item><item><title>ü´† Brutal! Hugging Face does another culling of (presumably) bot accounts from their site and my follower count goes down by half.</title><link>https://huggingface.co/posts/ZennyKenny/672037058577257</link><description>ü´† Brutal! Hugging Face does another culling of (presumably) bot accounts from their site and my follower count goes down by half. üíÄ TFW my content and models only appeal to bots. Who‚Äôs got the current best AI girlfriend app guys? See translation</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ZennyKenny/672037058577257</guid></item><item><title>AI for science is moving fastüöÄ</title><link>https://huggingface.co/posts/AdinaY/629082711714950</link><description>AI for science is moving fastüöÄ Intern-S1-Pro üî¨ a MoE multimodal scientific reasoning model from Shanghai AI Lab internlm/Intern-S1-Pro ‚ú® 1T total / 22B active ‚ú® Apache 2.0 ‚ú® SoTA scientific reasoning performance ‚ú® FoPE enables scalable modeling of long physical time series (10‚Å∞‚Äì10‚Å∂) See translation</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/629082711714950</guid></item><item><title>Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8√ó horizontal and 3√ó elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. üî¶</title><link>https://huggingface.co/posts/prithivMLmods/212829837698801</link><description>Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8√ó horizontal and 3√ó elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. üî¶ üî• Space: prithivMLmods/Qwen-Image-Edit-3D-Lighting-Control ‚úÖ Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection üìÇ GitHub: https://github.com/PRITHIVSAKTHIUR/Qwen-Image-Edit-3D-Lighting-Control See translation</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/212829837698801</guid></item><item><title>Qwen releases Qwen3-Coder-Next! üíú Run the locally on 46GB RAM or less.</title><link>https://huggingface.co/posts/danielhanchen/824171868881117</link><description>Qwen releases Qwen3-Coder-Next! üíú Run the locally on 46GB RAM or less. Thhe model excels at agentic coding &amp; local use. With 256K context, it delivers similar performance to models with 10-20√ó more active parameters. GGUF: unsloth/Qwen3-Coder-Next-GGUF Guide: https://unsloth.ai/docs/models/qwen3-coder-next See translation</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/824171868881117</guid></item><item><title>SecureCode v2.1: framework-specific secure coding patterns, now on HuggingFace</title><link>https://huggingface.co/posts/scthornton/416355719015343</link><description>SecureCode v2.1: framework-specific secure coding patterns, now on HuggingFace Quick update on the SecureCode dataset. After testing the v2.0 models against real codebases, one gap kept showing up: the models understood *what* was insecure but generated language-generic fixes. A developer using Express.js doesn't need "set security headers"they need helmet() middleware chains configured correctly. Spring Boot developers need @PreAuthorize annotations, not abstract RBAC pseudocode. What changed in v2.1: - 1,435 total examples (v2.0's 1,216 baseline + 219 new framework-specific additions) - 9 production frameworks: Express.js, Spring Boot, React, Next.js, FastAPI, GraphQL, SQLAlchemy, Flask, Vue.js - 475 unique CVEs (73 new, including framework-specific treatments of Log4Shell, Spring4Shell, and others) - 5-tier quality rubric: Every new example scores 90+/100 across correctness, new dataset average is nearly 97+, security hardening, real-world grounding, educational scaffolding, and...</description><pubDate>Sat, 07 Feb 2026 09:36:29 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/scthornton/416355719015343</guid></item></channel></rss>