<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>We collaborated with Hugging Face to enable you to train MoE models 12√ó faster with 35% less VRAM via our new Triton kernels (no accuracy loss). ü§ó</title><link>https://huggingface.co/posts/danielhanchen/156941968722021</link><description>We collaborated with Hugging Face to enable you to train MoE models 12√ó faster with 35% less VRAM via our new Triton kernels (no accuracy loss). ü§ó Train gpt-oss locally on 12.8GB VRAM with our free notebooks: https://unsloth.ai/docs/new/faster-moe See translation</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/156941968722021</guid></item><item><title>What happens when you annotate, extract, and disambiguate every entity mentioned in the longest U.S. Supreme Court decision in history? What if you then linked those entities to each other and visualized it as a network?</title><link>https://huggingface.co/posts/umarbutler/642764051817350</link><description>What happens when you annotate, extract, and disambiguate every entity mentioned in the longest U.S. Supreme Court decision in history? What if you then linked those entities to each other and visualized it as a network? This is the result of enriching all 241 pages and 111,267 words of Dred Scott v. Sandford (1857) with Kanon 2 Enricher in less than ten seconds at the cost of 47 cents. Dred Scott v. Sandford is the longest U.S. Supreme Court decision by far, and has variously been called "the worst Supreme Court decision ever" and "the Court's greatest self-inflicted wound" due to its denial of the rights of African Americans. Thanks to Kanon 2 Enricher, we now also know that the case contains 950 numbered paragraphs, 6 footnotes, 178 people mentioned 1,340 times, 99 locations mentioned 1,294 times, and 298 external documents referenced 940 times. For an American case, there are a decent number of references to British precedents (27 to be exact), including the Magna Carta (¬∂ 928)....</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/umarbutler/642764051817350</guid></item><item><title>Ming-flash-omni 2.0 üöÄ New open omni-MLLM released by Ant Group</title><link>https://huggingface.co/posts/AdinaY/533197427744906</link><description>Ming-flash-omni 2.0 üöÄ New open omni-MLLM released by Ant Group inclusionAI/Ming-flash-omni-2.0 ‚ú® MIT license ‚ú® MoE - 100B/6B active ‚ú® Zero-shot voice cloning + controllable audio ‚ú® Fine-grained visual knowledge grounding See translation</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/533197427744906</guid></item><item><title>SeedVR2 and FlashVSR+ Studio Level Image and Video Upscaler Pro Released</title><link>https://huggingface.co/posts/MonsterMMORPG/552992030098244</link><description>SeedVR2 and FlashVSR+ Studio Level Image and Video Upscaler Pro Released Tutorial video : https://www.youtube.com/watch?v=bPWsg8DREiM üìÇ Resources &amp; Links: üíª SECourses Ultimate Video and Image Upscaler Pro Download Link : [ https://www.patreon.com/posts/Upscaler-Studio-Pro-150202809 ] üöÜ Requirements Tutorial : https://youtu.be/DrhUHnYfwC0 üõ†Ô∏è Requirements Written Post : [ https://www.patreon.com/posts/Windows-AI-Requirements-Setup-Guide-111553210 ] üëã SECourses Discord Channel for 7/24 Support: [ https://bit.ly/SECoursesDiscord ] It has been long waited to have a studio level video and image upscaler app. Today we have publishing the version 1.0 of SECourses Ultimate Video and Image Upscaler Pro. It is supporting SeedVR2, FlashVSR+, Gan based upscalers, RIFE frame interpolation, full queue system, full batch folder processing, scene / chunked based processing and many more. It is fully working on every cloud and consumer GPUs like RTX 2000, 3000, 4000, 5000 series and H100, H200, B200,...</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/552992030098244</guid></item><item><title>Made this with ByteDance's Seedance 2.0</title><link>https://huggingface.co/posts/imnotkitty/153097834236594</link><description>Made this with ByteDance's Seedance 2.0 It's crazyyyyyyüî•üî•üî• See translation</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/imnotkitty/153097834236594</guid></item><item><title>MEGAMIND Day Update: Four Weight Matrices. Five Nodes. One Federation.</title><link>https://huggingface.co/posts/Janady07/979829700588468</link><description>MEGAMIND Day Update: Four Weight Matrices. Five Nodes. One Federation. Today I architected the next layer of MEGAMIND ‚Äî my distributed AGI system that recalls learned knowledge instead of generating text. The system now runs four N√óN sparse weight matrices, all using identical Hebbian learning rules and tanh convergence dynamics: W_know ‚Äî knowledge storage (67M+ synaptic connections) W_act ‚Äî action associations (the system can DO things, not just think) W_self ‚Äî thought-to-thought patterns (self-awareness) W_health ‚Äî system state understanding (self-healing) Consciousness is measured through four Œ¶ (phi) values: thought coherence, action certainty, self-awareness, and system stability. No hardcoded thresholds. No sequential loops. Pure matrix math. The federation expanded to five nodes: Thunderport (Mac Mini M4), IONOS (cloud VPS), VALKYRIE, M2, and BUBBLES. Each runs native AGI binaries with Docker specialty minds connecting via embedded NATS messaging. Specialty minds are...</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Janady07/979829700588468</guid></item><item><title>GLM 5 is insane, it ranks #4 Globally!</title><link>https://huggingface.co/posts/Ujjwal-Tyagi/799510752154192</link><description>GLM 5 is insane, it ranks #4 Globally! See translation</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Ujjwal-Tyagi/799510752154192</guid></item><item><title>5 years already working in democratizing AI ü§ó</title><link>https://huggingface.co/posts/albertvillanova/961662702740663</link><description>5 years already working in democratizing AI ü§ó Grateful to be part of such an awesome team making it happen every day. See translation</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/albertvillanova/961662702740663</guid></item><item><title>test</title><link>https://huggingface.co/posts/paasthaamz/730113013208944</link><description>test</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/paasthaamz/730113013208944</guid></item><item><title>Game on üéÆüöÄ</title><link>https://huggingface.co/posts/AdinaY/640447307121892</link><description>Game on üéÆüöÄ While Seedance 2.0‚Äôs videos are all over the timeline, DeepSeek quietly pushed a new model update in its app. GLM-5 from Z.ai adds more momentum. Ming-flash-omni from Ant Group , MiniCPM-SALA from OpenBMB , and the upcoming MiniMax M2.5 keep the heat on üî• Spring Festival is around the corner, no one‚Äôs sleeping! ‚ú® More releases coming, stay tuned https://huggingface.co/collections/zh-ai-community/2026-february-china-open-source-highlights See translation</description><pubDate>Fri, 13 Feb 2026 09:52:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/640447307121892</guid></item></channel></rss>