<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸ¨ Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition ğŸŒâœ¨</title><link>https://huggingface.co/posts/seawolf2357/883323339740165</link><description>ğŸ¨ Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition ğŸŒâœ¨ Hello creators! Today I'm introducing a special image generator that combines the beautiful aesthetics of Studio Ghibli with multilingual text integration! ğŸ˜ seawolf2357/Ghibli-Multilingual-Text-rendering âœ¨ Key Features Ghibli-Style Image Generation - High-quality animation-style images based on FLUX.1 Multilingual Text Rendering - Support for Korean, Japanese, English, and all languages! ğŸ‡°ğŸ‡·ğŸ‡¯ğŸ‡µğŸ‡¬ğŸ‡§ Automatic Image Editing with Simple Prompts - Just input your desired text and you're done! Two Stylistic Variations Provided - Get two different results from a single prompt Full Hugging Face Spaces Support - Deploy and share instantly! ğŸš€ How Does It Work? Enter a prompt describing your desired image (e.g., "a cat sitting by the window") Input the text you want to add (any language works!) Select the text position, size, and color Two different versions are automatically generated! ğŸ’¯...</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/seawolf2357/883323339740165</guid></item><item><title>ğŸ¯ Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! âœ¨</title><link>https://huggingface.co/posts/ginipick/807578740801859</link><description>ğŸ¯ Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! âœ¨ Hello AI enthusiasts! ğŸ™‹â€â™€ï¸ Today I'm introducing a truly magical project: Open Ghibli Studio ğŸ¨ ginigen/FLUX-Open-Ghibli-Studio ğŸŒŸ What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! ğŸï¸âœ¨ ğŸ”§ How Does It Work? ğŸ“¸ Upload your photo ğŸ¤– Florence-2 AI analyzes the image and generates a description âœï¸ "Ghibli style" is added to the description ğŸ­ Magic transformation happens using the FLUX.1 model and Ghibli LoRA! âš™ï¸ Customization Options Want more control? Adjust these in the advanced settings: ğŸ² Set a seed (for reproducible results) ğŸ“ Adjust image dimensions ğŸ” Guidance scale (prompt adherence) ğŸ”„ Number of generation steps ğŸ’« Ghibli style intensity ğŸš€ Try It Now! Click the "Transform to Ghibli Style" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? ğŸŒˆ ğŸŒ¿ Note: For best results,...</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/807578740801859</guid></item><item><title>ğŸ”¥ 'Open Meme Studio': Your Creative Meme Factory ğŸ­âœ¨</title><link>https://huggingface.co/posts/openfree/925352420925810</link><description>ğŸ”¥ 'Open Meme Studio': Your Creative Meme Factory ğŸ­âœ¨ Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. ğŸš€ VIDraft/Open-Meme-Studio ğŸ¯ Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! ğŸ› ï¸ Features You'll Love ğŸ“¸ Transform and reinterpret existing meme templates ğŸ­ Freely change expressions and poses ğŸ‘“ Add props (sunglasses, hats, etc.) ğŸï¸ Change backgrounds and composite characters ğŸ¨ Apply various artistic styles ğŸ’ª Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/925352420925810</guid></item><item><title>ğŸš€ Rapidata: Setting the Standard for Model Evaluation</title><link>https://huggingface.co/posts/jasoncorkill/394806250895359</link><description>ğŸš€ Rapidata: Setting the Standard for Model Evaluation Rapidata is proud to announce our first independent appearance in academic research, featured in the Lumina-Image 2.0 paper. This marks the beginning of our journey to become the standard for testing text-to-image and generative models. Our expertise in large-scale human annotations allows researchers to refine their models with accurate, real-world feedback. As we continue to establish ourselves as a key player in model evaluation, weâ€™re here to support researchers with high-quality annotations at scale. Reach out to info@rapidata.ai to see how we can help. Lumina-Image 2.0: A Unified and Efficient Image Generative Framework (2503.21758) See translation</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jasoncorkill/394806250895359</guid></item><item><title>JOURNEY TO 1 MILLION DEVELOPERS</title><link>https://huggingface.co/posts/abidlabs/192598522318521</link><description>JOURNEY TO 1 MILLION DEVELOPERS 5 years ago, we launched Gradio as a simple Python library to let researchers at Stanford easily demo computer vision models with a web interface. Today, Gradio is used by &gt;1 million developers each month to build and share AI web apps. This includes some of the most popular open-source projects of all time, like Automatic1111, Fooocus, Oobaboogaâ€™s Text WebUI, Dall-E Mini, and LLaMA-Factory. How did we get here? How did Gradio keep growing in the very crowded field of open-source Python libraries? I get this question a lot from folks who are building their own open-source libraries. This post distills some of the lessons that I have learned over the past few years: 1. Invest in good primitives, not high-level abstractions 2. Embed virality directly into your library 3. Focus on a (growing) niche 4. Your only roadmap should be rapid iteration 5. Maximize ways users can consume your library's outputs 1. Invest in good primitives, not high-level...</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/192598522318521</guid></item><item><title>To Meta AI Research: I would like to fold</title><link>https://huggingface.co/posts/hexgrad/182254197987426</link><description>To Meta AI Research: I would like to fold ylacombe/expresso into the training mix of an Apache TTS model series. Can you relax the Expresso dataset license to CC-BY or more permissive? Barring that, can I have an individual exception to train on the materials and distribute trained Apache models, without direct redistribution of the original files? Thanks! CC (Expresso paper authors whose handles I could find on HF) @ wnhsu @ adavirro @ bowenshi @ itaigat @ TalRemez @ JadeCopet @ hassid @ felixkreuk @ adiyoss @ edupoux See translation</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hexgrad/182254197987426</guid></item><item><title>Did we just drop personalized AI evaluation?! This tool auto-generates custom benchmarks on your docs to test which models are the best.</title><link>https://huggingface.co/posts/fdaudens/934723096237481</link><description>Did we just drop personalized AI evaluation?! This tool auto-generates custom benchmarks on your docs to test which models are the best. Most benchmarks test general capabilities, but what matters is how models handle your data and tasks. YourBench helps answer critical questions like: - Do you really need a hundreds-of-billions-parameter model sledgehammer to crack a nut? - Could a smaller, fine-tuned model work better? - How well do different models understand your domain? Some cool features: ğŸ“š Generates custom benchmarks from your own documents (PDFs, Word, HTML) ğŸ¯ Tests models on real tasks, not just general capabilities ğŸ”„ Supports multiple models for different pipeline stages ğŸ§  Generate both single-hop and multi-hop questions ğŸ” Evaluate top models and deploy leaderboards instantly ğŸ’° Full cost analysis to optimize for your budget ğŸ› ï¸ Fully configurable via a single YAML file 26 SOTA models tested for question generation. Interesting finding: Qwen2.5 32B leads in question...</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/934723096237481</guid></item><item><title>Dolphin ğŸ¬ an open ASR model released by DataOceanAI, one of the biggest AI data provider in China ğŸ”¥</title><link>https://huggingface.co/posts/AdinaY/602638381866736</link><description>Dolphin ğŸ¬ an open ASR model released by DataOceanAI, one of the biggest AI data provider in China ğŸ”¥ âœ¨ Supports 40 Eastern languages &amp; 22 Chinese dialects âœ¨ Apache2.0 âœ¨ With 21.2M hours of data (7.4M open data) Model: DataoceanAI/dolphin-base DataoceanAI/dolphin-small Paper: Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages (2503.20212) See translation</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/602638381866736</guid></item><item><title>I added OneSQL 3B to the model family, and its GGUF/AWQ/MLX quantizations. This model can fit into more places, and comfortably run on Apple M1 devices with twice the throughput (half the generation time) of its 7B sibling.</title><link>https://huggingface.co/posts/onekq/698802607217100</link><description>I added OneSQL 3B to the model family, and its GGUF/AWQ/MLX quantizations. This model can fit into more places, and comfortably run on Apple M1 devices with twice the throughput (half the generation time) of its 7B sibling. onekq-ai/onesql-v01-qwen-67d8e3eb1611c5532bb90c5f See translation</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/698802607217100</guid></item><item><title>ğŸš¨ Hot Take: GPT-4o might NOT be a purely autoregressive model! ğŸš¨</title><link>https://huggingface.co/posts/BestWishYsh/635596686204705</link><description>ğŸš¨ Hot Take: GPT-4o might NOT be a purely autoregressive model! ğŸš¨ Thereâ€™s a high chance it has a diffusion head. ğŸ¤¯ If true, this could be a game-changer for AI architecture. What do you think? ğŸ¤”ğŸ‘‡ Code: https://github.com/PicoTrex/GPT-ImgEval Paper: GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation (2504.02782) See translation</description><pubDate>Fri, 04 Apr 2025 13:30:13 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/BestWishYsh/635596686204705</guid></item></channel></rss>