<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>6 Comprehensive Resources on AI Coding</title><link>https://huggingface.co/posts/Kseniase/300455492795256</link><description>6 Comprehensive Resources on AI Coding AI coding is moving fast, and itâ€™s getting harder to tell what actually works. Agents, workflows, context management and many other aspects are reshaping how software gets built. Weâ€™ve collected a set of resources to help you understand how AI coding is evolving today and what building strategies work best: 1. AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities (2508.11126) Provides a clear taxonomy, compares agent architectures, and exposes practical gaps in tools, benchmarks, and reliability that AI coding agents now struggle with 2. Does AI-Assisted Coding Deliver? A Difference-in-Differences Study of Cursor's Impact on Software Projects (2511.04427) This survey from Carnegie Mellon University shows causal evidence that LLM agent assistants deliver short-term productivity gains but have lasting quality costs that can slow development over time 3. A Survey of Vibe Coding with Large Language Models (2510.12399) Turns...</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/300455492795256</guid></item><item><title>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! ğŸ”¥</title><link>https://huggingface.co/posts/danielhanchen/963278821580490</link><description>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! ğŸ”¥ Has 1M context window &amp; best in class performance for SWE-Bench, reasoning &amp; chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF ğŸ’š Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/963278821580490</guid></item><item><title>Check out your 2025 Hugging Face Wrapped, a small experimental recap</title><link>https://huggingface.co/posts/daqc/540565360726745</link><description>Check out your 2025 Hugging Face Wrapped, a small experimental recap hf-wrapped/2025 See translation</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/daqc/540565360726745</guid></item><item><title>Intelligent Inpainting for Precise Creative Control ğŸ¨âœ¨</title><link>https://huggingface.co/posts/DawnC/393405474084583</link><description>Intelligent Inpainting for Precise Creative Control ğŸ¨âœ¨ Transform your images with AI-powered precision! SceneWeaver delivers professional-quality image composition with intelligent background replacement and advanced object manipulation. What's New in This Update? ğŸ–Œï¸ Object Replacement â€” Select and transform any element in your scene with natural language prompts while maintaining perfect visual consistency with surrounding content ğŸ—‘ï¸ Object Removal â€” Intelligently remove unwanted objects with context-aware generation that preserves natural lighting, shadows, and scene coherence ğŸ¯ Context-Aware Processing â€” Advanced inpainting technology ensures seamless integration across all regenerated regions Core Capabilities âš¡ One-click transformation with smart subject detection, 24 curated professional backgrounds, custom scene generation through text prompts, and studio-quality results powered by BiRefNet, Stable Diffusion XL, and ControlNet Inpainting. Current Infrastructure &amp; Future...</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/393405474084583</guid></item><item><title>ğŸš€ Introducing VideoCoF: Unified Video Editing with a Temporal Reasoner (Chain-of-Frames)!</title><link>https://huggingface.co/posts/sanaka87/963485970840656</link><description>ğŸš€ Introducing VideoCoF: Unified Video Editing with a Temporal Reasoner (Chain-of-Frames)! Weâ€™re excited to introduce VideoCoF, a unified framework for instruction-based video editing that enables temporal reasoning and ~4Ã— video length extrapolation, trained with only 50k video pairs. ğŸ”¥ ğŸ” What makes VideoCoF different? ğŸ§  Chain-of-Frames reasoning , mimic human thinking process like Seeing â†’ Reasoning â†’ Editing to apply edits accurately over time without external masks, ensuring physically plausible results. ğŸ“ˆ Strong length generalization â€” trained on 33-frame clips, yet supports multi-shot editing and long-video extrapolation (~4Ã—). ğŸ¯ Unified fine-grained editing â€” Object Removal, Addition, Swap, and Local Style Transfer, with instance-level &amp; part-level, spatial-aware control. âš¡ Fast inference update ğŸš€ H100: ~20s / video with 4-step inference, making high-quality video editing far more practical for real-world use. ğŸ”— Links ğŸ“„ Paper: https://arxiv.org/abs/2512.07469 ğŸ’» Code:...</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sanaka87/963485970840656</guid></item><item><title>ğŸ“¢ For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios.</title><link>https://huggingface.co/posts/nicolay-r/350400879019559</link><description>ğŸ“¢ For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios. ğŸŒŸ bulk-chain: https://github.com/nicolay-r/bulk-chain ğŸ”‘ This features the no-string framework for quierrying LLMs in various modes: sync, async and with optional support for output streaming. ğŸ“¦ï¸ In the latest 1.2.0 release, the updates on outlining API parameters for inference mode. ğŸŒŸ Integration into web: https://github.com/nicolay-r/bulk-chain-web-integration See translation</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/350400879019559</guid></item><item><title>Making LLMs fast with KV-cache sharing is great. A new paper reports it's also a huge privacy risk.</title><link>https://huggingface.co/posts/MikeDoes/696146647062201</link><description>Making LLMs fast with KV-cache sharing is great. A new paper reports it's also a huge privacy risk. That's why we're excited to see the "SafeKV" paper from researchers at the University of Connecticut, Peking University, and others. Their solution-oriented framework selectively shares non-sensitive data while isolating PII. To validate the "Safe" part of their system, they needed a robust, multilingual privacy benchmark. We're proud that the Ai4Privacy pii-masking dataset was used for this critical evaluation related to privacy. This is a perfect win-win. Our open-source data enables researchers to build and validate more effective security solutions for core AI infrastructure. Their work, in turn, helps make the entire LLM ecosystem safer, showing that performance and privacy don't have to be mutually exclusive. Kudos to Kexin Chu, Zecheng Lin, Dawei Xiang, æ²ˆå­æ—­, Jianchang Su, cheng chu, Yiwei Yang, Wenhui Zhang, Wenfei Wu, and Wei Zhang on this beautiful work. ğŸ”— Check out their...</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/696146647062201</guid></item><item><title>New Preview Model:</title><link>https://huggingface.co/posts/unmodeled-tyler/439099944779481</link><description>New Preview Model: unmodeled-tyler/vanta-research-loux-preview VANTA Research is excited to announce a small lab preview of our new 675B fine tune, Loux-Large. Loux is an AI model with a sophisticated, rebellious edge designed to assist and collaborate with engineers, builders, and people working on technical projects. If you enjoy working with Loux and would like full access, let us know by liking the space or opening a discussion in the community! See translation</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/439099944779481</guid></item><item><title>How POTUS Completely Broke My Flash 2.5-Based Guardrail</title><link>https://huggingface.co/posts/martinsu/283521322948177</link><description>https://huggingface.co/blog/martinsu/potus-broke-my-pipeline How POTUS Completely Broke My Flash 2.5-Based Guardrail Did quite a bit of deep research on this one, since it IMHO matters. At first I used this story to amuse fellow MLOps guys, but then I went deeper and was surprised. To those who don't want to read too much, in plain English: when you give the model a high-stakes statement that clashes with what it "knows" about the world, it gets more brittle. Sometimes to a point of being unusable. Or an even shorter version: do not clash with the model's given worldviewâ€”it will degrade to some extent. And in practice, it means that in lower-resource languages like Latvian and Finnish (and probably others), Flash 2.5 is an unreliable guardrail model when something clashes with the model's general "worldview". However, I'm sure this degradation applies to other languages and models as well to varying extents. In one totally normal week of MLOps, my news summarization pipeline started...</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/martinsu/283521322948177</guid></item><item><title>ğŸ¦â€ğŸ”¥ I've just published Sentence Transformers v5.2.0! It introduces multi-processing for CrossEncoder (rerankers), multilingual NanoBEIR evaluators, similarity score outputs in mine_hard_negatives, Transformers v5 support and more. Details:</title><link>https://huggingface.co/posts/tomaarsen/853653818134091</link><description>ğŸ¦â€ğŸ”¥ I've just published Sentence Transformers v5.2.0! It introduces multi-processing for CrossEncoder (rerankers), multilingual NanoBEIR evaluators, similarity score outputs in mine_hard_negatives, Transformers v5 support and more. Details: - CrossEncoder multi-processing: Similar to SentenceTransformer and SparseEncoder, you can now use multi-processing with CrossEncoder rerankers. Useful for multi-GPU and CPU settings, and simple to configure: just device=["cuda:0", "cuda:1"] or device=["cpu"]*4 on the model.predict or model.rank calls. - Multilingual NanoBEIR Support: You can now use community translations of the tiny NanoBEIR retrieval benchmark instead of only the English one, by passing dataset_id , e.g. dataset_id="lightonai/NanoBEIR-de" for the German benchmark. - Similarity scores in Hard Negatives Mining: When mining for hard negatives to create a strong training dataset, you can now pass output_scores=True to get similarity scores returned. This can be useful for some...</description><pubDate>Tue, 16 Dec 2025 09:31:27 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tomaarsen/853653818134091</guid></item></channel></rss>