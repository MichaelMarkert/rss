<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Exciting New Tool for Knowledge Graph Extraction from Plain Text!</title><link>https://huggingface.co/posts/singhsidhukuldeep/815565847250252</link><description>Exciting New Tool for Knowledge Graph Extraction from Plain Text! I just came across a groundbreaking new tool called KGGen that's solving a major challenge in the AI world - the scarcity of high-quality knowledge graph data. KGGen is an open-source Python package that leverages language models to extract knowledge graphs (KGs) from plain text. What makes it special is its innovative approach to clustering related entities, which significantly reduces sparsity in the extracted KGs. The technical approach is fascinating: 1. KGGen uses a multi-stage process involving an LLM (GPT-4o in their implementation) to extract entities and relations from source text 2. It aggregates graphs across sources to reduce redundancy 3. Most importantly, it applies iterative LM-based clustering to refine the raw graph The clustering stage is particularly innovative - it identifies which nodes and edges refer to the same underlying entities or concepts. This normalizes variations in tense, plurality,...</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/singhsidhukuldeep/815565847250252</guid></item><item><title>Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months!</title><link>https://huggingface.co/posts/clem/866977064333227</link><description>Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months! Nvidia's org: https://huggingface.co/nvidia Enterprise hub: https://huggingface.co/enterprise See translation</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/866977064333227</guid></item><item><title>ü•ä Epic Agent Framework Showdown! Available today!</title><link>https://huggingface.co/posts/davidberenstein1957/655300080970392</link><description>ü•ä Epic Agent Framework Showdown! Available today! üîµ In the blue corner, the versatile challenger with a proven track record of knowledge retrieval: LlamaIndex! üõë In the red corner, the defender, weighing in with lightweight efficiency: Hugging Face smolagents! üîó URL: https://huggingface.co/agents-course We just published the LlamaIndex unit for the agents course, and it is set to offer a great contrast between the smolagents unit by looking at - What makes llama-index stand-out - How the LlamaHub is used for integrations - Creating QueryEngine components - Using agents and tools - Agentic and multi-agent workflows The team has been working flat-out on this for a few weeks. Supported by Logan Markewich and Laurie Voss over at LlamaIndex. Who won? You decide! See translation</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/davidberenstein1957/655300080970392</guid></item><item><title>Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949</link><description>Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free! duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset Access the full size dataset by creating an EDU account here- https://falcon.duality.ai/secure/documentation/ex3-dataset?sidebarMode=learn Or check it out in the linked HuggingFace dataset! What makes this dataset unique, useful, and capable of bridging the Sim2Real gap? üí† The digital twins are not generated by AI, but instead crafted by 3D artists to be INDISTINGUISHABLE from the physical-world objects. This allows the training from this data to transfer into real-world applicability üí† The simulation software, called FalconEditor, can easily create thousands of images with varying lighting, posing, occlusions, backgrounds, camera positions, and more. This enables robust model training. üí† The labels are created along with the data. This not only saves large amounts of time, but also ensures the...</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949</guid></item><item><title>Published a stable version of Ukrainian Text-to-Speech library on GitHub and PyPI.</title><link>https://huggingface.co/posts/Yehor/619825346186306</link><description>Published a stable version of Ukrainian Text-to-Speech library on GitHub and PyPI. Features: - Multi-speaker model: 2 female (Tetiana, Lada) + 1 male (Mykyta) voices; - Fine-grained control over speech parameters, including duration, fundamental frequency (F0), and energy; - High-fidelity speech generation using the RAD-TTS++ acoustic model; - Fast vocoding using Vocos; - Synthesizes long sentences effectively; - Supports a sampling rate of 44.1 kHz; - Tested on Linux environments and Windows/WSL; - Python API (requires Python 3.9 or later); - CUDA-enabled for GPU acceleration. Repository: https://github.com/egorsmkv/tts_uk See translation</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Yehor/619825346186306</guid></item><item><title>9 types of "Chain-of-..." approaches:</title><link>https://huggingface.co/posts/Kseniase/433849056207490</link><description>9 types of "Chain-of-..." approaches: Chain-of-Thought (CoT) prompting enhances reasoning in AI models by breaking down complex problems into step-by-step logical sequences. It continues proving its effectiveness, especially in top-performing reasoning models. However, there are other similar methods, that expand CoT and can be used for different purposes. Here are 9 of them: 1. Chain-of-Action-Thought (COAT) -&gt; Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search (2502.02508) Helps model decide when to keep thinking, double-check their work, or try a different approach, using special guiding tokens. 2. Chain of Draft (CoD) -&gt; Chain of Draft: Thinking Faster by Writing Less (2502.18600) It helps model generate short but meaningful reasoning steps, cutting costs and making processing faster 3. Chain-of-Agents -&gt; Chain of Agents: Large Language Models Collaborating on Long-Context Tasks (2406.02818) Uses multi-agent...</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/433849056207490</guid></item><item><title>ü´∏ New release to push vector search to the Hub with vicinity and work with any serialisable objects.</title><link>https://huggingface.co/posts/davidberenstein1957/915880767531433</link><description>ü´∏ New release to push vector search to the Hub with vicinity and work with any serialisable objects. üßë‚Äçüè´ KNN, HNSW, USEARCH, ANNOY, PYNNDESCENT, FAISS, and VOYAGER. üîó Example Repo: minishlab/my-vicinity-repo See translation</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/davidberenstein1957/915880767531433</guid></item><item><title>ü•≥ü•≥Just achieved 25m 59s of research with plain ChatGPT üî• Had it doing a complete internet search in just ONE call visiting 443 websites! Hard to beat huh!</title><link>https://huggingface.co/posts/luigi12345/685788730899562</link><description>ü•≥ü•≥Just achieved 25m 59s of research with plain ChatGPT üî• Had it doing a complete internet search in just ONE call visiting 443 websites! Hard to beat huh! PROMPT IN COMMENTS Check out the Massive Article created by the prompt: https://huggingface.co/blog/luigi12345/automating-lead-generation-with-ai See translation</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/luigi12345/685788730899562</guid></item><item><title>MoD ControlNet Tile Upscaler for SDXL: Upscale Your Images with Ease! üöÄ</title><link>https://huggingface.co/posts/elismasilva/752242610998926</link><description>MoD ControlNet Tile Upscaler for SDXL: Upscale Your Images with Ease! üöÄ Meet the MoD ControlNet Tile Upscaler for SDXL, a powerful tool that uses advanced technology to upscale your images without losing quality! Our app is designed to process images in tiles without leaving them blurry or with visible lines between the tiles. The result? Upscaled images with preserved details and smooth, natural transitions‚Äîall through a user-friendly interface. ‚ú® What MoD Upscaler Offers: üîç Preserved Details: Unlike traditional upscalers, the MoD ControlNet Tile Upscaler enlarges your images while maintaining clarity and adding details that might otherwise be lost. Your photos gain more definition without sacrificing original quality. üß© Advanced Tiling Technology: We use a smart combination of techniques to ensure natural and smooth transitions between tiles. This means your upscaled images remain consistent and high-quality, even at higher resolutions. No more visible lines or imperfections! ‚ö°...</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/elismasilva/752242610998926</guid></item><item><title>Exciting releases from the Chinese community this Februaryüî•</title><link>https://huggingface.co/posts/AdinaY/776127015570604</link><description>Exciting releases from the Chinese community this Februaryüî• üëâ zh-ai-community/2025-february-67a35aaa68e97812def5b6ef MLLM: ‚ú® Ovis2 by Alibaba AIDC-AI/ovis2-67ab36c7e497429034874464 ‚ú® Step Audio Chat by StepFun AI stepfun-ai/step-audio-67b33accf45735bb21131b0b Audio: ‚ú® Step Audio TTS by StepFunAI stepfun-ai/Step-Audio-TTS-3B ‚ú® InspireMusic by Alibaba https://huggingface.co/FunAudioLLM ‚ú® Baichuan Audio by BaichuanAI baichuan-inc/Baichuan-Audio-Instruct Video: ‚ú® Wan2.1 by Alibaba_Wan Wan-AI/Wan2.1-T2V-14B ‚ú® Stepvideo-T2V by StepFun AI stepfun-ai/stepvideo-t2v ‚ú® SkyReels-V1 by Skywork Skywork/skyreels-v1-67b34676ff65b4ec02d16307 ‚ú® LLaDA-8B by RenminUniversity GSAI-ML/LLaDA-8B-Instruct MoE: ‚ú® Moonlight-16B by MoonshotAI (Kimi) moonshotai/Moonlight-16B-A3B-Instruct Reasoning: ‚ú® TinyR1-32B by Qihoo360 qihoo360/TinyR1-32B-Preview Dataset: ‚ú® Chinese DeepSeek R1-Distill data -110k Congliu/Chinese-DeepSeek-R1-Distill-data-110k See translation</description><pubDate>Wed, 05 Mar 2025 13:28:28 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/776127015570604</guid></item></channel></rss>