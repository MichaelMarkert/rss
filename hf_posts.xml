<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>6 Essential Reads on core AI/ML topics:</title><link>https://huggingface.co/posts/Kseniase/570379597864718</link><description>6 Essential Reads on core AI/ML topics: Time to look at some free useful resources that can help you upgrade your knowledge of AI and machine learning! Today we offer you these 6 must-read surveys that can be your perfect guides to the major fields and techniques: 1. Foundations of Large Language Models by Tong Xiao and Jingbo Zhu ‚Üí https://arxiv.org/abs/2501.09223 Many recommend this 270-page book as a good resource to focus on fundamental concepts, such as pre-training, generative models, prompting, alignment, and inference 2. Large Language Models Post-Training: Surveying Techniques from Alignment to Reasoning -&gt; A Survey on Post-training of Large Language Models (2503.06072) Read this to master policy optimization (RLHF, DPO, GRPO), supervised and parameter-efficient fine-tuning, reasoning, integration, and adaptation techniques 3. Agentic Large Language Models, a survey by Leiden University ‚Üí https://arxiv.org/abs/2503.23037 Surveys agentic LLMs across reasoning, tools, and...</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/570379597864718</guid></item><item><title>Dropping the general-purpose reasoning dataset Poseidon-Reasoning-5M, which supports general thought processes, math, and science ‚Äî featuring a diverse mixture of domains üåä :</title><link>https://huggingface.co/posts/prithivMLmods/657825800018453</link><description>Dropping the general-purpose reasoning dataset Poseidon-Reasoning-5M, which supports general thought processes, math, and science ‚Äî featuring a diverse mixture of domains üåä : prithivMLmods/Poseidon-Reasoning-5M from datasets import load_dataset dataset = load_dataset( "prithivMLmods/Poseidon-Reasoning-5M" , split = "data" ) The compact version is as follows ‚Äî Poseidon-Reasoning-Mini-300K : prithivMLmods/Poseidon-Reasoning-Mini-300K from datasets import load_dataset dataset = load_dataset( "prithivMLmods/Poseidon-Reasoning-Mini-300K" , split = "train" ) Collection : prithivMLmods/poseidon-reasoning-6879ca98e118b307c781a9ba See translation</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/657825800018453</guid></item><item><title>Towards batch sizes too small to meterüéâ beautiful work! And my personal favorite so far - I adore peak performance at small/nano scale. Everyone deserves to run/train AGI locally:) our data, our god model!</title><link>https://huggingface.co/posts/Jaward/640818601212021</link><description>Towards batch sizes too small to meterüéâ beautiful work! And my personal favorite so far - I adore peak performance at small/nano scale. Everyone deserves to run/train AGI locally:) our data, our god model! They showed that: - you can train LLMs (upto 1B params) with as low as batch_size=1. This is unconventional given small batch sizes can lead to unstable/spiky training runs. - you can have a stable train run with just vanilla SGD(stochastic gradient descent), no momentum requiredü§Ø - small batch sizes are more robust to hyperparameters (i.e no worries with initialization) - smaller batch sizes outperforms (‚Äúbetter per-Flops performance‚Äù) larger batch sizes. ‚ÄúWe recommend that practitioners training large models in memory-constrained settings exploit the benefits of small batch sizes rather than trying to emulate the large batch size setting (e.g., through gradient accumulation) typically used in industry.‚Äù I‚Äôve been doing this for ages - my mantra: all my experiments must scale on...</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/640818601212021</guid></item><item><title>ZML just released a technical preview of their new Inference Engine: LLMD.</title><link>https://huggingface.co/posts/erikkaum/383373646875765</link><description>ZML just released a technical preview of their new Inference Engine: LLMD. - Just 2.4GB container, which means fast startup times and efficient autoscaling - Cross-Platform GPU Support: works on both NVIDIA and AMD GPUs. - written in Zig I just tried it out and deployed it on Hugging Face Inference Endpoints and wrote a quick guide üëá You can try it in like 5 minutes! https://huggingface.co/blog/erikkaum/test-driving-llmd-inference-engine See translation</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/erikkaum/383373646875765</guid></item><item><title>All you need is curation</title><link>https://huggingface.co/posts/etemiz/270501016622467</link><description>All you need is curation See translation</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/etemiz/270501016622467</guid></item><item><title>AudioRAG is becoming real! Just built a demo with ColQwen-Omni that does semantic search on raw audio, no transcription needed.</title><link>https://huggingface.co/posts/fdaudens/135737241770101</link><description>AudioRAG is becoming real! Just built a demo with ColQwen-Omni that does semantic search on raw audio, no transcription needed. Drop in a podcast, ask your question, and it finds the exact chunks where it happens. You can also get a written answer. What‚Äôs exciting: it skips transcription, making it faster and better at capturing emotion, ambient sound, and tone, surfacing results text search would miss. - Demo: fdaudens/colqwen-omni-demo - Blog post from ColQwen team: https://huggingface.co/blog/manu/colqwen-omni-omnimodal-retrieval See translation</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/135737241770101</guid></item><item><title>ü§ñ Technology means power, and whoever owns the technology owns the power.</title><link>https://huggingface.co/posts/giadap/921319982169542</link><description>ü§ñ Technology means power, and whoever owns the technology owns the power. Thrilled to share insights from my recent interview with MIT Technology Review about the growing movement toward local LLMs and what it means for AI democratization. Read here: https://www.technologyreview.com/2025/07/17/1120391/how-to-run-an-llm-on-your-laptop/ ü§î Why this matters: When we use "free" online AI services, we're often the product. Our conversations become training data, our personal stories get "cooked into" models, and our privacy becomes a commodity. But there's an alternative path forward. üí° The power shift is real: Local LLMs aren't just about privacy; they're about redistributing AI power away from a handful of tech giants. When individuals, organizations, and even entire nations can run their own models, we're democratizing access to AI capabilities. ü§ó At Hugging Face, we're proud to be at the center of this transformation. Our platform hosts the world's largest library of freely...</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/giadap/921319982169542</guid></item><item><title>Digital Heart Model: Initial Research Launch üöÄ</title><link>https://huggingface.co/posts/VolodymyrPugachov/444265930926373</link><description>Digital Heart Model: Initial Research Launch üöÄ I am excited to announce the launch of research on the Digital Heart Model (DHM), an AI-driven digital twin designed to transform personalized cardiovascular care. DHM integrates multimodal data, focusing initially on cardiac imaging, histopathological imaging, and ECG data, to predict patient outcomes and optimize interventions. Initial Model and Dataset Overview: Base Model: Multimodal AI foundation combining Convolutional Neural Networks (CNN), Vision Transformers (ViT), and Graph Neural Networks (GNN). Datasets: Cardiac MRI and CT imaging datasets, histopathological cardiac tissue images, and extensive ECG waveform data. Expected Results from First Iteration: Cardiac event prediction (e.g., myocardial infarction) accuracy: AUC ‚â• 0.90 Arrhythmia detection and classification accuracy: AUC ‚â• 0.88 Enhanced segmentation accuracy for cardiac imaging: Dice Score ‚â• 0.85 üîç Next Steps: Conducting initial retrospective validation. Preparing...</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/VolodymyrPugachov/444265930926373</guid></item><item><title>üß¨ Breaking news in Clinical AI: Introducing the OpenMed NER Model Discovery App on Hugging Face üî¨</title><link>https://huggingface.co/posts/MaziyarPanahi/751516664507693</link><description>üß¨ Breaking news in Clinical AI: Introducing the OpenMed NER Model Discovery App on Hugging Face üî¨ OpenMed is back! üî• Finding the right biomedical NER model just became as precise as a PCR assay! I'm thrilled to unveil my comprehensive OpenMed Named Entity Recognition Model Discovery App that puts 384 specialized biomedical AI models at your fingertips. üéØ Why This Matters in Healthcare AI: Traditional clinical text mining required hours of manual model evaluation. My Discovery App instantly connects researchers, clinicians, and data scientists with the exact NER models they need for their biomedical entity extraction tasks. üî¨ What You Can Discover: ‚úÖ Pharmacological Models - Extract "chemical compounds", "drug interactions", and "pharmaceutical" entities from clinical notes ‚úÖ Genomics &amp; Proteomics - Identify "DNA sequences", "RNA transcripts", "gene variants", "protein complexes", and "cell lines" ‚úÖ Pathology &amp; Disease Detection - Recognize "pathological formations", "cancer types",...</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MaziyarPanahi/751516664507693</guid></item><item><title>Upgraded the step-by-step notebook for fine-tuning SigLIP2 on domain-specific image classification tasks. The notebook supports both datasets with predefined train/test splits and those with only a train split, making it suitable for low-resource, custom, and real-world classification scenarios. üì¢üëâ</title><link>https://huggingface.co/posts/prithivMLmods/817042382276733</link><description>Upgraded the step-by-step notebook for fine-tuning SigLIP2 on domain-specific image classification tasks. The notebook supports both datasets with predefined train/test splits and those with only a train split, making it suitable for low-resource, custom, and real-world classification scenarios. üì¢üëâ ‚û∫ FineTuning-SigLIP2-Notebook : prithivMLmods/FineTuning-SigLIP2-Notebook ‚û∫ GitHub : https://github.com/PRITHIVSAKTHIUR/FineTuning-SigLIP-2 ‚û∫ In the first, datasets include predefined train and test splits, enabling conventional supervised learning and generalization evaluation : prithivMLmods/FineTuning-SigLIP2-Notebook (.ipynb) ‚û∫ In the second scenario, only a training split is available; in such cases, the training set is either partially reserved for validation or reused entirely for evaluation : prithivMLmods/FineTuning-SigLIP2-Notebook (.ipynb) This flexibility supports experimentation in constrained or domain-specific settings, where standard test annotations may not exist. See...</description><pubDate>Mon, 21 Jul 2025 13:41:51 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/817042382276733</guid></item></channel></rss>