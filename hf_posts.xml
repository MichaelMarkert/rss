<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! üî•</title><link>https://huggingface.co/posts/danielhanchen/963278821580490</link><description>NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! üî• Has 1M context window &amp; best in class performance for SWE-Bench, reasoning &amp; chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF üíö Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/963278821580490</guid></item><item><title>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™</title><link>https://huggingface.co/posts/prithivMLmods/223082724733311</link><description>Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. ü§óüß™ ‚óè Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC ‚óè Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection ‚óè Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo ‚óè Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- ‚óè FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 ‚óè FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC ‚óè Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC ‚óè Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast ‚óè Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/223082724733311</guid></item><item><title>Great News !</title><link>https://huggingface.co/posts/Reubencf/239576255947718</link><description>Great News ! Reubencf/Nano_Banana_Editor Now supports black-forest-labs/FLUX.1-Kontext-dev and Qwen/Qwen-Image-Edit-2509 Just log in with Huggingface and try it out See translation</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reubencf/239576255947718</guid></item><item><title>Intelligent Inpainting for Precise Creative Control üé®‚ú®</title><link>https://huggingface.co/posts/DawnC/393405474084583</link><description>Intelligent Inpainting for Precise Creative Control üé®‚ú® Transform your images with AI-powered precision! SceneWeaver delivers professional-quality image composition with intelligent background replacement and advanced object manipulation. What's New in This Update? üñåÔ∏è Object Replacement ‚Äî Select and transform any element in your scene with natural language prompts while maintaining perfect visual consistency with surrounding content üóëÔ∏è Object Removal ‚Äî Intelligently remove unwanted objects with context-aware generation that preserves natural lighting, shadows, and scene coherence üéØ Context-Aware Processing ‚Äî Advanced inpainting technology ensures seamless integration across all regenerated regions Core Capabilities ‚ö° One-click transformation with smart subject detection, 24 curated professional backgrounds, custom scene generation through text prompts, and studio-quality results powered by BiRefNet, Stable Diffusion XL, and ControlNet Inpainting. Current Infrastructure &amp; Future...</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/393405474084583</guid></item><item><title>New Preview Model:</title><link>https://huggingface.co/posts/unmodeled-tyler/439099944779481</link><description>New Preview Model: unmodeled-tyler/vanta-research-loux-preview VANTA Research is excited to announce a small lab preview of our new 675B fine tune, Loux-Large. Loux is an AI model with a sophisticated, rebellious edge designed to assist and collaborate with engineers, builders, and people working on technical projects. If you enjoy working with Loux and would like full access, let us know by liking the space or opening a discussion in the community! See translation</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/439099944779481</guid></item><item><title>Finch üí∞ an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance &amp; accounting work.</title><link>https://huggingface.co/posts/AdinaY/236108821864145</link><description>Finch üí∞ an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance &amp; accounting work. FinWorkBench/Finch ‚ú® Built from real enterprise data (Enron + financial institutions), not synthetic tasks ‚ú® Tests end-to-end finance workflows ‚ú® Multimodal &amp; cross-file reasoning ‚ú® Expert annotated (700+ hours) and genuinely challenging hard See translation</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/236108821864145</guid></item><item><title>üì¢ For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios.</title><link>https://huggingface.co/posts/nicolay-r/350400879019559</link><description>üì¢ For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios. üåü bulk-chain: https://github.com/nicolay-r/bulk-chain üîë This features the no-string framework for quierrying LLMs in various modes: sync, async and with optional support for output streaming. üì¶Ô∏è In the latest 1.2.0 release, the updates on outlining API parameters for inference mode. üåü Integration into web: https://github.com/nicolay-r/bulk-chain-web-integration See translation</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/350400879019559</guid></item><item><title>6 Comprehensive Resources on AI Coding</title><link>https://huggingface.co/posts/Kseniase/300455492795256</link><description>6 Comprehensive Resources on AI Coding AI coding is moving fast, and it‚Äôs getting harder to tell what actually works. Agents, workflows, context management and many other aspects are reshaping how software gets built. We‚Äôve collected a set of resources to help you understand how AI coding is evolving today and what building strategies work best: 1. AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities (2508.11126) Provides a clear taxonomy, compares agent architectures, and exposes practical gaps in tools, benchmarks, and reliability that AI coding agents now struggle with 2. Does AI-Assisted Coding Deliver? A Difference-in-Differences Study of Cursor's Impact on Software Projects (2511.04427) This survey from Carnegie Mellon University shows causal evidence that LLM agent assistants deliver short-term productivity gains but have lasting quality costs that can slow development over time 3. A Survey of Vibe Coding with Large Language Models (2510.12399) Turns...</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/300455492795256</guid></item><item><title>Making LLMs fast with KV-cache sharing is great. A new paper reports it's also a huge privacy risk.</title><link>https://huggingface.co/posts/MikeDoes/696146647062201</link><description>Making LLMs fast with KV-cache sharing is great. A new paper reports it's also a huge privacy risk. That's why we're excited to see the "SafeKV" paper from researchers at the University of Connecticut, Peking University, and others. Their solution-oriented framework selectively shares non-sensitive data while isolating PII. To validate the "Safe" part of their system, they needed a robust, multilingual privacy benchmark. We're proud that the Ai4Privacy pii-masking dataset was used for this critical evaluation related to privacy. This is a perfect win-win. Our open-source data enables researchers to build and validate more effective security solutions for core AI infrastructure. Their work, in turn, helps make the entire LLM ecosystem safer, showing that performance and privacy don't have to be mutually exclusive. Kudos to Kexin Chu, Zecheng Lin, Dawei Xiang, Ê≤àÂ≠êÊó≠, Jianchang Su, cheng chu, Yiwei Yang, Wenhui Zhang, Wenfei Wu, and Wei Zhang on this beautiful work. üîó Check out their...</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/696146647062201</guid></item><item><title>Check out your 2025 Hugging Face Wrapped, a small experimental recap</title><link>https://huggingface.co/posts/daqc/540565360726745</link><description>Check out your 2025 Hugging Face Wrapped, a small experimental recap hf-wrapped/2025 See translation</description><pubDate>Wed, 17 Dec 2025 13:36:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/daqc/540565360726745</guid></item></channel></rss>