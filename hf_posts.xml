<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>gpt-oss was possible thanks to new engineering efforts in ğŸ¤— transformers. We just dropped a blog covering them:</title><link>https://huggingface.co/posts/sergiopaniego/319778709690075</link><description>gpt-oss was possible thanks to new engineering efforts in ğŸ¤— transformers. We just dropped a blog covering them: - Kernels from the Hub - MXFP4 Quantization - Tensor &amp; Expert Parallelism - Dynamic Sliding Window &amp; Cache - Continuous Batching &amp; Paged Attention Grab a coffee &amp; dive in! â˜•ï¸ https://huggingface.co/blog/faster-transformers See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/319778709690075</guid></item><item><title>Most apps don't have great full-text search over their assets.</title><link>https://huggingface.co/posts/salma-remyx/853424776483426</link><description>Most apps don't have great full-text search over their assets. We've developed an agent to automate the environment building and testing of experimental codebases sourced from arXiv. We push these containerized reproductions daily to Docker Hub: https://hub.docker.com/u/remyxai However, searching for them can be challenging unless you know the specific arXiv ID associated with each paper. We are currently working on implementing a search feature in Remyx, which will make these assets easily discoverable and ready for testing ğŸ” Stay tuned! Discover your next best idea to experiment with here: https://engine.remyx.ai See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/853424776483426</guid></item><item><title>Hello everyone,</title><link>https://huggingface.co/posts/drvsbrkcn/494150147788454</link><description>Hello everyone, It is my first time using Hugging Face. It is hella nice. Take care. See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/drvsbrkcn/494150147788454</guid></item><item><title>Hunyuan Image 2.1 by Tencent Full Tutorial and 1-Click to Install Ultra Advanced App to Use Locally :</title><link>https://huggingface.co/posts/MonsterMMORPG/330916531424120</link><description>Hunyuan Image 2.1 by Tencent Full Tutorial and 1-Click to Install Ultra Advanced App to Use Locally : https://youtu.be/dNeA5mJ36hA Tutorial video : https://youtu.be/dNeA5mJ36hA Check the below screenshots Hunyuan Image 2.1 just published by Tencent and I have been working on developing the very best app to let you use HunyuanImage-2.1 with easiest and most accurate way. In this tutorial video, I will show you how to literally 1-click to install this model and our app on Windows (locally), Massed Compute (cloud) and RunPod (cloud). The images are all raw 2560x1440 pixels with 8-steps Refiner of Hunyuan Image 2.1 model This model native resolution is 2048x2048 pixels See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/330916531424120</guid></item><item><title>ğŸ‰ Big congratulations to the winners of the "Synthetic 2 Real Object Detection Challenge 2", the second Kaggle challenge that Duality AI hosted. This competition was more fierce than the last one, but these users managed to clench the win!</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/831958361085352</link><description>ğŸ‰ Big congratulations to the winners of the "Synthetic 2 Real Object Detection Challenge 2", the second Kaggle challenge that Duality AI hosted. This competition was more fierce than the last one, but these users managed to clench the win! ğŸ¥‡ 1st place: @ sergio-sanz-rodriguez (see the blog he produced with us outlining how he achieved his results: https://tinyurl.com/mreunr98 ) ğŸ¥ˆ 2nd place: Kaggle user Diana Shilova - https://tinyurl.com/yjjz3szm ğŸ¥‰ 3rd place: Kaggle user çœ‰é—´å°º - https://tinyurl.com/ycxskfzv View the entire leaderboard at - https://tinyurl.com/jm2ery7w Join our current Multi-Class Object Detection Synthetic2Real Kaggle competition here: https://tinyurl.com/y224rttu And we will soon be launching a new competition in a new domain! Hint: ğŸŒ„ ğŸ  ğŸŒ³ âœˆï¸ See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/831958361085352</guid></item><item><title>Build something cool with Nano Banana aka Gemini 2.5 Flash Image AIO [All-in-One]. Draw and transform on canvas, edit images, and generate imagesâ€”all in one place!ğŸŒ</title><link>https://huggingface.co/posts/prithivMLmods/195813965636174</link><description>Build something cool with Nano Banana aka Gemini 2.5 Flash Image AIO [All-in-One]. Draw and transform on canvas, edit images, and generate imagesâ€”all in one place!ğŸŒ âœ¦ï¸ Constructed with the Gemini API (GCP). Try it here: https://nano-banana-aio-886892687963.us-west1.run.app See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/195813965636174</guid></item><item><title>ModernBERT goes MULTILINGUAL! One of the most requested models I've seen, The Johns Hopkins University's CLSP has trained state-of-the-art massively multilingual encoders using the ModernBERT architecture: mmBERT.</title><link>https://huggingface.co/posts/tomaarsen/906557413568289</link><description>ModernBERT goes MULTILINGUAL! One of the most requested models I've seen, The Johns Hopkins University's CLSP has trained state-of-the-art massively multilingual encoders using the ModernBERT architecture: mmBERT. Model details: - 2 model sizes: - jhu-clsp/mmBERT-small - jhu-clsp/mmBERT-base - Uses the ModernBERT architecture, but with the Gemma2 multilingual tokenizer (so: flash attention, alternating global/local attention, unpadding/sequence packing, etc.) - Maximum sequence length of 8192 tokens, on the high end for encoders - Trained on 1833 languages using DCLM, FineWeb2, and many more sources - 3 training phases: 2.3T tokens pretraining on 60 languages, 600B tokens mid-training on 110 languages, and 100B tokens decay training on all 1833 languages. - Both models are MIT Licensed, and the full datasets and intermediary checkpoints are also publicly released Evaluation details: - Very competitive with ModernBERT at equivalent sizes on English (GLUE, MTEB v2 English after...</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tomaarsen/906557413568289</guid></item><item><title>ğŸ¤ Collaborating with AMD to ensure Hugging Face Transformers runs smoothly on AMD GPUs!</title><link>https://huggingface.co/posts/pagezyhf/845836724116614</link><description>ğŸ¤ Collaborating with AMD to ensure Hugging Face Transformers runs smoothly on AMD GPUs! We run daily CI on AMD MI325 to track the health of the most important model architectures and weâ€™ve just made our internal dashboard public. By making this easily accessible, we hope to spark community contributions and improve support for everyone! See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/pagezyhf/845836724116614</guid></item><item><title>A cute Intern With Hugging Face</title><link>https://huggingface.co/posts/vansin/596257741318226</link><description>A cute Intern With Hugging Face See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/vansin/596257741318226</guid></item><item><title>Tremendous quality of life upgrade on the Hugging Face Hub - we now have auto-complete emojis ğŸ¤— ğŸ¥³ ğŸ‘ ğŸ™Œ ğŸ‰</title><link>https://huggingface.co/posts/yjernite/185479802142810</link><description>Tremendous quality of life upgrade on the Hugging Face Hub - we now have auto-complete emojis ğŸ¤— ğŸ¥³ ğŸ‘ ğŸ™Œ ğŸ‰ Get ready for lots more very serious analysis on a whole range of topics from yours truly now that we have unlocked this full range of expression ğŸ˜„ ğŸ¤” ğŸ—£ ğŸ™Š See translation</description><pubDate>Sat, 13 Sep 2025 05:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/yjernite/185479802142810</guid></item></channel></rss>