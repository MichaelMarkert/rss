<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Gini's AI Spaces: Everything You Need for Visual Content Creation!</title><link>https://huggingface.co/posts/ginipick/539440985640088</link><description>Gini's AI Spaces: Everything You Need for Visual Content Creation! Hello! âœ¨ Let me introduce Giniâ€™s 5 AI Spaces that effortlessly generate various styles of visual content. Each Space leverages Diffusers and Gradio, so you can create stunning images in just a few clicks! 1) Flowchart Features: Hand-drawn style flowcharts for workflows or business processes Use Cases: Software release pipelines, data pipelines, corporate workflows Benefits: Clear stage-by-stage structure, simple icon usage ginigen/Flowchart 2) Infographic Features: Visually appealing infographics that communicate data or statistics Use Cases: Global energy charts, startup growth metrics, health tips and more Benefits: Eye-catching icons and layouts, perfect for storytelling at a glance ginigen/Infographic 3) Mockup Features: Sketch-style wireframes or UX mockups for apps/websites Use Cases: Mobile login flows, dashboards, e-commerce site layouts Benefits: Rapid prototyping of early design ideas, perfect for...</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/539440985640088</guid></item><item><title>Introducing VLM-R1!</title><link>https://huggingface.co/posts/tianchez/384417618281589</link><description>Introducing VLM-R1! GRPO has helped DeepSeek R1 to learn reasoning. Can it also help VLMs perform stronger for general computer vision tasks? The answer is YES and it generalizes better than SFT. We trained Qwen 2.5 VL 3B on RefCOCO (a visual grounding task) and eval on RefCOCO Val and RefGTA (an OOD task). https://github.com/om-ai-lab/VLM-R1 See translation</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/tianchez/384417618281589</guid></item><item><title>The last week of Impression Craft Arts and sketches from strangerzonehfğŸ¨ğŸ§‘ğŸ»â€ğŸ¨</title><link>https://huggingface.co/posts/prithivMLmods/804280933500371</link><description>The last week of Impression Craft Arts and sketches from strangerzonehfğŸ¨ğŸ§‘ğŸ»â€ğŸ¨ - Collection : strangerzonehf/Flux-Ultimate-LoRA-Collection Adapters: + Ld-Art : strangerzonehf/Ld-Art + Animeopix-Flux : strangerzonehf/Animeopix-Flux + Flux-Super-Paint-LoRA : strangerzonehf/Flux-Super-Paint-LoRA + CinematicShot-Pics-Flux : strangerzonehf/cinematicShot-Pics-Flux + Oil-Wall-Art-Flux : strangerzonehf/Oil-Wall-Art-Flux + Pixelo-Flux : strangerzonehf/Pixelo-Flux + Abstract-Shattered : strangerzonehf/Abstract-Shattered + Neon-Impressionism-Flux : strangerzonehf/Neon-Impressionism-Flux + NewG-Art : strangerzonehf/NewG-Art ğŸª§Demo : prithivMLmods/FLUX-LoRA-DLC ğŸ¤—Page : https://huggingface.co/strangerzonehf See translation</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/804280933500371</guid></item><item><title>I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait</title><link>https://huggingface.co/posts/Reality123b/533143502736808</link><description>I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait See translation</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reality123b/533143502736808</guid></item><item><title>ğŸ”® GPT-3 implemented in pure Free Pascal!</title><link>https://huggingface.co/posts/schuler/523097349867184</link><description>ğŸ”® GPT-3 implemented in pure Free Pascal! https://github.com/joaopauloschuler/gpt-3-for-pascal This implementation follows the GPT-3 Small architecture from the landmark paper "Language Models are Few-Shot Learners": â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ Input Layer â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ Token &amp; Positional â”‚ â”‚ Embedding â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ 12x Transformer â”‚ â”‚ Blocks â”‚ â”‚ - 12 heads â”‚ â”‚ - 768 hidden dims â”‚ â”‚ - 3072 intermediate â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚ Output Layer â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Clean Pascal Implementation for CntLayer := 1 to {Layers=} 12 do begin Result .AddTransformerBlockCAI( {Heads=} 12 , {intermediate dimensions=} 4 * 768 , {NoForward=} true , {HasNorm=} true , false ) ; end ; See translation</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/schuler/523097349867184</guid></item><item><title>8 New Applications of Test-Time Scaling</title><link>https://huggingface.co/posts/Kseniase/134685305854108</link><description>8 New Applications of Test-Time Scaling We've noticed a huge interest in test-time scaling (TTS), so we decided to explore this concept further. Test-time compute (TTC) refers to the amount of computational power used by an AI model when generating a response. Many researchers are now focused on scaling TTC, as it enables slow, deep "thinking" and step-by-step reasoning, which improves overall models' performance. Here are 8 fresh studies on test-time scaling: 1. Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach (2502.05171) Introduces an LM that scales TTC by reasoning in latent space instead of generating more tokens with no special training. Here, a recurrent block to processes information iteratively. 2. Generating Symbolic World Models via Test-time Scaling of Large Language Models (2502.04728) Shows how TTS is applied to enhance model's Planning Domain Definition Language (PDDL) reasoning capabilities, which can be used to generate a symbolic world...</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/134685305854108</guid></item><item><title>Try out my updated implementation of forked OpenDeepResearcher(link below) as an OpenAI compatible endpoint, but with full control, can be deployed completely free with Gemini api or completely locally with ollama, or pay-as-you-go in BYOK format, the AI agents will think dynamically based on the difficulties of given research, compatible with any OpenAI compatible configurable clients(Msty, Chatbox, even vscode AI Toolkit playground).</title><link>https://huggingface.co/posts/benhaotang/322538825901593</link><description>Try out my updated implementation of forked OpenDeepResearcher(link below) as an OpenAI compatible endpoint, but with full control, can be deployed completely free with Gemini api or completely locally with ollama, or pay-as-you-go in BYOK format, the AI agents will think dynamically based on the difficulties of given research, compatible with any OpenAI compatible configurable clients(Msty, Chatbox, even vscode AI Toolkit playground). If you don't want to pay OpenAI $200 to use or want to take control of your deep research, check out here: ğŸ‘‰ https://github.com/benhaotang/OpenDeepResearcher-via-searxng **Personal take** Based on my testing against Perplexity's and Gemini's implementation with some Physics domain questions, mine is comparable and very competent at finding even the most rare articles or methods. Also a funny benchmark of mine to test all these searching models, is to trouble shot a WSL2 hanging issue I experienced last year, with prompt: &gt; wsl2 in windows hangs in...</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/benhaotang/322538825901593</guid></item><item><title>I am pleased to introduce my first project built upon Hugging Faceâ€™s smolagents framework, integrated with Alpaca for financial market analysis automation ğŸ¦™ğŸ¤—</title><link>https://huggingface.co/posts/louisbrulenaudet/828105702758595</link><description>I am pleased to introduce my first project built upon Hugging Faceâ€™s smolagents framework, integrated with Alpaca for financial market analysis automation ğŸ¦™ğŸ¤— The project implements technical indicators such as the Relative Strength Index (RSI) and Bollinger Bands to provide momentum and volatility analysis. Market data is retrieved through the Alpaca API, enabling access to historical price information across various timeframes. AI-powered insights are generated using Hugging Faceâ€™s inference API, facilitating the analysis of market trends through natural language processing with DuckDuckGo search integration for real-time sentiment analysis based on financial news ğŸ¦† Link to the GitHub project: https://github.com/louisbrulenaudet/agentic-market-tool See translation</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/louisbrulenaudet/828105702758595</guid></item><item><title>hello, dev mode explorers!</title><link>https://huggingface.co/posts/nroggendorff/464265972064174</link><description>hello, dev mode explorers! See translation</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/464265972064174</guid></item><item><title>I was thinking i need to step up my game on training Flux LoRas models, time to have some fun ! â˜€ï¸</title><link>https://huggingface.co/posts/fffiloni/806803691807876</link><description>I was thinking i need to step up my game on training Flux LoRas models, time to have some fun ! â˜€ï¸ Expect a new drop per week on aesthetics that catched my attention, here are 3 of them that worked really well ! fffiloni/cute-comic-800 fffiloni/carbo-800 fffiloni/oniric-750 See translation</description><pubDate>Mon, 17 Feb 2025 13:27:38 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fffiloni/806803691807876</guid></item></channel></rss>