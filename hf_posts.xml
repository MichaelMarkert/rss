<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>8 Free Sources about AI Agents:</title><link>https://huggingface.co/posts/Kseniase/557379551700019</link><description>8 Free Sources about AI Agents: Agents seem to be everywhere and this collection is for a deep dive into the theory and practice: 1. "Agents" Google's whitepaper by Julia Wiesinger, Patrick Marlow and Vladimir Vuskovic -&gt; https://www.kaggle.com/whitepaper-agents Covers agents, their functions, tool use and how they differ from models 2. "Agents in the Long Game of AI. Computational Cognitive Modeling for Trustworthy, Hybrid AI" book by Marjorie McShane, Sergei Nirenburg, and Jesse English -&gt; https://direct.mit.edu/books/oa-monograph/5833/Agents-in-the-Long-Game-of-AIComputational Explores building AI agents, using Hybrid AI, that combines ML with knowledge-based reasoning 3. "AI Engineer Summit 2025: Agent Engineering" 8-hour video -&gt; https://www.youtube.com/watch?v=D7BzTxVVMuw Experts' talks that share insights on the freshest Agent Engineering advancements, such as Google Deep Research, scaling tips and more 4. AI Agents Course from Hugging Face -&gt;...</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/557379551700019</guid></item><item><title>She arrived ğŸ˜</title><link>https://huggingface.co/posts/stefan-it/765581033311913</link><description>She arrived ğŸ˜ [Expect more models soon...] See translation</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/stefan-it/765581033311913</guid></item><item><title>ğŸš€ Introducing MOUSE: Space Research Thinking on HuggingFace Spaces</title><link>https://huggingface.co/posts/ginipick/923354082387927</link><description>ğŸš€ Introducing MOUSE: Space Research Thinking on HuggingFace Spaces ğŸš€ How to Get Started ginipick/spaces-research-think Welcome to **MOUSE: Space Research Thinking** â€“ an innovative HuggingFace Spaces project designed to transform how you analyze and interact with Python code. Whether you're a developer, researcher, or simply passionate about coding, this tool provides state-of-the-art analysis, summarization, and usage guidance, all powered by advanced AI. --- ## ğŸŒŸ Key Features - **Real-Time Code Analysis** Instantly dissect your Python code to reveal its structure, functionality, and potential applications. Our tool delivers: - **Background &amp; Necessity**: Understand the context behind the code. - **Functional Utility &amp; Value**: Highlight core functionalities and benefits. - **Distinctive Features**: Discover what sets the project apart. - **Target Audience &amp; Applications**: Identify who can benefit and how. - **Expected Impact**: Envision the improvements and innovations the code...</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/923354082387927</guid></item><item><title>We now have a Deep Research for academia: SurveyX automatically writes academic surveys nearly indistinguishable from human-written ones ğŸ”¥</title><link>https://huggingface.co/posts/m-ric/788543954757847</link><description>We now have a Deep Research for academia: SurveyX automatically writes academic surveys nearly indistinguishable from human-written ones ğŸ”¥ Researchers from Beijing and Shanghai just published the first application of a deep research system to academia: their algorithm, given a question, can give you a survey of all papers on the subject. To make a research survey, you generally follow two steps, preparation (collect and organize papers) and writing (outline creation, writing, polishing). Researchers followed the same two steps and automated them. ğŸ¯ For the preparation part, a key part is find all the important references on the given subject. Researchers first cast a wide net of all relevant papers. But then finding the really important ones is like distilling knowledge from a haystack of information. To solve this challenge, they built an â€œAttributeTreeâ€ object that structures key information from citations. Ablating these AttributeTrees significantly decreased structure and...</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/m-ric/788543954757847</guid></item><item><title>Dropping some of the custom fine-tunes based on SigLIP2,</title><link>https://huggingface.co/posts/prithivMLmods/305640045790864</link><description>Dropping some of the custom fine-tunes based on SigLIP2, with a single-label classification problem type! ğŸŒ€ğŸ§¤ - AI vs Deepfake vs Real : prithivMLmods/AI-vs-Deepfake-vs-Real-Siglip2 - Deepfake Detect : prithivMLmods/Deepfake-Detect-Siglip2 - Fire Detection : prithivMLmods/Fire-Detection-Siglip2 - Deepfake Quality Assess : prithivMLmods/Deepfake-Quality-Assess-Siglip2 - Guard Against Unsafe Content : prithivMLmods/Guard-Against-Unsafe-Content-Siglip2 ğŸŒ Collection : prithivMLmods/siglip2-custom-67bcdb2de8fe96b99fb4e19e See translation</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/305640045790864</guid></item><item><title>ğŸš€ Just launched: A toolkit of 20 powerful AI tools that journalists can use right now - transcribe, analyze, create. 100% free &amp; open-source.</title><link>https://huggingface.co/posts/fdaudens/982146976081521</link><description>ğŸš€ Just launched: A toolkit of 20 powerful AI tools that journalists can use right now - transcribe, analyze, create. 100% free &amp; open-source. Been testing all these tools myself and created a searchable collection of the most practical ones - from audio transcription to image generation to document analysis. No coding needed, no expensive subscriptions. Some highlights I've tested personally: - Private, on-device transcription with speaker ID in 100+ languages using Whisper - Website scraping that just works - paste a URL, get structured data - Local image editing with tools like Finegrain (impressive results) - Document chat using Qwen 2.5 72B (handles technical papers well) Sharing this early because the best tools come from the community. Drop your favorite tools in the comments or join the discussion on what to add next! ğŸ‘‰ JournalistsonHF/ai-toolkit See translation</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/982146976081521</guid></item><item><title>Getting WebRTC and Websockets right in python is very tricky. If you've tried to wrap an LLM in a real-time audio layer then you know what I'm talking about.</title><link>https://huggingface.co/posts/freddyaboulton/628292960317038</link><description>Getting WebRTC and Websockets right in python is very tricky. If you've tried to wrap an LLM in a real-time audio layer then you know what I'm talking about. That's where FastRTC comes in! It makes WebRTC and Websocket streams super easy with minimal code and overhead. Check out our org: hf.co/fastrtc See translation</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/freddyaboulton/628292960317038</guid></item><item><title>ğŸ”¥ Agents can do anything!</title><link>https://huggingface.co/posts/alvarobartt/393660009896131</link><description>ğŸ”¥ Agents can do anything! @ microsoft Research just announced the release of Magma 8B! Magma is a new Visual Language Model (VLM) with 8B parameters for multi-modal agents designed to handle complex interactions across virtual and real environments; and it's MIT licensed! Magma comes with exciting new features such as: - Introduces the Set-of-Mark and Trace-of-Mark techniques for fine-tuning - Leverages a large amount of unlabeled video data to learn the spatial-temporal grounding and planning - A strong generalization and ability to be fine-tuned for other agentic tasks - SOTA in different multi-modal benchmarks spanning across UI navigation, robotics manipulation, image / video understanding and spatial understanding and reasoning - Generates goal-driven visual plans and actions for agentic use cases Model: microsoft/Magma-8B Technical Report: Magma: A Foundation Model for Multimodal AI Agents (2502.13130) See translation</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/alvarobartt/393660009896131</guid></item><item><title>Datasets Convertor ğŸš€</title><link>https://huggingface.co/posts/openfree/251902401084370</link><description>Datasets Convertor ğŸš€ openfree/Datasets-Convertor Welcome to Datasets Convertor, the cutting-edge solution engineered for seamless and efficient data format conversion. Designed with both data professionals and enthusiasts in mind, our tool simplifies the transformation process between CSV, Parquet, and JSONL, XLS file formats, ensuring that your data is always in the right shape for your next analytical or development challenge. ğŸ’»âœ¨ Why Choose Datasets Convertor? In todayâ€™s data-driven world, managing and converting large datasets can be a daunting task. Our converter is built on top of robust technologies like Pandas and Gradio, delivering reliable performance with a modern, intuitive interface. Whether youâ€™re a data scientist, analyst, or developer, Datasets Convertor empowers you to effortlessly switch between formats while maintaining data integrity and optimizing storage. Key Features and Capabilities: CSV â‡† Parquet Conversion: Easily transform your CSV files into the highly...</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/251902401084370</guid></item><item><title>Wan2.1 ğŸ”¥ğŸ“¹ new OPEN video model by Alibaba Wan team!</title><link>https://huggingface.co/posts/AdinaY/200256238569001</link><description>Wan2.1 ğŸ”¥ğŸ“¹ new OPEN video model by Alibaba Wan team! Model: Wan-AI/Wan2.1-T2V-14B Demo: Wan-AI/Wan2.1 âœ¨Apache 2.0 âœ¨8.19GB VRAM, runs on most GPUs âœ¨Multi-Tasking: T2V, I2V, Video Editing, T2I, V2A âœ¨Text Generation: Supports Chinese &amp; English âœ¨Powerful Video VAE: Encode/decode 1080P w/ temporal precision See translation</description><pubDate>Wed, 26 Feb 2025 09:22:44 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/200256238569001</guid></item></channel></rss>