<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Released 17 production-ready adaptive text classifiers that learn from just 100 examples per class and continuously improve without retraining.</title><link>https://huggingface.co/posts/codelion/935347664878969</link><description>Released 17 production-ready adaptive text classifiers that learn from just 100 examples per class and continuously improve without retraining. These models achieve 93% average accuracy across enterprise use cases like email routing, fraud detection, document classification, and support ticket categorization. Built on ModernBERT with prototype memory and elastic weight consolidation. Key benefits: 90% cost reduction vs API solutions, 90-120ms local inference, dynamic class addition, and zero vendor lock-in. All models available under adaptive-classifier organization. Install with pip install adaptive-classifier. Full technical details: https://huggingface.co/blog/codelion/enterprise-ready-classifiers Code: https://github.com/codelion/adaptive-classifier See translation</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/935347664878969</guid></item><item><title>On the verge of releasing Poseidon-Reasoning-5M, a dataset built to excel in general thought processes, mathematics, and science across a diverse mixture of domains, Iâ€™m also dropping the Gargantua-R1-Compact dataset, a collection of over six million high-quality reasoning QA pair traces.  ğŸ¤—ğŸš€</title><link>https://huggingface.co/posts/prithivMLmods/709724003805316</link><description>On the verge of releasing Poseidon-Reasoning-5M, a dataset built to excel in general thought processes, mathematics, and science across a diverse mixture of domains, Iâ€™m also dropping the Gargantua-R1-Compact dataset, a collection of over six million high-quality reasoning QA pair traces. ğŸ¤—ğŸš€ âœ¦ Gargantua-R1-Compact : prithivMLmods/Gargantua-R1-Compact from datasets import load_dataset dataset = load_dataset( "prithivMLmods/Gargantua-R1-Compact" , split = "train" ) Additionally, Iâ€™m adding the mini version of Gargantua â€” the Gargantua-R1-Wee : prithivMLmods/Gargantua-R1-Wee from datasets import load_dataset dataset = load_dataset( "prithivMLmods/Gargantua-R1-Wee" , split = "train" ) The composition spans 73.93% core mathematical reasoning involving problems, proofs, and computational challenges, 12.11% across diverse scientific domains such as physics, chemistry, biology, and interdisciplinary topics, 11.35% in competitive coding covering algorithms and data structures, 1.37% in...</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/709724003805316</guid></item><item><title>I am very sad to say that the budget in creating of SnowflakeCore-G1 1b and 7b MoE models ran out and I can't pre-train them anymore.</title><link>https://huggingface.co/posts/FlameF0X/910946879857355</link><description>I am very sad to say that the budget in creating of SnowflakeCore-G1 1b and 7b MoE models ran out and I can't pre-train them anymore. See translation</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/FlameF0X/910946879857355</guid></item><item><title>Qwen Image is literally unchallenged at understanding complex prompts and writing amazing text on generated images. This model feels almost as if itâ€™s illegal to be open source and free. It is my new tool for generating thumbnail images. Even with low-effort prompting, the results are excellent.</title><link>https://huggingface.co/posts/MonsterMMORPG/624409186500391</link><description>https://youtu.be/R6h02YY6gUs Qwen Image is literally unchallenged at understanding complex prompts and writing amazing text on generated images. This model feels almost as if itâ€™s illegal to be open source and free. It is my new tool for generating thumbnail images. Even with low-effort prompting, the results are excellent. This tutorial literally shows how these images were generated with Gemini 2.5 Pro made prompts : Qwen Image Dominates Text-to-Image: 700+ Tests Reveal Why Itâ€™s Better Than FLUX â€” Presets Published https://youtu.be/R6h02YY6gUs Gemini 2.5 Pro is freely available on Google Studio AI All images generated in easy to use SwarmUI and they are unmodified raw generations SwarmUI and ComfyUI install tutorial : Master Local AI Art &amp; Video Generation with SwarmUI (ComfyUI Backend): The Ultimate 2025 Tutorial https://www.youtube.com/watch?v=fTzlQ0tjxj0 See translation</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/624409186500391</guid></item><item><title>6 Must-read books about AI and Machine Learning:</title><link>https://huggingface.co/posts/Kseniase/253421169111650</link><description>6 Must-read books about AI and Machine Learning: Sharing some free, useful resources for you. In this collection, weâ€™ve gathered the most recent books to give you up-to-date information on key fundamental topics. Hope this helps you master AI and machine learning: 1. Machine Learning Systems by Vijay Janapa Reddi â†’ https://www.mlsysbook.ai/ Provides a framework for building effective ML solutions, covering data engineering, optimization, hardware-aware training, inference acceleration, architecture choice, and other key principles 2. Generative Diffusion Modeling: A Practical Handbook by Zihan Ding, Chi Jin â†’ https://arxiv.org/abs/2412.17162 Offers a unified view of diffusion models: probabilistic, score-based, consistency, rectified flow, pre/post-training. It aligns notations with code to close the â€œpaper-to-codeâ€ gap. 3. Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges â†’ https://arxiv.org/abs/2104.13478 Explores unified geometric principles to analyze neural...</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/253421169111650</guid></item><item><title>ğ—£ğ—®ğ—½ğ—²ğ—¿ğŸ®ğ—£ğ—¥ğ˜€</title><link>https://huggingface.co/posts/salma-remyx/749801614139816</link><description>ğ—£ğ—®ğ—½ğ—²ğ—¿ğŸ®ğ—£ğ—¥ğ˜€ Lately, we've been experimenting with recommending arXiv papers based on the context of what we're building in AI. At the same time, we're using an agent to help automate the building and testing of Docker Images. Check out the example here: https://hub.docker.com/repository/docker/remyxai/2507.20613v1/general Next, we're tasking our #ExperimentOps agent to open PRs in a target repo, to evaluate the core concepts from a new research paper in the context of your application and your kpis. Operationalize your Experimentation! Find Your Frontier! #BeAnExperimenter See translation</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/749801614139816</guid></item><item><title>Qwen Image + LoRA âš¡</title><link>https://huggingface.co/posts/ovi054/531850271042138</link><description>Qwen Image + LoRA âš¡ ovi054/Qwen-Image-LORA Qwen Image is the No. 1 trending Text-to-Image model right now. You can add a custom LoRA and generate images with this Space. ğŸ‘‰ Try it now: ovi054/Qwen-Image-LORA See translation</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/531850271042138</guid></item><item><title>After so many requests, I want to update everyone on the status of Ark, i.e., doing robotics in Python. First, thanks a lot for the amazing and impressive interest we got in it. We are now @ 1.13 K downloads, which is beyond my wildest expectations (</title><link>https://huggingface.co/posts/hba123/507696815739226</link><description>After so many requests, I want to update everyone on the status of Ark, i.e., doing robotics in Python. First, thanks a lot for the amazing and impressive interest we got in it. We are now @ 1.13 K downloads, which is beyond my wildest expectations ( https://pepy.tech/projects/ark-robotics?timeRange=threeMonths&amp;category=version&amp;includeCIDownloads=true&amp;granularity=daily&amp;viewType=line&amp;versions=0.1.1%2C0.1%2C0.0.1 )! 0. First and foremost, we are pip installable ( https://pypi.org/project/ark-robotics/ ) 1. We are currently working on supporting more robots: G1 and Drones are in the works with a cool set of amazing, fantastic colleagues. Those are coming. 2. We have support for multiple sensors and interfaces ( https://github.com/Robotics-Ark/ark_interfaces ) 3. We also now have support for machine learning via diffusion policies ( https://github.com/Robotics-Ark/ark_diffusion_policies_on_franka ) 4. We have a set of tutorials that detail each step (...</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hba123/507696815739226</guid></item><item><title>Teaching a 7B Model to Be Just the Right Amount of Snark</title><link>https://huggingface.co/posts/sweatSmile/885231425275352</link><description>Teaching a 7B Model to Be Just the Right Amount of Snark Ever wondered if a language model could get sarcasm? I fine-tuned Mistral-7B using LoRA and 4-bit quantisationâ€”on just ~720 hand-picked sarcastic promptâ€“response pairs from Reddit, Twitter, and real-life conversations. The challenge? Keeping it sarcastic but still helpful. LoRA rank 16 to avoid overfitting 4-bit NF4 quantization to fit on limited GPU memory 10 carefully monitored epochs so it didnâ€™t turn into a full-time comedian Result: a model that understands â€œOh great, another meetingâ€ exactly as you mean it. Read the full journey, tech details, and lessons learned on my blog: Fine-Tuning Mistral-7B for Sarcasm with LoRA and 4-Bit Quantisation Try the model here on Hugging Face: sweatSmile/Mistral-7B-Instruct-v0.1-Sarcasm. See translation</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sweatSmile/885231425275352</guid></item><item><title>ğŸ”¥Check out new SOTA Orpheus Auto-Continuations GeneratorğŸ”¥</title><link>https://huggingface.co/posts/asigalov61/289707289100732</link><description>ğŸ”¥Check out new SOTA Orpheus Auto-Continuations GeneratorğŸ”¥ asigalov61/Orpheus-Music-Transformer Now you can generate good music with Orpheus without supervision!!! @ Timzoid @ John6666 @ alvanalrakib See translation</description><pubDate>Mon, 11 Aug 2025 17:24:30 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/asigalov61/289707289100732</guid></item></channel></rss>