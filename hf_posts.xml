<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>How to compress long code context? ğŸ“š</title><link>https://huggingface.co/posts/YerbaPage/558970453952386</link><description>How to compress long code context? ğŸ“š Check out our LongCodeZip! Paper just got accepted to ASE 2025. ğŸ”¥ Code: https://github.com/YerbaPage/LongCodeZip Paper: LongCodeZip: Compress Long Context for Code Language Models (2510.00446) See translation</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/558970453952386</guid></item><item><title>GLM-4.6 is hereğŸš€</title><link>https://huggingface.co/posts/AdinaY/926192442043020</link><description>GLM-4.6 is hereğŸš€ zai-org/GLM-4.6 âœ¨ 200K context window âœ¨ Superior coding &amp; polished UI generation âœ¨ Stronger reasoning &amp; tool use âœ¨ More capable agents &amp; agent frameworks See translation</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/926192442043020</guid></item><item><title>ğŸš€ Qwen3-Omni for Marketing: A Game-Changer</title><link>https://huggingface.co/posts/Sri-Vigneshwar-DJ/891594547382960</link><description>ğŸš€ Qwen3-Omni for Marketing: A Game-Changer Just wanted to share something exciting I've been exploringâ€”Qwen3-Omni and how it's transforming marketing workflows. What makes it special? At Hawky.ai we are started experimenting with Qwen3 recently for Analysis and Optimization. Unlike traditional tools that look at text, images, or audio separately, Qwen3-Omni analyzes everything together. It handles 119 languages, processes 40-minute audio sequences, and understands both images and videosâ€”all at once. The cool part? It's 2-3x faster than similar models thanks to its MoE architecture. Real applications I'm seeing: Ad Analysis: It scores video ads by combining visual elements, audio tone, and textâ€”giving 25% better CTR predictions than single-mode tools. Campaign Localization: Drop in one ad, get 10 localized versions with native voiceovers in under a minute. Perfect for testing across markets. Market Research: Feed it competitor content, podcasts, or UGC videos. It extracts actionable...</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Sri-Vigneshwar-DJ/891594547382960</guid></item><item><title>Introducing</title><link>https://huggingface.co/posts/SelmaNajih001/721687692996128</link><description>Introducing SelmaNajih001/StockPredictionExplanation , built with GRPO and RAG: -GRPO trains the model to predict and explain stock direction. -RAG grounds explanations in historical financial news and central bank speeches. Together, they create a system that forecasts stock movements and shows the reasoning behind them. Full article: Explainable Financial Predictions â€” https://huggingface.co/blog/SelmaNajih001/explainable-financial-predictions Try it here: StockPredictionExplanation Space â€” SelmaNajih001/StockPredictionExplanation See translation</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/SelmaNajih001/721687692996128</guid></item><item><title>ğŸš€ Big news from XenArcAI!</title><link>https://huggingface.co/posts/Parveshiiii/228189451590505</link><description>ğŸš€ Big news from XenArcAI! Weâ€™ve just released our new dataset: **Bhagwatâ€‘Gitaâ€‘Infinity** ğŸŒ¸ğŸ“– âœ¨ Whatâ€™s inside: - Verseâ€‘aligned Sanskrit, Hindi, and English - Clean, structured, and ready for ML/AI projects - Perfect for research, education, and openâ€‘source exploration ğŸ”— Hugging Face: XenArcAI/Bhagwat-Gita-Infinity Letâ€™s bring timeless wisdom into modern AI together ğŸ™Œ See translation</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Parveshiiii/228189451590505</guid></item><item><title>Hello everyone,</title><link>https://huggingface.co/posts/andywu-kby/790599686035068</link><description>Hello everyone, I hope youâ€™re doing well. Weâ€™re currently developing a chatbot that can analyze and forecast sales directly from Excel files. Do you think this would be useful? Miragic-AI/Miragic-Sales-Pilot Please share your feedback by ğŸ‘ or ğŸ‘ this post. Best regards, See translation</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/andywu-kby/790599686035068</guid></item><item><title>Hey, amazing, awesome people of the beautiful internet ğŸ˜ğŸ¥°</title><link>https://huggingface.co/posts/hba123/508032894003486</link><description>Hey, amazing, awesome people of the beautiful internet ğŸ˜ğŸ¥° Distillation has been (from my point of view) a main driving factor for the success of hashtag#LLMs - like distilling the knowledge of an amazing big model (say hashtag#DeepSeekv3, or hashtag#GeminiAI) into yours. Probably, you have done it with minimising a KL divergence, and it somehow worked. Well, not that well, right? 1ï¸âƒ£ Your model tends to memorise! 2ï¸âƒ£ Your model might get the right answer, but its reasoning might be flawed. To fix those problems, we rethink distillation and process a new approach! A method that is based on constrained RL that comes with nice theoretical guarantees and excellent performance! Check it out: Rethinking Large Language Model Distillation: A Constrained Markov Decision Process Perspective (2509.22921) Let us do distillation right! Please upvote if you find it useful! See translation</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hba123/508032894003486</guid></item><item><title>Try the Hugging Face Space demo for</title><link>https://huggingface.co/posts/prithivMLmods/704561076669428</link><description>Try the Hugging Face Space demo for Logics-MLLM/Logics-Parsing , the latest multimodal VLM from the Logics Team at Alibaba Group. It enables end-to-end document parsing with precise content extraction in markdown format, and it also generates a clean HTML representation of the document while preserving its logical structure. ğŸ¤—ğŸ”¥ Additionally, Iâ€™ve integrated one of my recent works â€” prithivMLmods/Gliese-OCR-7B-Post1.0 â€” which also excels at document comprehension. â­ Space / App : prithivMLmods/Logics-Parsing-VLM ğŸ“„ Technical Report by the Logics Team, Alibaba Group : Logics-Parsing Technical Report (2509.19760) âš¡ Collections : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 Other Pages: â” Multimodal VLMs - July'25 : prithivMLmods/multimodal-vlms-until-july25-688312e6b840e1e156f13027 â” Multimodal VLMs - Aug'25 : prithivMLmods/multimodal-vlms-aug25-68a56aac39fe8084f3c168bd â” VL caption â€” &lt; Sep 15 â€™25 : prithivMLmods/vl-caption-sep-15-25-68c7f6d737985c63c13e2391 . . ....</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/704561076669428</guid></item><item><title>One of the hardest challenges in AI safety is finding the right balance: how do we protect people from harm without undermining their agency? This tension is especially visible in conversational systems, where safeguards can sometimes feel more paternalistic than supportive.</title><link>https://huggingface.co/posts/giadap/999915316832908</link><description>One of the hardest challenges in AI safety is finding the right balance: how do we protect people from harm without undermining their agency? This tension is especially visible in conversational systems, where safeguards can sometimes feel more paternalistic than supportive. In my latest piece for Hugging Face, I argue that open source and community-driven approaches offer a promising (though not exclusive) way forward. âœ¨ Transparency can make safety mechanisms into learning opportunities. âœ¨ Collaboration with diverse communities makes safeguards more relevant across contexts. âœ¨ Iteration in the open lets protections evolve rather than freeze into rigid, one-size-fits-all rules. Of course, this isnâ€™t a silver bullet. Top-down safety measures will still be necessary in some cases. But if we only rely on corporate control, we risk building systems that are safe at the expense of trust and autonomy. Read the blog post here: https://huggingface.co/blog/giadap/preserving-agency See...</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/giadap/999915316832908</guid></item><item><title>ğŸš€ Exciting News! We've released a Performance Marketing Expert Dataset from Hawky.ai [www.hawky.ai]</title><link>https://huggingface.co/posts/Sri-Vigneshwar-DJ/952078344859787</link><description>ğŸš€ Exciting News! We've released a Performance Marketing Expert Dataset from Hawky.ai [www.hawky.ai] Hawky-ai This dataset empowers AI models with cutting-edge strategies for Meta, Google Ads, and TikTok campaigns. It includes: 1. Multi-platform strategies for e-commerce, DTC, B2B, and more 2. Creative optimization and audience targeting insights 3. ROI-driven recommendations based on 2025 best practices Sri-Vigneshwar-DJ/Performance-Marketing-Data See translation</description><pubDate>Fri, 03 Oct 2025 13:29:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Sri-Vigneshwar-DJ/952078344859787</guid></item></channel></rss>