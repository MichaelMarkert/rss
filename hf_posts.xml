<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Want to get started with fine-tuning but donâ€™t know where to begin? ğŸ¤“â˜ï¸</title><link>https://huggingface.co/posts/sergiopaniego/364808323176425</link><description>Want to get started with fine-tuning but donâ€™t know where to begin? ğŸ¤“â˜ï¸ Weâ€™re expanding our collection of beginner-friendly free Colab notebooks so you can learn and fine-tune models using TRL at no cost ğŸ”¬ Check out the full list of free notebooks: https://huggingface.co/docs/trl/main/en/example_overview#notebooks ğŸ”¬ If you want more advanced content, we also have a lot to cover in the community tutorials: https://huggingface.co/docs/trl/community_tutorials And now the obvious question: what would you like us to add next? See translation</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/364808323176425</guid></item><item><title>One speech model with seven voices, streamlined with multimodal capabilities for vision tasks. Performs vision(image-text) to audio inference with Qwen2.5-VL + VibeVoice-Realtime-0.5B. Vision to VibeVoice (EN) -  The demo is live.  ğŸ—£ï¸ğŸ”¥</title><link>https://huggingface.co/posts/prithivMLmods/612580119302031</link><description>One speech model with seven voices, streamlined with multimodal capabilities for vision tasks. Performs vision(image-text) to audio inference with Qwen2.5-VL + VibeVoice-Realtime-0.5B. Vision to VibeVoice (EN) - The demo is live. ğŸ—£ï¸ğŸ”¥ ğŸ¤— Vision-to-VibeVoice-en [Demo]: prithivMLmods/Vision-to-VibeVoice-en âœ¨ Collection: https://huggingface.co/collections/prithivMLmods/multimodal-implementations âœ¨ Speech [VibeVoice-Realtime-0.5B]: microsoft/VibeVoice-Realtime-0.5B âœ¨ Vision [Qwen2.5-VL]: Qwen/Qwen2.5-VL-7B-Instruct To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/612580119302031</guid></item><item><title>Hello</title><link>https://huggingface.co/posts/omarkamali/275991644251688</link><description>Hello picomon ! AMD GPU Monitoring made easy Just run uvx picomon and behold: â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ GPU 0 GFX 42 % UMC 21 % â”‚ â”‚ GPU 1 GFX 78 % UMC 66 % â”‚ â”‚ PWR 135 / 250 W (54%) VRAM 10.0 / 16.0 GB 62 % â”‚ â”‚ PWR 210 / 250 W (84%) VRAM 14.5 / 16.0 GB 90 % â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ GFX â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–†â–‡â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â– â”‚ â”‚ GFX â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆâ–‡â–†â–…â–„â–‚â–‚â–ƒâ–…â–† â”‚ â”‚ PWR â–â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–ˆâ–ˆâ–‡â–†â–…â–„â–‚â– â”‚ â”‚ PWR â–‚â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–‚â–ƒ â”‚ â”‚ VRM â–â–â–‚â–‚â–ƒâ–„â–„â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–„â–‚ â”‚ â”‚ VRM â–‚â–ƒâ–„â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Repo at https://github.com/omarkamali/picomon Or pypi at https://pypi.org/project/picomon</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/omarkamali/275991644251688</guid></item><item><title>NotebookLM's infographics feature is amazing, it generates poster-type images from any text. Here is one I tried for my new HF article on ellora -</title><link>https://huggingface.co/posts/codelion/632031761173923</link><description>NotebookLM's infographics feature is amazing, it generates poster-type images from any text. Here is one I tried for my new HF article on ellora - https://huggingface.co/blog/codelion/ellora-lora-recipes See translation</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/codelion/632031761173923</guid></item><item><title>Mistral's new Ministral 3 models can now be Run &amp; Fine-tuned locally! (16GB RAM)</title><link>https://huggingface.co/posts/danielhanchen/849127033892624</link><description>Mistral's new Ministral 3 models can now be Run &amp; Fine-tuned locally! (16GB RAM) Ministral 3 have vision support and the best-in-class performance for their sizes. 14B Instruct GGUF: unsloth/Ministral-3-14B-Instruct-2512-GGUF 14B Reasoning GGUF: unsloth/Ministral-3-14B-Reasoning-2512-GGUF ğŸ± Step-by-step Guide: https://docs.unsloth.ai/new/ministral-3 All GGUFs, BnB, FP8 etc. variants uploads: https://huggingface.co/collections/unsloth/ministral-3 See translation</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/849127033892624</guid></item><item><title>Anim Lab AIâš¡</title><link>https://huggingface.co/posts/ovi054/581452329729774</link><description>Anim Lab AIâš¡ Turn any math concept or logic into a clear video explanation instantly using AI. This is my submission for the MCP 1st Birthday Hackathon, and itâ€™s already crossed 1,000 runs. ğŸ‘‰ Try it now: MCP-1st-Birthday/anim-lab-ai Demo outputs are attached ğŸ‘‡ See translation</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ovi054/581452329729774</guid></item><item><title>15 Outstanding Research Papers from NeurIPS 2025</title><link>https://huggingface.co/posts/Kseniase/673116238988658</link><description>15 Outstanding Research Papers from NeurIPS 2025 NeurIPS 2025, as a premier annual event in machine learning and computational neuroscience, tackles major topics like the future of AI, current research, and the most difficult challenges. While weâ€™re not attending this year, weâ€™re closely following the updates and today we pull together a quick, easy-to-digest roundup of a few standout papers so you can jump in without getting overwhelmed. Here is a list of 15 papers from NeurIPS 2025, including 8 top research papers that received awards, along with 7 others that caught our attention: 1. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks â†’ https://neurips.cc/virtual/2025/loc/san-diego/test-of-time/128328 Test of Time Award winner. Introduces the RPN, a small convnet that predicts objectness and boxes on shared features, enabling Faster R-CNN to share computation and run around 5 fps on a GPU 2. Artificial Hivemind: The Open-Ended Homogeneity of LMs (and...</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/673116238988658</guid></item><item><title>FYI: Mistral.Ministral-3 dequantizer FP8-&gt;BF16</title><link>https://huggingface.co/posts/csabakecskemeti/373541500179287</link><description>FYI: Mistral.Ministral-3 dequantizer FP8-&gt;BF16 https://github.com/csabakecskemeti/ministral-3_dequantizer_fp8-bf16 (The instruct model weights are in FP8) See translation</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/csabakecskemeti/373541500179287</guid></item><item><title>Miragic Releases Image Generation 1.2: A New Era of Text-to-Image and Image-to-Image AI Creativity</title><link>https://huggingface.co/posts/wang12390/559957056999176</link><description>Miragic Releases Image Generation 1.2: A New Era of Text-to-Image and Image-to-Image AI Creativity Artificial intelligence continues to reshape how we design, create, and communicate visually. Today, Miragic is proud to introduce Image Generation 1.2, the latest upgrade to our AI image generation ecosystem. This new release brings significant improvements in text-to-image and image-to-image capabilities, and it arrives with a powerful lineup of advanced AI models. Whether you're a designer, developer, marketer, or content creator, Image Generation 1.2 is engineered to help you turn ideas into stunning visuals faster and more accurately than ever before. With this release, users now have access to a diverse set of cutting-edge models including: Miragic v1.0 Miragic v1.1 Flux Schnell SDXL Hidream L1 Fast Nano Banana Imagen-3-Fast Seedream 4.0 Qwen-Image-Edit Each model brings a unique strengthâ€”ranging from hyper-realism and speed to detailed rendering and stylistic flexibilityâ€”giving...</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wang12390/559957056999176</guid></item><item><title>The new Mistral 3 models are here !</title><link>https://huggingface.co/posts/Jofthomas/993866418471203</link><description>The new Mistral 3 models are here ! Today, we announce Mistral 3, the next generation of Mistral models. Mistral 3 includes three state-of-the-art small, dense models (14B, 8B, and 3B) and Mistral Large 3 â€“ our most capable model to date â€“ a sparse mixture-of-experts trained with 41B active and 675B total parameters. All models are released under the Apache 2.0 license. Ministrals : https://huggingface.co/collections/mistralai/ministral-3 Mistral Large 3: https://huggingface.co/collections/mistralai/mistral-large-3 See translation</description><pubDate>Sun, 07 Dec 2025 17:19:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jofthomas/993866418471203</guid></item></channel></rss>