<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Happy 2026 everyone!</title><link>https://huggingface.co/posts/mike-ravkine/983643024828039</link><description>Happy 2026 everyone! I've been busy working on some new ranking/position methodologies and excited to start sharing some results. Plot legends: - X = truncation rate (low = good) - ? = confusion rate (low = good) - blue bars = average completion tokens (low = good) - black diamonds = CI-banded performance (high = good) - cluster squares = models inside this group are equivalent openai/gpt-oss-120b remains the king in all dimensions of interest: truncation rates, completion lengths and performance. If I had but one complaint it's the reason_effort does not seem to actually work - more on this soon. Second is a 3-way tie in performance between the Qwen3-235B-2507 we all know and love with an unexpected entrant - ByteDance-Seed/Seed-OSS-36B-Instruct This is a very capable model and it's reasoning effort controls actually works, but you should absolutely not leave it on the default "unlimited" - enable a sensible limit (4k works well for 8k context length). Third place is another 3-way...</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mike-ravkine/983643024828039</guid></item><item><title>The recent update to Meta's ad algorithm is very difficult to crack, and even the latest models struggle to keep up with it. To address this, we've created a small experimental dataset for fine-tuning models to better tackle Meta's Andromeda algorithm:</title><link>https://huggingface.co/posts/Sri-Vigneshwar-DJ/560303758243355</link><description>The recent update to Meta's ad algorithm is very difficult to crack, and even the latest models struggle to keep up with it. To address this, we've created a small experimental dataset for fine-tuning models to better tackle Meta's Andromeda algorithm: Sri-Vigneshwar-DJ/hawky-ai-andromeda-dataset See translation</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Sri-Vigneshwar-DJ/560303758243355</guid></item><item><title>Happy New Year, Hugging Face!</title><link>https://huggingface.co/posts/unmodeled-tyler/448164360090025</link><description>Happy New Year, Hugging Face! It's been a crazy year for me! This year I launched VANTA Research as a solo operator and managed to push out 14 original open source finetunes and 5 datasets in the span of about 4 months, completely on my own. The reception has been much higher than I ever anticipated and sincerely appreciate everyone that's checked out my work thus far. The good news is, I'm just getting started! In 2026 you can expect even more original models from VANTA Research, more open source datasets, and maybe some other cool things as well? üëÄ 2026 is gonna be big for AI in general, and I can't wait to experience it with all of you! See translation</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/448164360090025</guid></item><item><title>The list of hands-on notebooks (some beginner-friendly!) to get started with fine-tuning using TRL keeps growing!!</title><link>https://huggingface.co/posts/sergiopaniego/761887592219179</link><description>The list of hands-on notebooks (some beginner-friendly!) to get started with fine-tuning using TRL keeps growing!! ‚Ä¢ SFT ‚Ä¢ GRPO ‚Ä¢ Tool calling &amp; agents ‚Ä¢ RL environments with OpenEnv ‚Ä¢ LLMs and VLMs ‚ú® Many run on FREE Colab, making it super easy to get started fast! https://github.com/huggingface/trl/tree/main/examples/notebooks See translation</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/761887592219179</guid></item><item><title>We tested the maximum dynamic payload of the SO-ARM101 with our parallel gripper and a base servo replaced by a Feetech STS3250. The maximum load before failure was 630 g, at which point the Feetech STS3215 in joint 3 failed ‚Äî its large brass output gear was completely worn down.</title><link>https://huggingface.co/posts/branikita/824421158823011</link><description>We tested the maximum dynamic payload of the SO-ARM101 with our parallel gripper and a base servo replaced by a Feetech STS3250. The maximum load before failure was 630 g, at which point the Feetech STS3215 in joint 3 failed ‚Äî its large brass output gear was completely worn down. The Feetech STS3250 in the base with a metal gear train withstood a significantly higher load. See translation</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/824421158823011</guid></item><item><title>Happy New Years 2026!</title><link>https://huggingface.co/posts/mahimairaja/451884860016905</link><description>Happy New Years 2026! For next 365 days I will be commit to work on: - Document AI and OCR Automations - Voice Agents - Long Running Tasks - Durable Agents See translation</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mahimairaja/451884860016905</guid></item><item><title>New year, new dataset üöÄ</title><link>https://huggingface.co/posts/omarkamali/313633076135960</link><description>New year, new dataset üöÄ I just released omarkamali/wikipedia-labels , with all the structural labels and namespace from wikipedia in 300+ languages. A gift for the data preprocessors and cleaners among us. Happy new year 2026 everyone! üéÜ See translation</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/omarkamali/313633076135960</guid></item><item><title>With VLAgentIc, you can now use your local Qwen installation via Ollama and leverage the models</title><link>https://huggingface.co/posts/cedricbonhomme/885576259847463</link><description>With VLAgentIc, you can now use your local Qwen installation via Ollama and leverage the models CIRCL/vulnerability-severity-classification-roberta-base and CIRCL/cwe-parent-vulnerability-classification-roberta-base . The project is available here: https://github.com/vulnerability-lookup/VLAgentIc The VLAI Severity and CWE classifiers are available on Hugging Face: - CIRCL/vulnerability-severity-classification-roberta-base - CIRCL/cwe-parent-vulnerability-classification-roberta-base The concept of AI agents‚Äîcombining models, tools, and orchestration‚Äîhas become fairly standardized during the last year, but VLAgentIc brings something unique: - Agents communicate over XMPP, enabling concurrent tasks and asynchronous messaging thanks to the SPADE framework. - Built-in presence and discovery streamline interactions between components. - Flexible behaviours make orchestrating AI-assisted security workflows seamless for future connections - Last but not least, the VLAI Severity and VLAI...</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/cedricbonhomme/885576259847463</guid></item><item><title>gRPC support in Voiden</title><link>https://huggingface.co/posts/dhruv3006/444530398664756</link><description>gRPC support in Voiden gRPC has become a popular choice for building high-performance, scalable APIs, especially in microservices and real-time systems. Unlike traditional REST APIs, gRPC uses HTTP/2 and Protocol Buffers to deliver fast, efficient communication with strong typing and contract enforcement. Many developers in our community asked for it, so we have now added gRPC support in the latest Voiden release.You can now test and document gRPC APIs side-by-side with your REST and WebSocket APIs. Keep everything in one file-centric, Git-native workflow. Use reusable blocks and version control for gRPC requests, just like any other API call. Download the latest Voiden beta here: https://voiden.md/download See translation</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/444530398664756</guid></item><item><title>The Architecture of 2026: Beyond the Token Trap üöÄ</title><link>https://huggingface.co/posts/mindchain/406965796956131</link><description>The Architecture of 2026: Beyond the Token Trap üöÄ We are witnessing a tectonic shift in Transformer architecture. It‚Äôs no longer just about "predicting the next token"‚Äîit‚Äôs about executing latent plans on a high-speed data highway. What happens when we combine DeepSeek‚Äôs stability with Google‚Äôs strategic intelligence? 1Ô∏è‚É£ The Infrastructure: DeepSeek‚Äôs mHC Moving from a single-lane residual stream to a multi-lane highway. Using the Birkhoff Polytope, mHC ensures mathematical stability (Identity Mapping) while routing specialized data through dedicated lanes. 2Ô∏è‚É£ The Intelligence: Google‚Äôs Meta-Controller An internal AI unit that lives inside the Transformer. It escapes the "Token Trap" by extracting data to create a latent plan, steering the model via Temporal Abstraction. The Synergy: In a Topological Transformer, the Meta-Controller finally has the "dedicated lanes" it needs to steer complex reasoning without causing gradient explosions. We aren't just making models bigger; we are...</description><pubDate>Sun, 04 Jan 2026 13:32:52 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mindchain/406965796956131</guid></item></channel></rss>