<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Dropped the HeadshotX : a super-realistic headshot adapter for</title><link>https://huggingface.co/posts/prithivMLmods/508433106733374</link><description>Dropped the HeadshotX : a super-realistic headshot adapter for Qwen/Qwen-Image , an image generation model by Qwen. It is an advanced LoRA adaptation of the Qwen-Image model and an upgraded version of prithivMLmods/Qwen-Image-Studio-Realism , offering more precise portrait rendering with a strong focus on realism. The model was trained on diverse face types from across the world, labeled with florence2-en and caption-optimized using prithivMLmods/DeepCaption-VLA-7B . 11(types) √ó 5 different face types: Asian, Hispanic, Caucasian, Latina, Middle Eastern, etc. ‚Æû Modelü§ó: prithivMLmods/Qwen-Image-HeadshotX ‚Æû The Previous Adapter (LoRA): prithivMLmods/Qwen-Image-Studio-Realism ‚Æû Collection: prithivMLmods/qwen-image-exp-lora-68a978fe11400bc3165b0c4d . . . To know more about it, visit the app page or the respective model page!! See translation</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/508433106733374</guid></item><item><title>a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns.</title><link>https://huggingface.co/posts/hesamation/792197182072762</link><description>a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns. the table of contents looks like everything you need to know about agents + code: &gt; advanced prompt techniques &gt; multi-agent patterns &gt; tool use and MCP &gt; you name it read it here: https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0#heading=h.pxcur8v2qagu you can also pre-order on Amazon (published by Springer) and the royalties goes to Save the Children: https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/ See translation</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hesamation/792197182072762</guid></item><item><title>10 Latest Preference Optimization Techniques</title><link>https://huggingface.co/posts/Kseniase/304021452230579</link><description>10 Latest Preference Optimization Techniques Models need feedback on what makes outputs ‚Äúgood‚Äù or ‚Äúbad.‚Äù Policy optimization (PO) turns preferences and rewards into actual training signals. This field is evolving quickly, moving far beyond classics like PPO and GRPO. So here is our overview of 10 newest PO methods: 1. Pref-GRPO ‚Üí Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning (2508.20751) Stabilizes text-to-image reinforcement learning (RL) with pairwise preference rewards and a unified UNIGENBENCH benchmark 2. PVPO (Policy with Value Preference Optimization) ‚Üí PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning (2508.21104) This critic-free RL method uses a pre-trained model as a reference anchor to reduce bias and guide learning, selecting high-value examples through data pre-sampling 3. DCPO (Dynamic Clipping Policy Optimization) ‚Üí DCPO: Dynamic Clipping Policy Optimization (2509.02333) Uses dynamic clipping,...</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/304021452230579</guid></item><item><title>SUPIR is Still Unchallanged Image Upscaler ‚Äî Supports GPUs starting from RTX 1000 series to RTX 5000 series</title><link>https://huggingface.co/posts/MonsterMMORPG/213039111279918</link><description>SUPIR is Still Unchallanged Image Upscaler ‚Äî Supports GPUs starting from RTX 1000 series to RTX 5000 series App Download Link You can download SUPIR app from here : https://www.patreon.com/posts/99176057 CHECK BELOW SCREENSHOTS It has 1-click installers for Windows (only Python 3.10.11 and Git should be sufficient), RunPod (official Pytorch 2.2.0 template) and Massed Compute template Creator &gt; SECourses App Info SUPIR: Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild 1 click installer scripts. SUPIR Sampler and Text CFG Comparison : https://imgsli.com/MjU2ODQz/2/1 Gemini 2.5 Pro prompt to get image description for free : describe this image for sdxl. write single line prompt to regenerate it exactly same. make the prompt extremely detailed https://aistudio.google.com/prompts/new_chat Use Default preset for highest loyalty and Replicate preset for adding more details Human upscale from 1024x1024 to 3072x3072 (3x upscale and total 9x...</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/213039111279918</guid></item><item><title>Comparing: DeepCaption-VLA-7B, built on Qwen2.5-VL-7B-Instruct, is tailored for image captioning and vision-language attribution, focusing on precise, descriptive captions of visual properties, object attributes, and scene details. In contrast, Qwen2.5-VL-7B-Abliterated-Caption-it is fine-tuned for abliterated captioning, generating highly detailed descriptions across diverse visual categories.</title><link>https://huggingface.co/posts/prithivMLmods/101885688055842</link><description>Comparing: DeepCaption-VLA-7B, built on Qwen2.5-VL-7B-Instruct, is tailored for image captioning and vision-language attribution, focusing on precise, descriptive captions of visual properties, object attributes, and scene details. In contrast, Qwen2.5-VL-7B-Abliterated-Caption-it is fine-tuned for abliterated captioning, generating highly detailed descriptions across diverse visual categories. Modelsü§ó ‚ú¶ DeepCaption-VLA-7B : prithivMLmods/DeepCaption-VLA-7B ‚ú¶ Qwen2.5-VL-7B-Abliterated-Caption-it : prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it Spaces‚õµ ‚ûú VisionScope-R2 : prithivMLmods/VisionScope-R2 ‚ûú Qwen2.5-VL-Outpost : prithivMLmods/Qwen2.5-VL-Outpost CollectionüóûÔ∏è DeepCaption attr. : prithivMLmods/deepcaption-attr-68b041172ebcb867e45c556a VL Abliterated-Caption : prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 Multimodal VLMs - Until July'25 : prithivMLmods/multimodal-vlms-until-july25-688312e6b840e1e156f13027 Multimodal VLMs - Aug'25 : prithivMLmods/multimodal-...</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/101885688055842</guid></item><item><title>Shout out to the winners of the "Synthetic2Real Object Detection Challenge" Duality AI hosted earlier this year. Out of the 1000+ participants in our challenges, these users stood out above the rest.</title><link>https://huggingface.co/posts/DualityAI-RebekahBogdanoff/823785587931139</link><description>Shout out to the winners of the "Synthetic2Real Object Detection Challenge" Duality AI hosted earlier this year. Out of the 1000+ participants in our challenges, these users stood out above the rest. ü•á 1st place: Kaggle user "richardtroy" ü•à 2nd place: @ sergio-sanz-rodriguez ü•â 3rd place: @ Nadiaaaaaaa View the entire leaderboard at - https://tinyurl.com/38ebvcwf Join our current Grocery Items: Multi-Class Object Detection Synthetic2Real Kaggle competition here: https://tinyurl.com/y224rttu And be on the lookout for anther competition in the next couple weeks with a brand new domain! hint: ‚úàÔ∏è See translation</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DualityAI-RebekahBogdanoff/823785587931139</guid></item><item><title>The open source AI community is just made of people who are passionate and care about their work. So we thought it would be cool to share our favourite icons of the community with a fun award.</title><link>https://huggingface.co/posts/burtenshaw/554434209344305</link><description>The open source AI community is just made of people who are passionate and care about their work. So we thought it would be cool to share our favourite icons of the community with a fun award. Winners get free Hugging Face Pro Subscriptions, Merchandise, or compute credits for the hub. üîó Follow and nominate here: community-spotlight This is a new initiative to recognise and celebrate the incredible work being done by community members. It's all about inspiring more collaboration and innovation in the world of machine learning and AI. They're highlighting contributors in four key areas: - model creators: building and sharing innovative and state-of-the-art models. - educators: sharing knowledge through posts, articles, demos, and events. - tool builders: creating the libraries, frameworks, and applications that we all use. - community champions: supporting and mentoring others in forums. Know someone who deserves recognition? Nominate them by opening a post in the Hugging Face...</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/554434209344305</guid></item><item><title>The docs for GitRank are live! Follow along to see how you can:</title><link>https://huggingface.co/posts/salma-remyx/773060827423074</link><description>The docs for GitRank are live! Follow along to see how you can: üìñ Daily personalized papers from arXiv matching your project context üë©‚Äçüíª One-click PRs with complete implementation, tests, and docs üöÄ Parallel experimentation - test multiple ideas with ease Your next great idea is probably in a paper you haven't had time to implement. Try it today! http://docs.remyx.ai/resources/ideate See translation</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/salma-remyx/773060827423074</guid></item><item><title>Hello everyone</title><link>https://huggingface.co/posts/andywu-kby/346535541829962</link><description>Hello everyone Good day! We have launched the product - Virtual Try On üöÄ Say goodbye to the uncertainty of online shopping with Miragic‚Äôs Virtual Try-On solution! Our cutting-edge AI technology lets you try on clothes virtually, offering a seamless and interactive shopping experience. Whether you're exploring new outfits or simply trying before you buy, Miragic gives you a realistic view of how items will look on you‚Äîwithout ever stepping into a store. Miragic-AI/Miragic-Virtual-Try-On üåü Key Features: - Realistic 3D Try-On: See how clothes fit and look on your virtual self in real-time. - Personalized Fit: Using advanced body-scanning tech, Miragic adjusts the fit based on your unique measurements. - Wide Fashion Selection: Browse through various brands and styles, all available for a virtual try-on. - Sustainable Shopping: Reduce the need for returns and make more eco-friendly choices with a virtual experience that helps you shop smarter. üëö Why Virtual Try-On? - Save time and money...</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/andywu-kby/346535541829962</guid></item><item><title>Cua: Best State-of-the-Art Computer-Use Agent</title><link>https://huggingface.co/posts/dhruv3006/362032292361583</link><description>Cua: Best State-of-the-Art Computer-Use Agent Build a SOTA Computer-Use Agent using Cua ( https://github.com/trycua/cua ), the open-source infrastructure and agent framework for controlling real desktop and browser environments. Submissions are evaluated in HUD‚Äôs OSWorld-Verified benchmarking environment. The top-scoring team earns a secured interview with a Y Combinator partner for the next batch. Prizes: Guaranteed YC partner interview Feature on the Cua blog + social channels Swag pack for each team member Eligibility: To be considered for judging and prizes, sign up at https://www.trycua.com/hackathon See translation</description><pubDate>Mon, 08 Sep 2025 09:26:53 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/362032292361583</guid></item></channel></rss>