<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>4 must-try AI video models in 2026 ‚Äî all in one place on iMini! üé¨‚ú®</title><link>https://huggingface.co/posts/404Zen/731905286538257</link><description>4 must-try AI video models in 2026 ‚Äî all in one place on iMini! üé¨‚ú® Featuring Sora 2, Veo 3, Wan 2.5, and Seedance 3.0 ‚Äî no invite code, no watermark! Try it now üëâ https://imini.com/ See translation</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/404Zen/731905286538257</guid></item><item><title>How to compress long code context? üìö</title><link>https://huggingface.co/posts/YerbaPage/639392890035292</link><description>How to compress long code context? üìö Check out our LongCodeZip! Paper just got accepted to ASE 2025. üî• Code &amp; Demo: https://github.com/YerbaPage/LongCodeZip Paper: LongCodeZip: Compress Long Context for Code Language Models (2510.00446) See translation</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/639392890035292</guid></item><item><title>Just tried to create an educational assistant for younger people who can struggle with visualsation of 'what is this sorcery all about'.</title><link>https://huggingface.co/posts/s3nh/172255383269757</link><description>Just tried to create an educational assistant for younger people who can struggle with visualsation of 'what is this sorcery all about'. Its first step of my spare time projects, sft on Qwen3-8B, EduHelper is a child-friendly tutoring assistant fine-tuned from the Qwen3-8B base model using parameter-efficient fine-tuning (PEFT) with LoRA on the ajibawa-2023/Education-Young-Children dataset. s3nh/EduHelp-8B Glad to share my work, have a wonderful day! See translation</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/s3nh/172255383269757</guid></item><item><title>üì¢ Product Update: SalesPilot 1.2 Released!</title><link>https://huggingface.co/posts/andywu-kby/521155221047550</link><description>üì¢ Product Update: SalesPilot 1.2 Released! üîß What‚Äôs New: - Sales Forecasting, Sales Analysis using Excel - No technical skills required - Dashboard and Delete Functionality - Chatbot Application https://miragic.ai/products/sales-pilot Looking forward to your feedback! See translation</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/andywu-kby/521155221047550</guid></item><item><title>You think those playful puppies are real? üê∂‚ú®</title><link>https://huggingface.co/posts/Monica997/870861781065582</link><description>You think those playful puppies are real? üê∂‚ú® Nope! It‚Äôs a video I created using iMini‚Äôs newly integrated Sora 2 model ‚Äî no invite code, no watermark, just one simple text prompt to generate dynamic videos in seconds! üé¨ Limited-time offer: members can create without using credits! üëâ Try it now: https://imini.com/ See translation</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Monica997/870861781065582</guid></item><item><title>9 Powerful AI Video Generation Tools</title><link>https://huggingface.co/posts/Kseniase/543365627154110</link><description>9 Powerful AI Video Generation Tools Since Sora 2 is on fire these weeks, reminding us what high-quality video generation should look like, we decided you really need this list of video generation tools ‚Äì great alternatives or complements to it. 1. Sora 2 ‚Üí https://openai.com/sora/ It needs no introduction, but this OpenAI‚Äôs text-to-video model produces short, ultra-realistic clips across styles (cinematic, photorealistic, animated, etc.) with synced audio 2. Google Veo 3 (Gemini Video Generation) ‚Üí https://aistudio.google.com/models/veo-3 Part of Gemini AI. Generates 8-second high-fidelity videos from text or images with native sound: background soundtracks and realistic voices with near-perfect lip sync 3. Runway (Gen-4 by Runway ML) ‚Üí https://runwayml.com/ Text, image, or video-to-video generation with advanced editing like changing lighting, weather, camera angles or replacing objects. Popular in AI filmmaking 4. Pika Labs ‚Üí https://pollo.ai/m/pika-ai Provides creative, often...</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/543365627154110</guid></item><item><title>Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13:</title><link>https://huggingface.co/posts/mike-ravkine/324105560308241</link><description>Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13: aquif-ai/aquif-3.5-8B-Think Built on top of the solid Qwen3-8B foundation, aquif-3.5-8B-Think successfully preserves the high performance of the original model while consuming 30-50% less reasoning tokens. The most notable regression vs the base model here is in arithmetic - if your workload is math heavy this model demonstrates an unfortunate collapse with performance under growing complexity. The interesting combination of awesome overall performance on SVG simple shapes identification coupled with a total inability to recognize more complex shapes like 'House' or 'Arrow' is a behavior directly inherited from the base model (but with a ~20% improvement in token utilization). If you like your reasoning models token-efficient, Aquif-3.5-8B-Think is well worth a spin. Higher resolution, more detailed, interactive plots are available at the m12X explorer: https://reasonscape.com/m12x/explorer/...</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mike-ravkine/324105560308241</guid></item><item><title>Released an AWQ quantized version of BosonAI‚Äôs Higgs-Llama-3-70B model! üéâ</title><link>https://huggingface.co/posts/ronantakizawa/301388923540512</link><description>Released an AWQ quantized version of BosonAI‚Äôs Higgs-Llama-3-70B model! üéâ The Higgs-Llama-3-70B is an LLM specialized in role-playing, useful for game characters. Using an NVIDIA B200 GPU, I was able to compress the huge 140GB model into 37GB while keeping minimal perplexity üëç ronantakizawa/higgs-llama-3-70b-awq See translation</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/301388923540512</guid></item><item><title>Introducing Image-Guard-2.0, an experimental, lightweight vision-language encoder model with a size of 0.1B (&lt;100M parameters), trained on SigLIP2 (siglip2-base-patch16-224). Designed for multi-label image classification tasks, this model functions as an image safety system, serving as an image guard or moderator across a wide range of categories, from anime to realistic imagery.</title><link>https://huggingface.co/posts/prithivMLmods/280533880488225</link><description>Introducing Image-Guard-2.0, an experimental, lightweight vision-language encoder model with a size of 0.1B (&lt;100M parameters), trained on SigLIP2 (siglip2-base-patch16-224). Designed for multi-label image classification tasks, this model functions as an image safety system, serving as an image guard or moderator across a wide range of categories, from anime to realistic imagery. ‚ö°blog-article: https://huggingface.co/blog/prithivMLmods/image-guard-models It also performs strict moderation and filtering of artificially synthesized content, demonstrating strong detection and handling of explicit images. Image-Guard-2.0 delivers robust performance in streamlined scenarios, ensuring reliable and effective classification across diverse visual inputs. See translation</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/280533880488225</guid></item><item><title>‚úÖ New Article: *Humor as Structured Protocol*</title><link>https://huggingface.co/posts/kanaria007/662291776092926</link><description>‚úÖ New Article: *Humor as Structured Protocol* Title: üé≠ Humor as Structured Protocol: Joke-Protocols as Emotion Regulation and AGI Design Resource üîó https://huggingface.co/blog/kanaria007/humor-as-structured-protocol --- Summary: Humor isn‚Äôt a distraction ‚Äî it‚Äôs a *protocol*. By framing paradox as *benign*, humor vents overload, resets attention, and enables safe re-entry to difficult topics. In Structured Intelligence terms, jokes are *bounded anomalies* that discharge tension without breaking identity or trust. &gt; Laughter is relief. &gt; *Humor is the design that makes relief safe.* --- Why It Matters: ‚Ä¢ Turns ‚Äúcomic timing‚Äù into *recoverable state transitions* (no denial, no collapse) ‚Ä¢ Gives teams and products a *de-escalation primitive* that preserves dignity ‚Ä¢ Informs *AI/UX safety*: sandboxed incongruity, ethical gates, clear exit paths --- What‚Äôs Inside: ‚Ä¢ The Humor Protocol: trigger ‚Üí incongruity ‚Üí benign boundary ‚Üí release ‚Üí re-entry ‚Ä¢ Patterns: irony, self-deprecation,...</description><pubDate>Wed, 15 Oct 2025 09:26:08 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/662291776092926</guid></item></channel></rss>