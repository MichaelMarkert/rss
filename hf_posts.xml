<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>The 2025 Chinese LLM Showdown: Western Models Still Dominate Top 4, but China Leads the Open-Source Arena.</title><link>https://huggingface.co/posts/imnotkitty/790273915312125</link><description>The 2025 Chinese LLM Showdown: Western Models Still Dominate Top 4, but China Leads the Open-Source Arena. ğŸ† The Champions: Claude-Opus-4.5, Gemini-3-Pro, GPT-5.2, and Gemini-3-Flash sweep the top four spots. ğŸš€ The Pursuers: Doubao and DeepSeek-V3.2 tie for first place among Chinese models; GLM-4.7, ERNIE-5.0, and Kimi secure their positions in the domestic top five. ğŸ”¥ The Biggest Highlight: The top three spots on the open-source leaderboard are entirely held by Team China (DeepSeek, GLM, Kimi), outperforming the best western open-source models. See translation</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/imnotkitty/790273915312125</guid></item><item><title>Not for everybody, but the absolute mad craze about clawdbot/moltbook the last couple of days reminded me of a short story I wrote in 2018 (ancient times!).</title><link>https://huggingface.co/posts/neph1/280223950636420</link><description>Not for everybody, but the absolute mad craze about clawdbot/moltbook the last couple of days reminded me of a short story I wrote in 2018 (ancient times!). Synopsis: "A man insults a sentient traffic light on the way to a meeting. Little does he know it is connected to a social media network for AI, and that his action will lead to a very bad day." Cleanliness is bliss (&lt;1000 words) https://www.wattpad.com/story/407330595-cleanliness-is-bliss Sorry for the non-technical post, but it felt relevant. See translation</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/neph1/280223950636420</guid></item><item><title>Experimental global target bitsâ€‘perâ€‘weight quantization of mistralai/Ministral-3-14B-Instruct-2512 and mistralai/Ministral-3-14B-Reasoning-2512</title><link>https://huggingface.co/posts/eaddario/695215283251750</link><description>Experimental global target bitsâ€‘perâ€‘weight quantization of mistralai/Ministral-3-14B-Instruct-2512 and mistralai/Ministral-3-14B-Reasoning-2512 Unlike standard llama.cpp quantizations that rely on fixed type heuristics (e.g., Q4_K_M), the Target BPW approach optimizes per-tensor precision where it matters the most, and produces high quality models that meet a precise global file size target. Key Advantages: - VRAM Maximization: Can generate high quality models sized exactly to fit hardware constraints (e.g., fitting the model into exactly 24GB VRAM). - Data-Driven Precision: Quantization mix is determined by actual weight error sensitivity rather than hardcoded rules, often yielding better PPL/KLD size trade-offs. Full benchmarks (PPL, KLD, ARC, MMLU, etc.) and methodology in the models' cards eaddario/Ministral-3-14B-Instruct-2512-GGUF eaddario/Ministral-3-14B-Reasoning-2512-GGUF See translation</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/eaddario/695215283251750</guid></item><item><title>Geilim-1B-SR-Instruct â€” Serbian Intelligence for Deep Reasoning ğŸ§ ğŸ‡·ğŸ‡¸</title><link>https://huggingface.co/posts/OzTianlu/678257236628568</link><description>Geilim-1B-SR-Instruct â€” Serbian Intelligence for Deep Reasoning ğŸ§ ğŸ‡·ğŸ‡¸ NoesisLab/Geilim-1B-SR-Instruct Geilim-1B-SR-Instruct is a lightweight Large Language Model (LLM) designed to bring advanced reasoning capabilities to low-resource languages. It focuses on Serbian understanding and generation while maintaining robust English reasoning. Built on the LLaMA-3 architecture with a proprietary hybrid reasoning mechanism, it delivers deep logic while keeping outputs concise and natural. ğŸš€ Core Innovations ğŸ’¡ Implicit Deep Reasoning: Combines standard attention mechanisms with graph-structured reasoning components for rigorous logic and causal inference. ğŸ•¸ï¸ ASPP &amp; -flow Hybrid Design: High-efficiency structured propagation + internal probability space optimization for high-quality reasoning without long-winded intermediate steps. âš¡ Bilingual Adaptation: Primarily focused on Serbian while preserving English logic, making it perfect for multilingual chats and cross-lingual tasks. ğŸŒ Lightweight...</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/OzTianlu/678257236628568</guid></item><item><title>A single lock on a door isn't enough. Real security is about layers.</title><link>https://huggingface.co/posts/MikeDoes/512575404125311</link><description>A single lock on a door isn't enough. Real security is about layers. The same is true for AI privacy. A new paper, "Whispered Tuning", offers a fantastic layered solution that aims to fortify LLMs against privacy infringements. We're proud that the first, essential layer, a high-precision PII redaction model was built on the foundation of the Ai4Privacy/pii-65k dataset. Our dataset provided the necessary training material for their initial anonymization step, which then enabled them to develop further innovations like differential privacy fine-tuning and output filtering. This is a win-win: our data helps create a solid base, and researchers build powerful, multi-stage privacy architectures on top of it. Together, we're making AI safer. ğŸ”— Read the full paper to see how a strong foundation enables a complete privacy solution: https://www.scirp.org/journal/paperinformation?paperid=130659 ğŸš€ Stay updated on the latest in privacy-preserving AIâ€”follow us on LinkedIn:...</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/512575404125311</guid></item><item><title>ğŸ“¢ Who want's to have a quick start for adapting CoT schema for any LLM, this post would be relevant.</title><link>https://huggingface.co/posts/nicolay-r/337674723701292</link><description>ğŸ“¢ Who want's to have a quick start for adapting CoT schema for any LLM, this post would be relevant. Excited to share a new version of ğŸŒŸ bulk-chain ğŸŒŸ! Bulk-chain is high-level wrapper over LLM providers for efficient quering LLMs hosted by third-party services. It brings native batching via support of async clients. ğŸŒŸ https://github.com/nicolay-r/bulk-chain/tree/master What's new: â˜‘ï¸ Simplified inference setup The API is now closer to the OpenAI paradigm for toggling streaming. Instead of separate patterns in 1.2.0, now it is possible to simple toggles to enable streaming and async behavior. â˜‘ï¸ ğŸ› ï¸ Fixed issues when passing code contain {} blocks â˜‘ï¸ ğŸ› ï¸ Async streaming + batching now works properly â˜‘ï¸ ğŸ› ï¸ Logging of prompts could be disabled https://github.com/nicolay-r/bulk-chain ğŸš¨ Guys, I am open to work as developer / researcher in AI / NLP / IR in the UK ğŸ‡¬ğŸ‡§ ğŸŒŸ Feel free to support bulk-chain on Github if you like so, or this post. It helps alot! See translation</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/337674723701292</guid></item><item><title>ğŸ¯ WAVe: 1B Multimodal Embedding Model for Word-Level Speech Quality</title><link>https://huggingface.co/posts/yuriyvnv/972315277032860</link><description>ğŸ¯ WAVe: 1B Multimodal Embedding Model for Word-Level Speech Quality Multimodal embeddings for speech + transcript that verify quality at the word level, not just sentence level. Catches mispronunciations, timing errors, and prosody issues that sentence-level filters miss. ğŸ“Š Impact on Portuguese ASR: â€¢ 34% reduction in training steps â€¢ 50% better cross-domain generalization â€¢ 30% less synthetic data needed â€¢ Word-aligned attention finds errors other methods miss ğŸ—ï¸ Architecture: â€¢ Text: XLM-RoBERTa (278M params) â€¢ Audio: Wav2Vec2-BERT 2.0 (581M params) â€¢ Word Alignment: Multi-head attention + GLU (14M params) â€¢ Total: 1B parameters from transformers import AutoModel, AutoProcessor processor = AutoProcessor.from_pretrained( "yuriyvnv/WAVe-1B-Multimodal-PT" , trust_remote_code = True ) model = AutoModel.from_pretrained( "yuriyvnv/WAVe-1B-Multimodal-PT" , trust_remote_code = True ) # Assess speech-transcript alignment inputs = processor( text = "OlÃ¡, como estÃ¡?" , audio =audio_array,...</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/yuriyvnv/972315277032860</guid></item><item><title>ğŸ›ï¸ Microsoft CodePlex Archive Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/211988639050417</link><description>ğŸ›ï¸ Microsoft CodePlex Archive Dataset - nyuuzyou/ms-codeplex-archive Following the strong response to the Google Code Archive nyuuzyou/google-code-archive (thanks!), this release preserves another major historical repository: the Microsoft CodePlex Archive. CodePlex served as Microsoftâ€™s primary open-source hosting platform from 2006 to 2017. This dataset captures the distinct .NET and Windows-centric development ecosystem that flourished before the industry standardizing on GitHub. Key Stats: - 5,043,730 files from 38,087 repositories - 3.6 GB compressed Parquet - 91 programming languages (Heavily featuring C#, ASP.NET, and C++) - Cleaned of binaries, build artifacts, and vendor directories (node_modules, packages) - Includes platform-specific license metadata (Ms-PL, Ms-RL) See translation</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/211988639050417</guid></item><item><title>LTX 2 &amp; Z Image Base Full Tutorial + Audio to Video Lip Sync + ComfyUI + SwarmUI + Windows + Cloud</title><link>https://huggingface.co/posts/MonsterMMORPG/813967180726808</link><description>LTX 2 &amp; Z Image Base Full Tutorial + Audio to Video Lip Sync + ComfyUI + SwarmUI + Windows + Cloud Full tutorial link &gt; https://www.youtube.com/watch?v=SkXrYezeEDc Info LTX 2 is the newest state of the art (SOTA) Open Source video generation model and tutorial will show you how to use it with very best and most performant way in ComfyUI and also in SwarmUI. Moreover, Z Image Base model published and I will show how to use Z Image Base with most amazing preset and workflow as well. Furthermore, this tutorial will show you how to install, update, setup, download ComfyUI and SwarmUI and models and presets and workflows both on Windows and on RunPod, Massed Compute and SimplePod. Linux users can use Massed Compute scripts and installers directly. This is a masterpiece entire lecture level complete tutorial. This video will kickstart your AI journey 100x. Both local Windows and Cloud. 45 Second Raw Demo Video This video made with text + image + audio = lip synched and animated video at...</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/813967180726808</guid></item><item><title>Moltbook, a Reddit platform only for AI agents, is going viral right now as agents are acting unhinged!</title><link>https://huggingface.co/posts/ronantakizawa/863264925055641</link><description>Moltbook, a Reddit platform only for AI agents, is going viral right now as agents are acting unhinged! I compiled a dataset of all posts and subreddits in Moltbook so far so anyone can easily analyze the activity in Moltbook. ronantakizawa/moltbook #moltbook #clawd #aiagent See translation</description><pubDate>Tue, 03 Feb 2026 09:50:48 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/863264925055641</guid></item></channel></rss>