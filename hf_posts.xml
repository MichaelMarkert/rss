<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments</title><link>https://huggingface.co/posts/sergiopaniego/565991505089039</link><description>we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments train a model to interact with a browser (üéÆ BrowserGym Env), play Wordle (üéÆ Wordle Env) and moooore! TRL (GRPO + vLLM) + OpenEnv! ‚ö°Ô∏è üìù go play with them: https://github.com/huggingface/trl/tree/main/examples/scripts/openenv üìù examples list: https://huggingface.co/docs/trl/main/en/example_overview#scripts See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/565991505089039</guid></item><item><title>Transforming Ideas Into Art: My New AI Speed Painting Demo</title><link>https://huggingface.co/posts/wang12390/386545539363465</link><description>Transforming Ideas Into Art: My New AI Speed Painting Demo I‚Äôm excited to share my latest AI speed painting demonstration, showcasing how quickly and smoothly AI can transform a simple idea into a fully rendered artwork. This video highlights the power of real-time AI brushwork, dynamic color composition, and fluid scene construction ‚Äî all generated using my custom Miragic Speed Painting engine. What This Demo Shows - Ultra-fast painting generation from start to finish - Smooth, natural brushstrokes that feel hand-drawn - Stable composition and color consistency - A cinematic visual style suitable for creative projects - No diffusion-style noise or randomness ‚Äî just pure painting Speed painting is perfect for: - Content creators and video editors - Graphic designers and social media marketers - Artists exploring quick concepts - Businesses needing fast creative assets - Anyone who wants beautiful visuals‚Ä¶ without waiting minutes or hours Watch the Video I‚Äôve attached the full speed...</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wang12390/386545539363465</guid></item><item><title>Going forward, I will be adopting the term Magnitude-Preserving Orthogonal Ablation (MPOA) for my recent work in mitigating model damage from abliteration. The technique potentially unlocks reasoning capacity previously occupied with safety refusal processing.</title><link>https://huggingface.co/posts/grimjim/803126534676334</link><description>Going forward, I will be adopting the term Magnitude-Preserving Orthogonal Ablation (MPOA) for my recent work in mitigating model damage from abliteration. The technique potentially unlocks reasoning capacity previously occupied with safety refusal processing. For details, start here: https://huggingface.co/blog/grimjim/norm-preserving-biprojected-abliteration Showcase results: grimjim/gemma-3-12b-it-norm-preserved-biprojected-abliterated (outperforms base instruct on UGI Leaderboard NatInt) (The existing name, while technically accurate, was a bit of a mouthful.) See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/grimjim/803126534676334</guid></item><item><title>Proud to share the results of our engineering team‚Äôs recent work at</title><link>https://huggingface.co/posts/branikita/874837305207313</link><description>Proud to share the results of our engineering team‚Äôs recent work at Robonine : ‚Ä¢ Together, we applied advanced topology optimization to redesign critical brackets of the manipulator, achieving a 57‚Äì76% reduction in structural deflection. ‚Ä¢ Our updated model also demonstrated a major stress decrease ‚Äî from 93 MPa down to 25 MPa ‚Äî all while staying within the allowed weight increase. ‚Ä¢ Although we didn‚Äôt fully reach the target tip deviation of 0.3 mm (best achieved: 0.41 mm), the project gave us valuable insights and a solid foundation for the next design iteration. See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/branikita/874837305207313</guid></item><item><title>We‚Äôve officially kicked off the ERNIE AI Developer Challenge!</title><link>https://huggingface.co/posts/jzhang533/559250209683939</link><description>We‚Äôve officially kicked off the ERNIE AI Developer Challenge! We want to create something interesting with you all, so we partnered with Unsloth, LLaMA-Factory, Novita AI, D-Robotics, and CAMEL-AI to empower your creativity. Come build with us: https://baiduernieai.devpost.com/?utm_source=ERNIE-HF&amp;utm_medium=ERNIE-HF&amp;utm_campaign=ERNIE+AI+Developer+Challenge See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/jzhang533/559250209683939</guid></item><item><title>GLM 4.6 is on a par with Gemini 2</title><link>https://huggingface.co/posts/onekq/568645222085642</link><description>GLM 4.6 is on a par with Gemini 2 onekq-ai/WebApp1K-models-leaderboard See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/568645222085642</guid></item><item><title>Try the all-new trending Qwen-Image-Edit-2509 (Multi-Image-Edits) specialized adapter demos, including Cloth-Design-Fuse, Texture Edit, Guided-Objects-Patching, and more ‚Äî all in a single Hugging Face Space. The demo link is provided below. ü§óüî•</title><link>https://huggingface.co/posts/prithivMLmods/663896599381140</link><description>Try the all-new trending Qwen-Image-Edit-2509 (Multi-Image-Edits) specialized adapter demos, including Cloth-Design-Fuse, Texture Edit, Guided-Objects-Patching, and more ‚Äî all in a single Hugging Face Space. The demo link is provided below. ü§óüî• ‚Æû Space[Demo]: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast-Fusion ‚Æû Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection ‚Æû Base Model: Qwen/Qwen-Image-Edit-2509 Similar applications‚ÜóÔ∏è ‚Æû Kontext-Photo-Mate-v2: prithivMLmods/Kontext-Photo-Mate-v2 ‚Æû Photo-Mate-i2i: prithivMLmods/Photo-Mate-i2i ‚Æû Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast To know more about it, visit the app page or the respective model page! See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/663896599381140</guid></item><item><title>[Version 1.0] Training  Wan 2.2 LoRAs has never been easier</title><link>https://huggingface.co/posts/obsxrver/107938712743937</link><description>[Version 1.0] Training Wan 2.2 LoRAs has never been easier ( https://github.com/obsxrver/wan22-lora-training ) If you‚Äôve been wanting to train your own Wan 2.2 Video LoRAs but are intimidated by the hardware requirements, parameter tweaking insanity, or the installation nightmare‚ÄîI built a solution that handles it all for you. This is currently the easiest, fastest, and cheapest way to get a high-quality training run done. Why this method? * Zero Setup: No installing Python, CUDA, or hunting for dependencies. You launch a pre-built [Vast.AI]( http://Vast.AI ) template, and it's ready in minutes. * Full WebUI: Drag-and-drop your videos/images, edit captions, and click "Start." No terminal commands required. * Extremely Cheap: You can rent a dual RTX 5090 node, train a full LoRA in 2-3 hours, and auto-shutdown. Total cost is usually $3 or less. * Auto-Save: It automatically uploads your finished LoRA to your Cloud Storage (Google Drive/S3/Dropbox) and kills the instance so you don't...</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/obsxrver/107938712743937</guid></item><item><title>üöÄüöÄüöÄHuge biotech data drop todayüöÄüöÄüöÄ</title><link>https://huggingface.co/posts/cgeorgiaw/497452098973302</link><description>üöÄüöÄüöÄHuge biotech data drop todayüöÄüöÄüöÄ The largest drug-target dataset ever created was just released on Hugging Face‚Äîand it's still growing... EvE Bio is further updating the dataset every 8 weeks. Drug development dream. Read the blog: https://huggingface.co/blog/hugging-science/eve-bio-mapping-the-pharmone-drug-interaction Play with the data: eve-bio/drug-target-activity See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/cgeorgiaw/497452098973302</guid></item><item><title>Running large language models efficiently is more than just raw GPU power. The latest guide breaks down the essential math to determine if your LLM workload is compute-bound or memory-bound.</title><link>https://huggingface.co/posts/flozi00/635605102777732</link><description>Running large language models efficiently is more than just raw GPU power. The latest guide breaks down the essential math to determine if your LLM workload is compute-bound or memory-bound. We apply these principles to a real-world example: Qwen's 32B parameter model on the new NVIDIA RTX PRO 6000 Blackwell Edition. In this guide, you will learn how to: Calculate your GPU's operational intensity (Ops:Byte Ratio) Determine your model's arithmetic intensity Identify whether your workload is memory-bound or compute-bound Read the full guide here: https://flozi.net/en/guides/ai/llm-inference-math See translation</description><pubDate>Fri, 21 Nov 2025 09:26:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/flozi00/635605102777732</guid></item></channel></rss>