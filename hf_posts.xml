<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Happy New Years 2026!</title><link>https://huggingface.co/posts/mahimairaja/451884860016905</link><description>Happy New Years 2026! For next 365 days I will be commit to work on: - Document AI and OCR Automations - Voice Agents - Long Running Tasks - Durable Agents See translation</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mahimairaja/451884860016905</guid></item><item><title>Anonymizing a prompt is half the battle. Reliably de-anonymizing the response is the other.</title><link>https://huggingface.co/posts/MikeDoes/647817712633860</link><description>Anonymizing a prompt is half the battle. Reliably de-anonymizing the response is the other. To build a truly reliable privacy pipeline, you have to test it. A new Master's thesis does just that, and our data was there for every step. We're excited to showcase this work on handling confidential data in LLM prompts from Nedim Karavdic at M√§lardalen University. To build their PII anonymization pipeline, they first trained a custom NER model. We're proud that the Ai4Privacy pii-masking-200k dataset was used as the foundational training data for this critical first step. But it didn't stop there. The research also used our dataset to create the parallel data needed to train and test the generative "Seek" models for de-anonymization. It's a win-win when our open-source data not only helps build the proposed "better solution" but also helps prove why it's better by enabling a rigorous, data-driven comparison. üîó Check out the full thesis for a great deep-dive into building a practical, end-...</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MikeDoes/647817712633860</guid></item><item><title>As 2025 is ending i would like to thank everyone for trying out</title><link>https://huggingface.co/posts/Reubencf/502627640855049</link><description>As 2025 is ending i would like to thank everyone for trying out Reubencf/Nano_Banana_Editor looking forward to build and release more in the future for the open source community See translation</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Reubencf/502627640855049</guid></item><item><title>üî•Project Los Angeles is proud to announce the release of midisim üî•</title><link>https://huggingface.co/posts/projectlosangeles/197104277785831</link><description>üî•Project Los Angeles is proud to announce the release of midisim üî• midisim is a SOTA Python package for calculating, searching and analyzing MIDI-to-MIDI similarity at speed and scale! projectlosangeles/midisim projectlosangeles/midisim-embeddings projectlosangeles/midisim-samples If you like midisim, please ‚ù§Ô∏è Project Los Angeles Tegridy Code 2025 See translation</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/projectlosangeles/197104277785831</guid></item><item><title>EZTinker: A easy tinker-style RL-as-a-service demo</title><link>https://huggingface.co/posts/di-zhang-fdu/784326148954716</link><description>EZTinker: A easy tinker-style RL-as-a-service demo https://github.com/trotsky1997/EZTinker See translation</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/di-zhang-fdu/784326148954716</guid></item><item><title>Git is powerful, but it‚Äôs also one of the biggest sources of developer mistakes.</title><link>https://huggingface.co/posts/dhruv3006/142145591956765</link><description>Git is powerful, but it‚Äôs also one of the biggest sources of developer mistakes. What is Git GUI, and how does it help here ? Git GUI makes version control visual, predictable, and easier to reason about especially when things go wrong. That‚Äôs exactly why we built Git GUI in Voiden. Instead of relying on memorized commands, Voiden lets you see what Git is doing before it does it. What Voiden‚Äôs Git GUI helps developers do ‚Ä¢ View exact file and line-level changes before committing ‚Ä¢ Stage only intended changes (no accidental commits) ‚Ä¢ Clearly distinguish staged vs unstaged files ‚Ä¢ Inspect visual diffs with full context ‚Ä¢ Understand branches, commit history, and repo state instantly When Git behavior is hidden, errors increase. Voiden‚Äôs Git GUI doesn‚Äôt abstract Git away, it explains Git. Whether you‚Äôre new to Git or an experienced developer who prefers clarity, this is Git you can reason about. Version control should feel safe, not stressful. What Git pain points slow you down today?...</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/dhruv3006/142145591956765</guid></item><item><title>How to Use SwarmUI Presets &amp; Workflows in ComfyUI + Custom Model Paths Setup for ComfyUI &amp; SwarmUI :</title><link>https://huggingface.co/posts/MonsterMMORPG/729956870553821</link><description>How to Use SwarmUI Presets &amp; Workflows in ComfyUI + Custom Model Paths Setup for ComfyUI &amp; SwarmUI : https://www.youtube.com/watch?v=EqFilBM3i7s Full tutorial link &gt; https://www.youtube.com/watch?v=EqFilBM3i7s Info Generating workflow inside SwarmUI and using in ComfyUI is literally 1-click. In this tutorial I will show you how to use our 40+ amazing generative AI presets made for SwarmUI in ComfyUI with most easy way. You will be able to get very best outcomes of all AI models such as SDXL, FLUX, Z Image Turbo, Wan 2.1, Wan 2.2, FLUX 2, Qwen Image, Qwen Image Edit, FLUX Kontext, Image Outpainting, Image Inpainting and many more. Moreover, I will show how to use custom model paths in ComfyUI and SwarmUI to unify your models in same folder and avoid model duplication and save massive amount of disk space. See translation</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/729956870553821</guid></item><item><title>Happy 2026 everyone!</title><link>https://huggingface.co/posts/mike-ravkine/983643024828039</link><description>Happy 2026 everyone! I've been busy working on some new ranking/position methodologies and excited to start sharing some results. Plot legends: - X = truncation rate (low = good) - ? = confusion rate (low = good) - blue bars = average completion tokens (low = good) - black diamonds = CI-banded performance (high = good) - cluster squares = models inside this group are equivalent openai/gpt-oss-120b remains the king in all dimensions of interest: truncation rates, completion lengths and performance. If I had but one complaint it's the reason_effort does not seem to actually work - more on this soon. Second is a 3-way tie in performance between the Qwen3-235B-2507 we all know and love with an unexpected entrant - ByteDance-Seed/Seed-OSS-36B-Instruct This is a very capable model and it's reasoning effort controls actually works, but you should absolutely not leave it on the default "unlimited" - enable a sensible limit (4k works well for 8k context length). Third place is another 3-way...</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mike-ravkine/983643024828039</guid></item><item><title>NEW MODEL ALERT:</title><link>https://huggingface.co/posts/unmodeled-tyler/317153123097379</link><description>NEW MODEL ALERT: vanta-research/atom-27b Atom-27B has arrived! This model is the largest open-weight model so far from VANTA Research, and is our 4th model in Project Atom - an effort to scale our collaborative Atom persona from 4B-400B+ Atom-27B is based on Google's Gemma 3 27B architecture, and embodies the familiar friendly, warm, and curious persona that appeared in previous releases. Atom is designed to think WITH you, not FOR you - marking VANTA Research's commitment to building frontier collaborative models. Check it out! See translation</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/unmodeled-tyler/317153123097379</guid></item><item><title>Run Qwen-Image-2512, the new SOTA text-to-image model! üíú</title><link>https://huggingface.co/posts/danielhanchen/205178013124950</link><description>Run Qwen-Image-2512, the new SOTA text-to-image model! üíú It's the top performing open diffusion model and has more realistic + accurate images/text. Run locally with 14GB RAM via our Dynamic GGUF: unsloth/Qwen-Image-2512-GGUF Guide: https://unsloth.ai/docs/models/qwen-image-2512 See translation</description><pubDate>Fri, 02 Jan 2026 05:30:15 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/205178013124950</guid></item></channel></rss>