<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Finally finished my extensive **Qwen 3 evaluations** across a range of formats and quantisations, focusing on **MMLU-Pro** (Computer Science).</title><link>https://huggingface.co/posts/wolfram/819510719695955</link><description>Finally finished my extensive **Qwen 3 evaluations** across a range of formats and quantisations, focusing on **MMLU-Pro** (Computer Science). A few take-aways stood out - especially for those interested in local deployment and performance trade-offs: 1Ô∏è‚É£ **Qwen3-235B-A22B** (via Fireworks API) tops the table at **83.66%** with ~55 tok/s. 2Ô∏è‚É£ But the **30B-A3B Unsloth** quant delivered **82.20%** while running locally at ~45 tok/s and with zero API spend. 3Ô∏è‚É£ The same Unsloth build is ~5x faster than Qwen's **Qwen3-32B**, which scores **82.20%** as well yet crawls at &lt;10 tok/s. 4Ô∏è‚É£ On Apple silicon, the **30B MLX** port hits **79.51%** while sustaining ~64 tok/s - arguably today's best speed/quality trade-off for Mac setups. 5Ô∏è‚É£ The **0.6B** micro-model races above 180 tok/s but tops out at **37.56%** - that's why it's not even on the graph (50 % performance cut-off). All local runs were done with LM Studio on an M4 MacBook Pro, using Qwen's official recommended settings....</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/wolfram/819510719695955</guid></item><item><title>I've made an open version of Google's NotebookLM, and it shows the superiority of the open source tech task! üí™</title><link>https://huggingface.co/posts/m-ric/347153743407715</link><description>I've made an open version of Google's NotebookLM, and it shows the superiority of the open source tech task! üí™ The app's workflow is simple. Given a source PDF or URL, it extracts the content from it, then tasks Meta's Llama 3.3-70B with writing the podcast script, with a good prompt crafted by @ gabrielchua ("two hosts, with lively discussion, fun notes, insightful question etc.") Then it hands off the text-to-speech conversion to Kokoro-82M, and there you go, you have two hosts discussion any article. The generation is nearly instant, because: &gt; Llama 3.3 70B is running at 1,000 tokens/seconds with Cerebras inference &gt; The audio is generated in streaming mode by the tiny (yet powerful) Kokoro, generating voices faster than real-time. And the audio generation runs for free on Zero GPUs, hosted by HF on H200s. Overall, open source solutions rival the quality of closed-source solutions at close to no cost! Try it here üëâüëâ m-ric/open-notebooklm See translation</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/m-ric/347153743407715</guid></item><item><title>PawMatchAI üêæ: The Complete Dog Breed Platform</title><link>https://huggingface.co/posts/DawnC/256239584865203</link><description>PawMatchAI üêæ: The Complete Dog Breed Platform PawMatchAI offers a comprehensive suite of features designed for dog enthusiasts and prospective owners alike. This all-in-one platform delivers five essential tools to enhance your canine experience: 1. üîçBreed Detection: Upload any dog photo and the AI accurately identifies breeds from an extensive database of 124+ different dog breeds. The system detects dogs in the image and provides confident breed identification results. 2.üìäBreed Information: Access detailed profiles for each breed covering exercise requirements, typical lifespan, grooming needs, health considerations, and noise behavior - giving you complete understanding of any breed's characteristics. 3.üìã Breed Comparison : Compare any two breeds side-by-side with intuitive visualizations highlighting differences in care requirements, personality traits, health factors, and more - perfect for making informed decisions. 4.üí° Breed Recommendation: Receive personalized breed...</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/256239584865203</guid></item><item><title>TRELLIS is still the lead Open Source AI model to generate high-quality 3D Assets from static images ‚Äî Some mind blowing examples ‚Äî Supports multi-angle improved image to 3D as well ‚Äî Works as low as 6 GB GPUs</title><link>https://huggingface.co/posts/MonsterMMORPG/718201459901945</link><description>TRELLIS is still the lead Open Source AI model to generate high-quality 3D Assets from static images ‚Äî Some mind blowing examples ‚Äî Supports multi-angle improved image to 3D as well ‚Äî Works as low as 6 GB GPUs Tutorial link : https://www.youtube.com/watch?v=EhU7Jil9WAk App Link : https://www.patreon.com/posts/Trellis-App-Installer-Zip-File-117470976 Our app is super advanced with so many features and supports as low as 6 GB GPUs Also fully supports RTX 5000 GPUs as well TRELLIS is currently the state of the art locally run-able open source image-to-3D very high quality asset generator. I have developed a 1-click installers and super advanced Gradio app for this model with so many amazing features. In this tutorial video I will show you how to step by step use this amazing AI tool and generate the very best very high-quality 3D assets locally. Moreover, you can also use this tool on RunPod and Massed Compute as well if you are GPU poor. üîóFollow below link to download the zip file...</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/718201459901945</guid></item><item><title>Curated list of **Next-Gen Code Generation** papers &amp; benchmarks! üî•</title><link>https://huggingface.co/posts/YerbaPage/714560003437397</link><description>Curated list of **Next-Gen Code Generation** papers &amp; benchmarks! üî• Stay ahead with the latest in: ‚úÖ Repo-level Issue Resolution (SWE-bench, Agents) ‚úÖ Repo-level Code Completion (Repo understanding) ‚úÖ Datasets &amp; Benchmarks üëâ Check it out: https://github.com/YerbaPage/Awesome-Repo-Level-Code-Generation üî• See translation</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/714560003437397</guid></item><item><title>Dropping some image classification models for content moderation, balancers, and classifiers trained on synthetic datasets‚Äîalong with others based on datasets available on the Hub. Also loaded a few low-rank datasets for realistic gender portrait classification and document-type classifiers, all fine-tuned on the SigLIP-2 Patch-16 224 backbone. Models and datasets are listed below:</title><link>https://huggingface.co/posts/prithivMLmods/333972839751670</link><description>Dropping some image classification models for content moderation, balancers, and classifiers trained on synthetic datasets‚Äîalong with others based on datasets available on the Hub. Also loaded a few low-rank datasets for realistic gender portrait classification and document-type classifiers, all fine-tuned on the SigLIP-2 Patch-16 224 backbone. Models and datasets are listed below: ü§óModels &amp; Datasets : Realistic Gender Classification : prithivMLmods/Realistic-Gender-Classification ‚éô prithivMLmods/Realistic-Portrait-Gender-1024px Document Type Detection : prithivMLmods/Document-Type-Detection ‚éô prithivMLmods/Document-Type-Detection Face Mask Detection : prithivMLmods/Face-Mask-Detection ‚éô DamarJati/Face-Mask-Detection Alzheimer Stage Classifier : prithivMLmods/Alzheimer-Stage-Classifier ‚éô SilpaCS/Augmented_alzheimer Bone Fracture Detection : prithivMLmods/Bone-Fracture-Detection ‚éô Hemg/bone-fracture-detection GiD Land Cover Classification : prithivMLmods/GiD-Land-Cover-Classification...</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/333972839751670</guid></item><item><title>The new Mistral medium model is very impressive for its size. Will it be open sourced given the history of Mistral? Does anyone have insights?</title><link>https://huggingface.co/posts/onekq/350712908160959</link><description>The new Mistral medium model is very impressive for its size. Will it be open sourced given the history of Mistral? Does anyone have insights? onekq-ai/WebApp1K-models-leaderboard See translation</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/350712908160959</guid></item><item><title>HunyuanCustom üî• a multimodal video generation framework supporting image, audio, video &amp; text conditions, released by TencentHunyuan</title><link>https://huggingface.co/posts/AdinaY/542794382158017</link><description>HunyuanCustom üî• a multimodal video generation framework supporting image, audio, video &amp; text conditions, released by TencentHunyuan tencent/HunyuanCustom HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation (2505.04512) ‚ú®Strong Identity Consistency ‚ú®SOTA outperforms See translation</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/542794382158017</guid></item><item><title>This time Gemini is very quick with API support on its 2.5 pro May release. The performance is impressive too, now it is among top contenders like o4, R1, and Claude.</title><link>https://huggingface.co/posts/onekq/737528561026190</link><description>This time Gemini is very quick with API support on its 2.5 pro May release. The performance is impressive too, now it is among top contenders like o4, R1, and Claude. onekq-ai/WebApp1K-models-leaderboard See translation</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/737528561026190</guid></item><item><title>What do you think of Intellite‚Äôs new icons/logo? Let us know!</title><link>https://huggingface.co/posts/ProCreations/529551865318111</link><description>What do you think of Intellite‚Äôs new icons/logo? Let us know! Also Intellite chat technically does work! But we decided to scale it up a bit (same parameter count at 100m, but we went from trained on 4b tokens to 200b tokens, big upgrade!) for max quality. See translation</description><pubDate>Sun, 11 May 2025 05:21:32 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ProCreations/529551865318111</guid></item></channel></rss>