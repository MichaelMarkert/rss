<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SigLIP2 Image Classification  🧤</title><link>https://huggingface.co/posts/prithivMLmods/550891236404805</link><description>SigLIP2 Image Classification 🧤 &gt; https://huggingface.co/blog/prithivMLmods/siglip2-finetune-image-classification See translation</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/550891236404805</guid></item><item><title>Hi there!</title><link>https://huggingface.co/posts/Undi95/824593315166092</link><description>Hi there! If you want to create your own thinking model or do a better MistralThinker, I just uploaded my entire dataset made on Deepseek R1 and the axolotl config. (well I made them public) Axolotl config : Undi95/MistralThinker-v1.1 The dataset : Undi95/R1-RP-ShareGPT3 You can also read all I did on those two discord screenshot from two days ago, I'm a little lazy to rewrite all kek. Hope you will use them! See translation</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Undi95/824593315166092</guid></item><item><title>Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months!</title><link>https://huggingface.co/posts/clem/866977064333227</link><description>Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months! Nvidia's org: https://huggingface.co/nvidia Enterprise hub: https://huggingface.co/enterprise See translation</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/866977064333227</guid></item><item><title>🚀 Big news for AI agents! With the latest release of smolagents, you can now securely execute Python code in sandboxed Docker or E2B environments. 🦾🔒</title><link>https://huggingface.co/posts/albertvillanova/674737128301579</link><description>🚀 Big news for AI agents! With the latest release of smolagents, you can now securely execute Python code in sandboxed Docker or E2B environments. 🦾🔒 Here's why this is a game-changer for agent-based systems: 🧵👇 1️⃣ Security First 🔐 Running AI agents in unrestricted Python environments is risky! With sandboxing, your agents are isolated, preventing unintended file access, network abuse, or system modifications. 2️⃣ Deterministic &amp; Reproducible Runs 📦 By running agents in containerized environments, you ensure that every execution happens in a controlled and predictable setting—no more environment mismatches or dependency issues! 3️⃣ Resource Control &amp; Limits 🚦 Docker and E2B allow you to enforce CPU, memory, and execution time limits, so rogue or inefficient agents don’t spiral out of control. 4️⃣ Safer Code Execution in Production 🏭 Deploy AI agents confidently, knowing that any generated code runs in an ephemeral, isolated environment, protecting your host machine and...</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/albertvillanova/674737128301579</guid></item><item><title>I’m super excited to work with</title><link>https://huggingface.co/posts/burtenshaw/281561952705692</link><description>I’m super excited to work with @ mlabonne to build the first practical example in the reasoning course. 🔗 https://huggingface.co/reasoning-course Here's a quick walk through of the first drop of material that works toward the use case: - a fundamental introduction to reinforcement learning. Answering questions like, ‘what is a reward?’ and ‘how do we create an environment for a language model?’ - Then it focuses on Deepseek R1 by walking through the paper and highlighting key aspects. This is an old school way to learn ML topics, but it always works. - Next, it takes to you Transformers Reinforcement Learning and demonstrates potential reward functions you could use. This is cool because it uses Marimo notebooks to visualise the reward. - Finally, Maxime walks us through a real training notebook that uses GRPO to reduce generation length. I’m really into this because it works and Maxime took the time to validate it share assets and logging from his own runs for you to compare with....</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/281561952705692</guid></item><item><title>AI will bring us "a country of yes-men on servers" instead of one of "Einsteins sitting in a data center" if we continue on current trends.</title><link>https://huggingface.co/posts/fdaudens/198644025808355</link><description>AI will bring us "a country of yes-men on servers" instead of one of "Einsteins sitting in a data center" if we continue on current trends. Must-read by @ thomwolf deflating overblown AI promises and explaining what real scientific breakthroughs require. https://thomwolf.io/blog/scientific-ai.html See translation</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/198644025808355</guid></item><item><title>Extremely bullish on</title><link>https://huggingface.co/posts/andito/495335597913303</link><description>Extremely bullish on @ CohereForAI 's Aya Vision (8B &amp; 32B) - new SOTA open-weight VLMs - 8B wins up to 81% of the time in its class, better than Gemini Flash - 32B beats Llama 3.2 90B! - Covers 23 languages, excels in image captioning, VQA &amp; more - Integrated on transformers from Day 0! Efficient multimodal models are here to stay!!🔥 Check out their blog! https://huggingface.co/blog/aya-vision See translation</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/andito/495335597913303</guid></item><item><title>I just released a fully automated evaluation framework for your RAG applications!📈</title><link>https://huggingface.co/posts/as-cle-bert/983515572081803</link><description>I just released a fully automated evaluation framework for your RAG applications!📈 GitHub 👉 https://github.com/AstraBert/diRAGnosis PyPi 👉 https://pypi.org/project/diragnosis/ It's called 𝐝𝐢𝐑𝐀𝐆𝐧𝐨𝐬𝐢𝐬 and is a lightweight framework that helps you 𝗱𝗶𝗮𝗴𝗻𝗼𝘀𝗲 𝘁𝗵𝗲 𝗽𝗲𝗿𝗳𝗼𝗿𝗺𝗮𝗻𝗰𝗲 𝗼𝗳 𝗟𝗟𝗠𝘀 𝗮𝗻𝗱 𝗿𝗲𝘁𝗿𝗶𝗲𝘃𝗮𝗹 𝗺𝗼𝗱𝗲𝗹𝘀 𝗶𝗻 𝗥𝗔𝗚 𝗮𝗽𝗽𝗹𝗶𝗰𝗮𝘁𝗶𝗼𝗻𝘀. You can launch it as an application locally (it's Docker-ready!🐋) or, if you want more flexibility, you can integrate it in your code as a python package📦 The workflow is simple: 🧠 You choose your favorite LLM provider and model (supported, for now, are Mistral AI, Groq, Anthropic, OpenAI and Cohere) 🧠 You pick the embedding models provider and the embedding model you prefer (supported, for now, are Mistral AI, Hugging Face, Cohere and OpenAI) 📄 You prepare and provide your documents ⚙️ Documents are ingested into a Qdrant vector database and transformed into a synthetic question dataset with the help of LlamaIndex 📊 The LLM is evaluated for the faithfulness and...</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/983515572081803</guid></item><item><title>New amazing updates arrived to our ultimate Wan 2.1 (1-Click Install) Gradio APP</title><link>https://huggingface.co/posts/MonsterMMORPG/739966885386928</link><description>New amazing updates arrived to our ultimate Wan 2.1 (1-Click Install) Gradio APP Source : https://www.patreon.com/posts/123105403 Tutorial video : https://youtu.be/hnAhveNy-8s Please checkout the screenshots See translation</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/739966885386928</guid></item><item><title>Babel🗼A multilingual LLM supporting 25 languages, released by the Alibaba DAMO team.</title><link>https://huggingface.co/posts/AdinaY/919420343093208</link><description>Babel🗼A multilingual LLM supporting 25 languages, released by the Alibaba DAMO team. Model: Tower-Babel/babel-67c172157372d4d6c4b4c6d5 Paper: Babel: Open Multilingual Large Language Models Serving Over 90% of Global Speakers (2503.00865) ✨ 9B/83B chat &amp; base ✨ Supports 25 languages: English, Chinese, Hindi, Spanish, Arabic, French, Bengali, Portuguese, Russian, Urdu, Indonesian, German, Japanese, Swahili, Filipino, Tamil, Vietnamese, Turkish, Italian, Javanese, Korean, Hausa, Persian, Thai, and Burmese See translation</description><pubDate>Fri, 07 Mar 2025 09:22:26 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/919420343093208</guid></item></channel></rss>