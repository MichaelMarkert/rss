<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>We just crossed 1,500,000 public models on Hugging Face (and 500k spaces, 330k datasets, 50k papers). One new repository is created every 15 seconds. Congratulations all!</title><link>https://huggingface.co/posts/clem/238420842235482</link><description>We just crossed 1,500,000 public models on Hugging Face (and 500k spaces, 330k datasets, 50k papers). One new repository is created every 15 seconds. Congratulations all! See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/clem/238420842235482</guid></item><item><title>üöÄ Idea Transformer:</title><link>https://huggingface.co/posts/openfree/269373246432749</link><description>üöÄ Idea Transformer: Idea Transformer: Infinity is an innovative tool that unlocks infinite creativity by generating unique transformation ideas and design images from up to three keywords and a chosen category. Leveraging a state-of-the-art diffusion pipeline, real-time translation, and a powerful LLM, it delivers fresh ideas every time. üé®‚ú® openfree/Idea-Transformer Key Features Diverse Ideas: Randomly selects creative variations from your keywords and category ‚Äî the possibilities are nearly endless! üé≤ Unique Design Images: Your text prompt produces striking, varied design images via the diffusion model. üñºÔ∏è Real-Time Translation &amp; Expansion: Korean inputs are automatically translated and enriched using an advanced LLM for high-quality output. üîÑ Dual-Language Support: Enjoy an intuitive Gradio interface with separate English and Korean tabs for a global audience. üåç Explore a Wide Range of Categories: Sensor Functions üì°: Creative changes in sensor technologies. Size &amp; Shape Change üìè:...</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/269373246432749</guid></item><item><title>to the nvidia employee that won't respond to my emails: hear me now.</title><link>https://huggingface.co/posts/nroggendorff/181073331446889</link><description>to the nvidia employee that won't respond to my emails: hear me now. you have made a semi-powerful to irrelevant enemy. you have been warned See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nroggendorff/181073331446889</guid></item><item><title>üåê GraphMind: Phi-3 Instruct Graph Explorer</title><link>https://huggingface.co/posts/ginipick/554089753491641</link><description>üåê GraphMind: Phi-3 Instruct Graph Explorer ‚ú® Extract and visualize knowledge graphs from any text in multiple languages! GraphMind is a powerful tool that leverages the capabilities of Phi-3 to transform unstructured text into structured knowledge graphs, helping you understand complex relationships within any content. ginigen/Graph-Mind üöÄ Key Features Multi-language Support üåç: Process text in English, Korean, and many other languages Instant Visualization üß©: See extracted entities and relationships in an interactive graph Entity Recognition üè∑Ô∏è: Automatically identifies and categorizes named entities Optimized Performance ‚ö°: Uses caching to deliver faster results for common examples Intuitive Interface üëÜ: Simple design makes complex graph extraction accessible to everyone üí° Use Cases Content Analysis: Extract key entities and relationships from articles or documents Research Assistance: Quickly visualize connections between concepts in research papers Educational Tool: Help students...</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/554089753491641</guid></item><item><title>This is the most exciting of this week‚Äôs release for me: Gemini Robotics - A SOTA generalist Vision-Language-Action model that brings intelligence to the physical world. It comes with a verifiable real-world knowledge Embodied Reasoning QA benchmark. Cool part is that the model can be specialized with fast adaptation to new tasks and have such adaptations transferred to new robot embodiment like humanoids. Looking forward to the model and data on hf, it‚Äôs about time I go full physical:)</title><link>https://huggingface.co/posts/Jaward/782050409908004</link><description>This is the most exciting of this week‚Äôs release for me: Gemini Robotics - A SOTA generalist Vision-Language-Action model that brings intelligence to the physical world. It comes with a verifiable real-world knowledge Embodied Reasoning QA benchmark. Cool part is that the model can be specialized with fast adaptation to new tasks and have such adaptations transferred to new robot embodiment like humanoids. Looking forward to the model and data on hf, it‚Äôs about time I go full physical:) Technical Report: https://storage.googleapis.com/deepmind-media/gemini-robotics/gemini_robotics_report.pdf See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Jaward/782050409908004</guid></item><item><title>Qwen made good students, DeepSeek made a genius.</title><link>https://huggingface.co/posts/onekq/182897139123508</link><description>Qwen made good students, DeepSeek made a genius. This is my summaries of their differentiations. I don't think these two players are coordinated but they both have clear goals. One is to build ecosystem and the other is to push AGI. And IMO they are both doing really well. See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/182897139123508</guid></item><item><title>üì¢ With the recent release of Gemma-3, If you interested to play with textual chain-of-though, the notebook below is a wrapper over the the model (native transformers inference API) for passing the predefined schema of promps in batching mode.</title><link>https://huggingface.co/posts/nicolay-r/281728882424630</link><description>üì¢ With the recent release of Gemma-3, If you interested to play with textual chain-of-though, the notebook below is a wrapper over the the model (native transformers inference API) for passing the predefined schema of promps in batching mode. https://github.com/nicolay-r/nlp-thirdgate/blob/master/tutorials/llm_gemma_3.ipynb Limitation: schema supports texts only (for now), while gemma-3 is a text+image to text. Model: google/gemma-3-1b-it Provider: https://github.com/nicolay-r/nlp-thirdgate/blob/master/llm/transformers_gemma3.py See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nicolay-r/281728882424630</guid></item><item><title>Open Sora 2.0 is out üî•</title><link>https://huggingface.co/posts/AdinaY/501114368839718</link><description>Open Sora 2.0 is out üî• hpcai-tech/open-sora-20-67cfb7efa80a73999ccfc2d5 ‚ú® 11B with Apache2.0 ‚ú® Low training cost - $200k ‚ú® open weights, code and training workflow See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/AdinaY/501114368839718</guid></item><item><title>Still speed running Gemma 3 to think. Today I focused on setting up gpu poor hardware to run GRPO.</title><link>https://huggingface.co/posts/burtenshaw/988620578150041</link><description>Still speed running Gemma 3 to think. Today I focused on setting up gpu poor hardware to run GRPO. This is a plain TRL and PEFT notebook which works on mac silicone or colab T4. This uses the 1b variant of Gemma 3 and a reasoning version of GSM8K dataset. üßë‚Äçüç≥ There‚Äôs more still in the oven like releasing models, an Unsloth version, and deeper tutorials, but hopefully this should bootstrap your projects. Here‚Äôs a link to the 1b notebook: https://colab.research.google.com/drive/1mwCy5GQb9xJFSuwt2L_We3eKkVbx2qSt?usp=sharing See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/burtenshaw/988620578150041</guid></item><item><title>I just pushed another amazing update to our Wan 2.1 APP. LoRA loading for 14B Wan 2.1 models were taking over 15 minutes. Optimized to take only few seconds now. Fully supports RTX 5000 series and fully optimized for both VRAM and RAM.</title><link>https://huggingface.co/posts/MonsterMMORPG/969493556484477</link><description>I just pushed another amazing update to our Wan 2.1 APP. LoRA loading for 14B Wan 2.1 models were taking over 15 minutes. Optimized to take only few seconds now. Fully supports RTX 5000 series and fully optimized for both VRAM and RAM. Our APP here : https://www.patreon.com/posts/wan-2-1-ultra-as-123105403 Tutorial 1 : https://youtu.be/hnAhveNy-8s Tutorial 2 : https://youtu.be/ueMrzmbdWBg It is also pushed to the original repo you can see pull request here : https://github.com/modelscope/DiffSynth-Studio/pull/442 See translation</description><pubDate>Sat, 15 Mar 2025 09:20:18 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/969493556484477</guid></item></channel></rss>