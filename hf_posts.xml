<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ğŸ”® Mistral Perflexity AI - Local LLM Space with Web Search Capabilities ğŸŒ</title><link>https://huggingface.co/posts/ginipick/917789522887291</link><description>ğŸ”® Mistral Perflexity AI - Local LLM Space with Web Search Capabilities ğŸŒ Hello AI enthusiasts! Today I'm excited to introduce my special Hugging Face space! ğŸš€ ginigen/Mistral-Perflexity âœ¨ Key Features Powerful Model: Using Private-BitSix-Mistral-Small-3.1-24B-Instruct-2503, optimized through 6-bit quantization to run smoothly on local 4090 GPUs! ğŸ’ª Web Search Integration: Leveraging the Brave Search API to provide real-time web search results for user queries! ğŸ” Customizable Responses: Shape AI personality and response format through system messages âš™ï¸ Multilingual Support: Perfect handling of both English and Korean! ğŸ‡ºğŸ‡¸ğŸ‡°ğŸ‡· ğŸ› ï¸ Technical Highlights GGUF Format: Optimized quantized model with excellent memory efficiency Flash Attention: Applied optimization technology for faster inference speeds 8K Context Window: Capable of handling lengthy conversations and complex queries Streaming Responses: Watch text being generated in real-time ğŸ’¡ Use Cases Complex Q&amp;A requiring real-time...</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/917789522887291</guid></item><item><title>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me!</title><link>https://huggingface.co/posts/fdaudens/694548457778636</link><description>Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me! Just tested it with Steve Jobs' Stanford speech and was speechless (pun intended). The video isnâ€™t sped up. 3 things that floored me: - Transcription took just 10 seconds for a 15-min file - Got a CSV with perfect timestamps, punctuation &amp; capitalization - Stunning accuracy (correctly captured "Reed College" and other specifics) NVIDIA also released a demo where you can click any transcribed segment to play it instantly. The improvement is significant: number 1 on the ASR Leaderboard, 6% error rate (best in class) with complete commercial freedom (cc-by-4.0 license). Time to update those Whisper pipelines! H/t @ Steveeeeeeen for the finding! Model: nvidia/parakeet-tdt-0.6b-v2 Demo: nvidia/parakeet-tdt-0.6b-v2 ASR Leaderboard: hf-audio/open_asr_leaderboard See translation</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/694548457778636</guid></item><item><title>ğŸ”¥ Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities ğŸš€</title><link>https://huggingface.co/posts/openfree/174131256400578</link><description>ğŸ”¥ Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities ğŸš€ openfree/qwen3-30b-a3b-research openfree/qwen3-235b-a22b-research Hello AI researchers! ğŸ‘‹ Today I'm introducing a powerful chatbot implementation with real-time web search capabilities. âœ¨ Key Features ğŸ§  Chatbot based on qwen3-30b-a3b and llama4-maverick models ğŸ” LLM-based optimal keyword extraction ğŸŒ Real-time web search using SerpHouse API ğŸ’¬ Streaming responses for natural conversation experience ğŸ› ï¸ Technology Stack Gradio: Implementation of intuitive web interface Fireworks.ai API: Access to high-performance LLM models SerpHouse API: Collection of real-time search results ğŸŒŸ Application Areas Question answering systems requiring up-to-date information Providing current information beyond training data Delivering reliable information with accurate sources Add real-time search capabilities to your AI applications with this project! ğŸ‰ Leave your questions or suggestions in the comments! Let's...</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/174131256400578</guid></item><item><title>VisionScout â€” Now with Scene Understanding! ğŸš€</title><link>https://huggingface.co/posts/DawnC/822045713383062</link><description>VisionScout â€” Now with Scene Understanding! ğŸš€ I'm excited to share a major update to VisionScout, my interactive vision tool that combines powerful object detection with emerging scene understanding capabilities! ğŸ‘€ğŸ” What can VisionScout do today? ğŸ–¼ï¸ Upload any image and detect 80 object types using YOLOv8. ğŸ”„ Instantly switch between Nano, Medium, and XLarge models depending on speed vs. accuracy needs. ğŸ¯ Filter specific classes (people, vehicles, animals, etc.) to focus only on what matters to you. ğŸ“Š View detailed statistics on detected objects, confidence levels, and spatial distribution. â­ï¸ NEW: Scene understanding layer now added! - Automatically interprets the scene based on detected objects. - Uses a combination of rule-based reasoning and CLIP-powered semantic validation. - Outputs descriptions, possible activities, and even safety concerns. Whatâ€™s coming next? ğŸ” Expanding YOLOâ€™s object categories. ğŸ¥ Adding video processing and multi-frame object tracking. âš¡ Faster real-time...</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/DawnC/822045713383062</guid></item><item><title>HOW TO ADD MCP SUPPORT TO ANY ğŸ¤— SPACE</title><link>https://huggingface.co/posts/abidlabs/810486848644944</link><description>HOW TO ADD MCP SUPPORT TO ANY ğŸ¤— SPACE Gradio now supports MCP! If you want to convert an existing Space, like this one hexgrad/Kokoro-TTS , so that you can use it with Claude Desktop / Cursor / Cline / TinyAgents / or any LLM that supports MCP, here's all you need to do: 1. Duplicate the Space (in the Settings Tab) 2. Upgrade the Gradio sdk_version to 5.28 (in the README.md ) 3. Set mcp_server=True in launch() 4. (Optionally) add docstrings to the function so that the LLM knows how to use it, like this: def generate ( text, speed= 1 ): """ Convert text to speech audio. Parameters: text (str): The input text to be converted to speech. speed (float, optional): Playback speed of the generated speech. That's it! Now your LLM will be able to talk to you ğŸ¤¯ See translation</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/810486848644944</guid></item><item><title>ğŸ–¼ï¸ OpenClipart SVG Dataset -</title><link>https://huggingface.co/posts/nyuuzyou/253978208604387</link><description>ğŸ–¼ï¸ OpenClipart SVG Dataset - nyuuzyou/openclipart Collection of 178,604 Public Domain Scalable Vector Graphics (SVG) clipart images featuring: - Comprehensive metadata: title, description, artist name, tags, original page URL, and more. - Contains complete SVG XML content (minified) for direct use or processing. - All images explicitly released into the public domain under the CC0 license. - Organized in a single train split with 178,604 entries. See translation</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/nyuuzyou/253978208604387</guid></item><item><title>Hi everyone,</title><link>https://huggingface.co/posts/mrfakename/455751106173013</link><description>Hi everyone, I just launched TTS Arena V2 - a platform for benchmarking TTS models by blind A/B testing. The goal is to make it easy to compare quality between open-source and commercial models, including conversational ones. What's new in V2: - **Conversational Arena**: Evaluate models like CSM-1B, Dia 1.6B, and PlayDialog in multi-turn settings - **Personal Leaderboard**: Optional login to see which models you tend to prefer - **Multi-speaker TTS**: Random voices per generation to reduce speaker bias - **Performance Upgrade**: Rebuilt from Gradio â†’ Flask. Much faster with fewer failed generations. - **Keyboard Shortcuts**: Vote entirely via keyboard Also added models like MegaTTS 3, Cartesia Sonic, and ElevenLabs' full lineup. I'd love any feedback, feature suggestions, or ideas for models to include. TTS-AGI/TTS-Arena-V2 See translation</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/mrfakename/455751106173013</guid></item><item><title>you can easily fine-tune, quantize, play with sota vision LM InternVL3 now ğŸ”¥</title><link>https://huggingface.co/posts/merve/777073133757524</link><description>you can easily fine-tune, quantize, play with sota vision LM InternVL3 now ğŸ”¥ we have recently merged InternVL3 to Hugging Face transformers and released converted checkpoints ğŸ¤— collection for converted checkpoints: merve/internvl3-hf-6814be2943b2ae0e711c92a5 notebook: https://colab.research.google.com/drive/1wAQ7cyjyaCwLXbMA_OjXZe7aCxCFm6sI?usp=sharing ğŸ“– See translation</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/777073133757524</guid></item><item><title>ğŸš€ Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformerï½</title><link>https://huggingface.co/posts/RiverZ/535015681556179</link><description>ğŸš€ Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformerï½ ğŸ¨ Daily Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) ğŸ”“ Code is now open source! ğŸ”¥ Huggingface DEMO: RiverZ/ICEdit ğŸŒ Project Website: https://river-zhang.github.io/ICEdit-gh-pages/ ğŸ  GitHub Repository: https://github.com/River-Zhang/ICEdit/blob/main/scripts/gradio_demo.py ğŸ¤— Huggingface: sanaka87/ICEdit-MoE-LoRA ğŸ“„ arxiv Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) ğŸ”¥ Why itâ€™s cool: - Achieves high-quality, multi-task image editing. - Uses only 1% of the training parameters and 0.1% of the training data compared to existing methods â€” extremely efficient - Beats several commercial models on background preservation, ID control, and consistency - Open-...</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/RiverZ/535015681556179</guid></item><item><title>One of the biggest challenges I've been facing since I started developing [ğğğŸğˆğ­ğƒğ¨ğ°ğ§](</title><link>https://huggingface.co/posts/as-cle-bert/299436064475061</link><description>One of the biggest challenges I've been facing since I started developing [ğğğŸğˆğ­ğƒğ¨ğ°ğ§]( https://github.com/AstraBert/PdfItDown ) was handling correctly the conversion of files like Excel sheets and CSVs: table conversion was bad and messy, almost unusable for downstream tasksğŸ«£ That's why today I'm excited to introduce ğ«ğğšğğğ«ğ¬, the new feature of PdfItDown v1.4.0!ğŸ‰ With ğ˜³ğ˜¦ğ˜¢ğ˜¥ğ˜¦ğ˜³ğ˜´, you can choose among three (for nowğŸ‘€) flavors of text extraction and conversion to PDF: - ğ——ğ—¼ğ—°ğ—¹ğ—¶ğ—»ğ—´, which does a fantastic work with presentations, spreadsheets and word documentsğŸ¦† - ğ—Ÿğ—¹ğ—®ğ—ºğ—®ğ—£ğ—®ğ—¿ğ˜€ğ—² by LlamaIndex, suitable for more complex and articulated documents, with mixture of texts, images and tablesğŸ¦™ - ğ— ğ—®ğ—¿ğ—¸ğ—œğ˜ğ——ğ—¼ğ˜„ğ—» by Microsoft, not the best at handling highly structured documents, by extremly flexible in terms of input file format (it can even convert XML, JSON and ZIP files!)âœ’ï¸ You can use this new feature in your python scripts (check the attached code snippet!ğŸ˜‰) and in the command line interface as well!ğŸ...</description><pubDate>Sun, 04 May 2025 17:18:10 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/as-cle-bert/299436064475061</guid></item></channel></rss>