<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Bu post'u Ã§evirebilirsiniz ğŸ¤—ğŸ’—</title><link>https://huggingface.co/posts/merve/523189303979360</link><description>Bu post'u Ã§evirebilirsiniz ğŸ¤—ğŸ’— See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/523189303979360</guid></item><item><title>&gt; New Model</title><link>https://huggingface.co/posts/KaraKaraWitch/569360445188531</link><description>&gt; New Model &gt; Looks at Model Card &gt; "Open-Weights" See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/KaraKaraWitch/569360445188531</guid></item><item><title>ğŸ‰ğŸ¥³ SOTA!!! ğŸš€ğŸ‘‘</title><link>https://huggingface.co/posts/onekq/484907766797591</link><description>ğŸ‰ğŸ¥³ SOTA!!! ğŸš€ğŸ‘‘ ğŸ¥‡ Claude 4 Opus !!ğŸ¥‡ 7 months!! âŒ›âŒ› I thought the day would never come. But here it is. onekq-ai/WebApp1K-models-leaderboard Cost me quite a bit of ğŸ’µmoney ğŸ’µ but it is all worth it. Enjoy and make out of this as much as you can! See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/484907766797591</guid></item><item><title>Hereâ€™s what happens when a national institution builds its own digital intelligence: Franceâ€™s Ministry of Culture just released 17K+ real users testing 30+ chatbots in French. Raw, diverse, and a goldmine for studying LLMs in the wild.</title><link>https://huggingface.co/posts/fdaudens/207889594956018</link><description>Hereâ€™s what happens when a national institution builds its own digital intelligence: Franceâ€™s Ministry of Culture just released 17K+ real users testing 30+ chatbots in French. Raw, diverse, and a goldmine for studying LLMs in the wild. ministere-culture/comparia-conversations See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/fdaudens/207889594956018</guid></item><item><title>Google released MedGemma on I/O'25 ğŸ‘</title><link>https://huggingface.co/posts/merve/962316386830239</link><description>Google released MedGemma on I/O'25 ğŸ‘ google/medgemma-release-680aade845f90bec6a3f60c4 &gt; 4B and 27B instruction fine-tuned vision LMs and a 4B pre-trained vision LM for medicine &gt; available with transformers from the get-go ğŸ¤— they also released a cool demo for scan reading â¡ï¸ google/rad_explain use with transformers â¤µï¸ See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/962316386830239</guid></item><item><title>âœ¨ Today weâ€™re releasing Tiny Agents in Python â€” an MCP-powered Agent in ~70 lines of code ğŸ</title><link>https://huggingface.co/posts/celinah/946156020996069</link><description>âœ¨ Today weâ€™re releasing Tiny Agents in Python â€” an MCP-powered Agent in ~70 lines of code ğŸ Inspired by Tiny Agents in JS from @ julien-c , we ported the idea to Python and integrated it directly into huggingface_hub â€” with a built-in MCP Client and a Tiny Agents CLI. TL;DR: With MCP (Model Context Protocol), you can expose tools like web search or image generation and connect them directly to LLMs. Itâ€™s simple â€” and surprisingly powerful. pip install "huggingface_hub[mcp]&gt;=0.32.0" We wrote a blog post where we show how to run Tiny Agents, and dive deeper into how they work and how to build your own. ğŸ‘‰ https://huggingface.co/blog/python-tiny-agents See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/celinah/946156020996069</guid></item><item><title>tis the year of any-to-any/omni models ğŸ¤ </title><link>https://huggingface.co/posts/merve/870882250701193</link><description>tis the year of any-to-any/omni models ğŸ¤  ByteDance-Seed/BAGEL-7B-MoT 7B native multimodal model that understands and generates both image + text it outperforms leading VLMs like Qwen 2.5-VL ğŸ‘ and has Apache 2.0 license ğŸ˜± See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/merve/870882250701193</guid></item><item><title>ğŸŒ¾ NH Prediction: AI System for Korean Agricultural Price Forecasting ğŸŒ¾</title><link>https://huggingface.co/posts/openfree/102455854917725</link><description>ğŸŒ¾ NH Prediction: AI System for Korean Agricultural Price Forecasting ğŸŒ¾ ğŸ“Š Project Introduction Price volatility in agricultural markets has significant impacts from producers to consumers! NH Prediction is an innovative system that utilizes cutting-edge AI technology to predict Korean agricultural wholesale prices based on extensive data spanning 40 years. ğŸš€ VIDraft/NH-Prediction ginipick/NH-Korea ğŸ§  VIDraft's 14 Enhanced Prediction Models The VIDraft research team has developed 14 advanced prediction models by reinforcing existing forecasting approaches: ğŸ”® VID-SARIMA Series: Precisely models seasonality and trends (up to 99.99% accuracy) âš–ï¸ VID-ETS Series: Captures multiplicative/additive variation patterns ğŸ“ˆ VID-Holt/Holt-Winters: Simultaneous analysis of linear trends and seasonality ğŸ“‰ VID-MovingAverage/WeightedMA: Noise removal and medium-term trend identification ğŸ” VID-Fourier+LR: Hybrid approach capturing complex periodicity âœ¨ Key Features ğŸŒŸ Item-Specific Optimization:...</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/102455854917725</guid></item><item><title>Curated list of **Next Gen Code Generation** papers &amp; benchmarks! ğŸ”¥ with 60+ â­ï¸ now!</title><link>https://huggingface.co/posts/YerbaPage/971729248373235</link><description>Curated list of **Next Gen Code Generation** papers &amp; benchmarks! ğŸ”¥ with 60+ â­ï¸ now! Stay ahead with the latest in: âœ… Repo-level Issue Resolution (SWE-bench, Agents) âœ… Repo-level Code Completion (Repo understanding) âœ… Datasets &amp; Benchmarks ğŸ‘‰ Check it out: https://github.com/YerbaPage/Awesome-Repo-Level-Code-Generation ğŸ”¥ ğŸ’¡PRs are welcomed! See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/YerbaPage/971729248373235</guid></item><item><title>SwarmUI Teacache Full Tutorial With Very Best Wan 2.1 I2V &amp; T2V Presets â€” ComfyUI Used as Backend â€” 2x and more Speed Up</title><link>https://huggingface.co/posts/MonsterMMORPG/933543778464672</link><description>SwarmUI Teacache Full Tutorial With Very Best Wan 2.1 I2V &amp; T2V Presets â€” ComfyUI Used as Backend â€” 2x and more Speed Up Video Tutorial Link https://youtu.be/r38eWyNoXHo Tutorial Info Teacache is used to speed up AI generations significantly and I will show how to use it in SwarmUI with ComfyUI backend in this tutorial. Moreover, I am sharing presets and full details of how to use Wan 2.1 Text-to-Image and Text-to-Video models properly in SwarmUI with ComfyUI backend so easily and accurately. See translation</description><pubDate>Sat, 24 May 2025 13:29:49 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/MonsterMMORPG/933543778464672</guid></item></channel></rss>