<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Qwen3-Next can now be Run locally! (30GB RAM)</title><link>https://huggingface.co/posts/danielhanchen/212249714773740</link><description>Qwen3-Next can now be Run locally! (30GB RAM) Instruct GGUF: unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF The models come in Thinking and Instruct versions and utilize a new architecture, allowing it to have ~10x faster inference than Qwen32B. ğŸ’œ Step-by-step Guide: https://docs.unsloth.ai/models/qwen3-next Thinking GGUF: unsloth/Qwen3-Next-80B-A3B-Thinking-GGUF See translation</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/danielhanchen/212249714773740</guid></item><item><title>Introducing the  Super-OCRs Demo, a comparison of state-of-the-art multimodal OCR VLMs, including HunyuanOCR, DeepSeekOCR, Dots, and Nanonets in one space for performing OCR, rendering LaTeX and Markdown, and visual grounding (layout). Find the related Spaces and models below.ğŸ¤—ğŸ”¥</title><link>https://huggingface.co/posts/prithivMLmods/107899220924462</link><description>Introducing the Super-OCRs Demo, a comparison of state-of-the-art multimodal OCR VLMs, including HunyuanOCR, DeepSeekOCR, Dots, and Nanonets in one space for performing OCR, rendering LaTeX and Markdown, and visual grounding (layout). Find the related Spaces and models below.ğŸ¤—ğŸ”¥ âœ¨Super-OCRs[Demo]: prithivMLmods/Super-OCRs-Demo âœ¨Collection: https://huggingface.co/collections/prithivMLmods/multimodal-implementations âœ¨GitHub: https://github.com/PRITHIVSAKTHIUR/Super-OCRs-Demo â­ Models Used: âœ¦ HunyuanOCR: tencent/HunyuanOCR âœ¦ DeepSeek-OCR: (-) deepseek-ai/DeepSeek-OCR (+) prithivMLmods/DeepSeek-OCR-Latest-BF16.I64 âœ¦ Dots.OCR: (-) rednote-hilab/dots.ocr (+) prithivMLmods/Dots.OCR-Latest-BF16 âœ¦ Nanonets-OCR2-3B: nanonets/Nanonets-OCR2-3B â­ Some Other Relevant Apps: âœ¦ Qwen3-VL-HF-Demo: prithivMLmods/Qwen3-VL-HF-Demo âœ¦ Qwen3-VL-Outpost: prithivMLmods/Qwen3-VL-Outpost âœ¦ Multimodal-OCR: prithivMLmods/Multimodal-OCR âœ¦ Multimodal-OCR2: prithivMLmods/Multimodal-OCR2 âœ¦ Multimodal-OCR3:...</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/107899220924462</guid></item><item><title>nanochat is now in transformers!</title><link>https://huggingface.co/posts/sergiopaniego/367599205240435</link><description>nanochat is now in transformers! The LLM by @ karpathy is officially in the library, and we wrote a blog covering: how did we port the model, differences from the original, and how to run or train it. go read it ğŸ¤“ nanochat-students/transformers See translation</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/sergiopaniego/367599205240435</guid></item><item><title>4æœˆï¼Ÿã”ã‚ã«å‚åŠ ã—ãŸCerebrasã®ãƒãƒƒã‚«ã‚½ãƒ³ã‹ã‚‰ä½•æ•…ã‹Huggingfaceã®proãƒ—ãƒ©ãƒ³ãŒç¶šã„ã¦ã‚‹ã‚“ã§ã™ã‚ˆã­...</title><link>https://huggingface.co/posts/Holy-fox/916850799845292</link><description>4æœˆï¼Ÿã”ã‚ã«å‚åŠ ã—ãŸCerebrasã®ãƒãƒƒã‚«ã‚½ãƒ³ã‹ã‚‰ä½•æ•…ã‹Huggingfaceã®proãƒ—ãƒ©ãƒ³ãŒç¶šã„ã¦ã‚‹ã‚“ã§ã™ã‚ˆã­... å¤šåˆ†ãƒãƒƒã‚«ã‚½ãƒ³æœŸé–“ã ã‘ã®ã¯ãšãªã‚“ã ã‘ã©ã€å¤–ã‚Œãªã„ã®ã‚ˆã­ã€‚ ã¾ã‚ã€ã‚¯ãƒ¬ã‚«ã¨ã‹ã¯ç™»éŒ²ã—ã¦ãªã„ã‹ã‚‰å¤§ä¸ˆå¤«ã ã¨ã¯æ€ã†ã‘ã© See translation</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Holy-fox/916850799845292</guid></item><item><title>Why I think local, open-source models will eventually win.</title><link>https://huggingface.co/posts/abidlabs/941146046599374</link><description>Why I think local, open-source models will eventually win. The most useful AI applications are moving toward multi-turn agentic behavior: systems that take hundreds or even thousands of iterative steps to complete a task, e.g. Claude Code, computer-control agents that click, type, and test repeatedly. In these cases, the power of the model is not how smart it is per token, but in how quickly it can interact with its environment and tools across many steps. In that regime, model quality becomes secondary to latency. An open-source model that can call tools quickly, check that the right thing was clicked, or verify that a code change actually passes tests can easily outperform a slightly â€œsmarterâ€ closed model that has to make remote API calls for every move. Eventually, the balance tips: it becomes impractical for an agent to rely on remote inference for every micro-action. Just as no one would tolerate a keyboard that required a network request per keystroke, users wonâ€™t accept...</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/abidlabs/941146046599374</guid></item><item><title>Made a multimodal mental health system using Llama-3.2-3B, Kokoro TTS, and DeepFace FER! Currently exploring the use of APIs for better quality given my lack of resources for a more thorough Llama 3 fine-tune ğŸ¤™ğŸ»</title><link>https://huggingface.co/posts/IniNLP247/427756844233002</link><description>Made a multimodal mental health system using Llama-3.2-3B, Kokoro TTS, and DeepFace FER! Currently exploring the use of APIs for better quality given my lack of resources for a more thorough Llama 3 fine-tune ğŸ¤™ğŸ» IniNLP247/Kenko See translation</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/IniNLP247/427756844233002</guid></item><item><title>Reached 2500+ total downloads across my models and datasets! ğŸ‰</title><link>https://huggingface.co/posts/ronantakizawa/608886392582341</link><description>Reached 2500+ total downloads across my models and datasets! ğŸ‰ Follow me for more @ ronantakizawa See translation</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ronantakizawa/608886392582341</guid></item><item><title>Ilya's interview has been widely cited. I won't address meta points but share 2 cents on two mundane issues.</title><link>https://huggingface.co/posts/onekq/703993717643284</link><description>Ilya's interview has been widely cited. I won't address meta points but share 2 cents on two mundane issues. I will start with the leaderboard phenomena. This is a feature, not bug. Model training is a project under founder mode. But still like all projects, it needs north stars. And you guess right, (famous) leaderboards are the north stars. For those startups which found PMFs, many maintain their own proprietary leaderboards/benchmarks condensed from user traffic. The path is blocked on both directions: startups won's share their moats, model makers won't prioritize either. So instead of complaining, we should celebrate that our prompts work (most of the time) See translation</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/onekq/703993717643284</guid></item><item><title>âœ… New Article: *Structured Intelligence Computers â€” A Stack That Fixes Its Own Bottlenecks*</title><link>https://huggingface.co/posts/kanaria007/247583181528224</link><description>âœ… New Article: *Structured Intelligence Computers â€” A Stack That Fixes Its Own Bottlenecks* Title: ğŸ§ â¡ï¸ğŸ–¥ï¸ Structured Intelligence Computers: A Stack That Fixes Its Own Bottlenecks ğŸ”— https://huggingface.co/blog/kanaria007/sic-fixes-its-own-bottlenecks --- Summary: Traditional supercomputers scale FLOPS, bandwidth, and memory. Structured Intelligence Computers (SICs) scale something else entirely: *meaning throughput*. This article gives a stack-level tour of SIC â€” from SI-Core and SI-NOS to SIL, GSPUs, Semantic Compression, and SCP â€” and shows how *each layer is designed to absorb a specific bottleneck* in the layer beneath it. &gt; Supercomputers calculate faster. &gt; *SICs think with structure.* --- Why It Matters: * Moves from â€œbits over wiresâ€ to *semantic graph packets with causal &amp; ethical context* * Treats *rollback, ethics, and determinism* as kernel concerns, not app glue * Bridges *specs + PoCs* (SI-Core, SI-NOS, SIL, GSPU, SCP) into one coherent paradigm * Gives AI/infra teams a...</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kanaria007/247583181528224</guid></item><item><title>Free Radar Dataset to for System Integrators and AI/ML Innovators</title><link>https://huggingface.co/posts/InezCornell/623914128392808</link><description>Free Radar Dataset to for System Integrators and AI/ML Innovators Plextek, a leading UK-based electronics design consultancy, is supporting AI/ML and System Integration companies who want to experiment with radar but lack access to quality datasets. This free radar dataset service is designed to help businesses explore and expand their offerings by incorporating radar as a data type into their solutions. Small scale start-ups - to medium-sized companies eager to explore radar-enabled capabilities often find that they are held back by the initial hardware purchase cost, steep learning curve and the limited availability of realistic, accessible radar data. Plextekâ€™s initiative directly addresses this gap by providing: Curated, real-world radar data for non-commercial experimentation Expert guidance to help teams interpret and work with radar data A potential path to future collaboration on radar-enabled projects â€œWhether you're training algorithms, validating models, or responding to...</description><pubDate>Sun, 30 Nov 2025 05:24:23 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/InezCornell/623914128392808</guid></item></channel></rss>