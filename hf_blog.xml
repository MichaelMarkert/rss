<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Blog</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the HuggingFace Blog.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>TextQuests: How Good are LLMs at Text-Based Video Games?</title><link>https://huggingface.co/blog/textquests</link><description>Back to Articles TextQuests: How Good are LLMs at Text-Based Video Games? Published August 12, 2025 Update on GitHub Upvote 20 +14 Long Phan justinphan3110 Follow cais Cl√©mentine Fourrier clefourrier Follow TextQuests Evaluations Discussion Citations The rapid advancement of Large Language Models (LLMs) has enabled remarkable progress on established academic and industrial benchmarks. Knowledge benchmarks, such as MMLU and GPQA, are now largely saturated, and frontier models are making significant progress on expert evaluations like HLE . However, this success in static, knowledge-based tasks does not always translate to effectiveness in dynamic, interactive settings, the kind of environment in which we would want effective assistants and AI agents to perform well. Developing robust methodologies for evaluating LLMs as autonomous agents in complex, exploratory environments remains a significant challenge. Two core avenues exist to evaluate autonomous agents: either use real-world...</description><pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/textquests</guid></item><item><title>Introducing AI Sheets: a tool to work with datasets using open AI models!</title><link>https://huggingface.co/blog/aisheets</link><description>Back to Articles Introducing AI Sheets: a tool to work with datasets using open AI models! Published August 8, 2025 Update on GitHub Upvote 53 +47 Daniel Vila dvilasuero Follow Ame Vi Ameeeee Follow Francisco Aranda frascuchon Follow Dami√°n Pumar damianpumar Follow Leandro von Werra lvwerra Follow Thomas Wolf thomwolf Follow Useful links What is AI Sheets What can I use it for How to use it Getting started Working with your dataset Refining and expanding the dataset Exporting your final dataset to the Hub Running data generation scripts using HF Jobs Examples Vibe testing and comparing models Add categories to a Hub dataset Evaluate models with LLMs-as-Judge Next steps üß≠TL;DR Hugging Face AI Sheets is a new, open-source tool for building, enriching, and transforming datasets using AI models with no code . The tool can be deployed locally or on the Hub. It lets you use thousands of open models from the Hugging Face Hub via Inference Providers or local models, including gpt-oss from...</description><pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/aisheets</guid></item><item><title>Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training</title><link>https://huggingface.co/blog/accelerate-nd-parallel</link><description>Back to Articles Accelerate ND-Parallel: A guide to Efficient Multi-GPU Training Published August 8, 2025 Update on GitHub Upvote 45 +39 Salman Mohammadi smohammadi Follow axolotl-ai-co Matej Sirovatka siro1 Follow wing lian winglian Follow axolotl-ai-co Marc Sun marcsun13 Follow Dan Saunders djsaunde Follow axolotl-ai-co Contents Data Parallelism Fully Sharded Data Parallelism Tensor Parallelism Context Parallelism ND Parallelisms Hybrid Sharded Data Parallelism Fully Sharded Data Parallelism + Tensor Parallelism Fully Sharded Data Parallelism + Context Parallelism Hybrid Sharded Data Parallelism + Tensor Parallelism Usage notes Training large models across multiple GPUs can be challenging due to the complexities of different parallelism strategies. In Accelerate, together with Axolotl , we have integrated a quick and easy way to use any combination of parallelism strategies in your training script! Here is how to add it to your training script: from transformers import...</description><pubDate>Fri, 08 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/accelerate-nd-parallel</guid></item><item><title>üáµüá≠ FilBench - Can LLMs Understand and Generate Filipino?</title><link>https://huggingface.co/blog/filbench</link><description>Back to Articles üáµüá≠ FilBench - Can LLMs Understand and Generate Filipino? Published August 12, 2025 Update on GitHub Upvote 8 +2 Lj V. Miranda ljvmiranda921 Follow UD-Filipino Elyanah Aco acocodes Follow UD-Filipino Conner Manuel connermanuel Follow UD-Filipino Jan Christian Blaise Cruz jcblaise Follow UD-Filipino Jan Christian Blaise Cruz jcblaise Follow SEACrowd Joseph Imperial josephimperial Follow SEACrowd Daniel van Strien davanstrien Follow Nathan Habib SaylorTwift Follow Cl√©mentine Fourrier clefourrier Follow FilBench What did we learn from FilBench? Finding #1: Although region-specific LLMs still lag behind GPT-4, collecting data to train these models is still a promising direction Finding #2: Filipino translation is still a difficult task for LLMs Finding #3: Open LLMs Remain a Cost-Effective Choice for Filipino Language Tasks Does your LLM work on Philippine Languages? Try it on FilBench! Acknowledgements Citation As large language models (LLMs) become increasingly...</description><pubDate>Tue, 12 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/filbench</guid></item><item><title>Vision Language Model Alignment in TRL ‚ö°Ô∏è</title><link>https://huggingface.co/blog/trl-vlm-alignment</link><description>Back to Articles Vision Language Model Alignment in TRL ‚ö°Ô∏è Published August 7, 2025 Update on GitHub Upvote 61 +55 Sergio Paniego sergiopaniego Follow merve merve Follow Quentin Gallou√©dec qgallouedec Follow Kashif Rasul kashif Follow Aritra Roy Gosthipaty ariG23498 Follow Introduction Table of Contents Alignment for Vision Language Models Mixed Preference Optimization (MPO) Multimodal Group Relative Policy Optimization (GRPO) Group Sequence Policy Optimization (GSPO) Comparison Native Supervised Fine-tuning Support vLLM Integration in TRL Useful Resources Introduction Vision Language Models (VLMs) are getting stronger, but aligning them to human preferences still matters. In TRL, we already showed how to post-train VLMs with Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) . This time, we‚Äôre going further. tl;dr We have added two new multimodal alignment methods to TRL: Group Relative Policy Optimization (GRPO) , its variant Group Sequence Policy Optimization...</description><pubDate>Thu, 07 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/trl-vlm-alignment</guid></item><item><title>Welcome GPT OSS, the new open-source model family from OpenAI!</title><link>https://huggingface.co/blog/welcome-openai-gpt-oss</link><description>Back to Articles Welcome GPT OSS, the new open-source model family from OpenAI! Published August 5, 2025 Update on GitHub Upvote 459 +453 Vaibhav Srivastav reach-vb Follow Pedro Cuenca pcuenq Follow Lewis Tunstall lewtun Follow Clem ü§ó clem Follow Matthew Carrigan Rocketknight1 Follow Cl√©mentine Fourrier clefourrier Follow C√©lina Hanouti celinah Follow Lucain Pouget Wauplin Follow Marc Sun marcsun13 Follow Simon Pagezy pagezyhf Follow √Åkos Hadnagy ahadnagy Follow Joao Gante joaogante Follow Contents Overview of Capabilities and Architecture API access through Inference Providers Local Inference Using Transformers Llama.cpp vLLM transformers serve Fine-Tuning Deploy on Hugging Face Partners Azure Dell Evaluating the Model Chats and Chat Templates System and Developer Messages Tool Use With transformers Acknowledgements GPT OSS is a hugely anticipated open-weights release by OpenAI, designed for powerful reasoning, agentic tasks, and versatile developer use cases. It comprises two...</description><pubDate>Tue, 05 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/welcome-openai-gpt-oss</guid></item><item><title>Build an AI Shopping Assistant with Gradio MCP Servers</title><link>https://huggingface.co/blog/gradio-vton-mcp</link><description>Back to Articles Implementing MCP Servers in Python: An AI Shopping Assistant with Gradio Published July 31, 2025 Update on GitHub Upvote 49 +43 Freddy Boulton freddyaboulton Follow The Goal: Your Personal AI Stylist Building the Gradio MCP Server Configuring VS Code Putting It All Together Conclusion Python Developers, want to give your LLM superpowers? Gradio is the fastest way to do it! With Gradio's Model Context Protocol (MCP) integration, your LLM can plug directly into the thousands of AI models and Spaces hosted on the Hugging Face Hub . By pairing the general reasoning capabilities of LLMs with the specialized abilities of models found on Hugging Face, your LLM can go beyond simply answering text questions to actually solving problems in your daily life. For Python developers, Gradio makes implementing powerful MCP servers a breeze, offering features like: Automatic conversion of python functions into LLM tools: Each API endpoint in your Gradio app is automatically...</description><pubDate>Thu, 31 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/gradio-vton-mcp</guid></item><item><title>Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face</title><link>https://huggingface.co/blog/trackio</link><description>Back to Articles Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face Published July 29, 2025 Update on GitHub Upvote 155 +149 Abubakar Abid abidlabs Follow Zach Nation znation Follow Nouamane Tazi nouamanetazi Follow Sasha Luccioni sasha Follow Quentin Gallou√©dec qgallouedec Follow Background Why We Switched to Trackio Using Trackio Installing Usage Visualizing Results Sharing with ü§ó Spaces Integrated with ü§ó Transformers and ü§ó Accelerate Design Principles Next Steps TL;DR: Trackio is a new, open-source, and free experiment tracking Python library that provides a local dashboard and seamless integration with Hugging Face Spaces for easy sharing and collaboration. Since trackio is a drop-in replacement for wandb , you can get started with the syntax you already know! Background If you have trained your own machine learning model, you know how important it is to be able to track metrics, parameters, and hyperparameters during training and visualize them...</description><pubDate>Tue, 29 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/trackio</guid></item><item><title>Say hello to `hf`: a faster, friendlier Hugging Face CLI ‚ú®</title><link>https://huggingface.co/blog/hf-cli</link><description>Back to Articles Say hello to `hf`: a faster, friendlier Hugging Face CLI ‚ú® Published July 25, 2025 Update on GitHub Upvote 75 +69 Lucain Pouget Wauplin Follow C√©lina Hanouti celinah Follow Julien Chaumond julien-c Follow Getting started üîÄ Migration One more thing... üí• hf jobs We are glad to announce a long-awaited quality-of-life improvement: the Hugging Face CLI has been officially renamed from huggingface-cli to hf ! So... why this change? Typing huggingface-cli constantly gets old fast. More importantly, the CLI‚Äôs command structure became messy as new features were added over time (upload, download, cache management, repo management, etc.). Renaming the CLI is a chance to reorganize commands into a clearer, more consistent format. We decided not to reinvent the wheel and instead follow a well-known CLI pattern: hf &lt;resource&gt; &lt;action&gt; . This predictable grammar makes the Hugging Face CLI more ergonomic and discoverable, while also setting the stage for upcoming features. Getting...</description><pubDate>Fri, 25 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/hf-cli</guid></item><item><title>Parquet Content-Defined Chunking</title><link>https://huggingface.co/blog/parquet-cdc</link><description>Back to Articles Parquet Content-Defined Chunking Published July 25, 2025 Update on GitHub Upvote 56 +50 Krisztian Szucs kszucs Follow Table of Contents Introduction Data Preparation Upload the table as a Parquet file to Hugging Face Hub Different Use Cases for Parquet Deduplication 1. Re-uploading Exact Copies of the Table 2. Adding and Removing Columns from the Table 3. Changing Column Types in the Table 4. Appending New Rows and Concatenating Tables 5. Inserting / Deleting Rows in the Table 6. Using Different Row-group Sizes 7. Using Varying File-Level Splits Using Parquet CDC feature with Pandas References Conclusion Reduce Parquet file upload and download times on Hugging Face Hub by leveraging the new Xet storage layer and Apache Arrow‚Äôs Parquet Content-Defined Chunking (CDC) feature enabling more efficient and scalable data workflows. TL;DR: Parquet Content-Defined Chunking (CDC) is now available in PyArrow and Pandas, enabling efficient deduplication of Parquet files on...</description><pubDate>Fri, 25 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/parquet-cdc</guid></item><item><title>TimeScope: How Long Can Your Video Large Multimodal Model Go?</title><link>https://huggingface.co/blog/timescope-video-lmm-benchmark</link><description>Back to Articles TimeScope: How Long Can Your Video Large Multimodal Model Go? Published July 23, 2025 Update on GitHub Upvote 37 +31 Orr Zohar orrzohar Follow Stanford Rui Li ruili0 Follow guest Andres Marafioti andito Follow huggingface Xiaohan Wang nicholswang Follow Stanford TL;DR Table of Contents Why TimeScope? Motivating a Better Benchmark for Video Benchmark Design 1. Localized Retrieval 2. Information Synthesis 3. Fine-Grained Temporal Perception Evaluations &amp; Leaderboard What did we learn? Conclusion ‚Äì Let‚Äôs Raise the Bar for Long-Video AI TL;DR TimeScope is an open-source benchmark designed to measure how well vision-language models understand long videos. By adding short ‚Äúneedle‚Äù clips into videos ranging from 1 minute to 8 hours, it evaluates three skills: localized retrieval, information synthesis, fine-grained temporal perception. Timescope reveals that many state-of-the-art models still struggle with true temporal comprehension. Table of Contents Why TimeScope?...</description><pubDate>Wed, 23 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/timescope-video-lmm-benchmark</guid></item><item><title>Fast LoRA inference for Flux with Diffusers and PEFT</title><link>https://huggingface.co/blog/lora-fast</link><description>Back to Articles Fast LoRA inference for Flux with Diffusers and PEFT Published July 23, 2025 Update on GitHub Upvote 43 +37 Sayak Paul sayakpaul Follow Benjamin Bossan BenjaminB Follow Technical details of hotswapping Resources LoRA adapters provide a great deal of customization for models of all shapes and sizes. When it comes to image generation, they can empower the models with different styles, different characters, and much more . Sometimes, they can also be leveraged to reduce inference latency . Hence, their importance is paramount, particularly when it comes to customizing and fine-tuning models. In this post, we take the Flux.1-Dev model for text-to-image generation because of its widespread popularity and adoption, and how to optimize its inference speed when using LoRAs (~2.3x). It has over 30k adapters trained with it ( as reported on the Hugging Face Hub platform). Therefore, its importance to the community is significant. Note that even though we demonstrate speedups...</description><pubDate>Wed, 23 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/lora-fast</guid></item><item><title>Arc Virtual Cell Challenge: A Primer</title><link>https://huggingface.co/blog/virtual-cell-challenge</link><description>Back to Articles Arc Virtual Cell Challenge: A Primer Published July 18, 2025 Update on GitHub Upvote 51 +45 Christopher Fleetwood FL33TW00D-HF Follow Abhinav Adduri abhinadduri Follow arcinstitute Training data Modelling the challenge State Transition Model (ST) State Embedding Model (SE) A little biological detour Back to the model Perturbation Discrimination Differential Expression Conclusion Arc Institute recently unveiled the Virtual Cell Challenge . Participants are required to train a model capable of predicting the effect of silencing a gene in a (partially) unseen cell type, a task they term context generalization . For ML engineers with little to no biology background, the jargon and required context can seem quite daunting. To encourage participation, we recapitulate the challenge in a form better suited to engineers from other disciplines. Goal Train a model to predict the effect on a cell of silencing a gene using CRISPR. Doing things in the world of atoms is expensive,...</description><pubDate>Fri, 18 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/virtual-cell-challenge</guid></item><item><title>Consilium: When Multiple LLMs Collaborate</title><link>https://huggingface.co/blog/consilium-multi-llm</link><description>Back to Articles Consilium: When Multiple LLMs Collaborate Published July 17, 2025 Update on GitHub Upvote 25 +19 Andreas azettl Follow guest From Concept to Architecture Building the Visual Foundation Session State Management Making LLMs Actually Discuss LLM Selection and Research Integration Discovering the Open Floor Protocol Lessons Learned and Future Implications Picture this: four AI experts sitting around a poker table, debating your toughest decisions in real-time. That's exactly what Consilium, the multi-LLM platform I built during the Gradio Agents &amp; MCP Hackathon , does. It lets AI models discuss complex questions and reach consensus through structured debate. The platform works both as a visual Gradio interface and as an MCP (Model Context Protocol) server that integrates directly with applications like Cline (Claude Desktop had issues as the timeout could not be adjusted). The core idea was always about LLMs reaching consensus through discussion; that's where the name...</description><pubDate>Thu, 17 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/consilium-multi-llm</guid></item><item><title>Back to The Future: Evaluating AI Agents on Predicting Future Events</title><link>https://huggingface.co/blog/futurebench</link><description>Back to Articles Back to The Future: Evaluating AI Agents on Predicting Future Events Published July 17, 2025 Update on GitHub Upvote 36 +30 Federico Bianchi vinid Follow guest Junlin Wang junlinw Follow togethercomputer Zain Hasan zainhasan Follow togethercomputer Shang Zhu shangzhu Follow guest Roy coolcat21 Follow togethercomputer Cl√©mentine Fourrier clefourrier Follow James ZOu jameszou Follow guest Future of AI Can Agents Predict Future Events? 1. News-Generated Questions: Finding Tomorrow's Headlines Today 2. Polymarket Integration: Leveraging Prediction Markets Example Questions Future Bench: Three Levels of Systematic Evaluation Predicting The Future: Agents and Initial Results Initial Results Interesting Action Patterns References Future of AI Most current AI benchmarks focus on answering questions about the past, either by testing models on existing knowledge (in a static manner, such as HLE or GPQA, or augmented, like BrowseComp or GAIA) or previously solved problems...</description><pubDate>Thu, 17 Jul 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/futurebench</guid></item></channel></rss>