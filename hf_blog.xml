<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Blog</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the HuggingFace Blog.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SOTA OCR on-device with Core ML and dots.ocr</title><link>https://huggingface.co/blog/dots-ocr-ne</link><description>Back to Articles SOTA OCR on-device with Core ML and dots.ocr Published October 2, 2025 Update on GitHub Upvote 35 +29 Christopher Fleetwood FL33TW00D-HF Follow Pedro Cuenca pcuenq Follow Conversion Dots.OCR Step 0: Understand and simplify the model Step 1: A simple harness Step 2: Bug hunting Step 3: Benchmarking Every year our hardware is a little more powerful, our models a little smarter for each parameter. In 2025, it is more feasible than ever to run truly competitive models on-device. dots.ocr , a 3B parameter OCR model from RedNote, surpasses Gemini 2.5 Pro in OmniDocBench , making OCR a truly no compromises on-device use case. Running models on-device is certainly appealing to developers: no smuggling API keys, zero cost, and no network required. However, if we want these models to run on-device, we need to be mindful of the limited compute and power budgets. Enter the Neural Engine, Apple's custom AI accelerator that has shipped with every Apple device since 2017. This...</description><pubDate>Thu, 02 Oct 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/dots-ocr-ne</guid></item><item><title>Introducing RTEB: A New Standard for Retrieval Evaluation</title><link>https://huggingface.co/blog/rteb</link><description>Back to Articles Introducing RTEB: A New Standard for Retrieval Evaluation Published October 1, 2025 Update on GitHub Upvote 105 +99 Frank Liu fzliu Follow guest Kenneth C. Enevoldsen KennethEnevoldsen Follow mteb Solomatin Roman Samoed Follow mteb Isaac Chung isaacchung Follow mteb Tom Aarsen tomaarsen Follow mteb Fődi, Zoltán fzoll Follow guest Why Existing Benchmarks Fall Short Introducing RTEB A Hybrid Strategy for True Generalization Built for Real-World Domains Launching RTEB: A Community Effort Limitations and Future Work TL;DR – We’re excited to introduce the beta version of the Retrieval Embedding Benchmark (RTEB) , a new benchmark designed to reliably evaluate the retrieval accuracy of embedding models for real-world applications. Existing benchmarks struggle to measure true generalization, while RTEB addresses this with a hybrid strategy of open and private datasets. Its goal is simple: to create a fair, transparent, and application-focused standard for measuring how...</description><pubDate>Wed, 01 Oct 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/rteb</guid></item><item><title>Accelerating Qwen3-8B Agent on Intel® Core™ Ultra with Depth-Pruned Draft Models</title><link>https://huggingface.co/blog/intel-qwen3-agent</link><description>Back to Articles Accelerating Qwen3-8B Agent on Intel® Core™ Ultra with Depth-Pruned Draft Models Published September 29, 2025 Update on GitHub Upvote 17 +11 Igor Margulis imargulis Follow Intel Ofir Zafrir ofirzaf Follow Intel Shira Guskin sguskin Follow Intel Guy Boudoukh guybd Follow Intel Pedro Cuenca pcuenq Follow Qwen3 Accelerating Qwen3-8B on Intel® Core™ Ultra with Speculative Decoding Pushing Performance Further Integration with 🤗smolagents References TL;DR: Qwen3-8B is one of the most exciting recent releases—a model with native agentic capabilities, making it a natural fit for the AIPC. With OpenVINO.GenAI , we’ve been able to accelerate generation by ~1.3× using speculative decoding with a lightweight Qwen3-0.6B draft. By using speculative decoding and applying a simple pruning process to the draft, we pushed the speedup even further to ~1.4× We wrapped this up by showing how these improvements can be used to run a fast, local AI Agent with 🤗 smolagents Qwen3 Qwen3-8B is...</description><pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/intel-qwen3-agent</guid></item><item><title>VibeGame: Exploring Vibe Coding Games</title><link>https://huggingface.co/blog/vibegame</link><description>Back to Articles VibeGame: Exploring Vibe Coding Games Published September 29, 2025 Update on GitHub Upvote 19 +13 Dylan Ebert dylanebert Follow The Problem What Is "Vibe Coding"? Context Management Initial Exploration Attempt 1: Roblox MCP Attempt 2: Unity MCP Attempt 3: Web Stack Comparison Summary The Solution: VibeGame Design Philosophy So Does It Actually Work? Try It Yourself What's Next? The Problem People are trying to vibe code games. And it kind of works, at first. However, as the project grows, things begin to fall apart. Why? And what can we do about it? I'll talk about the problem, how I fixed it, and where to go from here. What Is "Vibe Coding"? First, what is vibe coding? It's originally coined by Andrej Karpathy in a viral tweet where it's defined as where you "fully give in to the vibes, embrace exponentials and forget the code even exists". However, since then, it's used descriptively to mean a lot of different things, anywhere from just "using AI when coding" to...</description><pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/vibegame</guid></item><item><title>Swift Transformers Reaches 1.0 — and Looks to the Future</title><link>https://huggingface.co/blog/swift-transformers</link><description>Back to Articles Swift Transformers Reaches 1.0 – and Looks to the Future Published September 26, 2025 Update on GitHub Upvote 28 +22 Pedro Cuenca pcuenq Follow Christopher Fleetwood FL33TW00D-HF Follow Mattt mattt Follow Vaibhav Srivastav reach-vb Follow What is swift-transformers How is the community using it What changes with v1.0 Usage Examples What comes next We couldn’t have done this without you 🫵 We released swift-transformers two years ago (!) with the goal to support Apple developers and help them integrate local LLMs in their apps. A lot has changed since then (MLX and chat templates did not exist!), and we’ve learned how the community is actually using the library. We want to double down on the use cases that provide most benefits to the community, and lay out the foundations for the future. Spoiler alert: after this release, we’ll focus a lot on MLX and agentic use cases 🚀 What is swift-transformers swift-transformers is a Swift library that aims to reduce the friction...</description><pubDate>Fri, 26 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/swift-transformers</guid></item><item><title>Smol2Operator: Post-Training GUI Agents for Computer Use</title><link>https://huggingface.co/blog/smol2operator</link><description>Back to Articles Smol2Operator: Post-Training GUI Agents for Computer Use Published September 23, 2025 Update on GitHub Upvote 115 +109 Amir Mahla A-Mahla Follow merve merve Follow Sergio Paniego sergiopaniego Follow Vaibhav Srivastav reach-vb Follow Lewis Tunstall lewtun Follow Table of Contents Introduction 1. Data Transformation and Unified Action Space The Challenge of Inconsistent Action Spaces Our Unified Approach Example Data Transformation (Bonus) Custom Action Space Adaptation with Action Space Converter Key Features Usage Example Transformed and Released Datasets 2. Phase 1: From Zero to Perception Training Data Optimization Experiments Image Resolution and Coordinate System Analysis Key Findings Phase 1 Results 3. Phase 2: From Perception to Cognition Training Data Phase 2 Results 4. All you need is Open Source 5. Conclusion What's Next? TL;DR: This work shows how a lightweight vision–language model can acquire GUI-grounded skills and evolve into an agentic GUI coder. We...</description><pubDate>Tue, 23 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/smol2operator</guid></item><item><title>Gaia2 and ARE: Empowering the community to study agents</title><link>https://huggingface.co/blog/gaia2</link><description>Back to Articles Gaia2 and ARE: Empowering the Community to Evaluate Agents Published September 22, 2025 Update on GitHub Upvote 109 +103 Clémentine Fourrier clefourrier Follow OpenEvals Maxime Lecanu mlcu Follow meta-agents-research-environments Pierre Andrews mortimerp9 Follow meta-agents-research-environments Adrien Carreira XciD Follow frere thibaud tfrere Follow Avijit Ghosh evijit Follow hfpolicy Romain Froger RomainFroger Follow meta-agents-research-environments Dheeraj Mekala dheeraj7596 Follow meta-agents-research-environments Caroline Pascal CarolinePascal Follow lerobot Ulyana Piterbarg upiter Follow meta-agents-research-environments Gaia2: Agentic Evaluation on Real Life Assistant Tasks How does Gaia2 run? Results Compare with your favorite models! Evaluating on Gaia2 Beyond Gaia2: study your agents with ARE 1) Testing an agent on a simple task: event organisation 2) Understanding agents: deep diving the traces 3) Playing around and extending the demo: Connecting the...</description><pubDate>Mon, 22 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/gaia2</guid></item><item><title>Scaleway on Hugging Face Inference Providers 🔥</title><link>https://huggingface.co/blog/inference-providers-scaleway</link><description>Back to Articles Scaleway on Hugging Face Inference Providers 🔥 Published September 19, 2025 Update on GitHub Upvote 21 +15 Guillaume Noale gnoale Follow guest Franck Pagny fpagny Follow guest Fred Bardolle f14e Follow guest Guillaume Calmettes gcalmettes Follow guest Constance Morales C-morales Follow guest Célina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Scaleway is now a supported Inference Provider on the Hugging Face Hub! Scaleway joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub’s model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access popular open-...</description><pubDate>Fri, 19 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers-scaleway</guid></item><item><title>Democratizing AI Safety with RiskRubric.ai</title><link>https://huggingface.co/blog/riskrubric</link><description>Back to Articles Democratizing AI Safety with RiskRubric.ai Published September 18, 2025 Update on GitHub Upvote 16 +10 Gal Moyal galmo-noma Follow guest Risk Rubric, a new Standardized Assessment of Risk for models What we found (as of September 2025) Conclusion Building trust in the open model ecosystem through standardized risk assessment More than 500,000 models can be found on the Hugging Face hub, but it’s not always clear to users how to choose the best model for them, notably on the security aspects. Developers might find a model that perfectly fits their use case, but have no systematic way to evaluate its security posture, privacy implications, or potential failure modes. As models become more powerful and adoption accelerates, we need equally rapid progress in AI safety and security reporting. We're therefore excited to announce RiskRubric.ai , a novel initiative led by Cloud Security Alliance and Noma Security , with contributions by Haize Labs and Harmonic Security, for...</description><pubDate>Thu, 18 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/riskrubric</guid></item><item><title>Public AI on Hugging Face Inference Providers 🔥</title><link>https://huggingface.co/blog/inference-providers-publicai</link><description>Back to Articles Public AI on Hugging Face Inference Providers 🔥 Published September 17, 2025 Update on GitHub Upvote 21 +15 Joseph Low Jolow Follow publicai Joshua Tan thelastjosh Follow publicai Célina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Public AI is now a supported Inference Provider on the Hugging Face Hub! Public AI joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub’s model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access public and sovereign models from institutions like the Swiss AI Initiative and AI Singapore — right from Hugging Face. You...</description><pubDate>Wed, 17 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers-publicai</guid></item><item><title>`LeRobotDataset`: Bringing large-scale datasets to lerobot</title><link>https://huggingface.co/blog/lerobot-datasets-v3</link><description>Back to Articles LeRobotDataset:v3.0: Bringing large-scale datasets to lerobot Published September 16, 2025 Update on GitHub Upvote 37 +31 Francesco Capuano fracapuano Follow Michel Aractingi aractingi Follow Quentin Lhoest lhoestq Follow Caroline Pascal CarolinePascal Follow Pepijn Kooijmans pepijn223 Follow Jade Choghari jadechoghari Follow Remi Cadene cadene Follow Simon Alibert aliberts Follow Adil Zouitine AdilZtn Follow Martino Russi nepyope Follow Steven Palma imstevenpmwork Follow Table of Contents LeRobotDataset, v3.0 Install lerobot , and record a dataset Migrate your v2.1 dataset to v3.0 Code Example: Using LeRobotDataset with torch.utils.data.DataLoader Streaming Conclusion Acknowledgements TL;DR Today we release LeRobotDataset:v3 ! In our previous LeRobotDataset:v2 release, we stored one episode per file, hitting file-system limitations when scaling datasets to millions of episodes. LeRobotDataset:v3 packs multiple episodes in a single file, using relational metadata to...</description><pubDate>Tue, 16 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/lerobot-datasets-v3</guid></item><item><title>Visible Watermarking with Gradio</title><link>https://huggingface.co/blog/watermarking-with-gradio</link><description>Back to Articles Visible Watermarking with Gradio Published September 15, 2025 Update on GitHub Upvote 17 +11 Margaret Mitchell meg Follow Last year, we shared a blogpost on watermarking , explaining what it means to watermark generative AI content, and why it's important. The need for watermarking has become even more critical as people all over the world have begun to generate and share AI-generated images, video, audio, and text. Images and video have become so realistic that they’re nearly impossible to distinguish from what you’d see captured by a real camera. Addressing this issue is multi-faceted, but there is one, clear, low-hanging fruit 🍇: In order for people to know what's real and what's synthetic, use visible watermarks. To help out, we at Hugging Face have made visible watermarking trivially easy: Whenever you create a Space like an app or a demo , you can use our in-house app-building library Gradio to display watermarks with a single command. For images and video,...</description><pubDate>Mon, 15 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/watermarking-with-gradio</guid></item><item><title>Tricks from OpenAI gpt-oss YOU 🫵 can use with transformers</title><link>https://huggingface.co/blog/faster-transformers</link><description>Back to Articles Tricks from OpenAI gpt-oss YOU 🫵 can use with transformers Published September 11, 2025 Update on GitHub Upvote 153 +147 Aritra Roy Gosthipaty ariG23498 Follow Sergio Paniego sergiopaniego Follow Vaibhav Srivastav reach-vb Follow Pedro Cuenca pcuenq Follow Arthur Zucker ArthurZ Follow Nathan Habib SaylorTwift Follow Cyril Vallez cyrilvallez Follow Zero-build Kernels, downloadable from the Hub Custom Kernels for GPT-OSS Flash Attention 3 MXFP4 Quantization What is MXFP4 MXFP4 in transformers Requirements and fallbacks Kernels for MXFP4 Tensor Parallelism What this enables in transformers When to reach for TP Expert Parallelism Dynamic Sliding Window Layer &amp; Cache How to use it Continuous Batching &amp; Paged Attention Load larger models faster Conclusion Read More OpenAI recently released their GPT-OSS series of models . The models feature some novel techniques like MXFP4 quantization, efficient kernels, a brand new chat format, and more. To enable the release of gpt-oss...</description><pubDate>Thu, 11 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/faster-transformers</guid></item><item><title>Jupyter Agents: training LLMs to reason with notebooks</title><link>https://huggingface.co/blog/jupyter-agent-2</link><description>Back to Articles Jupyter Agents: training LLMs to reason with notebooks Published September 10, 2025 Update on GitHub Upvote 52 +46 Baptiste Colle baptistecolle Follow Hanna Yukhymenko hannayukhymenko Follow Leandro von Werra lvwerra Follow 🏁 Primer: the DABStep Benchmark 🎯 First Baseline 🔧 Primer on Scaffolding 🏃‍♂️ Training Pipeline ⚙️ Dataset Pipeline 1. Large-scale deduplication 2. Downloading linked datasets 3. Edu scoring 4. Filtering irrelevant notebooks 5. QA generation 6. Trace generation 7. Final curation 🏃‍♂️ Training Pipeline 📊 Results Try Jupyter Agent Yourself 🔮 Next Steps The past year has been all about giving LLMs more tools and autonomy to solve more complex and open ended tasks. The goal of the Jupyter Agent is to give the model the ultimate tool: code execution. A natural way to display multi-step code execution together with reasoning is within a Jupyter Notebook, which consists of code and markdown cells. So we built Jupyter Agent to act as an agent that can...</description><pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/jupyter-agent-2</guid></item><item><title>mmBERT: ModernBERT goes Multilingual</title><link>https://huggingface.co/blog/mmbert</link><description>Back to Articles mmBERT: ModernBERT goes Multilingual Published September 9, 2025 Update on GitHub Upvote 110 +104 Marc Marone mmarone Follow jhu-clsp Orion Weller orionweller Follow jhu-clsp William Fleshman will-fleshman Follow guest Eugene Yang eugene-yang Follow jhu-clsp Dawn Lawrie dlawrie Follow jhu-clsp Ben Van Durme vandurme Follow jhu-clsp TL;DR Training Data Training Recipe and Novel Components Architecture Three-Phase Training Approach Novel Training Techniques Results Natural Language Understanding (NLU) Retrieval Performance Learning Languages in the Decay Phase Efficiency Improvements Usage Examples Fine-tuning Examples Encoders Model Family and Links TL;DR This blog post introduces mmBERT , a state-of-the-art massively multilingual encoder model trained on 3T+ tokens of text in over 1800 languages. It shows significant performance and speed improvements over previous multilingual models, being the first to improve upon XLM-R, while also developing new strategies for...</description><pubDate>Tue, 09 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/mmbert</guid></item></channel></rss>