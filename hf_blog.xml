<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Blog</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the HuggingFace Blog.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek</title><link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2</link><description></description><pubDate>Tue, 27 Jan 2026 17:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2</guid></item><item><title>Alyah ⭐️: Toward Robust Evaluation of Emirati Dialect Capabilities in Arabic LLMs</title><link>https://huggingface.co/blog/tiiuae/emirati-benchmarks</link><description></description><pubDate>Tue, 27 Jan 2026 17:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/tiiuae/emirati-benchmarks</guid></item><item><title>Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective</title><link>https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl</link><description></description><pubDate>Tue, 27 Jan 2026 17:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl</guid></item><item><title>**NVIDIA Earth-2 Open Models Span the Whole Weather Stack**</title><link>https://huggingface.co/blog/nvidia/earth-2-open-models</link><description></description><pubDate>Tue, 27 Jan 2026 17:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/nvidia/earth-2-open-models</guid></item><item><title>AssetOpsBench: Bridging the Gap Between AI Agent Benchmarks and Industrial Reality</title><link>https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face</link><description></description><pubDate>Tue, 27 Jan 2026 17:32:59 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face</guid></item><item><title>One Year Since the “DeepSeek Moment”</title><link>https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</link><description></description><pubDate>Tue, 27 Jan 2026 17:33:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment</guid></item><item><title>Differential Transformer V2</title><link>https://huggingface.co/blog/microsoft/diff-attn-v2</link><description></description><pubDate>Tue, 27 Jan 2026 17:33:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/microsoft/diff-attn-v2</guid></item><item><title>Introducing Waypoint-1: Real-time interactive video diffusion from Overworld</title><link>https://huggingface.co/blog/waypoint-1</link><description>Back to Articles Waypoint-1: Real-time Interactive Video Diffusion from Overworld Published January 20, 2026 Update on GitHub Upvote 26 +20 Andrew Lapp lapp0 Follow guest Louis Castricato LouisCastricato Follow guest Scott Fox ScottieFox Follow guest Shahbuland Matiana shahbuland Follow guest David Rossi xAesthetics Follow guest Waypoint-1 Weights on the Hub Try Out The Model What is Waypoint-1? How was it trained? The Inference Library: WorldEngine Build with World Engine Stay in Touch Waypoint-1 Weights on the Hub Waypoint-1-Small Waypoint-1-Medium (Coming Soon!) Try Out The Model Overworld Stream: https://overworld.stream What is Waypoint-1? Waypoint-1 is Overworld’s real-time-interactive video diffusion model, controllable and prompted via text, mouse, and keyboard. You can give the model some frames, run the model, and have it create a world you can step into and interact with. The backbone of the model is a frame-causal rectified flow transformer trained on 10,000 hours of...</description><pubDate>Tue, 20 Jan 2026 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/waypoint-1</guid></item><item><title>Open Responses: What you need to know</title><link>https://huggingface.co/blog/open-responses</link><description>Back to Articles Open Responses: What you need to know Published January 15, 2026 Update on GitHub Upvote 95 +89 shaun smith evalstate Follow ben burtenshaw burtenshaw Follow merve merve Follow Pedro Cuenca pcuenq Follow What is Open Responses? What do we need to know to build with Open Responses? Client Requests to Open Responses Changes for Inference Clients and Providers Open Responses for Routing Tools Sub Agent Loops Next Steps Open Responses is a new and open inference standard. Initiated by OpenAI, built by the open source AI community, and backed by the Hugging Face ecosystem, Open Responses is based on the Responses API and is designed for the future of Agents. In this blog post, we’ll look at how Open Responses works and why the open source community should use Open Responses. The era of the chatbot is long gone, and agents dominate inference workloads. Developers are shifting toward autonomous systems that reason, plan, and act over long-time horizons. Despite this shift,...</description><pubDate>Thu, 15 Jan 2026 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/open-responses</guid></item><item><title>NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI</title><link>https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</link><description></description><pubDate>Tue, 27 Jan 2026 17:33:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning</guid></item><item><title>Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture</title><link>https://huggingface.co/blog/tiiuae/falcon-h1-arabic</link><description></description><pubDate>Tue, 27 Jan 2026 17:33:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/tiiuae/falcon-h1-arabic</guid></item><item><title>NVIDIA brings agents to life with DGX Spark and Reachy Mini</title><link>https://huggingface.co/blog/nvidia-reachy-mini</link><description>Back to Articles NVIDIA brings agents to life with DGX Spark and Reachy Mini Published January 5, 2026 Update on GitHub Upvote 58 +52 Jeff Boudier jeffboudier Follow Nader Khalil nader-at-nvidia Follow nvidia Alec Fong alecfong Follow nvidia Ingredients Giving agentic powers to Reachy Building the agent Step 0: Set up and get access to models and services Step 1: Build a chat interface Step 2: Add NeMo Agent Toolkit’s built-in ReAct agent for tool calling Step 3: Add a router to direct queries to different models Step 4: Add a Pipecat bot for real-time voice + vision Step 5: Hook everything up to Reachy (hardware or simulation) Run the full system Try these example prompts Where to go next Today at CES 2026, NVIDIA unveiled a world of new open models to enable the future of agents, online and in the real world. From the recently released NVIDIA Nemotron reasoning LLMs to the new NVIDIA Isaac GR00T N1.6 open reasoning VLA and NVIDIA Cosmos world foundation models , all the building...</description><pubDate>Mon, 05 Jan 2026 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/nvidia-reachy-mini</guid></item><item><title>AprielGuard: A Guardrail for Safety and Adversarial Robustness in Modern LLM Systems</title><link>https://huggingface.co/blog/ServiceNow-AI/aprielguard</link><description></description><pubDate>Tue, 27 Jan 2026 17:33:01 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/ServiceNow-AI/aprielguard</guid></item><item><title>Tokenization in Transformers v5: Simpler, Clearer, and More Modular</title><link>https://huggingface.co/blog/tokenizers</link><description>Back to Articles Tokenization in Transformers v5: Simpler, Clearer, and More Modular Published December 18, 2025 Update on GitHub Upvote 116 +110 Ita Zaporozhets itazap Follow Aritra Roy Gosthipaty ariG23498 Follow Arthur Zucker ArthurZ Follow Sergio Paniego sergiopaniego Follow merve merve Follow Pedro Cuenca pcuenq Follow Table of Contents What is tokenization? The tokenization pipeline Tokenization algorithms Accessing tokenizers through transformers How do you bridge the gap between raw tokenization and model requirements? The tokenizer class hierarchy in transformers PreTrainedTokenizerBase defines the common interface for all tokenizers TokenizersBackend wraps the tokenizers library PythonBackend provides a pure-Python mixin SentencePieceBackend handles SentencePiece models AutoTokenizer automatically selects the correct tokenizer class v5 Separates Tokenizer Architecture from Trained Vocab The problem with v4: tokenizers were opaque and tightly coupled The v5 solution:...</description><pubDate>Thu, 18 Dec 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/tokenizers</guid></item></channel></rss>