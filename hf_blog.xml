<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Blog</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the HuggingFace Blog.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Google Cloud C4 Brings a 70% TCO improvement on GPT OSS with Intel and Hugging Face</title><link>https://huggingface.co/blog/gpt-oss-on-intel-xeon</link><description>Back to Articles Google Cloud C4 Brings a 70% TCO improvement on GPT OSS with Intel and Hugging Face Published October 16, 2025 Update on GitHub Upvote 10 +4 Jiqing.Feng Jiqing Follow Intel Matrix Yao MatrixYao Follow Intel Ke Ding kding1 Follow Intel Ilyas Moutawwakil IlyasMoutawwakil Follow Introduction Benchmark Scope &amp; Hardware Configuration Summary Hardware Under Test Create instance C3 C4 Set up the environment Benchmark Procedure Results Normalized Throughput per vCPU Cost &amp; TCO Conclusion Intel and Hugging Face collaborated to demonstrate the real-world value of upgrading to Google‚Äôs latest C4 Virtual Machine (VM) running on Intel¬Æ Xeon¬Æ 6 processors (codenamed Granite Rapids (GNR)). We specifically wanted to benchmark improvements in the text generation performance of OpenAI GPT OSS Large Language Model(LLM). The results are in, and they are impressive, demonstrating a 1.7x improvement in Total Cost of Ownership(TCO) over the previous-generation Google C3 VM instances. The...</description><pubDate>Thu, 16 Oct 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/gpt-oss-on-intel-xeon</guid></item><item><title>Get your VLM running in 3 simple steps on Intel CPUs</title><link>https://huggingface.co/blog/openvino-vlm</link><description>Back to Articles Get your VLM running in 3 simple steps on Intel CPUs Published October 15, 2025 Update on GitHub Upvote 9 +3 Ezequiel Lanza ezelanza Follow Intel Helena helenai Follow Intel Nikita nikita-savelyev-intel Follow Intel Ella Charlaix echarlaix Follow Ilyas Moutawwakil IlyasMoutawwakil Follow Deploy your model with Optimum Step 1: Convert your model Step 2: Quantization Option 1: Weight Only Quantization Option 2: Static Quantization Step 3: Run inference Evaluation and Conclusion Useful Links &amp; Resources With the growing capability of large language models (LLMs), a new class of models has emerged: Vision Language Models (VLMs) . These models can analyze images and videos to describe scenes, create captions, and answer questions about visual content. While running AI models on your own device can be difficult as these models are often computationally demanding, it also offers significant benefits: including improved privacy since your data stays on your machine, and...</description><pubDate>Wed, 15 Oct 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/openvino-vlm</guid></item><item><title>SOTA OCR on-device with Core ML and dots.ocr</title><link>https://huggingface.co/blog/dots-ocr-ne</link><description>Back to Articles SOTA OCR on-device with Core ML and dots.ocr Published October 2, 2025 Update on GitHub Upvote 43 +37 Christopher Fleetwood FL33TW00D-HF Follow Pedro Cuenca pcuenq Follow Conversion Dots.OCR Step 0: Understand and simplify the model Step 1: A simple harness Step 2: Bug hunting Step 3: Benchmarking Every year our hardware is a little more powerful, our models a little smarter for each parameter. In 2025, it is more feasible than ever to run truly competitive models on-device. dots.ocr , a 3B parameter OCR model from RedNote, surpasses Gemini 2.5 Pro in OmniDocBench , making OCR a truly no compromises on-device use case. Running models on-device is certainly appealing to developers: no smuggling API keys, zero cost, and no network required. However, if we want these models to run on-device, we need to be mindful of the limited compute and power budgets. Enter the Neural Engine, Apple's custom AI accelerator that has shipped with every Apple device since 2017. This...</description><pubDate>Thu, 02 Oct 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/dots-ocr-ne</guid></item><item><title>Introducing RTEB: A New Standard for Retrieval Evaluation</title><link>https://huggingface.co/blog/rteb</link><description>Back to Articles Introducing RTEB: A New Standard for Retrieval Evaluation Published October 1, 2025 Update on GitHub Upvote 114 +108 Frank Liu fzliu Follow guest Kenneth C. Enevoldsen KennethEnevoldsen Follow mteb Solomatin Roman Samoed Follow mteb Isaac Chung isaacchung Follow mteb Tom Aarsen tomaarsen Follow mteb F≈ëdi, Zolt√°n fzoll Follow guest Why Existing Benchmarks Fall Short Introducing RTEB A Hybrid Strategy for True Generalization Built for Real-World Domains Launching RTEB: A Community Effort Limitations and Future Work TL;DR ‚Äì We‚Äôre excited to introduce the beta version of the Retrieval Embedding Benchmark (RTEB) , a new benchmark designed to reliably evaluate the retrieval accuracy of embedding models for real-world applications. Existing benchmarks struggle to measure true generalization, while RTEB addresses this with a hybrid strategy of open and private datasets. Its goal is simple: to create a fair, transparent, and application-focused standard for measuring how...</description><pubDate>Wed, 01 Oct 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/rteb</guid></item><item><title>VibeGame: Exploring Vibe Coding Games</title><link>https://huggingface.co/blog/vibegame</link><description>Back to Articles VibeGame: Exploring Vibe Coding Games Published September 29, 2025 Update on GitHub Upvote 23 +17 Dylan Ebert dylanebert Follow The Problem What Is "Vibe Coding"? Context Management Initial Exploration Attempt 1: Roblox MCP Attempt 2: Unity MCP Attempt 3: Web Stack Comparison Summary The Solution: VibeGame Design Philosophy So Does It Actually Work? Try It Yourself What's Next? The Problem People are trying to vibe code games. And it kind of works, at first. However, as the project grows, things begin to fall apart. Why? And what can we do about it? I'll talk about the problem, how I fixed it, and where to go from here. What Is "Vibe Coding"? First, what is vibe coding? It's originally coined by Andrej Karpathy in a viral tweet where it's defined as where you "fully give in to the vibes, embrace exponentials and forget the code even exists". However, since then, it's used descriptively to mean a lot of different things, anywhere from just "using AI when coding" to...</description><pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/vibegame</guid></item><item><title>Accelerating Qwen3-8B Agent on Intel¬Æ Core‚Ñ¢ Ultra with Depth-Pruned Draft Models</title><link>https://huggingface.co/blog/intel-qwen3-agent</link><description>Back to Articles Accelerating Qwen3-8B Agent on Intel¬Æ Core‚Ñ¢ Ultra with Depth-Pruned Draft Models Published September 29, 2025 Update on GitHub Upvote 17 +11 Igor Margulis imargulis Follow Intel Ofir Zafrir ofirzaf Follow Intel Shira Guskin sguskin Follow Intel Guy Boudoukh guybd Follow Intel Pedro Cuenca pcuenq Follow Qwen3 Accelerating Qwen3-8B on Intel¬Æ Core‚Ñ¢ Ultra with Speculative Decoding Pushing Performance Further Integration with ü§ósmolagents References TL;DR: Qwen3-8B is one of the most exciting recent releases‚Äîa model with native agentic capabilities, making it a natural fit for the AIPC. With OpenVINO.GenAI , we‚Äôve been able to accelerate generation by ~1.3√ó using speculative decoding with a lightweight Qwen3-0.6B draft. By using speculative decoding and applying a simple pruning process to the draft, we pushed the speedup even further to ~1.4√ó We wrapped this up by showing how these improvements can be used to run a fast, local AI Agent with ü§ó smolagents Qwen3 Qwen3-8B is...</description><pubDate>Mon, 29 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/intel-qwen3-agent</guid></item><item><title>Swift Transformers Reaches 1.0 ‚Äî and Looks to the Future</title><link>https://huggingface.co/blog/swift-transformers</link><description>Back to Articles Swift Transformers Reaches 1.0 ‚Äì and Looks to the Future Published September 26, 2025 Update on GitHub Upvote 32 +26 Pedro Cuenca pcuenq Follow Christopher Fleetwood FL33TW00D-HF Follow Mattt mattt Follow Vaibhav Srivastav reach-vb Follow What is swift-transformers How is the community using it What changes with v1.0 Usage Examples What comes next We couldn‚Äôt have done this without you ü´µ We released swift-transformers two years ago (!) with the goal to support Apple developers and help them integrate local LLMs in their apps. A lot has changed since then (MLX and chat templates did not exist!), and we‚Äôve learned how the community is actually using the library. We want to double down on the use cases that provide most benefits to the community, and lay out the foundations for the future. Spoiler alert: after this release, we‚Äôll focus a lot on MLX and agentic use cases üöÄ What is swift-transformers swift-transformers is a Swift library that aims to reduce the friction...</description><pubDate>Fri, 26 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/swift-transformers</guid></item><item><title>Smol2Operator: Post-Training GUI Agents for Computer Use</title><link>https://huggingface.co/blog/smol2operator</link><description>Back to Articles Smol2Operator: Post-Training GUI Agents for Computer Use Published September 23, 2025 Update on GitHub Upvote 118 +112 Amir Mahla A-Mahla Follow merve merve Follow Sergio Paniego sergiopaniego Follow Vaibhav Srivastav reach-vb Follow Lewis Tunstall lewtun Follow Table of Contents Introduction 1. Data Transformation and Unified Action Space The Challenge of Inconsistent Action Spaces Our Unified Approach Example Data Transformation (Bonus) Custom Action Space Adaptation with Action Space Converter Key Features Usage Example Transformed and Released Datasets 2. Phase 1: From Zero to Perception Training Data Optimization Experiments Image Resolution and Coordinate System Analysis Key Findings Phase 1 Results 3. Phase 2: From Perception to Cognition Training Data Phase 2 Results 4. All you need is Open Source 5. Conclusion What's Next? TL;DR: This work shows how a lightweight vision‚Äìlanguage model can acquire GUI-grounded skills and evolve into an agentic GUI coder. We...</description><pubDate>Tue, 23 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/smol2operator</guid></item><item><title>Gaia2 and ARE: Empowering the community to study agents</title><link>https://huggingface.co/blog/gaia2</link><description>Back to Articles Gaia2 and ARE: Empowering the Community to Evaluate Agents Published September 22, 2025 Update on GitHub Upvote 113 +107 Cl√©mentine Fourrier clefourrier Follow OpenEvals Maxime Lecanu mlcu Follow meta-agents-research-environments Pierre Andrews mortimerp9 Follow meta-agents-research-environments Adrien Carreira XciD Follow frere thibaud tfrere Follow Avijit Ghosh evijit Follow hfpolicy Romain Froger RomainFroger Follow meta-agents-research-environments Dheeraj Mekala dheeraj7596 Follow meta-agents-research-environments Caroline Pascal CarolinePascal Follow lerobot Ulyana Piterbarg upiter Follow meta-agents-research-environments Gaia2: Agentic Evaluation on Real Life Assistant Tasks How does Gaia2 run? Results Compare with your favorite models! Evaluating on Gaia2 Beyond Gaia2: study your agents with ARE 1) Testing an agent on a simple task: event organisation 2) Understanding agents: deep diving the traces 3) Playing around and extending the demo: Connecting the...</description><pubDate>Mon, 22 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/gaia2</guid></item><item><title>Scaleway on Hugging Face Inference Providers üî•</title><link>https://huggingface.co/blog/inference-providers-scaleway</link><description>Back to Articles Scaleway on Hugging Face Inference Providers üî• Published September 19, 2025 Update on GitHub Upvote 21 +15 Guillaume Noale gnoale Follow guest Franck Pagny fpagny Follow guest Fred Bardolle f14e Follow guest Guillaume Calmettes gcalmettes Follow guest Constance Morales C-morales Follow guest C√©lina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Scaleway is now a supported Inference Provider on the Hugging Face Hub! Scaleway joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub‚Äôs model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access popular open-...</description><pubDate>Fri, 19 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers-scaleway</guid></item><item><title>Democratizing AI Safety with RiskRubric.ai</title><link>https://huggingface.co/blog/riskrubric</link><description>Back to Articles Democratizing AI Safety with RiskRubric.ai Published September 18, 2025 Update on GitHub Upvote 17 +11 Gal Moyal galmo-noma Follow guest Risk Rubric, a new Standardized Assessment of Risk for models What we found (as of September 2025) Conclusion Building trust in the open model ecosystem through standardized risk assessment More than 500,000 models can be found on the Hugging Face hub, but it‚Äôs not always clear to users how to choose the best model for them, notably on the security aspects. Developers might find a model that perfectly fits their use case, but have no systematic way to evaluate its security posture, privacy implications, or potential failure modes. As models become more powerful and adoption accelerates, we need equally rapid progress in AI safety and security reporting. We're therefore excited to announce RiskRubric.ai , a novel initiative led by Cloud Security Alliance and Noma Security , with contributions by Haize Labs and Harmonic Security, for...</description><pubDate>Thu, 18 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/riskrubric</guid></item><item><title>Public AI on Hugging Face Inference Providers üî•</title><link>https://huggingface.co/blog/inference-providers-publicai</link><description>Back to Articles Public AI on Hugging Face Inference Providers üî• Published September 17, 2025 Update on GitHub Upvote 22 +16 Joseph Low Jolow Follow publicai Joshua Tan thelastjosh Follow publicai C√©lina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Public AI is now a supported Inference Provider on the Hugging Face Hub! Public AI joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub‚Äôs model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access public and sovereign models from institutions like the Swiss AI Initiative and AI Singapore ‚Äî right from Hugging Face. You...</description><pubDate>Wed, 17 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers-publicai</guid></item><item><title>`LeRobotDataset`: Bringing large-scale datasets to lerobot</title><link>https://huggingface.co/blog/lerobot-datasets-v3</link><description>Back to Articles LeRobotDataset:v3.0: Bringing large-scale datasets to lerobot Published September 16, 2025 Update on GitHub Upvote 38 +32 Francesco Capuano fracapuano Follow Michel Aractingi aractingi Follow Quentin Lhoest lhoestq Follow Caroline Pascal CarolinePascal Follow Pepijn Kooijmans pepijn223 Follow Jade Choghari jadechoghari Follow Remi Cadene cadene Follow Simon Alibert aliberts Follow Adil Zouitine AdilZtn Follow Martino Russi nepyope Follow Steven Palma imstevenpmwork Follow Table of Contents LeRobotDataset, v3.0 Install lerobot , and record a dataset Migrate your v2.1 dataset to v3.0 Code Example: Using LeRobotDataset with torch.utils.data.DataLoader Streaming Conclusion Acknowledgements TL;DR Today we release LeRobotDataset:v3 ! In our previous LeRobotDataset:v2 release, we stored one episode per file, hitting file-system limitations when scaling datasets to millions of episodes. LeRobotDataset:v3 packs multiple episodes in a single file, using relational metadata to...</description><pubDate>Tue, 16 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/lerobot-datasets-v3</guid></item><item><title>Visible Watermarking with Gradio</title><link>https://huggingface.co/blog/watermarking-with-gradio</link><description>Back to Articles Visible Watermarking with Gradio Published September 15, 2025 Update on GitHub Upvote 17 +11 Margaret Mitchell meg Follow Last year, we shared a blogpost on watermarking , explaining what it means to watermark generative AI content, and why it's important. The need for watermarking has become even more critical as people all over the world have begun to generate and share AI-generated images, video, audio, and text. Images and video have become so realistic that they‚Äôre nearly impossible to distinguish from what you‚Äôd see captured by a real camera. Addressing this issue is multi-faceted, but there is one, clear, low-hanging fruit üçá: In order for people to know what's real and what's synthetic, use visible watermarks. To help out, we at Hugging Face have made visible watermarking trivially easy: Whenever you create a Space like an app or a demo , you can use our in-house app-building library Gradio to display watermarks with a single command. For images and video,...</description><pubDate>Mon, 15 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/watermarking-with-gradio</guid></item></channel></rss>