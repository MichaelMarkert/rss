<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Blog</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the HuggingFace Blog.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Welcome Fireworks.ai on the Hub üéÜ</title><link>https://huggingface.co/blog/fireworks-ai</link><description>Back to Articles Welcome Fireworks.ai on the Hub üéÜ Published February 14, 2025 Update on GitHub Upvote 37 +31 teofeliu Teo Feliu fireworks-ai shaunak-fireworks Shaunak Godbole fireworks-ai julien-c Julien Chaumond How it works In the website UI From the client SDKs From HTTP calls Billing Following our recent announcement on Inference Providers on the Hub , we're thrilled to share that Fireworks.ai is now a supported Inference Provider on HF Hub! Fireworks.ai delivers blazing-fast serverless inference directly on model pages, as well as throughout the whole HF ecosystem of libraries and tools, making it easier than ever to run inference on your favorite models. Among others, starting now, you can run serverless inference to the following models via Fireworks.ai: deepseek-ai/DeepSeek-R1 deepseek-ai/DeepSeek-V3 mistralai/Mistral-Small-24B-Instruct-2501 Qwen/Qwen2.5-Coder-32B-Instruct meta-llama/Llama-3.2-90B-Vision-Instruct and many more, you can find the full list here . Light up...</description><pubDate>Fri, 14 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/fireworks-ai</guid></item><item><title>Fixing Open LLM Leaderboard with Math-Verify</title><link>https://huggingface.co/blog/math_verify_leaderboard</link><description>Back to Articles Fixing Open LLM Leaderboard with Math-Verify Published February 14, 2025 Update on GitHub Upvote 19 +13 hynky Hynek Kydlicek alozowski Alina Lozovskaya SaylorTwift Nathan Habib clefourrier Cl√©mentine Fourrier Why math evaluation on the Open LLM Leaderboard was broken Which model is the best at math? A complete reshuffling of cards thanks to fairer evaluations Impact of the change Model Family Changes Changes in the MATH-Hard Leaderboard Changes in the Leaderboard Wrapping Up 3 weeks ago, we showed how hard it is to correctly evaluate LLM performance on math problems, and introduced Math-Verify , a better solution to validate models on math (read more in the announcement )! Today, we‚Äôre thrilled to share that we‚Äôve used Math-Verify to thoroughly re-evaluate all 3,751 models ever submitted to the Open LLM Leaderboard, for even fairer and more robust model comparisons! Why math evaluation on the Open LLM Leaderboard was broken The Open LLM Leaderboard is the most used...</description><pubDate>Fri, 14 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/math_verify_leaderboard</guid></item><item><title>1 Billion Classifications</title><link>https://huggingface.co/blog/billion-classifications</link><description>Back to Articles 1 Billion Classifications Published February 13, 2025 Update on GitHub Upvote 37 +31 derek-thomas Derek Thomas guest Approach Optimization Setup Load Testing Parameters K6 Orchestration Classification Introduction Experiment Results Embedding Introduction Experiment Results Vision Embedding Introduction Experiment Results Analysis Conclusion References Appendix Sanity Checks Cost Analysis Infinity Client Other Lessons Learned Future Improvements You‚Äôve optimized your model. Your pipeline is running smoothly. But now, your cloud bill has skyrocketed. Running 1B+ classifications or embeddings per day isn‚Äôt just a technical challenge‚Äîit‚Äôs a financial one. How do you process at this scale without blowing your budget? Whether you're running large-scale document classification or bulk embedding pipelines for Retrieval-Augmented Generation (RAG), you need cost-efficient, high-throughput inference to make it feasible, and you get that from having a well optimized...</description><pubDate>Thu, 13 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/billion-classifications</guid></item><item><title>From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub</title><link>https://huggingface.co/blog/from-chunks-to-blocks</link><description>Back to Articles From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub Published February 12, 2025 Update on GitHub Upvote 44 +38 jsulz Jared Sulzdorf xet-team yuchenglow yuchenglow xet-team znation Zach Nation xet-team saba9 saba noorassa xet-team The Realities of Scaling Deduplication Design Principles for Deduplication at Scale Scaling Deduplication with Aggregation Aggregated Deduplication in Practice Content-defined chunking (CDC) plays a central role in enabling deduplication within a Xet-backed repository . The idea is straightforward: break each file‚Äôs data into chunks, store only unique ones, reap the benefits. In practice, it's more complex. If we focused solely on maximizing deduplication, the design would call for the smallest possible chunk size. By doing that, we‚Äôd create significant overheads for the infrastructure and the builders on the Hub. On Hugging Face's Xet team , we're bringing CDC from theory to production to deliver faster uploads and...</description><pubDate>Wed, 12 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/from-chunks-to-blocks</guid></item><item><title>Build awesome datasets for video generation</title><link>https://huggingface.co/blog/vid_ds_scripts</link><description>Back to Articles Build awesome datasets for video generation Published February 12, 2025 Update on GitHub Upvote 24 +18 hlky hlky sayakpaul Sayak Paul Tooling Stage 1 (Acquisition) Stage 2 (Pre-processing/filtering) Stage 3 (Processing) Filtering examples OCR/Caption Putting this tooling to use üë®‚Äçüç≥ Your Turn Tooling for image generation datasets is well established, with img2dataset being a fundamental tool used for large scale dataset preparation, and complemented with various community guides, scripts and UIs that cover smaller scale initiatives. Our ambition is to make tooling for video generation datasets equally established, by creating open video dataset scripts suited for small scale, and leveraging video2dataset for large scale use cases. ‚ÄúIf I have seen further it is by standing on the shoulders of giants‚Äù In this post, we provide an overview of the tooling we are developing to make it easy for the community to build their own datasets for fine-tuning video generation...</description><pubDate>Wed, 12 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/vid_ds_scripts</guid></item><item><title>The Open Arabic LLM Leaderboard 2</title><link>https://huggingface.co/blog/leaderboard-arabic-v2</link><description>Back to Articles The Open Arabic LLM Leaderboard 2 Published February 10, 2025 Update on GitHub Upvote 25 +19 alielfilali01 Ali El Filali 2A2I Manel-Hik Manel ALOUI OALL tarickMorty Tarique Husaain AI71ai amztheory Ahmed Alzubaidi tiiuae Basma-b Basma Boussaha tiiuae rcojocaru Ruxandra Cojocaru tiiuae HakimHacid Hakim Hacid tiiuae clefourrier Cl√©mentine Fourrier Current status of Arabic LLMs leaderboards Impact of the previous leaderboard Why do we need a new leaderboard? What's new in this version? Results from v1 and v2 Conclusion and future work Acknowledgments Citations References Current status of Arabic LLMs leaderboards The growing availability of LLMs supporting Arabic, both as monolingual and multilingual models, prompted the community to create dedicated Arabic language leaderboards. Previously, Arabic-focused leaderboards were typically confined to narrow benchmarks introduced by specific authors, often as demos for their work. In these cases, the authors would set up...</description><pubDate>Mon, 10 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/leaderboard-arabic-v2</guid></item><item><title>Open-source DeepResearch ‚Äì Freeing our search agents</title><link>https://huggingface.co/blog/open-deep-research</link><description>Back to Articles Open-source DeepResearch ‚Äì Freeing our search agents Published February 4, 2025 Update on GitHub Upvote 1013 +1007 m-ric Aymeric Roucher albertvillanova Albert Villanova del Moral merve Merve Noyan thomwolf Thomas Wolf clefourrier Cl√©mentine Fourrier TLDR Table of Contents What are Agent frameworks and why they matter? The GAIA benchmark Building an open Deep Research Using a CodeAgent Making the right tools üõ†Ô∏è Results üèÖ Community Reproductions Most important next steps TLDR Yesterday, OpenAI released Deep Research , a system that browses the web to summarize content and answer questions based on the summary. The system is impressive and blew our minds when we tried it for the first time. One of the main results in the blog post is a strong improvement of performances on the General AI Assistants benchmark (GAIA) , a benchmark we‚Äôve been playing with recently as well, where they successfully reached near 67% correct answers on 1-shot on average, and 47.6% on...</description><pubDate>Tue, 04 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/open-deep-research</guid></item><item><title>œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control</title><link>https://huggingface.co/blog/pi0</link><description>Back to Articles œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control Published February 4, 2025 Update on GitHub Upvote 100 +94 danaaubakirova Dana Aubakirova Molbap Pablo Montalvo mshukor Mustafa Shukor cadene Remi Cadene Introduction üîç What is œÄ0? How to Use œÄ0 in LeRobot? Inference on œÄ0 pretrained model Fine-tuning the œÄ0 Pretrained Model What is the difference between VLMs and VLAs? Attention Mechanisms in Robotics Policies Key Idea ‚ö° Towards the Faster Attention in œÄ0 Handling 2D Attention Masks Can we use FlashAttention2? Using FlexAttention in PyTorch How to effectively represent Actions? üöÄ What is œÄ0-FAST? Key Advantages of œÄ0-FAST: How does FAST work? How to use FAST tokenizer? What‚Äôs Next for Generalist Robot Intelligence? Additional Resources References We have ported the first robotics foundation models to Hugging Face LeRobot ! Both œÄ0 and œÄ0-FAST , developed by Physical Intelligence, are now available in the LeRobot repository , bringing generalist...</description><pubDate>Tue, 04 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/pi0</guid></item><item><title>DABStep: Data Agent Benchmark for Multi-step Reasoning</title><link>https://huggingface.co/blog/dabstep</link><description>Back to Articles DABStep: Data Agent Benchmark for Multi-step Reasoning Published February 4, 2025 Update on GitHub Upvote 47 +41 eggie5 Alex Egg guest martinigoyanes Martin Iglesias Goyanes guest frisokingma Friso Kingma guest andreumora Andreu Mora guest lvwerra Leandro von Werra thomwolf Thomas Wolf Motivation Introducing DABstep What's inside the DABstep? Data Tasks Evaluations Real-time leaderboard Baselines Getting Started and Infra Future direction Related Works Language models are becoming increasingly capable and can solve tasks autonomously as agents. There are many exciting use cases, especially at the intersection of reasoning, code, and data. However, proper evaluation benchmarks on real-world problems are lacking and hinder progress in the field. To tackle this challenge, Adyen and Hugging Face built the Data Agent Benchmark for Multi-step Reasoning (DABstep) together. DABstep consists of over 450 data analysis tasks designed to evaluate the capabilities of state-of-...</description><pubDate>Tue, 04 Feb 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/dabstep</guid></item><item><title>The AI tools for Art Newsletter - Issue 1</title><link>https://huggingface.co/blog/ai-art-newsletter-jan-25</link><description>Back to Articles The AI tools for Art Newsletter Published January 31, 2025 Update on GitHub Upvote 53 +47 linoyts Linoy Tsaban multimodalart Apolin√°rio from multimodal AI art First issue üéâ Table of Contents Major Releases of 2024 Image Generation Text-to-image generation Personalization &amp; stylization Video Generation Audio Generation Creative Tools that Shined in 2024 What should we expect for AI &amp; Art in 2025? Starting off strong - Open source releases of January 25 Announcing Our Newsletter üóûÔ∏è The AI space is moving so fast it‚Äôs hard to believe that a year ago we still struggled to generate people with the correct amount of fingers üòÇ. The last couple of years have been pivotal for open source models and tools for artistic usage. AI tools for creative expression have never been more accessible, and we‚Äôre only scratching the surface. Join us as we look back at the key milestones, tools, and breakthroughs in AI &amp; Arts from 2024, and forward for what‚Äôs to come in 2025 (spoiler üëÄ:...</description><pubDate>Fri, 31 Jan 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/ai-art-newsletter-jan-25</guid></item><item><title>How to deploy and fine-tune DeepSeek models on AWS</title><link>https://huggingface.co/blog/deepseek-r1-aws</link><description>Back to Articles How to deploy and fine-tune DeepSeek models on AWS Published January 30, 2025 Update on GitHub Upvote 45 +39 pagezyhf Simon Pagezy jeffboudier Jeff Boudier dacorvo David Corvoysier What is DeepSeek-R1? Deploy DeepSeek R1 models Deploy on AWS with Hugging Face Inference Endpoints Deploy on Amazon Bedrock Marketplace Deploy on Amazon Sagemaker AI with Hugging Face LLM DLCs Deploy on EC2 Neuron with the Hugging Face Neuron Deep Learning AMI Fine-tune DeepSeek R1 models Fine tune on Amazon SageMaker AI with Hugging Face Training DLCs Fine tune on EC2 Neuron with the Hugging Face Neuron Deep Learning AMI A running document to showcase how to deploy and fine-tune DeepSeek R1 models with Hugging Face on AWS. What is DeepSeek-R1? If you‚Äôve ever struggled with a tough math problem, you know how useful it is to think a little longer and work through it carefully. OpenAI‚Äôs o1 model showed that when LLMs are trained to do the same‚Äîby using more compute during inference‚Äîthey get...</description><pubDate>Thu, 30 Jan 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/deepseek-r1-aws</guid></item><item><title>Welcome to Inference Providers on the Hub üî•</title><link>https://huggingface.co/blog/inference-providers</link><description>Back to Articles Welcome to Inference Providers on the Hub üî• Published January 28, 2025 Update on GitHub Upvote 376 +370 burkaygur Burkay Gur fal zeke Zeke Sikelianos replicate aton2006 Anton McGonnell sambanovasystems hassanelmghari Hassan El Mghari togethercomputer sbrandeis Simon Brandeis kramp Bertrand Chevrier julien-c Julien Chaumond How it works In the website UI From the client SDKs From HTTP calls Billing Feedback and next steps Today, we are launching the integration of four awesome serverless Inference Providers ‚Äì fal, Replicate, Sambanova, Together AI ‚Äì directly on the Hub‚Äôs model pages. They are also seamlessly integrated into our client SDKs (for JS and Python), making it easier than ever to explore serverless inference of a wide variety of models that run on your favorite providers. We‚Äôve been hosting a serverless Inference API on the Hub for a long time (we launched the v1 in summer 2020 ‚Äì wow, time flies ü§Ø). While this has enabled easy exploration and prototyping,...</description><pubDate>Tue, 28 Jan 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers</guid></item><item><title>Open-R1: a fully open reproduction of DeepSeek-R1</title><link>https://huggingface.co/blog/open-r1</link><description>Back to Articles Open-R1: a fully open reproduction of DeepSeek-R1 Published January 28, 2025 Update on GitHub Upvote 752 +746 eliebak Elie Bakouch lvwerra Leandro von Werra lewtun Lewis Tunstall What is DeepSeek-R1? How did they do it? Open-R1: the missing pieces What is DeepSeek-R1? If you‚Äôve ever struggled with a tough math problem, you know how useful it is to think a little longer and work through it carefully. OpenAI‚Äôs o1 model showed that when LLMs are trained to do the same‚Äîby using more compute during inference‚Äîthey get significantly better at solving reasoning tasks like mathematics, coding, and logic. However, the recipe behind OpenAI‚Äôs reasoning models has been a well kept secret. That is, until last week, when DeepSeek released their DeepSeek-R1 model and promptly broke the internet (and the stock market! ). Besides performing as well or better than o1, the DeepSeek-R1 release was accompanied by a detailed tech report that outlined the key steps of their training...</description><pubDate>Tue, 28 Jan 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/open-r1</guid></item><item><title>State of open video generation models in Diffusers</title><link>https://huggingface.co/blog/video_gen</link><description>Back to Articles State of open video generation models in Diffusers Published January 27, 2025 Update on GitHub Upvote 39 +33 sayakpaul Sayak Paul a-r-r-o-w Aryan V S dn6 Dhruv Nair Today‚Äôs Video Generation Models and their Limitations Why is Video Generation Hard? Open Video Generation Models Video Generation with Diffusers Memory requirements Suite of optimizations Fine-tuning Looking ahead Resources OpenAI‚Äôs Sora demo marked a striking advance in AI-generated video last year and gave us a glimpse of the potential capabilities of video generation models. The impact was immediate and since that demo, the video generation space has become increasingly competitive with major players and startups producing their own highly capable models such as Google‚Äôs Veo2, Haliluo‚Äôs Minimax, Runway‚Äôs Gen3 Alpha, Kling, Pika, and Luma Lab‚Äôs Dream Machine. Open-source has also had its own surge of video generation models with CogVideoX, Mochi-1, Hunyuan, Allegro, and LTX Video. Is the video...</description><pubDate>Mon, 27 Jan 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/video_gen</guid></item><item><title>We now support VLMs in smolagents!</title><link>https://huggingface.co/blog/smolagents-can-see</link><description>Back to Articles We just gave sight to smolagents Published January 24, 2025 Update on GitHub Upvote 82 +76 m-ric Aymeric Roucher merve Merve Noyan albertvillanova Albert Villanova del Moral TL;DR Table of Contents Overview How we gave sight to smolagents How to create a Web browsing agent with vision Running the agent Next Steps You hypocrite, first take the log out of your own eye, and then you will see clearly to take the speck out of your brother's eye. Matthew 7, 3-5 TL;DR We have added vision support to smolagents, which unlocks the use of vision language models in agentic pipelines natively. Table of Contents Overview How we gave sight to smolagents How to create a Web browsing agent with vision Next Steps Overview In the agentic world, many capabilities are hidden behind a vision wall. A common example is web browsing: web pages feature rich visual content that you never fully recover by simply extracting their text, be it the relative position of objects, messages...</description><pubDate>Fri, 24 Jan 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/smolagents-can-see</guid></item></channel></rss>