<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Blog</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the HuggingFace Blog.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Swift Transformers Reaches 1.0 ‚Äî and Looks to the Future</title><link>https://huggingface.co/blog/swift-transformers</link><description>Back to Articles Swift Transformers Reaches 1.0 ‚Äì and Looks to the Future Published September 26, 2025 Update on GitHub Upvote 23 +17 Pedro Cuenca pcuenq Follow Christopher Fleetwood FL33TW00D-HF Follow Mattt mattt Follow Vaibhav Srivastav reach-vb Follow What is swift-transformers How is the community using it What changes with v1.0 Usage Examples What comes next We couldn‚Äôt have done this without you ü´µ We released swift-transformers two years ago (!) with the goal to support Apple developers and help them integrate local LLMs in their apps. A lot has changed since then (MLX and chat templates did not exist!), and we‚Äôve learned how the community is actually using the library. We want to double down on the use cases that provide most benefits to the community, and lay out the foundations for the future. Spoiler alert: after this release, we‚Äôll focus a lot on MLX and agentic use cases üöÄ What is swift-transformers swift-transformers is a Swift library that aims to reduce the friction...</description><pubDate>Fri, 26 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/swift-transformers</guid></item><item><title>Smol2Operator: Post-Training GUI Agents for Computer Use</title><link>https://huggingface.co/blog/smol2operator</link><description>Back to Articles Smol2Operator: Post-Training GUI Agents for Computer Use Published September 23, 2025 Update on GitHub Upvote 96 +90 Amir Mahla A-Mahla Follow merve merve Follow Sergio Paniego sergiopaniego Follow Vaibhav Srivastav reach-vb Follow Lewis Tunstall lewtun Follow Table of Contents Introduction 1. Data Transformation and Unified Action Space The Challenge of Inconsistent Action Spaces Our Unified Approach Example Data Transformation (Bonus) Custom Action Space Adaptation with Action Space Converter Key Features Usage Example Transformed and Released Datasets 2. Phase 1: From Zero to Perception Training Data Optimization Experiments Image Resolution and Coordinate System Analysis Key Findings Phase 1 Results 3. Phase 2: From Perception to Cognition Training Data Phase 2 Results 4. All you need is Open Source 5. Conclusion What's Next? TL;DR: This work shows how a lightweight vision‚Äìlanguage model can acquire GUI-grounded skills and evolve into an agentic GUI coder. We...</description><pubDate>Tue, 23 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/smol2operator</guid></item><item><title>Gaia2 and ARE: Empowering the community to study agents</title><link>https://huggingface.co/blog/gaia2</link><description>Back to Articles Gaia2 and ARE: Empowering the Community to Evaluate Agents Published September 22, 2025 Update on GitHub Upvote 95 +89 Cl√©mentine Fourrier clefourrier Follow OpenEvals Maxime Lecanu mlcu Follow meta-agents-research-environments Pierre Andrews mortimerp9 Follow meta-agents-research-environments Adrien Carreira XciD Follow frere thibaud tfrere Follow Avijit Ghosh evijit Follow hfpolicy Romain Froger RomainFroger Follow meta-agents-research-environments Dheeraj Mekala dheeraj7596 Follow meta-agents-research-environments Caroline Pascal CarolinePascal Follow lerobot Ulyana Piterbarg upiter Follow meta-agents-research-environments Gaia2: Agentic Evaluation on Real Life Assistant Tasks How does Gaia2 run? Results Compare with your favorite models! Evaluating on Gaia2 Beyond Gaia2: study your agents with ARE 1) Testing an agent on a simple task: event organisation 2) Understanding agents: deep diving the traces 3) Playing around and extending the demo: Connecting the agent...</description><pubDate>Mon, 22 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/gaia2</guid></item><item><title>Scaleway on Hugging Face Inference Providers üî•</title><link>https://huggingface.co/blog/inference-providers-scaleway</link><description>Back to Articles Scaleway on Hugging Face Inference Providers üî• Published September 19, 2025 Update on GitHub Upvote 18 +12 Guillaume Noale gnoale Follow guest Franck P. fpagny Follow guest Fred Bardolle f14e Follow scaleway Guillaume Calmettes gcalmettes Follow guest Constance Morales C-morales Follow guest C√©lina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Scaleway is now a supported Inference Provider on the Hugging Face Hub! Scaleway joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub‚Äôs model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access popular open-...</description><pubDate>Fri, 19 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers-scaleway</guid></item><item><title>Democratizing AI Safety with RiskRubric.ai</title><link>https://huggingface.co/blog/riskrubric</link><description>Back to Articles Democratizing AI Safety with RiskRubric.ai Published September 18, 2025 Update on GitHub Upvote 15 +9 Gal Moyal galmo-noma Follow guest Risk Rubric, a new Standardized Assessment of Risk for models What we found (as of September 2025) Conclusion Building trust in the open model ecosystem through standardized risk assessment More than 500,000 models can be found on the Hugging Face hub, but it‚Äôs not always clear to users how to choose the best model for them, notably on the security aspects. Developers might find a model that perfectly fits their use case, but have no systematic way to evaluate its security posture, privacy implications, or potential failure modes. As models become more powerful and adoption accelerates, we need equally rapid progress in AI safety and security reporting. We're therefore excited to announce RiskRubric.ai , a novel initiative led by Cloud Security Alliance and Noma Security , with contributions by Haize Labs and Harmonic Security, for...</description><pubDate>Thu, 18 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/riskrubric</guid></item><item><title>Public AI on Hugging Face Inference Providers üî•</title><link>https://huggingface.co/blog/inference-providers-publicai</link><description>Back to Articles Public AI on Hugging Face Inference Providers üî• Published September 17, 2025 Update on GitHub Upvote 19 +13 Joseph Low Jolow Follow publicai Joshua Tan thelastjosh Follow publicai C√©lina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Public AI is now a supported Inference Provider on the Hugging Face Hub! Public AI joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub‚Äôs model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access public and sovereign models from institutions like the Swiss AI Initiative and AI Singapore ‚Äî right from Hugging Face. You...</description><pubDate>Wed, 17 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers-publicai</guid></item><item><title>`LeRobotDataset`: Bringing large-scale datasets to lerobot</title><link>https://huggingface.co/blog/lerobot-datasets-v3</link><description>Back to Articles LeRobotDataset:v3.0: Bringing large-scale datasets to lerobot Published September 16, 2025 Update on GitHub Upvote 29 +23 Francesco Capuano fracapuano Follow Michel Aractingi aractingi Follow Quentin Lhoest lhoestq Follow Caroline Pascal CarolinePascal Follow Pepijn Kooijmans pepijn223 Follow Jade Choghari jadechoghari Follow Remi Cadene cadene Follow Simon Alibert aliberts Follow Adil Zouitine AdilZtn Follow Martino Russi nepyope Follow Steven Palma imstevenpmwork Follow Table of Contents LeRobotDataset, v3.0 Install lerobot , and record a dataset Migrate your v2.1 dataset to v3.0 Code Example: Using LeRobotDataset with torch.utils.data.DataLoader Streaming Conclusion Acknowledgements TL;DR Today we release LeRobotDataset:v3 ! In our previous LeRobotDataset:v2 release, we stored one episode per file, hitting file-system limitations when scaling datasets to millions of episodes. LeRobotDataset:v3 packs multiple episodes in a single file, using relational metadata to...</description><pubDate>Tue, 16 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/lerobot-datasets-v3</guid></item><item><title>Visible Watermarking with Gradio</title><link>https://huggingface.co/blog/watermarking-with-gradio</link><description>Back to Articles Visible Watermarking with Gradio Published September 15, 2025 Update on GitHub Upvote 15 +9 Margaret Mitchell meg Follow Last year, we shared a blogpost on watermarking , explaining what it means to watermark generative AI content, and why it's important. The need for watermarking has become even more critical as people all over the world have begun to generate and share AI-generated images, video, audio, and text. Images and video have become so realistic that they‚Äôre nearly impossible to distinguish from what you‚Äôd see captured by a real camera. Addressing this issue is multi-faceted, but there is one, clear, low-hanging fruit üçá: In order for people to know what's real and what's synthetic, use visible watermarks. To help out, we at Hugging Face have made visible watermarking trivially easy: Whenever you create a Space like an app or a demo , you can use our in-house app-building library Gradio to display watermarks with a single command. For images and video,...</description><pubDate>Mon, 15 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/watermarking-with-gradio</guid></item><item><title>Tricks from OpenAI gpt-oss YOU ü´µ can use with transformers</title><link>https://huggingface.co/blog/faster-transformers</link><description>Back to Articles Tricks from OpenAI gpt-oss YOU ü´µ can use with transformers Published September 11, 2025 Update on GitHub Upvote 149 +143 Aritra Roy Gosthipaty ariG23498 Follow Sergio Paniego sergiopaniego Follow Vaibhav Srivastav reach-vb Follow Pedro Cuenca pcuenq Follow Arthur Zucker ArthurZ Follow Nathan Habib SaylorTwift Follow Cyril Vallez cyrilvallez Follow Zero-build Kernels, downloadable from the Hub Custom Kernels for GPT-OSS Flash Attention 3 MXFP4 Quantization What is MXFP4 MXFP4 in transformers Requirements and fallbacks Kernels for MXFP4 Tensor Parallelism What this enables in transformers When to reach for TP Expert Parallelism Dynamic Sliding Window Layer &amp; Cache How to use it Continuous Batching &amp; Paged Attention Load larger models faster Conclusion Read More OpenAI recently released their GPT-OSS series of models . The models feature some novel techniques like MXFP4 quantization, efficient kernels, a brand new chat format, and more. To enable the release of gpt-oss...</description><pubDate>Thu, 11 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/faster-transformers</guid></item><item><title>Jupyter Agents: training LLMs to reason with notebooks</title><link>https://huggingface.co/blog/jupyter-agent-2</link><description>Back to Articles Jupyter Agents: training LLMs to reason with notebooks Published September 10, 2025 Update on GitHub Upvote 45 +39 Baptiste Colle baptistecolle Follow Hanna Yukhymenko hannayukhymenko Follow Leandro von Werra lvwerra Follow üèÅ Primer: the DABStep Benchmark üéØ First Baseline üîß Primer on Scaffolding üèÉ‚Äç‚ôÇÔ∏è Training Pipeline ‚öôÔ∏è Dataset Pipeline 1. Large-scale deduplication 2. Downloading linked datasets 3. Edu scoring 4. Filtering irrelevant notebooks 5. QA generation 6. Trace generation 7. Final curation üèÉ‚Äç‚ôÇÔ∏è Training Pipeline üìä Results Try Jupyter Agent Yourself üîÆ Next Steps The past year has been all about giving LLMs more tools and autonomy to solve more complex and open ended tasks. The goal of the Jupyter Agent is to give the model the ultimate tool: code execution. A natural way to display multi-step code execution together with reasoning is within a Jupyter Notebook, which consists of code and markdown cells. So we built Jupyter Agent to act as an agent that can...</description><pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/jupyter-agent-2</guid></item><item><title>mmBERT: ModernBERT goes Multilingual</title><link>https://huggingface.co/blog/mmbert</link><description>Back to Articles mmBERT: ModernBERT goes Multilingual Published September 9, 2025 Update on GitHub Upvote 100 +94 Marc Marone mmarone Follow jhu-clsp Orion Weller orionweller Follow jhu-clsp William Fleshman will-fleshman Follow guest Eugene Yang eugene-yang Follow jhu-clsp Dawn Lawrie dlawrie Follow jhu-clsp Ben Van Durme vandurme Follow jhu-clsp TL;DR Training Data Training Recipe and Novel Components Architecture Three-Phase Training Approach Novel Training Techniques Results Natural Language Understanding (NLU) Retrieval Performance Learning Languages in the Decay Phase Efficiency Improvements Usage Examples Fine-tuning Examples Encoders Model Family and Links TL;DR This blog post introduces mmBERT , a state-of-the-art massively multilingual encoder model trained on 3T+ tokens of text in over 1800 languages. It shows significant performance and speed improvements over previous multilingual models, being the first to improve upon XLM-R, while also developing new strategies for...</description><pubDate>Tue, 09 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/mmbert</guid></item><item><title>Welcome EmbeddingGemma, Google's new efficient embedding model</title><link>https://huggingface.co/blog/embeddinggemma</link><description>Back to Articles Welcome EmbeddingGemma, Google's new efficient embedding model Published September 4, 2025 Update on GitHub Upvote 228 +222 Tom Aarsen tomaarsen Follow Joshua Xenova Follow Alvaro Bartolome alvarobartt Follow Aritra Roy Gosthipaty ariG23498 Follow Pedro Cuenca pcuenq Follow Sergio Paniego sergiopaniego Follow TL;DR Table of Contents Introduction Architecture Evaluation Demo Usage Sentence Transformers LangChain LlamaIndex Haystack txtai Transformers.js Text Embeddings Inference ONNX Runtime Finetuning Full Finetuning Script Training Finetuned Evaluation Further Reading TL;DR Today, Google releases EmbeddingGemma , a state-of-the-art multilingual embedding model perfect for on-device use cases. Designed for speed and efficiency, the model features a compact size of 308M parameters and a 2K context window , unlocking new possibilities for mobile RAG pipelines, agents, and more. EmbeddingGemma is trained to support over 100 languages and is the highest-ranking text-...</description><pubDate>Thu, 04 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/embeddinggemma</guid></item><item><title>Make your ZeroGPU Spaces go brrr with PyTorch ahead-of-time compilation</title><link>https://huggingface.co/blog/zerogpu-aoti</link><description>Back to Articles Make your ZeroGPU Spaces go brrr with ahead-of-time compilation Published September 2, 2025 Update on GitHub Upvote 64 +58 Charles Bensimon cbensimon Follow Sayak Paul sayakpaul Follow Linoy Tsaban linoyts Follow Apolin√°rio from multimodal AI art multimodalart Follow Table of Contents What is ZeroGPU PyTorch compilation Ahead-of-time compilation on ZeroGPU 1. Getting example inputs 2. Exporting the model 3. Compiling the exported model 4. Using the compiled model in the pipeline 5. Wrapping it all together Gotchas Quantization Dynamic shapes Multi-compile / shared weights FlashAttention-3 Regional compilation Use a compiled graph from the Hub AoT compiled ZeroGPU Spaces demos Speedup comparison Featured AoTI Spaces Regional compilation Conclusion Resources ZeroGPU lets anyone spin up powerful Nvidia H200 hardware in Hugging Face Spaces without keeping a GPU locked for idle traffic. It‚Äôs efficient, flexible, and ideal for demos but it doesn‚Äôt always make full use of...</description><pubDate>Tue, 02 Sep 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/zerogpu-aoti</guid></item><item><title>Generate Images with Claude and Hugging Face</title><link>https://huggingface.co/blog/claude-and-mcp</link><description>Back to Articles Generate Images with Claude and Hugging Face Published August 19, 2025 Update on GitHub Upvote 35 +29 shaun smith evalstate Follow Introduction Natural Images with Flux.1 Krea Dev Qwen Image Conclusion TL;DR: It's easier than ever to generate detailed pictures with state-of-the-art AI models by connecting Claude to Hugging Face Spaces. This article describes how and why, and introduces recently launched models which excel at producing natural images or images that include text. Introduction Recent advances in image generation models have improved their ability to produce realistic outputs and incorporate high quality text. It's easier than ever to use these models by connecting them directly to Claude. The advantages of generating pictures this way are: The AI can assist in building detailed prompts that may improve the quality of generated images. The AI can "see" the generated images, then help iterate on designs and techniques to get perfect results. You can...</description><pubDate>Tue, 19 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/claude-and-mcp</guid></item><item><title>From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels</title><link>https://huggingface.co/blog/kernel-builder</link><description>Back to Articles From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels Published August 18, 2025 Update on GitHub Upvote 73 +67 David Holtz drbh Follow Dani√´l de Kok danieldk Follow What You‚Äôll Learn Part 1: Anatomy of a Modern CUDA Kernel Step 1: Project Structure Step 2: The build.toml Manifest Step 3: The flake.nix Reproducibility File Step 4: Writing the CUDA Kernel Step 5: Registering a Native PyTorch Operator Step 6: Building the Kernel Step 7: Sharing with the World Step 8: Loading and Testing Your Custom Op Part 2: From One Kernel to Many: Solving Production Challenges Kernel Versions Pre-downloading Locked Kernels Creating Legacy Python Wheels Custom CUDA kernels give your models a serious performance edge, but building them for the real world can feel daunting. How do you move beyond a simple GPU function to create a robust, scalable system without getting bogged down by endless build times and dependency nightmares? We created the kernel-builder...</description><pubDate>Mon, 18 Aug 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/kernel-builder</guid></item></channel></rss>