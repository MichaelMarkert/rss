<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Blog</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the HuggingFace Blog.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>17 Reasons Why Gradio Isn't Just Another UI Library</title><link>https://huggingface.co/blog/why-gradio-stands-out</link><description>Back to Articles 17 Reasons Why Gradio Isn't Just Another UI Library Published April 16, 2025 Update on GitHub Upvote 17 +11 ysharma yuvraj sharma abidlabs Abubakar Abid Introduction 1. Universal API Access 2. Interactive API Recorder for Development 3. Fast ML Apps with Server-Side Rendering 4. Automatic Queue Management for ML Tasks 5. High-Performance Streaming for Real-Time ML Outputs 6. Integrated Multi-Page Application Support 7. New Client-Side Function Execution With Groovy 8. A Comprehensive Theming System and Modern UI Components 9. Gradio's Dynamic Interfaces 10. Visual Interface Development with Gradio Sketch 11. Progressive Web App (PWA) Support 12. In-Browser Execution with Gradio Lite 13. Accelerated Development with AI-Assisted Tooling 14. Hassle-Free App Sharing 15. Enterprise-Grade Security and Production Readiness 16. Enhanced Dataframe Component 17. Deep Links for Sharing App States Conclusion Introduction "Oh, Gradio? That's a Python library for building UIs,...</description><pubDate>Wed, 16 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/why-gradio-stands-out</guid></item><item><title>Cohere on Hugging Face Inference Providers üî•</title><link>https://huggingface.co/blog/inference-providers-cohere</link><description>Back to Articles Cohere on Hugging Face Inference Providers üî• Published April 16, 2025 Update on GitHub Upvote 96 +90 reach-vb Vaibhav Srivastav burtenshaw ben burtenshaw merve Merve Noyan celinah C√©lina Hanouti alexrs Alejandro Rodriguez CohereLabs julien-c Julien Chaumond sbrandeis Simon Brandeis Cohere Models CohereLabs/c4ai-command-a-03-2025 üîó CohereLabs/aya-expanse-32b üîó CohereLabs/c4ai-command-r7b-12-2024 üîó CohereLabs/aya-vision-32b üîó How it works In the website UI From the client SDKs From OpenAI client Tool Use with Cohere Models Billing We're thrilled to share that Cohere is now a supported Inference Provider on HF Hub! This also marks the first model creator to share and serve their models directly on the Hub. Cohere is committed to building and serving models purpose-built for enterprise use-cases. Their comprehensive suite of secure AI solutions, from cutting-edge Generative AI to powerful Embeddings and Ranking models, are designed to tackle real-world business...</description><pubDate>Wed, 16 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/inference-providers-cohere</guid></item><item><title>Introducing HELMET</title><link>https://huggingface.co/blog/helmet</link><description>Back to Articles Introducing HELMET : Holistically Evaluating Long-context Language Models Published April 16, 2025 Update on GitHub Upvote 21 +15 hyen Howard Yen guest gaotianyu1350 Tianyu Gao guest houminmin Minmin Hou Intel kding1 Ke Ding Intel danf Daniel Fleischer Intel moshew Moshe Wasserblat Intel cdq10131 Danqi Chen guest Evaluating long-context language models is challenging but important Existing evaluations overly rely on synthetic tasks Crafting diverse, controllable, and reliable evaluation for LCLMs Key improvements over existing benchmarks LCLMs still have a long way to go on real-world tasks Diverse evaluation is needed for assessing long-context abilities Models degrade with increasing lengths and task complexity Using HELMET for future developments How to run HELMET Faster development Quick comparison with existing models Looking ahead Acknowledgements Citation Contact: hyen@cs.princeton.edu Paper: https://arxiv.org/abs/2410.02694 Website: https://princeton-...</description><pubDate>Wed, 16 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/helmet</guid></item><item><title>Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ</title><link>https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition</link><description>Back to Articles Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ Published April 14, 2025 Update on GitHub Upvote 38 +32 thomwolf Thomas Wolf clem Clem ü§ó matthieu-lapeyre Matthieu Lapeyre pollen-robotics Hugging Face‚Äôs Robotics Venture Timeline About Hugging Face About Pollen Robotics About Reachy 2 Simon Alibert and R√©mi Cad√®ne from the LeRobot team with Reachy 1 ‚Äî Photo: L√©a Crespi Since Hugging Face started the LeRobot library in 2024, led by ex-Tesla lead Remi Cadene, the Hugging Face Hub has quickly become the most widely used hub and software platform for open robotics with models, datasets, spaces and libraries. Today, we‚Äôre excited to take it a step further by welcoming Pollen Robotics to Hugging Face, a team that's spent the last 9 years building open-source robots and hardware. We believe robotics could be the next frontier unlocked by AI ‚Äî and it should be open, affordable, and private. Our vision: a future where everyone in the community,...</description><pubDate>Mon, 14 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition</guid></item><item><title>4M Models Scanned: Protect AI + Hugging Face 6 Months In</title><link>https://huggingface.co/blog/pai-6-month</link><description>Back to Articles 4M Models Scanned: Protect AI + Hugging Face 6 Months In Published April 14, 2025 Update on GitHub Upvote 25 +19 sean-pai Sean Morgan protectai Maintaining a Zero Trust Approach to Model Security Evolving Guardian‚Äôs Model Vulnerability Detection Capabilities Common attack themes Delivering Comprehensive Threat Detection for Hugging Face Users It Only Gets Better from Here Hugging Face and Protect AI partnered in October 2024 to enhance machine learning (ML) model security through Guardian‚Äôs scanning technology for the community of developers who explore and use models from the Hugging Face Hub. The partnership has been a natural fit from the start‚ÄîHugging Face is on a mission to democratize the use of open source AI, with a commitment to safety and security; and Protect AI is building the guardrails to make open source models safe for all. 4 new threat detection modules launched Since October, Protect AI has significantly expanded Guardian's detection capabilities,...</description><pubDate>Mon, 14 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/pai-6-month</guid></item><item><title>Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC</title><link>https://huggingface.co/blog/fastrtc-cloudflare</link><description>Back to Articles Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC Published April 9, 2025 Update on GitHub Upvote 21 +15 freddyaboulton Freddy Boulton Meeting a Gap in the Toolbox of AI Developers Free Access with Your Hugging Face Account Why This Matters for AI Developers Getting Started What's Next? We're excited to announce a new partnership between Cloudflare and Hugging Face that gives FastRTC developers instant access to enterprise-grade WebRTC infrastructure with a Hugging Face token. As a preview of what you can build with FastRTC and Cloudflare, check out this voice chat app built with Meta's new Llama 4 model! Meeting a Gap in the Toolbox of AI Developers As conversational AI becomes a core interface for tools, products, and services, real-time communication infrastructure is increasingly essential to support natural, multimodal interactions. Hugging Face built FastRTC to let AI developers build low-latency AI-powered audio and...</description><pubDate>Wed, 09 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/fastrtc-cloudflare</guid></item><item><title>Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More</title><link>https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval</link><description>Back to Articles Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More Published April 8, 2025 Update on GitHub Upvote 15 +9 alielfilali01 Ali El Filali inceptionai SarahAlBarri Sarah AlBarri inceptionai Arwa88 Abouelseoud inceptionai samta-kamboj samta kamboj inceptionai neha1710 Neha Sengupta inceptionai preslavnakov Preslav Nakov MBZUAI Arabic-Leaderboards Space Latest Updates in AraGen Leaderboard AraGen-03-25 Release Dynamic Evaluation and Ranking Analysis Instruction Following Leaderboard What is Instruction Following as a Benchmark? Dataset: Arabic IFEval Evaluation Methodology &amp; Metrics Results &amp; Analysis Upcoming Work At Inception, we have been working to enhance AI model evaluations within the Arabic language context. Previously, we introduced AraGen , one of the first generative Arabic leaderboards, serving as a benchmark for evaluating Arabic LLMs on generative tasks. As part of our ongoing efforts, we are excited to share the following...</description><pubDate>Tue, 08 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval</guid></item><item><title>Welcome Llama 4 Maverick &amp; Scout on Hugging Face!</title><link>https://huggingface.co/blog/llama4-release</link><description>Back to Articles Welcome Llama 4 Maverick &amp; Scout on Hugging Face Published April 5, 2025 Update on GitHub Upvote 140 +134 burtenshaw ben burtenshaw reach-vb Vaibhav Srivastav pcuenq Pedro Cuenca clem Clem ü§ó rajatarya Rajat Arya xet-team jsulz Jared Sulzdorf xet-team lysandre Lysandre What is Llama 4? Features and Integrations on Hugging Face Context Length and Architecture Choices How to Use with Transformers Evaluation Scores Pre-trained models Instruction tuned models Acknowledgments References We are incredibly excited to welcome the next generation of large language models from Meta to the Hugging Face Hub: Llama 4 Maverick (~400B) and Llama 4 Scout (~109B)! ü§ó Both are Mixture of Experts (MoE) models with 17B active parameters. Released today, these powerful, natively multimodal models represent a significant leap forward. We've worked closely with Meta to ensure seamless integration into the Hugging Face ecosystem, including both transformers and TGI from day one. This is just...</description><pubDate>Sat, 05 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/llama4-release</guid></item><item><title>Journey to 1 Million Gradio Users!</title><link>https://huggingface.co/blog/gradio-1m</link><description>Back to Articles Journey to 1 Million Gradio Users! Published April 4, 2025 Update on GitHub Upvote 18 +12 abidlabs Abubakar Abid 5 years ago, we launched Gradio as a simple Python library to let researchers at Stanford easily demo computer vision models with a web interface. Today, Gradio is used by &gt;1 million developers each month to build and share AI web apps. This includes some of the most popular open-source projects of all time, like Automatic1111 , Oobabooga‚Äôs Text Generation WebUI , Dall-E Mini , and LLaMA-Factory . How did we get here? How did Gradio keep growing in the very crowded field of open-source Python libraries? I get this question a lot from folks who are building their own open-source libraries. This post distills some of the lessons that I have learned over the past few years: Invest in good primitives, not high-level abstractions Embed virality directly into your library Focus on a (growing) niche Your only roadmap should be rapid iteration Maximize ways users...</description><pubDate>Fri, 04 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/gradio-1m</guid></item><item><title>The NLP Course is becoming the LLM Course!</title><link>https://huggingface.co/blog/llm-course</link><description>Back to Articles The NLP Course is becoming the LLM Course! Published April 3, 2025 Update on GitHub Upvote 82 +76 burtenshaw ben burtenshaw reach-vb Vaibhav Srivastav lewtun Lewis Tunstall fdaudens Florent Daudens pcuenq Pedro Cuenca tomaarsen Tom Aarsen coyotte508 Eliott Coyac mishig Mishig Davaadorj sergiopaniego Sergio Paniego julien-c Julien Chaumond What‚Äôs going to happen to the NLP course material? Will there be new chapters? Will there be interactive exercises and live sessions? What‚Äôs next? Education has always been at the heart of Hugging Face‚Äôs mission to democratize AI and we‚Äôre doubling down on that by giving hf.co/learn a big upgrade! Our NLP course has been a go-to resource for the open-source AI community for the past 3 years, and it‚Äôs now time for a refresh. We‚Äôre updating and expanding it to keep up with all the exciting stuff happening in AI (which is not easy when there are breakthroughs every week!) We felt the excitement during the experimental smol-course and...</description><pubDate>Thu, 03 Apr 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/llm-course</guid></item><item><title>How Hugging Face Scaled Secrets Management for AI Infrastructure</title><link>https://huggingface.co/blog/scaling-secrets-management</link><description>Back to Articles How Hugging Face Scaled Secrets Management for AI Infrastructure Published March 31, 2025 Update on GitHub Upvote 5 segudev Thomas Segura Infisical Background Implementation Kubernetes Integration Local Development Security and Access Management CI/CD and Infrastructure Integration Technical Outcomes &amp; Insights Conclusion Resources Hugging Face has become synonymous with advancing AI at scale. With over 4 million builders deploying models on the Hub, the rapid growth of the platform necessitated a rethinking of how sensitive configuration data ‚Äîsecrets‚Äî are managed. Last year, the engineering teams set out to improve the handling of their secrets and credentials. After evaluating tools like HashiCorp Vault, they ultimately chose Infisical . This case study details their migration to Infisical, explains how they integrated its powerful features, and highlights how it enabled engineers to work more efficiently and securely. Background As Hugging Face's infrastructure...</description><pubDate>Mon, 31 Mar 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/scaling-secrets-management</guid></item><item><title>Accelerating LLM Inference with TGI on Intel Gaudi</title><link>https://huggingface.co/blog/intel-gaudi-backend-for-tgi</link><description>Back to Articles üöÄ Accelerating LLM Inference with TGI on Intel Gaudi Published March 28, 2025 Update on GitHub Upvote 13 +7 baptistecolle Baptiste Colle regisss R√©gis Pierrard IlyasMoutawwakil Ilyas Moutawwakil echarlaix Ella Charlaix kding1 Ke Ding Intel ‚ú® What's New? üåü Why This Matters üö¶ Getting Started with TGI on Gaudi üéâ Top features üí™ Getting Involved We're excited to announce the native integration of Intel Gaudi hardware support directly into Text Generation Inference (TGI), our production-ready serving solution for Large Language Models (LLMs). This integration brings the power of Intel's specialized AI accelerators to our high-performance inference stack, enabling more deployment options for the open-source AI community üéâ ‚ú® What's New? We've fully integrated Gaudi support into TGI's main codebase in PR #3091 . Previously, we maintained a separate fork for Gaudi devices at tgi-gaudi . This was cumbersome for users and prevented us from supporting the latest TGI features at...</description><pubDate>Fri, 28 Mar 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/intel-gaudi-backend-for-tgi</guid></item><item><title>Training and Finetuning Reranker Models with Sentence Transformers v4</title><link>https://huggingface.co/blog/train-reranker</link><description>Back to Articles Training and Finetuning Reranker Models with Sentence Transformers v4 Published March 26, 2025 Update on GitHub Upvote 117 +111 tomaarsen Tom Aarsen Table of Contents What are Reranker models? Why Finetune? Training Components Dataset Data on the Hugging Face Hub Local Data (CSV, JSON, Parquet, Arrow, SQL) Local Data that requires pre-processing Dataset Format Hard Negatives Mining Loss Function Training Arguments Evaluator CrossEncoderCorrelationEvaluator with STSb CrossEncoderRerankingEvaluator with GooAQ mined negatives Trainer Callbacks Multi-Dataset Training Training Tips Evaluation Additional Resources Training Examples Documentation Sentence Transformers is a Python library for using and training embedding and reranker models for a wide range of applications, such as retrieval augmented generation, semantic search, semantic textual similarity, paraphrase mining, and more. Its v4.0 update introduces a new training approach for rerankers, also known as cross-...</description><pubDate>Wed, 26 Mar 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/train-reranker</guid></item><item><title>Introducing Gradio's new Dataframe!</title><link>https://huggingface.co/blog/gradio-dataframe-upgrade</link><description>Back to Articles Introducing Gradio's new Dataframe! Published March 24, 2025 Update on GitHub Upvote 23 +17 hmb hannah abidlabs Abubakar Abid What‚Äôs next? Try it yourself! Gradio‚Äôs gr.Dataframe component is one of our most popular components, we've seen it used in a variety of awesome apps, like leaderboards, dashboards, and interactive visualisations. Although we hadn't made any changes to the dataframe in quite some time, our backlog of issues had been growing, and some improvements had been in demand for a while. Well ‚Äî we‚Äôre now super excited to release a host of new updates to Gradio‚Äôs dataframe component. Over the last 6 weeks, we‚Äôve closed over 70 dataframe issues - including bugs, improvements and enhancements. 1. Multi-Cell Selection You can select multiple cells at once! Copy or delete values across your selection with ease. 2. Row Numbers &amp; Column Pinning Add row number columns and keep critical columns in view while navigating wide datasets using the pinned_columns...</description><pubDate>Mon, 24 Mar 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/gradio-dataframe-upgrade</guid></item><item><title>The New and Fresh analytics in Inference Endpoints</title><link>https://huggingface.co/blog/endpoint-analytics</link><description>Back to Articles Analytics is important Published March 21, 2025 Update on GitHub Upvote 19 +13 erikkaum Erik Kaunism√§ki beurkinger Thibault Goehringer rtrm Remy co42 Corentin Regal michellehbn Michelle Habonneau Analytics and metrics are the cornerstone of understanding what's happening with your deployment. Are your Inference Endpoints overloaded? How many requests are they handling? Having well-visualized, relevant metrics displayed in real-time is crucial for monitoring and debugging. We realized that our analytics dashboard needed a refresh. Since we debug a lot of endpoints ourselves, we‚Äôve felt the same pain as our users. That‚Äôs why we sat down to plan and make several improvements to provide a better experience for you. What‚Äôs New? ‚è∞ Real-Time Metrics: Data now updates in real-time, ensuring you get an accurate and up-to-the-second view of your endpoint‚Äôs performance. Whether you‚Äôre monitoring request latency, response times, or error rates, you can now see the events as...</description><pubDate>Fri, 21 Mar 2025 00:00:00 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/blog/endpoint-analytics</guid></item></channel></rss>