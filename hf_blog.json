{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/screensuite", "image": "https://huggingface.co/blog/assets/screensuite/thumbnail.png", "title": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!", "content_text": "Back to Articles ScreenSuite - The most comprehensive evaluation suite for GUI Agents! Published June 6, 2025 Update on GitHub Upvote 26 +20 Amir Mahla A-Mahla Follow Aymeric Roucher m-ric Follow Thomas Wolf thomwolf Follow Releasing ScreenSuite, the most comprehensive evaluation suite for GUI Agents! WTF is a GUI Agent? Introducing ScreenSuite \ud83e\udd73 Ranking leading VLMs on ScreenSuite \ud83d\udcca Start your custom evaluation in 30s \u26a1\ufe0f Next steps \ud83d\ude80 Releasing ScreenSuite, the most comprehensive evaluation suite for GUI Agents! TL;DR Over the past few weeks, we\u2019ve been working tirelessly on making GUI agents more open, accessible and easy to integrate. Along the way, we created the largest benchmarking suite for GUI agents performances \ud83d\udc49 let us introduce ScreenSuite . We are very excited to share it with you today: ScreenSuite is the most comprehensive and easiest way to evaluate Vision Language Models (VLMs)across many agentic capabilities! WTF is a GUI Agent? GUI Agents in action - courtesy of...", "url": "https://huggingface.co/blog/screensuite", "date_published": "2025-06-06T00:00:00"}, {"id": "https://huggingface.co/blog/kv-cache", "image": "https://huggingface.co/blog/assets/kv-cache/thumbnail.png", "title": "KV Cache from scratch in nanoVLM", "content_text": "Back to Articles KV Cache from scratch in nanoVLM Published June 4, 2025 Update on GitHub Upvote 59 +53 Aritra Roy Gosthipaty ariG23498 Follow Kashif Rasul kashif Follow Luis Wiedmann lusxvr Follow Andres Marafioti andito Follow Pedro Cuenca pcuenq Follow TL;DR Introduction Revisiting the Transformer Architecture Self-Attention Computation Where Redundancy Creeps In How KV Caching Fixes It KV Caching in nanoVLM: From Theory to Practice 1. Updating KV Cache in the Attention Block 2. Tracking Cache Across Layers 3. Prefill vs Decode in the Generation Loop Summary of Changes Summary: Why KV Caching Matters TL;DR We have implemented KV Caching from scratch in our nanoVLM repository (a small codebase to train your own Vision Language Model with pure PyTorch). This gave us a 38% speedup in generation. In this blog post we cover KV Caching and all our experiences while implementing it. The lessons learnt are general and can be applied to all autoregressive language model generations....", "url": "https://huggingface.co/blog/kv-cache", "date_published": "2025-06-04T00:00:00"}, {"id": "https://huggingface.co/blog/smolvla", "image": "https://huggingface.co/blog/assets/smolvla/SmolVLA_thumbnail.png", "title": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data", "content_text": "Back to Articles SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data Published June 3, 2025 Update on GitHub Upvote 107 +101 Dana Aubakirova danaaubakirova Follow Andres Marafioti andito Follow Merve Noyan merve Follow Aritra Roy Gosthipaty ariG23498 Follow Francesco Capuano fracapuano Follow Loubna Ben Allal loubnabnl Follow Pedro Cuenca pcuenq Follow Mustafa Shukor mshukor Follow Remi Cadene cadene Follow \ud83e\uddedTL;DR \ud83d\udcda Table of Contents Introduction Meet SmolVLA! \ud83d\ude80 How to Use SmolVLA? Install Finetune the pretrained model Train from scratch Method Main Architecture Design Choices for Efficiency and Robustness Asynchronous Inference Community Datasets Improving Task Annotations Standardizing Camera Views Results Conclusion Call to Action: \ud83e\uddedTL;DR Today, we introduce SmolVLA , a compact (450M), open-source Vision-Language-Action model for robotics that runs on consumer hardware. Pretrained only on compatibly licensed, open-source community-shared datasets...", "url": "https://huggingface.co/blog/smolvla", "date_published": "2025-06-03T00:00:00"}, {"id": "https://huggingface.co/blog/vllm-colocate", "image": "https://huggingface.co/blog/assets/vllm-colocate/thumbnail.png", "title": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL", "content_text": "Back to Articles No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL Published June 3, 2025 Update on GitHub Upvote 40 +34 Mert Toslali toslali-ibm Follow Yu Chin Fabian Lim mirinflim Follow Quentin Gallou\u00e9dec qgallouedec Follow Ed Snible esnible Follow Raghu Ganti rganti Follow Mudhakar Srivatsa mudhakar Follow \ud83d\ude80 Introduction \ud83e\udde8 The Problem \ud83d\udca1 The Opportunity What It Enables \ud83e\udde9 Design: From Separate Servers to Shared GPUs Server TRL Setup (Top Row) Co-located TRL Setup (Bottom Row) \ud83d\udee0\ufe0f Implementation Notes \ud83d\udcca Showcase: Co-located vs. Plain TRL Performance Experiment 1: 1.5B Model \u2014 Varying Batch Sizes Experiment 2: 1.5B Model \u2014 Varying Tensor Parallelism (TP) Experiment 3: 7B Model \u2014 Varying Batch Sizes Experiment 4: 7B Model \u2014 Varying Tensor Parallelism (TP) \ud83d\udcca Scaling to 72B Model Sleep Mode in vLLM DeepSpeed Optimizations Accelerate Integration Experiment 5: Qwen2.5-Math-72B \u2014 Throughput, Accuracy, and Benchmark Results \ud83c\udf93 Challenges & Lessons Learned & next steps...", "url": "https://huggingface.co/blog/vllm-colocate", "date_published": "2025-06-03T00:00:00"}, {"id": "https://huggingface.co/blog/structured-codeagent", "image": "https://huggingface.co/blog/assets/structured-codeagent/thumbnail-codeagent.png", "title": "CodeAgents + Structure: A Better Way to Execute Actions", "content_text": "Back to Articles CodeAgents + Structure: A Better Way to Execute Actions Published May 28, 2025 Update on GitHub Upvote 50 +44 Aksel Joonas Reedi akseljoonas Follow Aymeric Roucher m-ric Follow \ud83e\udd14 The Evolution of Agent Actions \u27a1\ufe0f Adding Structured outputs to Code Agent \ud83e\uddea Benchmark Results \ud83d\udca1 Why Structure (Generally) Helps The Parsing Problem is Real The Structure Tax \ud83d\ude80 When to Use Structured CodeAgents How to use with smolagents: Implementation Tips The Bigger Picture - What's Next? Today we're sharing research that bridges two powerful paradigms in AI agent design: the expressiveness of code-based actions and the reliability of structured generation. Our findings show that forcing CodeAgents to generate both thoughts and code in a structured JSON format can significantly outperform traditional approaches across multiple benchmarks. Figure 1: Accuracy comparison of three approaches: Structured CodeAgent (blue), CodeAgent (orange), and ToolCallingAgent (gray) on SmolBench (GAIA,...", "url": "https://huggingface.co/blog/structured-codeagent", "date_published": "2025-05-28T00:00:00"}, {"id": "https://huggingface.co/blog/liger-grpo", "image": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png", "title": "\ud83d\udc2f Liger GRPO meets TRL", "content_text": "Back to Articles \ud83d\udc2f Liger GRPO meets TRL Published May 25, 2025 Update on GitHub Upvote 36 +30 Shivam Sahni shisahni Follow Kashif Rasul kashif Follow Salman Mohammadi smohammadi Follow Shirin Yamani ShirinYamani Follow Yanning Chen m0m0chen Follow Liberty liberty4321 Follow Motivation How Liger Kernel slashes memory for GRPO Plug-and-Play integration with TRL Benchmarks Scaling further with FSDP and PEFT Scaling even further with vLLM Conclusion TL; DR Liger supercharges TRL \u2019s Group Relative Policy Optimization GRPO Trainer by slashing memory usage by 40% with zero drop in model quality. We also added support for FSDP and PEFT , making it easier than ever to scale GRPO across multiple GPUs. Motivation Fine-tuning language models using reinforcement learning (RL) is a crucial step in a model's training lifecycle for steering models towards desirable behaviours which are more complex than can be achieved through typical supervised fine-tuning. RL has traditionally been applied to...", "url": "https://huggingface.co/blog/liger-grpo", "date_published": "2025-05-25T00:00:00"}, {"id": "https://huggingface.co/blog/dell-ai-applications", "image": "https://huggingface.co/blog/assets/dell-ai-applications/dell-post-thumbnail.png", "title": "Dell Enterprise Hub is all you need to build AI on premises", "content_text": "Back to Articles Dell Enterprise Hub is all you need to build AI on premises Published May 23, 2025 Update on GitHub Upvote 18 +12 Jeff Boudier jeffboudier Follow Andrew Reed andrewrreed Follow Simon Pagezy pagezyhf Follow Alvaro Bartolome alvarobartt Follow Thibault Goehringer beurkinger Follow Florent Gbelidji florentgbelidji Follow Arjuna ark393 Follow Balachandran Rajendran balaatdell Follow Models Ready for Action Introducing AI Applications Powered by NVIDIA, AMD and Intel On-Device Models for Dell AI PC Now with CLI and Python SDK Wrapping up This week at Dell Tech World, we announced the new version of Dell Enterprise Hub , with a complete suite of models and applications to easily build AI running on premises with Dell AI servers and AI PCs. Models Ready for Action If you go to the Dell Enterprise Hub today, you can find some of the most popular models, like Meta Llama 4 Maverick , DeepSeek R1 or Google Gemma 3 , available for deployment and training in a few clicks. But...", "url": "https://huggingface.co/blog/dell-ai-applications", "date_published": "2025-05-23T00:00:00"}, {"id": "https://huggingface.co/blog/python-tiny-agents", "image": "https://huggingface.co/blog/assets/python-tiny-agents/thumbnail.png", "title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code", "content_text": "Back to Articles Tiny Agents in Python: an MCP-powered agent in ~70 lines of code Published May 23, 2025 Update on GitHub Upvote 122 +116 C\u00e9lina Hanouti celinah Follow Julien Chaumond julien-c Follow Lucain Pouget Wauplin Follow shaun smith evalstate Follow How to Run the Demo Agent Configuration LLMs Can Use Tools Building our Python MCP Client Using the Tools: Streaming and Processing 1. Prepare tools and calling the LLM 2. Executing tools Our Tiny Python Agent: It's (Almost) Just a Loop! 1. Initializing the Agent 2. The agent\u2019s core: the Loop Next Steps Inspired by Tiny Agents in JS , we ported the idea to Python \ud83d\udc0d and extended the huggingface_hub client SDK to act as a MCP Client so it can pull tools from MCP servers and pass them to the LLM during inference. MCP ( Model Context Protocol ) is an open protocol that standardizes how Large Language Models (LLMs) interact with external tools and APIs. Essentially, it removed the need to write custom integrations for each tool,...", "url": "https://huggingface.co/blog/python-tiny-agents", "date_published": "2025-05-23T00:00:00"}, {"id": "https://huggingface.co/blog/diffusers-quantization", "image": "https://huggingface.co/blog/assets/diffusers-quantization/thumbnail.png", "title": "Exploring Quantization Backends in Diffusers", "content_text": "Back to Articles Exploring Quantization Backends in Diffusers Published May 21, 2025 Update on GitHub Upvote 33 +27 Derek Liu derekl35 Follow Marc Sun marcsun13 Follow Sayak Paul sayakpaul Follow Spot The Quantized Model Quantization Backends in Diffusers bitsandbytes (BnB) torchao Quanto GGUF FP8 Layerwise Casting ( enable_layerwise_casting ) Combining with More Memory Optimizations and torch.compile Ready to use quantized checkpoints Conclusion Large diffusion models like Flux (a flow-based text-to-image generation model) can create stunning images, but their size can be a hurdle, demanding significant memory and compute resources. Quantization offers a powerful solution, shrinking these models to make them more accessible without drastically compromising performance. But the big question always is: can you actually tell the difference in the final image? Before we dive into the technical details of how various quantization backends in Hugging Face Diffusers work, why not test...", "url": "https://huggingface.co/blog/diffusers-quantization", "date_published": "2025-05-21T00:00:00"}, {"id": "https://huggingface.co/blog/nanovlm", "image": "https://huggingface.co/blog/assets/nanovlm/thumbnail.png", "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch", "content_text": "Back to Articles nanoVLM: The simplest repository to train your VLM in pure PyTorch Published May 21, 2025 Update on GitHub Upvote 144 +138 Aritra Roy Gosthipaty ariG23498 Follow Luis Wiedmann lusxvr Follow Andres Marafioti andito Follow Sergio Paniego sergiopaniego Follow Merve Noyan merve Follow Pedro Cuenca pcuenq Follow Vaibhav Srivastav reach-vb Follow Table of contents: TL;DR What is a Vision Language Model? Working with the repository Architecture Train your own VLM Run inference on a pre-trained model Conclusion References nanoVLM is the simplest way to get started with training your very own Vision Language Model (VLM) using pure PyTorch. It is lightweight toolkit which allows you to launch a VLM training on a free tier colab notebook . We were inspired by Andrej Karpathy \u2019s nanoGPT , and provide a similar project for the vision domain. At its heart, nanoVLM is a toolkit that helps you build and train a model that can understand both images and text, and then generate text...", "url": "https://huggingface.co/blog/nanovlm", "date_published": "2025-05-21T00:00:00"}, {"id": "https://huggingface.co/blog/azure-ai-foundry", "image": "https://huggingface.co/blog/assets/azure-ai-foundry/satya-hf-build-compressed.png", "title": "Microsoft and Hugging Face expand collaboration", "content_text": "Back to Articles Microsoft and Hugging Face expand collaboration to make open models easy to use on Azure Published May 19, 2025 Update on GitHub Upvote 21 +15 Jeff Boudier jeffboudier Follow Simon Pagezy pagezyhf Follow Alvaro Bartolome alvarobartt Follow It\u2019s time to build - an expanded collaboration How to use Hugging Face in Azure AI Foundry More Hugging Face to come in Azure AI Foundry Today at the Microsoft Build conference, Satya Nadella announced an expanded collaboration with Hugging Face, to make its wide diversity of open models easy to deploy on Azure secure infrastructure. If you head over to Azure AI Foundry today, you will find a vastly expanded collection of 10,000+ Hugging Face models you can deploy in a couple clicks to power AI applications working with text, audio and images. And we\u2019re just getting started! It\u2019s time to build - an expanded collaboration 2 years ago, Microsoft and Hugging Face started a collaboration to make open models more easily accessible on...", "url": "https://huggingface.co/blog/azure-ai-foundry", "date_published": "2025-05-19T00:00:00"}, {"id": "https://huggingface.co/blog/transformers-model-definition", "image": "https://huggingface.co/blog/assets/transformers-model-definition/transformers-thumbnail.png", "title": "The Transformers Library: standardizing model definitions", "content_text": "Back to Articles The Transformers Library: standardizing model definitions Published May 15, 2025 Update on GitHub Upvote 112 +106 Lysandre lysandre Follow Arthur Zucker ArthurZ Follow Pedro Cuenca pcuenq Follow Julien Chaumond julien-c Follow A model-definition library Striving for even simpler model contributions How does this affect you? What this means for you, as a model user What this means for you, as a model creator TLDR: Going forward, we're aiming for Transformers to be the pivot across frameworks: if a model architecture is supported by transformers, you can expect it to be supported in the rest of the ecosystem. Transformers was created in 2019, shortly following the release of the BERT Transformer model. Since then, we've continuously aimed to add state-of-the-art architectures, initially focused on NLP, then growing to Audio and computer vision. Today, transformers is the default library for LLMs and VLMs in the Python ecosystem. Transformers now supports 300+ model...", "url": "https://huggingface.co/blog/transformers-model-definition", "date_published": "2025-05-15T00:00:00"}, {"id": "https://huggingface.co/blog/kaggle-integration", "image": "https://huggingface.co/blog/assets/kaggle-integration/thumbnail.png", "title": "Improving Hugging Face Model Access for Kaggle Users", "content_text": "Back to Articles Improving Hugging Face Model Access for Kaggle Users Published May 14, 2025 Update on GitHub Upvote 28 +22 Vincent Roseberry roseberryv Follow Meg Risdal megrisdal Follow Julien Chaumond julien-c Follow Pedro Cuenca pcuenq Follow Vaibhav Srivastav reach-vb Follow How to get started How does this work with private and consent-gated Hugging Face models? What\u2019s next Kaggle and Hugging Face users are part of one AI community. That\u2019s why we\u2019re excited to announce our plans to bring our platforms and communities closer to better serve AI developers everywhere. Beginning today, Kaggle is launching an integration that enhances visibility and discoverability for Hugging Face models directly on Kaggle. How to get started You can navigate from Hugging Face models to Kaggle and vice versa. Start by visiting a Hugging Face model page like Qwen/Qwen3-1.7B . To use it in a Kaggle Notebook, you can click on \u201cUse this model\u201d and select \u201cKaggle\u201d to open up a Kaggle notebook with a...", "url": "https://huggingface.co/blog/kaggle-integration", "date_published": "2025-05-14T00:00:00"}, {"id": "https://huggingface.co/blog/fast-whisper-endpoints", "image": "https://huggingface.co/blog/assets/fast-whisper-endpoints/thumbnail.png", "title": "Blazingly fast whisper transcriptions with Inference Endpoints", "content_text": "Back to Articles Blazingly fast whisper transcriptions with Inference Endpoints Published May 13, 2025 Update on GitHub Upvote 68 +62 Morgan Funtowicz mfuntowicz Follow Freddy Boulton freddyaboulton Follow Steven Zheng Steveeeeeeen Follow Vaibhav Srivastav reach-vb Follow Erik Kaunism\u00e4ki erikkaum Follow Michelle Habonneau michellehbn Follow Inference Stack Benchmarks How to deploy Inference FastRTC Demo Today we are happy to introduce a new blazing fast OpenAI Whisper deployment option on Inference Endpoints . It provides up to 8x performance improvements compared to the previous version, and makes everyone one click away from deploying dedicated, powerful transcription models in a cost-effective way, leveraging the amazing work done by the AI community. Through this release, we would like to make Inference Endpoints more community-centric and allow anyone to come and contribute to create incredible inference deployments on the Hugging Face Platform. Along with the community, we...", "url": "https://huggingface.co/blog/fast-whisper-endpoints", "date_published": "2025-05-13T00:00:00"}, {"id": "https://huggingface.co/blog/vlms-2025", "image": "https://huggingface.co/blog/assets/vlms2/vlms2.png", "title": "Vision Language Models (Better, Faster, Stronger)", "content_text": "Back to Articles Vision Language Models (Better, Faster, Stronger) Published May 12, 2025 Update on GitHub Upvote 427 +421 Merve Noyan merve Follow Sergio Paniego sergiopaniego Follow Aritra Roy Gosthipaty ariG23498 Follow Pedro Cuenca pcuenq Follow Andres Marafioti andito Follow Motivation Table of Contents New model trends Any-to-any models Reasoning Models Smol yet Capable Models Mixture-of-Experts as Decoders Vision-Language-Action Models Specialized Capabilities Object Detection, Segmentation, Counting with Vision Language Models Multimodal Safety Models Multimodal RAG: retrievers, rerankers Multimodal Agents Video Language Models New Alignment Techniques for Vision Language Models New benchmarks MMT-Bench MMMU-Pro Useful Resources Motivation Vision Language Models (VLMs) are the talk of the town. In a previous blog post (from April 2024 ), we talked a lot about VLMs. A major chunk was about LLaVA , the first successful and easily reproducible open-source vision language model,...", "url": "https://huggingface.co/blog/vlms-2025", "date_published": "2025-05-12T00:00:00"}]}