{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/hf-cli", "image": "https://huggingface.co/blog/assets/hf-cli-thumbnail.png", "title": "Say hello to `hf`: a faster, friendlier Hugging Face CLI \u2728", "content_text": "Back to Articles Say hello to `hf`: a faster, friendlier Hugging Face CLI \u2728 Published July 25, 2025 Update on GitHub Upvote 50 +44 Lucain Pouget Wauplin Follow C\u00e9lina Hanouti celinah Follow Julien Chaumond julien-c Follow Getting started \ud83d\udd00 Migration One more thing... \ud83d\udca5 hf jobs We are glad to announce a long-awaited quality-of-life improvement: the Hugging Face CLI has been officially renamed from huggingface-cli to hf ! So... why this change? Typing huggingface-cli constantly gets old fast. More importantly, the CLI\u2019s command structure became messy as new features were added over time (upload, download, cache management, repo management, etc.). Renaming the CLI is a chance to reorganize commands into a clearer, more consistent format. We decided not to reinvent the wheel and instead follow a well-known CLI pattern: hf <resource> <action> . This predictable grammar makes the Hugging Face CLI more ergonomic and discoverable, while also setting the stage for upcoming features. Getting...", "url": "https://huggingface.co/blog/hf-cli", "date_published": "2025-07-25T00:00:00"}, {"id": "https://huggingface.co/blog/parquet-cdc", "image": "https://huggingface.co/blog/assets/parquet-cdc/thumbnail.png", "title": "Parquet Content-Defined Chunking", "content_text": "Back to Articles Parquet Content-Defined Chunking Published July 25, 2025 Update on GitHub Upvote 44 +38 Krisztian Szucs kszucs Follow Table of Contents Introduction Data Preparation Upload the table as a Parquet file to Hugging Face Hub Different Use Cases for Parquet Deduplication 1. Re-uploading Exact Copies of the Table 2. Adding and Removing Columns from the Table 3. Changing Column Types in the Table 4. Appending New Rows and Concatenating Tables 5. Inserting / Deleting Rows in the Table 6. Using Different Row-group Sizes 7. Using Varying File-Level Splits Using Parquet CDC feature with Pandas References Conclusion Reduce Parquet file upload and download times on Hugging Face Hub by leveraging the new Xet storage layer and Apache Arrow\u2019s Parquet Content-Defined Chunking (CDC) feature enabling more efficient and scalable data workflows. TL;DR: Parquet Content-Defined Chunking (CDC) is now available in PyArrow and Pandas, enabling efficient deduplication of Parquet files on...", "url": "https://huggingface.co/blog/parquet-cdc", "date_published": "2025-07-25T00:00:00"}, {"id": "https://huggingface.co/blog/timescope-video-lmm-benchmark", "image": "https://huggingface.co/blog/assets/timescope/thumbnail.png", "title": "TimeScope: How Long Can Your Video Large Multimodal Model Go?", "content_text": "Back to Articles TimeScope: How Long Can Your Video Large Multimodal Model Go? Published July 23, 2025 Update on GitHub Upvote 29 +23 Orr Zohar orrzohar Follow Stanford Rui Li ruili0 Follow guest Andres Marafioti andito Follow huggingface Xiaohan Wang nicholswang Follow Stanford TL;DR Table of Contents Why TimeScope? Motivating a Better Benchmark for Video Benchmark Design 1. Localized Retrieval 2. Information Synthesis 3. Fine-Grained Temporal Perception Evaluations & Leaderboard What did we learn? Conclusion \u2013 Let\u2019s Raise the Bar for Long-Video AI TL;DR TimeScope is an open-source benchmark designed to measure how well vision-language models understand long videos. By adding short \u201cneedle\u201d clips into videos ranging from 1 minute to 8 hours, it evaluates three skills: localized retrieval, information synthesis, fine-grained temporal perception. Timescope reveals that many state-of-the-art models still struggle with true temporal comprehension. Table of Contents Why TimeScope?...", "url": "https://huggingface.co/blog/timescope-video-lmm-benchmark", "date_published": "2025-07-23T00:00:00"}, {"id": "https://huggingface.co/blog/lora-fast", "image": "https://huggingface.co/blog/assets/lora-fast/thumbnail.png", "title": "Fast LoRA inference for Flux with Diffusers and PEFT", "content_text": "Back to Articles Fast LoRA inference for Flux with Diffusers and PEFT Published July 23, 2025 Update on GitHub Upvote 32 +26 Sayak Paul sayakpaul Follow Benjamin Bossan BenjaminB Follow Technical details of hotswapping Resources LoRA adapters provide a great deal of customization for models of all shapes and sizes. When it comes to image generation, they can empower the models with different styles, different characters, and much more . Sometimes, they can also be leveraged to reduce inference latency . Hence, their importance is paramount, particularly when it comes to customizing and fine-tuning models. In this post, we take the Flux.1-Dev model for text-to-image generation because of its widespread popularity and adoption, and how to optimize its inference speed when using LoRAs (~2.3x). It has over 30k adapters trained with it ( as reported on the Hugging Face Hub platform). Therefore, its importance to the community is significant. Note that even though we demonstrate speedups...", "url": "https://huggingface.co/blog/lora-fast", "date_published": "2025-07-23T00:00:00"}, {"id": "https://huggingface.co/blog/virtual-cell-challenge", "image": "https://huggingface.co/blog/assets/virtual-cell-challenge/thumbnail.png", "title": "Arc Virtual Cell Challenge: A Primer", "content_text": "Back to Articles Arc Virtual Cell Challenge: A Primer Published July 18, 2025 Update on GitHub Upvote 40 +34 Christopher Fleetwood FL33TW00D-HF Follow Abhinav Adduri abhinadduri Follow Training data Modelling the challenge State Transition Model (ST) State Embedding Model (SE) A little biological detour Back to the model Perturbation Discrimination Differential Expression Conclusion Arc Institute recently unveiled the Virtual Cell Challenge . Participants are required to train a model capable of predicting the effect of silencing a gene in a (partially) unseen cell type, a task they term context generalization . For ML engineers with little to no biology background, the jargon and required context can seem quite daunting. To encourage participation, we recapitulate the challenge in a form better suited to engineers from other disciplines. Goal Train a model to predict the effect on a cell of silencing a gene using CRISPR. Doing things in the world of atoms is expensive, laborious...", "url": "https://huggingface.co/blog/virtual-cell-challenge", "date_published": "2025-07-18T00:00:00"}, {"id": "https://huggingface.co/blog/consilium-multi-llm", "image": "https://huggingface.co/blog/assets/consilium-multi-llm/thumbnail.png", "title": "Consilium: When Multiple LLMs Collaborate", "content_text": "Back to Articles Consilium: When Multiple LLMs Collaborate Published July 17, 2025 Update on GitHub Upvote 17 +11 Andreas azettl Follow guest From Concept to Architecture Building the Visual Foundation Session State Management Making LLMs Actually Discuss LLM Selection and Research Integration Discovering the Open Floor Protocol Lessons Learned and Future Implications Picture this: four AI experts sitting around a poker table, debating your toughest decisions in real-time. That's exactly what Consilium, the multi-LLM platform I built during the Gradio Agents & MCP Hackathon , does. It lets AI models discuss complex questions and reach consensus through structured debate. The platform works both as a visual Gradio interface and as an MCP (Model Context Protocol) server that integrates directly with applications like Cline (Claude Desktop had issues as the timeout could not be adjusted). The core idea was always about LLMs reaching consensus through discussion; that's where the name...", "url": "https://huggingface.co/blog/consilium-multi-llm", "date_published": "2025-07-17T00:00:00"}, {"id": "https://huggingface.co/blog/futurebench", "image": "https://huggingface.co/blog/assets/futurebench/leaderboard.png", "title": "Back to The Future: Evaluating AI Agents on Predicting Future Events", "content_text": "Back to Articles Back to The Future: Evaluating AI Agents on Predicting Future Events Published July 17, 2025 Update on GitHub Upvote 26 +20 Federico Bianchi vinid Follow guest Junlin Wang junlinw Follow togethercomputer Zain Hasan zainhasan Follow togethercomputer Shang Zhu shangzhu Follow guest Roy coolcat21 Follow togethercomputer Cl\u00e9mentine Fourrier clefourrier Follow James ZOu jameszou Follow guest Future of AI Can Agents Predict Future Events? 1. News-Generated Questions: Finding Tomorrow's Headlines Today 2. Polymarket Integration: Leveraging Prediction Markets Example Questions Future Bench: Three Levels of Systematic Evaluation Predicting The Future: Agents and Initial Results Initial Results Interesting Action Patterns References Future of AI Most current AI benchmarks focus on answering questions about the past, either by testing models on existing knowledge (in a static manner, such as HLE or GPQA, or augmented, like BrowseComp or GAIA) or previously solved problems...", "url": "https://huggingface.co/blog/futurebench", "date_published": "2025-07-17T00:00:00"}, {"id": "https://huggingface.co/blog/gradio-mcp-updates", "image": "https://huggingface.co/blog/assets/gradio-mcp-updates/5_mcp_improvements.png", "title": "Five Big Improvements to Gradio MCP Servers", "content_text": "Back to Articles Five Big Improvements to Gradio MCP Servers Published July 17, 2025 Update on GitHub Upvote 18 +12 Freddy Boulton freddyaboulton Follow Seamless Local File Support Real-time Progress Notifications Transform OpenAPI Specs to MCP in One Line Improvements to Authentication Modifying Tool Descriptions Conclusion Gradio is an open-source Python package for creating AI-powered web applications. Gradio is compliant with the MCP server protocol and powers thousands of MCP servers hosted on Hugging Face Spaces . The Gradio team is betting big on Gradio and Spaces being the best way to build and host AI-powered MCP servers. To that end, here are some of the big improvements we've added to Gradio MCP servers as of version 5.38.0 . Seamless Local File Support If you've tried to use a remote Gradio MCP server that takes a file as input (image, video, audio), you've probably encountered this error: This happens because the Gradio server is hosted on a different machine, meaning...", "url": "https://huggingface.co/blog/gradio-mcp-updates", "date_published": "2025-07-17T00:00:00"}, {"id": "https://huggingface.co/blog/ettin", "image": "https://huggingface.co/blog/assets/ettin/thumbnail.png", "title": "Seq vs Seq: the Ettin Suite of Paired Encoders and Decoders", "content_text": "Back to Articles Ettin Suite: SoTA Paired Encoders and Decoders Published July 16, 2025 Update on GitHub Upvote 50 +44 Orion Weller orionweller Follow jhu-clsp K Ricci kdricci Follow jhu-clsp Marc Marone mmarone Follow jhu-clsp Antoine Chaffin NohTow Follow lightonai Dawn Lawrie dlawrie Follow jhu-clsp Ben Van Durme vandurme Follow jhu-clsp TL;DR Encoders vs Decoders: The Architecture Divide Training Recipe: Modern Techniques for Both Architectures Sizes Three-Phase Training Process Modern Architecture Components Data Sources and Quality Encoder Results: Beating ModernBERT Decoder Results: Beating Llama 3.2 and SmolLM2 Fair Fight: Encoders vs Decoders on Even Ground Architecture-Specific Advantages Persist Cross-Objective Training Falls Short Beyond Performance: Understanding Model Behavior Usage Examples Encoders Decoders Fine-tuning Examples Encoders Decoders Model Family and Links TL;DR What would happen if you took the ModernBERT recipe and applied it to a decoder-only model?...", "url": "https://huggingface.co/blog/ettin", "date_published": "2025-07-16T00:00:00"}, {"id": "https://huggingface.co/blog/migrating-the-hub-to-xet", "image": "https://huggingface.co/blog/assets/migrating-the-hub-to-xet/thumbnail.png", "title": "Migrating the Hub from Git LFS to Xet", "content_text": "Back to Articles Migrating the Hub from Git LFS to Xet Published July 15, 2025 Update on GitHub Upvote 23 +17 Jared Sulzdorf jsulz Follow xet-team Joseph Godlewski jgodlewski Follow xet-team Sam Horradarn sirahd Follow xet-team Bridges and backward compatibility Scaling migrations Zero friction, faster transfers Xet for everyone In January of this year, Hugging Face's Xet Team deployed a new storage backend, and shortly after shifted ~6% of Hub downloads through the infrastructure . This represented a significant milestone, but it was just the beginning. In 6 months, 500,000 repositories holding 20 PB joined the move to Xet as the Hub outgrows Git LFS and transitions to a storage system that scales with the workloads of AI builders. Today, more than 1 million people on the Hub are using Xet. In May, it became the default on the Hub for new users and organizations . With only a few dozen GitHub issues, forum threads, and Discord messages, this is perhaps the quietest migration of...", "url": "https://huggingface.co/blog/migrating-the-hub-to-xet", "date_published": "2025-07-15T00:00:00"}, {"id": "https://huggingface.co/blog/async-robot-inference", "image": "https://huggingface.co/blog/assets/async_inference/thumbnail_async_blog.png", "title": "Asynchronous Robot Inference: Decoupling Action Prediction and Execution", "content_text": "Back to Articles Asynchronous Robot Inference: Decoupling Action Prediction and Execution Published July 10, 2025 Update on GitHub Upvote 37 +31 Francesco Capuano fracapuano Follow Steven Palma imstevenpmwork Follow Michel Aractingi aractingi Follow Mustafa Shukor mshukor Follow Dana Aubakirova danaaubakirova Follow Adil Zouitine AdilZtn Follow Simon Alibert aliberts Follow Table of Contents Getting started Async inference: a deep dive 1. Why sequential inference falls short 2. Asynchronous inference, in a nutshell 3. System Architecture Robot Client Policy Server 4. Analyzing async inference 5. Using async in your setup Conclusions TL;DR Robotic policies are increasingly bulky, and predict chunks of future actions rather than a single next action. This results in the robot being idle while awaiting new actions to perform, introducing noticeable lags at execution, and lacking responsiveness. Asynchronous inference tightens the control loop, removing lags at runtime and resulting in...", "url": "https://huggingface.co/blog/async-robot-inference", "date_published": "2025-07-10T00:00:00"}, {"id": "https://huggingface.co/blog/screenenv", "image": "https://huggingface.co/blog/assets/screenenv/screenenv.png", "title": "ScreenEnv: Deploy your full stack Desktop Agent", "content_text": "Back to Articles ScreenEnv: Deploy your full stack Desktop Agent Published July 10, 2025 Update on GitHub Upvote 55 +49 Amir Mahla A-Mahla Follow Aymeric Roucher m-ric Follow What is ScreenEnv? Why ScreenEnv? \ud83c\udfaf One-Line Setup Two Integration Approaches Option 1: Direct Sandbox API Option 2: MCP Server Integration \u2728 Create a Desktop Agent with screenenv and smolagents 1. Choose Your Model 2. Define Your Custom Desktop Agent 3. Run the Agent on a Desktop Task Get Started Today What's Next? TL;DR : ScreenEnv is a powerful Python library that lets you create isolated Ubuntu desktop environments in Docker containers for testing and deploying GUI Agents (aka Computer Use agents). With built-in support for the Model Context Protocol (MCP), it's never been easier to deploy desktop agents that can see, click, and interact with real applications. What is ScreenEnv? Imagine you need to automate desktop tasks, test GUI applications, or build an AI agent that can interact with software. This...", "url": "https://huggingface.co/blog/screenenv", "date_published": "2025-07-10T00:00:00"}, {"id": "https://huggingface.co/blog/building-hf-mcp", "image": "https://huggingface.co/blog/assets/building-hf-mcp/building-hf-mcp.png", "title": "Building the Hugging Face MCP Server", "content_text": "Back to Articles Building the Hugging Face MCP Server Published July 10, 2025 Update on GitHub Upvote 51 +45 shaun smith evalstate Follow Julien Chaumond julien-c Follow Eliott Coyac coyotte508 Follow Abubakar Abid abidlabs Follow Introduction Design Choices Remote Servers Production Deployment Conclusion TL;DR: The Hugging Face Official MCP Server offers unique customization options for AI Assistants accessing the Hub, along with access to thousands of AI applications through one simple URL. We used MCPs \"Streamable HTTP\" transport for deployment, and examine in detail the trade-offs that Server Developers have. We've learned many things about building a useful MCP server in the last month - we'll describe our journey here. Introduction The Model Context Protocol (MCP) is fulfilling its promise of being the standard to connect AI Assistants to the outside world. At Hugging Face, providing access to the Hub via MCP is an obvious choice, and this article shares our experience...", "url": "https://huggingface.co/blog/building-hf-mcp", "date_published": "2025-07-10T00:00:00"}, {"id": "https://huggingface.co/blog/reachy-mini", "image": "https://huggingface.co/blog/assets/reachy-mini/thumbnail.jpg", "title": "Reachy Mini - The Open-Source Robot for Today's and Tomorrow's AI Builders", "content_text": "Back to Articles Reachy Mini \u2013 The Open-Source Robot for Today's and Tomorrow's AI Builders Published July 9, 2025 Update on GitHub Upvote 613 +607 Thomas Wolf thomwolf Follow Matthieu Lapeyre matthieu-lapeyre Follow pollen-robotics \ud83d\udd29 Robot technical info \ud83e\udde0 Built for Exploring, Playing, Learning & Sharing \ud83e\udd1d Designed for Human-Robot Interaction \ud83c\udf0d Open, Modular & Community-Powered Tiny price, small size, huge possibilities. Code, learn, share with AI builders of all ages, all around the globe. Order the lite version Order the wireless version $299 (+ taxes + shipping) $449 (+ taxes + shipping) Reachy Mini is an expressive, open-source robot designed for human-robot interaction, creative coding, and AI experimentation. Fully programmable in Python (and soon JavaScript, Scratch) and priced from $299 , it's your gateway into robotics AI: fun, customizable, and ready to be part of your next coding project. Whether you're an AI developer, hacker, researcher, teacher, robot enthusiast, or...", "url": "https://huggingface.co/blog/reachy-mini", "date_published": "2025-07-09T00:00:00"}, {"id": "https://huggingface.co/blog/mi300kernels", "image": "https://huggingface.co/blog/assets/mi300kernels/thumbnail.png", "title": "Creating custom kernels for the AMD MI300", "content_text": "Back to Articles Creating custom kernels for the AMD MI300 Published July 9, 2025 Update on GitHub Upvote 43 +37 R\u00e9mi Ouazan Reboul ror Follow seungrok jung seungrokj Follow amd AMD Kernels How to use these kernels The hf-rocm-kernels repo Integration in VLLM A quick introduction to the MI300X Threads Warps Compute units XCDs The entire GPU (MI300X) Day 0 performance analysis RMS norm kernel Optimization: memory-related Results SwiGLU kernel Optimization: compute-related Results Skinny GEMM kernel Optimization: split-K Optimization: removing padding Optimization: warp specialization and asynchronous execution Results Conclusion Introduction More than a billion per day: that\u2019s a low estimate of how many requests ChatGPT handles daily, a number which is unlikely to go down soon. For each request and each generated token, we run an inference of a multi-billion parameters model. This is why model optimization is paramount at each and every level: when one deals with these kinds of...", "url": "https://huggingface.co/blog/mi300kernels", "date_published": "2025-07-09T00:00:00"}]}