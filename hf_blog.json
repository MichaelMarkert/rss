{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/intel-qwen3-agent", "image": "https://huggingface.co/blog/assets/intel-qwen3-agent/smolagents-1300-650.png", "title": "Accelerating Qwen3-8B Agent on Intel\u00ae Core\u2122 Ultra with Depth-Pruned Draft Models", "content_text": "Back to Articles Accelerating Qwen3-8B Agent on Intel\u00ae Core\u2122 Ultra with Depth-Pruned Draft Models Published September 29, 2025 Update on GitHub Upvote 12 +6 Igor Margulis imargulis Follow Intel Ofir Zafrir ofirzaf Follow Intel Shira Guskin sguskin Follow Intel Guy Boudoukh guybd Follow Intel Pedro Cuenca pcuenq Follow Qwen3 Accelerating Qwen3-8B on Intel\u00ae Core\u2122 Ultra with Speculative Decoding Pushing Performance Further Integration with \ud83e\udd17smolagents References TL;DR: Qwen3-8B is one of the most exciting recent releases\u2014a model with native agentic capabilities, making it a natural fit for the AIPC. With OpenVINO.GenAI , we\u2019ve been able to accelerate generation by ~1.3\u00d7 using speculative decoding with a lightweight Qwen3-0.6B draft. By using speculative decoding and applying a simple pruning process to the draft, we pushed the speedup even further to ~1.4\u00d7 We wrapped this up by showing how these improvements can be used to run a fast, local AI Agent with \ud83e\udd17 smolagents Qwen3 Qwen3-8B is...", "url": "https://huggingface.co/blog/intel-qwen3-agent", "date_published": "2025-09-29T00:00:00"}, {"id": "https://huggingface.co/blog/vibegame", "image": "https://huggingface.co/blog/assets/vibegame/thumbnail.png", "title": "VibeGame: Exploring Vibe Coding Games", "content_text": "Back to Articles VibeGame: Exploring Vibe Coding Games Published September 29, 2025 Update on GitHub Upvote 11 +5 Dylan Ebert dylanebert Follow The Problem What Is \"Vibe Coding\"? Context Management Initial Exploration Attempt 1: Roblox MCP Attempt 2: Unity MCP Attempt 3: Web Stack Comparison Summary The Solution: VibeGame Design Philosophy So Does It Actually Work? Try It Yourself What's Next? The Problem People are trying to vibe code games. And it kind of works, at first. However, as the project grows, things begin to fall apart. Why? And what can we do about it? I'll talk about the problem, how I fixed it, and where to go from here. What Is \"Vibe Coding\"? First, what is vibe coding? It's originally coined by Andrej Karpathy in a viral tweet where it's defined as where you \"fully give in to the vibes, embrace exponentials and forget the code even exists\". However, since then, it's used descriptively to mean a lot of different things, anywhere from just \"using AI when coding\" to...", "url": "https://huggingface.co/blog/vibegame", "date_published": "2025-09-29T00:00:00"}, {"id": "https://huggingface.co/blog/swift-transformers", "image": "https://huggingface.co/blog/assets/swift-transformers/swift-transformers-thumb.png", "title": "Swift Transformers Reaches 1.0 \u2014 and Looks to the Future", "content_text": "Back to Articles Swift Transformers Reaches 1.0 \u2013 and Looks to the Future Published September 26, 2025 Update on GitHub Upvote 24 +18 Pedro Cuenca pcuenq Follow Christopher Fleetwood FL33TW00D-HF Follow Mattt mattt Follow Vaibhav Srivastav reach-vb Follow What is swift-transformers How is the community using it What changes with v1.0 Usage Examples What comes next We couldn\u2019t have done this without you \ud83e\udef5 We released swift-transformers two years ago (!) with the goal to support Apple developers and help them integrate local LLMs in their apps. A lot has changed since then (MLX and chat templates did not exist!), and we\u2019ve learned how the community is actually using the library. We want to double down on the use cases that provide most benefits to the community, and lay out the foundations for the future. Spoiler alert: after this release, we\u2019ll focus a lot on MLX and agentic use cases \ud83d\ude80 What is swift-transformers swift-transformers is a Swift library that aims to reduce the friction...", "url": "https://huggingface.co/blog/swift-transformers", "date_published": "2025-09-26T00:00:00"}, {"id": "https://huggingface.co/blog/smol2operator", "image": "https://huggingface.co/blog/assets/smol2operator/thumbnail.png", "title": "Smol2Operator: Post-Training GUI Agents for Computer Use", "content_text": "Back to Articles Smol2Operator: Post-Training GUI Agents for Computer Use Published September 23, 2025 Update on GitHub Upvote 101 +95 Amir Mahla A-Mahla Follow merve merve Follow Sergio Paniego sergiopaniego Follow Vaibhav Srivastav reach-vb Follow Lewis Tunstall lewtun Follow Table of Contents Introduction 1. Data Transformation and Unified Action Space The Challenge of Inconsistent Action Spaces Our Unified Approach Example Data Transformation (Bonus) Custom Action Space Adaptation with Action Space Converter Key Features Usage Example Transformed and Released Datasets 2. Phase 1: From Zero to Perception Training Data Optimization Experiments Image Resolution and Coordinate System Analysis Key Findings Phase 1 Results 3. Phase 2: From Perception to Cognition Training Data Phase 2 Results 4. All you need is Open Source 5. Conclusion What's Next? TL;DR: This work shows how a lightweight vision\u2013language model can acquire GUI-grounded skills and evolve into an agentic GUI coder. We...", "url": "https://huggingface.co/blog/smol2operator", "date_published": "2025-09-23T00:00:00"}, {"id": "https://huggingface.co/blog/gaia2", "image": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_mare_gaia2.png", "title": "Gaia2 and ARE: Empowering the community to study agents", "content_text": "Back to Articles Gaia2 and ARE: Empowering the Community to Evaluate Agents Published September 22, 2025 Update on GitHub Upvote 96 +90 Cl\u00e9mentine Fourrier clefourrier Follow OpenEvals Maxime Lecanu mlcu Follow meta-agents-research-environments Pierre Andrews mortimerp9 Follow meta-agents-research-environments Adrien Carreira XciD Follow frere thibaud tfrere Follow Avijit Ghosh evijit Follow hfpolicy Romain Froger RomainFroger Follow meta-agents-research-environments Dheeraj Mekala dheeraj7596 Follow meta-agents-research-environments Caroline Pascal CarolinePascal Follow lerobot Ulyana Piterbarg upiter Follow meta-agents-research-environments Gaia2: Agentic Evaluation on Real Life Assistant Tasks How does Gaia2 run? Results Compare with your favorite models! Evaluating on Gaia2 Beyond Gaia2: study your agents with ARE 1) Testing an agent on a simple task: event organisation 2) Understanding agents: deep diving the traces 3) Playing around and extending the demo: Connecting the agent...", "url": "https://huggingface.co/blog/gaia2", "date_published": "2025-09-22T00:00:00"}, {"id": "https://huggingface.co/blog/inference-providers-scaleway", "image": "https://huggingface.co/blog/assets/inference-providers/welcome-scaleway.jpg", "title": "Scaleway on Hugging Face Inference Providers \ud83d\udd25", "content_text": "Back to Articles Scaleway on Hugging Face Inference Providers \ud83d\udd25 Published September 19, 2025 Update on GitHub Upvote 18 +12 Guillaume Noale gnoale Follow guest Franck P. fpagny Follow guest Fred Bardolle f14e Follow scaleway Guillaume Calmettes gcalmettes Follow guest Constance Morales C-morales Follow guest C\u00e9lina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Scaleway is now a supported Inference Provider on the Hugging Face Hub! Scaleway joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub\u2019s model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access popular open-...", "url": "https://huggingface.co/blog/inference-providers-scaleway", "date_published": "2025-09-19T00:00:00"}, {"id": "https://huggingface.co/blog/riskrubric", "image": "https://huggingface.co/blog/assets/riskrubric/thumbnail.png", "title": "Democratizing AI Safety with RiskRubric.ai", "content_text": "Back to Articles Democratizing AI Safety with RiskRubric.ai Published September 18, 2025 Update on GitHub Upvote 15 +9 Gal Moyal galmo-noma Follow guest Risk Rubric, a new Standardized Assessment of Risk for models What we found (as of September 2025) Conclusion Building trust in the open model ecosystem through standardized risk assessment More than 500,000 models can be found on the Hugging Face hub, but it\u2019s not always clear to users how to choose the best model for them, notably on the security aspects. Developers might find a model that perfectly fits their use case, but have no systematic way to evaluate its security posture, privacy implications, or potential failure modes. As models become more powerful and adoption accelerates, we need equally rapid progress in AI safety and security reporting. We're therefore excited to announce RiskRubric.ai , a novel initiative led by Cloud Security Alliance and Noma Security , with contributions by Haize Labs and Harmonic Security, for...", "url": "https://huggingface.co/blog/riskrubric", "date_published": "2025-09-18T00:00:00"}, {"id": "https://huggingface.co/blog/inference-providers-publicai", "image": "https://huggingface.co/blog/assets/inference-providers/welcome-publicai.jpg", "title": "Public AI on Hugging Face Inference Providers \ud83d\udd25", "content_text": "Back to Articles Public AI on Hugging Face Inference Providers \ud83d\udd25 Published September 17, 2025 Update on GitHub Upvote 19 +13 Joseph Low Jolow Follow publicai Joshua Tan thelastjosh Follow publicai C\u00e9lina Hanouti celinah Follow Julien Chaumond julien-c Follow Simon Brandeis sbrandeis Follow Lucain Pouget Wauplin Follow How it works In the website UI From the client SDKs Billing Feedback and next steps We're thrilled to share that Public AI is now a supported Inference Provider on the Hugging Face Hub! Public AI joins our growing ecosystem, enhancing the breadth and capabilities of serverless inference directly on the Hub\u2019s model pages. Inference Providers are also seamlessly integrated into our client SDKs (for both JS and Python), making it super easy to use a wide variety of models with your preferred providers. This launch makes it easier than ever to access public and sovereign models from institutions like the Swiss AI Initiative and AI Singapore \u2014 right from Hugging Face. You...", "url": "https://huggingface.co/blog/inference-providers-publicai", "date_published": "2025-09-17T00:00:00"}, {"id": "https://huggingface.co/blog/lerobot-datasets-v3", "image": "https://huggingface.co/blog/assets/lerobot-dataset-v3/thumbnail.png", "title": "`LeRobotDataset`: Bringing large-scale datasets to lerobot", "content_text": "Back to Articles LeRobotDataset:v3.0: Bringing large-scale datasets to lerobot Published September 16, 2025 Update on GitHub Upvote 30 +24 Francesco Capuano fracapuano Follow Michel Aractingi aractingi Follow Quentin Lhoest lhoestq Follow Caroline Pascal CarolinePascal Follow Pepijn Kooijmans pepijn223 Follow Jade Choghari jadechoghari Follow Remi Cadene cadene Follow Simon Alibert aliberts Follow Adil Zouitine AdilZtn Follow Martino Russi nepyope Follow Steven Palma imstevenpmwork Follow Table of Contents LeRobotDataset, v3.0 Install lerobot , and record a dataset Migrate your v2.1 dataset to v3.0 Code Example: Using LeRobotDataset with torch.utils.data.DataLoader Streaming Conclusion Acknowledgements TL;DR Today we release LeRobotDataset:v3 ! In our previous LeRobotDataset:v2 release, we stored one episode per file, hitting file-system limitations when scaling datasets to millions of episodes. LeRobotDataset:v3 packs multiple episodes in a single file, using relational metadata to...", "url": "https://huggingface.co/blog/lerobot-datasets-v3", "date_published": "2025-09-16T00:00:00"}, {"id": "https://huggingface.co/blog/watermarking-with-gradio", "image": "https://huggingface.co/blog/assets/watermarking-with-gradio/thumbnail.png", "title": "Visible Watermarking with Gradio", "content_text": "Back to Articles Visible Watermarking with Gradio Published September 15, 2025 Update on GitHub Upvote 16 +10 Margaret Mitchell meg Follow Last year, we shared a blogpost on watermarking , explaining what it means to watermark generative AI content, and why it's important. The need for watermarking has become even more critical as people all over the world have begun to generate and share AI-generated images, video, audio, and text. Images and video have become so realistic that they\u2019re nearly impossible to distinguish from what you\u2019d see captured by a real camera. Addressing this issue is multi-faceted, but there is one, clear, low-hanging fruit \ud83c\udf47: In order for people to know what's real and what's synthetic, use visible watermarks. To help out, we at Hugging Face have made visible watermarking trivially easy: Whenever you create a Space like an app or a demo , you can use our in-house app-building library Gradio to display watermarks with a single command. For images and video,...", "url": "https://huggingface.co/blog/watermarking-with-gradio", "date_published": "2025-09-15T00:00:00"}, {"id": "https://huggingface.co/blog/faster-transformers", "image": "https://huggingface.co/blog/assets/faster-transformers/thumbnail.png", "title": "Tricks from OpenAI gpt-oss YOU \ud83e\udef5 can use with transformers", "content_text": "Back to Articles Tricks from OpenAI gpt-oss YOU \ud83e\udef5 can use with transformers Published September 11, 2025 Update on GitHub Upvote 149 +143 Aritra Roy Gosthipaty ariG23498 Follow Sergio Paniego sergiopaniego Follow Vaibhav Srivastav reach-vb Follow Pedro Cuenca pcuenq Follow Arthur Zucker ArthurZ Follow Nathan Habib SaylorTwift Follow Cyril Vallez cyrilvallez Follow Zero-build Kernels, downloadable from the Hub Custom Kernels for GPT-OSS Flash Attention 3 MXFP4 Quantization What is MXFP4 MXFP4 in transformers Requirements and fallbacks Kernels for MXFP4 Tensor Parallelism What this enables in transformers When to reach for TP Expert Parallelism Dynamic Sliding Window Layer & Cache How to use it Continuous Batching & Paged Attention Load larger models faster Conclusion Read More OpenAI recently released their GPT-OSS series of models . The models feature some novel techniques like MXFP4 quantization, efficient kernels, a brand new chat format, and more. To enable the release of gpt-oss...", "url": "https://huggingface.co/blog/faster-transformers", "date_published": "2025-09-11T00:00:00"}, {"id": "https://huggingface.co/blog/jupyter-agent-2", "image": "https://huggingface.co/blog/assets/jupyter-agent-2/thumbnail.png", "title": "Jupyter Agents: training LLMs to reason with notebooks", "content_text": "Back to Articles Jupyter Agents: training LLMs to reason with notebooks Published September 10, 2025 Update on GitHub Upvote 46 +40 Baptiste Colle baptistecolle Follow Hanna Yukhymenko hannayukhymenko Follow Leandro von Werra lvwerra Follow \ud83c\udfc1 Primer: the DABStep Benchmark \ud83c\udfaf First Baseline \ud83d\udd27 Primer on Scaffolding \ud83c\udfc3\u200d\u2642\ufe0f Training Pipeline \u2699\ufe0f Dataset Pipeline 1. Large-scale deduplication 2. Downloading linked datasets 3. Edu scoring 4. Filtering irrelevant notebooks 5. QA generation 6. Trace generation 7. Final curation \ud83c\udfc3\u200d\u2642\ufe0f Training Pipeline \ud83d\udcca Results Try Jupyter Agent Yourself \ud83d\udd2e Next Steps The past year has been all about giving LLMs more tools and autonomy to solve more complex and open ended tasks. The goal of the Jupyter Agent is to give the model the ultimate tool: code execution. A natural way to display multi-step code execution together with reasoning is within a Jupyter Notebook, which consists of code and markdown cells. So we built Jupyter Agent to act as an agent that can...", "url": "https://huggingface.co/blog/jupyter-agent-2", "date_published": "2025-09-10T00:00:00"}, {"id": "https://huggingface.co/blog/mmbert", "image": "https://huggingface.co/blog/assets/mmbert/thumbnail.png", "title": "mmBERT: ModernBERT goes Multilingual", "content_text": "Back to Articles mmBERT: ModernBERT goes Multilingual Published September 9, 2025 Update on GitHub Upvote 102 +96 Marc Marone mmarone Follow jhu-clsp Orion Weller orionweller Follow jhu-clsp William Fleshman will-fleshman Follow guest Eugene Yang eugene-yang Follow jhu-clsp Dawn Lawrie dlawrie Follow jhu-clsp Ben Van Durme vandurme Follow jhu-clsp TL;DR Training Data Training Recipe and Novel Components Architecture Three-Phase Training Approach Novel Training Techniques Results Natural Language Understanding (NLU) Retrieval Performance Learning Languages in the Decay Phase Efficiency Improvements Usage Examples Fine-tuning Examples Encoders Model Family and Links TL;DR This blog post introduces mmBERT , a state-of-the-art massively multilingual encoder model trained on 3T+ tokens of text in over 1800 languages. It shows significant performance and speed improvements over previous multilingual models, being the first to improve upon XLM-R, while also developing new strategies for...", "url": "https://huggingface.co/blog/mmbert", "date_published": "2025-09-09T00:00:00"}, {"id": "https://huggingface.co/blog/embeddinggemma", "image": "https://huggingface.co/blog/assets/embeddinggemma/thumbnail.png", "title": "Welcome EmbeddingGemma, Google's new efficient embedding model", "content_text": "Back to Articles Welcome EmbeddingGemma, Google's new efficient embedding model Published September 4, 2025 Update on GitHub Upvote 230 +224 Tom Aarsen tomaarsen Follow Joshua Xenova Follow Alvaro Bartolome alvarobartt Follow Aritra Roy Gosthipaty ariG23498 Follow Pedro Cuenca pcuenq Follow Sergio Paniego sergiopaniego Follow TL;DR Table of Contents Introduction Architecture Evaluation Demo Usage Sentence Transformers LangChain LlamaIndex Haystack txtai Transformers.js Text Embeddings Inference ONNX Runtime Finetuning Full Finetuning Script Training Finetuned Evaluation Further Reading TL;DR Today, Google releases EmbeddingGemma , a state-of-the-art multilingual embedding model perfect for on-device use cases. Designed for speed and efficiency, the model features a compact size of 308M parameters and a 2K context window , unlocking new possibilities for mobile RAG pipelines, agents, and more. EmbeddingGemma is trained to support over 100 languages and is the highest-ranking text-...", "url": "https://huggingface.co/blog/embeddinggemma", "date_published": "2025-09-04T00:00:00"}, {"id": "https://huggingface.co/blog/zerogpu-aoti", "image": "https://huggingface.co/blog/assets/zerogpu-aoti/thumbnail.png", "title": "Make your ZeroGPU Spaces go brrr with PyTorch ahead-of-time compilation", "content_text": "Back to Articles Make your ZeroGPU Spaces go brrr with ahead-of-time compilation Published September 2, 2025 Update on GitHub Upvote 64 +58 Charles Bensimon cbensimon Follow Sayak Paul sayakpaul Follow Linoy Tsaban linoyts Follow Apolin\u00e1rio from multimodal AI art multimodalart Follow Table of Contents What is ZeroGPU PyTorch compilation Ahead-of-time compilation on ZeroGPU 1. Getting example inputs 2. Exporting the model 3. Compiling the exported model 4. Using the compiled model in the pipeline 5. Wrapping it all together Gotchas Quantization Dynamic shapes Multi-compile / shared weights FlashAttention-3 Regional compilation Use a compiled graph from the Hub AoT compiled ZeroGPU Spaces demos Speedup comparison Featured AoTI Spaces Regional compilation Conclusion Resources ZeroGPU lets anyone spin up powerful Nvidia H200 hardware in Hugging Face Spaces without keeping a GPU locked for idle traffic. It\u2019s efficient, flexible, and ideal for demos but it doesn\u2019t always make full use of...", "url": "https://huggingface.co/blog/zerogpu-aoti", "date_published": "2025-09-02T00:00:00"}]}