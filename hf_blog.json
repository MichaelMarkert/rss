{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/transformers-model-definition", "image": "https://huggingface.co/blog/assets/transformers-model-definition/transformers-thumbnail.png", "title": "The Transformers Library: standardizing model definitions", "content_text": "Back to Articles The Transformers Library: standardizing model definitions Published May 15, 2025 Update on GitHub Upvote 79 +73 lysandre Lysandre ArthurZ Arthur Zucker pcuenq Pedro Cuenca julien-c Julien Chaumond A model-definition library Striving for even simpler model contributions How does this affect you? What this means for you, as a model user What this means for you, as a model creator TLDR: Going forward, we're aiming for Transformers to be the pivot across frameworks: if a model architecture is supported by transformers, you can expect it to be supported in the rest of the ecosystem. Transformers was created in 2019, shortly following the release of the BERT Transformer model. Since then, we've continuously aimed to add state-of-the-art architectures, initially focused on NLP, then growing to Audio and computer vision. Today, transformers is the default library for LLMs and VLMs in the Python ecosystem. Transformers now supports 300+ model architectures, with an average...", "url": "https://huggingface.co/blog/transformers-model-definition", "date_published": "2025-05-15T00:00:00"}, {"id": "https://huggingface.co/blog/kaggle-integration", "image": "https://huggingface.co/blog/assets/kaggle-integration/thumbnail.png", "title": "Improving Hugging Face Model Access for Kaggle Users", "content_text": "Back to Articles Improving Hugging Face Model Access for Kaggle Users Published May 14, 2025 Update on GitHub Upvote 18 +12 roseberryv Vincent Roseberry kaggle megrisdal Meg Risdal kaggle julien-c Julien Chaumond pcuenq Pedro Cuenca reach-vb Vaibhav Srivastav How to get started How does this work with private and consent-gated Hugging Face models? What\u2019s next Kaggle and Hugging Face users are part of one AI community. That\u2019s why we\u2019re excited to announce our plans to bring our platforms and communities closer to better serve AI developers everywhere. Beginning today, Kaggle is launching an integration that enhances visibility and discoverability for Hugging Face models directly on Kaggle. How to get started You can navigate from Hugging Face models to Kaggle and vice versa. Start by visiting a Hugging Face model page like Qwen/Qwen3-1.7B . To use it in a Kaggle Notebook, you can click on \u201cUse this model\u201d and select \u201cKaggle\u201d to open up a Kaggle notebook with a pre-populated code...", "url": "https://huggingface.co/blog/kaggle-integration", "date_published": "2025-05-14T00:00:00"}, {"id": "https://huggingface.co/blog/fast-whisper-endpoints", "image": "https://huggingface.co/blog/assets/fast-whisper-endpoints/thumbnail.png", "title": "Blazingly fast whisper transcriptions with Inference Endpoints", "content_text": "Back to Articles Blazingly fast whisper transcriptions with Inference Endpoints Published May 13, 2025 Update on GitHub Upvote 56 +50 mfuntowicz Morgan Funtowicz freddyaboulton Freddy Boulton Steveeeeeeen Steven Zheng reach-vb Vaibhav Srivastav erikkaum Erik Kaunism\u00e4ki michellehbn Michelle Habonneau Inference Stack Benchmarks How to deploy Inference FastRTC Demo Today we are happy to introduce a new blazing fast OpenAI Whisper deployment option on Inference Endpoints . It provides up to 8x performance improvements compared to the previous version, and makes everyone one click away from deploying dedicated, powerful transcription models in a cost-effective way, leveraging the amazing work done by the AI community. Through this release, we would like to make Inference Endpoints more community-centric and allow anyone to come and contribute to create incredible inference deployments on the Hugging Face Platform. Along with the community, we would like to propose optimized deployments...", "url": "https://huggingface.co/blog/fast-whisper-endpoints", "date_published": "2025-05-13T00:00:00"}, {"id": "https://huggingface.co/blog/vlms-2025", "image": "https://huggingface.co/blog/assets/vlms2/vlms2.png", "title": "Vision Language Models (Better, Faster, Stronger)", "content_text": "Back to Articles Vision Language Models (Better, Faster, Stronger) Published May 12, 2025 Update on GitHub Upvote 310 +304 merve Merve Noyan sergiopaniego Sergio Paniego ariG23498 Aritra Roy Gosthipaty pcuenq Pedro Cuenca andito Andres Marafioti Motivation Table of Contents New model trends Any-to-any models Reasoning Models Smol yet Capable Models Mixture-of-Experts as Decoders Vision-Language-Action Models Specialized Capabilities Object Detection, Segmentation, Counting with Vision Language Models Multimodal Safety Models Multimodal RAG: retrievers, rerankers Multimodal Agents Video Language Models New Alignment Techniques for Vision Language Models New benchmarks MMT-Bench MMMU-Pro Useful Resources Motivation Vision Language Models (VLMs) are the talk of the town. In a previous blog post (from April 2024 ), we talked a lot about VLMs. A major chunk was about LLaVA , the first successful and easily reproducible open-source vision language model, along with tips on how to...", "url": "https://huggingface.co/blog/vlms-2025", "date_published": "2025-05-12T00:00:00"}, {"id": "https://huggingface.co/blog/lerobot-datasets", "image": "https://huggingface.co/blog/assets/195_lerobot_datasets/1.png", "title": "LeRobot Community Datasets: The \u201cImageNet\u201d of Robotics \u2014 When and How?", "content_text": "Back to Articles LeRobot Community Datasets: The \u201cImageNet\u201d of Robotics \u2014 When and How? Published May 11, 2025 Update on GitHub Upvote 45 +39 danaaubakirova Dana Aubakirova Beegbrain Alexandre Chapin guest mshukor Mustafa Shukor m1b Marina guest villekuosmanen Ville Kuosmanen guest cadene Remi Cadene pcuenq Pedro Cuenca Introduction From Models to Data: Shifting the Perspective Why does Robotics lack its ImageNet Moment? Building a LeRobot Community Scaling Responsibly Better data = Better models Challenges with Current Community Datasets 1. Incomplete or Inconsistent Task Annotations 2. Feature Mapping Inconsistencies 3. Low-Quality or Incomplete Episodes 4. Inconsistent Action/State Dimensions What Makes a Good Dataset? Image Quality Metadata & Recording Protocol Feature Naming Conventions Task Annotation How Can You Help? \ud83e\udded TL;DR \u2014 Why This Blogpost? In this post, we: Recognize the growing impact of community-contributed LeRobot datasets Highlight the current challenges in...", "url": "https://huggingface.co/blog/lerobot-datasets", "date_published": "2025-05-11T00:00:00"}, {"id": "https://huggingface.co/blog/gradio-mcp", "image": "https://huggingface.co/blog/assets/gradio-mcp/thumbnail.png", "title": "How to Build an MCP Server with Gradio", "content_text": "Back to Articles How to Build an MCP Server in 5 Lines of Python Published April 30, 2025 Update on GitHub Upvote 104 +98 abidlabs Abubakar Abid ysharma yuvraj sharma Why Build an MCP Server? Example: Counting Letters in a Word Key features of the Gradio <> MCP Integration Further Reading Gradio is a Python library used by more than 1 million developers each month to build interfaces for machine learning models. Beyond just creating UIs, Gradio also exposes API capabilities and \u2014 now! \u2014 Gradio apps can be launched Model Context Protocol (MCP) servers for LLMs. This means that your Gradio app, whether it's an image generator or a tax calculator or something else entirely, can be called as a tool by an LLM. This guide will show you how to use Gradio to build an MCP server in just a few lines of Python. Prerequisites If not already installed, please install Gradio with the MCP extra: pip install \"gradio[mcp]\" This will install the necessary dependencies, including the mcp package....", "url": "https://huggingface.co/blog/gradio-mcp", "date_published": "2025-04-30T00:00:00"}, {"id": "https://huggingface.co/blog/llama-guard-4", "image": "https://huggingface.co/blog/assets/llama-guard-4/thumbnail.png", "title": "Welcoming Llama Guard 4 on Hugging Face Hub", "content_text": "Back to Articles Welcoming Llama Guard 4 on Hugging Face Hub Published April 29, 2025 Update on GitHub Upvote 36 +30 merve Merve Noyan ariG23498 Aritra Roy Gosthipaty sergiopaniego Sergio Paniego pcuenq Pedro Cuenca Table-of-Contents What is Llama Guard 4? Model Details Llama Guard 4 Llama Prompt Guard 2 Getting Started using \ud83e\udd17 transformers Llama Prompt Guard 2 Useful Resources TL;DR: Today, Meta releases Llama Guard 4, a 12B dense (not a MoE!) multimodal safety model, and two new Llama Prompt Guard 2 models. This release comes with multiple open model checkpoints, along with an interactive notebook for you to get started easily \ud83e\udd17. Model checkpoints can be found in Llama 4 Collection . Table-of-Contents What is Llama Guard 4? Model Details Llama Guard 4 Llama Prompt Guard 2 Getting Started using \ud83e\udd17transformers Llama Guard 4 Llama Prompt Guard 2 Useful Resources What is Llama Guard 4? Vision and large language models deployed to production can be exploited to generate unsafe output...", "url": "https://huggingface.co/blog/llama-guard-4", "date_published": "2025-04-29T00:00:00"}, {"id": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive", "image": "https://huggingface.co/blog/assets/qwen-3-chat-template-deep-dive/thumbnail.png", "title": "The 4 Things Qwen-3's Chat Template Teaches Us", "content_text": "Back to Articles The 4 Things Qwen-3\u2019s Chat Template Teaches Us Published April 30, 2025 Update on GitHub Upvote 38 +32 cfahlgren1 Caleb Fahlgren What is a Chat Template? 1. Reasoning doesn't have to be forced 2. Context Management Should be Dynamic Example 3. Tool Arguments Need Better Serialization 4. There's No Need for a Default System Prompt Conclusion What a boring Jinja snippet tells us about the new Qwen-3 model. The new Qwen-3 model by Qwen ships with a much more sophisticated chat template than it's predecessors Qwen-2.5 and QwQ. By taking a look at the differences in the Jinja template, we can find interesting insights into the new model. Chat Templates Qwen-3 Chat Template Qwen-2.5 Chat Template Qwen-QwQ Chat Template What is a Chat Template? A chat template defines how conversations between users and models are structured and formatted. The template acts as a translator, converting a human-readable conversation: [ { role : \"user\" , content : \"Hi there!\" }, { role :...", "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive", "date_published": "2025-04-30T00:00:00"}, {"id": "https://huggingface.co/blog/tiny-agents", "image": "https://huggingface.co/blog/assets/tiny-agents/thumbnail.jpg", "title": "Tiny Agents: a MCP-powered agent in 50 lines of code", "content_text": "Back to Articles Tiny Agents: an MCP-powered agent in 50 lines of code Published April 25, 2025 Update on GitHub Upvote 242 +236 julien-c Julien Chaumond How to run the complete demo Default model and provider Where does the code live The foundation for this: tool calling native support in LLMs. Implementing an MCP client on top of InferenceClient How to use the tools Our 50-lines-of-code Agent \ud83e\udd2f The complete while loop Next steps Over the past few weeks, I've been diving into MCP ( Model Context Protocol ) to understand what the hype around it was all about. My TL;DR is that it's fairly simple, but still quite powerful: MCP is a standard API to expose sets of Tools that can be hooked to LLMs. It is fairly simple to extend an Inference Client \u2013 at HF, we have two official client SDKs: @huggingface/inference in JS, and huggingface_hub in Python \u2013 to also act as a MCP client and hook the available tools from MCP servers into the LLM inference. But while doing that, came my second...", "url": "https://huggingface.co/blog/tiny-agents", "date_published": "2025-04-25T00:00:00"}, {"id": "https://huggingface.co/blog/autoround", "image": "https://huggingface.co/blog/assets/autoround/thumbnail.png", "title": "Introducing AutoRound: Intel\u2019s Advanced Quantization for LLMs and VLMs", "content_text": "Back to Articles What is AutoRound? Published April 29, 2025 Update on GitHub Upvote 26 +20 wenhuach wenhua cheng Intel Haihao Haihao Shen Intel weiweiz1 weiweiz1 Intel n1ck-guo Heng Guo Intel isaacmac Huang, Tai Intel kding1 Ke Ding Intel IlyasMoutawwakil Ilyas Moutawwakil marcsun13 Marc Sun medmekk Mohamed Mekkouri Superior Accuracy at Low Bit Widths 2. Broad Compatibility Models Devices Quantization Configurations Export Formats 3. Flexible/Efficient Quantization Installation Quantization and Serialization Command Line Usage AutoRound API Usage Inference CPU/Intel GPU/CUDA Convert GPTQ/AWQ to AutoRound As large language models (LLMs) and vision-language models (VLMs) continue to grow in size and complexity, deploying them efficiently becomes increasingly challenging. Quantization offers a solution by reducing model size and inference latency. Intel's AutoRound emerges as a cutting-edge quantization tool that balances accuracy, efficiency, and compatibility. AutoRound is a weight-...", "url": "https://huggingface.co/blog/autoround", "date_published": "2025-04-29T00:00:00"}, {"id": "https://huggingface.co/blog/why-gradio-stands-out", "image": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png", "title": "17 Reasons Why Gradio Isn't Just Another UI Library", "content_text": "Back to Articles 17 Reasons Why Gradio Isn't Just Another UI Library Published April 16, 2025 Update on GitHub Upvote 32 +26 ysharma yuvraj sharma abidlabs Abubakar Abid Introduction 1. Universal API Access 2. Interactive API Recorder for Development 3. Fast ML Apps with Server-Side Rendering 4. Automatic Queue Management for ML Tasks 5. High-Performance Streaming for Real-Time ML Outputs 6. Integrated Multi-Page Application Support 7. New Client-Side Function Execution With Groovy 8. A Comprehensive Theming System and Modern UI Components 9. Gradio's Dynamic Interfaces 10. Visual Interface Development with Gradio Sketch 11. Progressive Web App (PWA) Support 12. In-Browser Execution with Gradio Lite 13. Accelerated Development with AI-Assisted Tooling 14. Hassle-Free App Sharing 15. Enterprise-Grade Security and Production Readiness 16. Enhanced Dataframe Component 17. Deep Links for Sharing App States Conclusion Introduction \"Oh, Gradio? That's a Python library for building UIs,...", "url": "https://huggingface.co/blog/why-gradio-stands-out", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/inference-providers-cohere", "image": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png", "title": "Cohere on Hugging Face Inference Providers \ud83d\udd25", "content_text": "Back to Articles Cohere on Hugging Face Inference Providers \ud83d\udd25 Published April 16, 2025 Update on GitHub Upvote 125 +119 reach-vb Vaibhav Srivastav burtenshaw ben burtenshaw merve Merve Noyan celinah C\u00e9lina Hanouti alexrs Alejandro Rodriguez CohereLabs julien-c Julien Chaumond sbrandeis Simon Brandeis Cohere Models CohereLabs/c4ai-command-a-03-2025 \ud83d\udd17 CohereLabs/aya-expanse-32b \ud83d\udd17 CohereLabs/c4ai-command-r7b-12-2024 \ud83d\udd17 CohereLabs/aya-vision-32b \ud83d\udd17 How it works In the website UI From the client SDKs From OpenAI client Tool Use with Cohere Models Billing We're thrilled to share that Cohere is now a supported Inference Provider on HF Hub! This also marks the first model creator to share and serve their models directly on the Hub. Cohere is committed to building and serving models purpose-built for enterprise use-cases. Their comprehensive suite of secure AI solutions, from cutting-edge Generative AI to powerful Embeddings and Ranking models, are designed to tackle real-world business...", "url": "https://huggingface.co/blog/inference-providers-cohere", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/helmet", "image": "https://huggingface.co/blog/assets/helmet/thumbnail.png", "title": "Introducing HELMET", "content_text": "Back to Articles Introducing HELMET : Holistically Evaluating Long-context Language Models Published April 16, 2025 Update on GitHub Upvote 27 +21 hyen Howard Yen guest gaotianyu1350 Tianyu Gao guest houminmin Minmin Hou Intel kding1 Ke Ding Intel danf Daniel Fleischer Intel moshew Moshe Wasserblat Intel cdq10131 Danqi Chen guest Evaluating long-context language models is challenging but important Existing evaluations overly rely on synthetic tasks Crafting diverse, controllable, and reliable evaluation for LCLMs Key improvements over existing benchmarks LCLMs still have a long way to go on real-world tasks Diverse evaluation is needed for assessing long-context abilities Models degrade with increasing lengths and task complexity Using HELMET for future developments How to run HELMET Faster development Quick comparison with existing models Looking ahead Acknowledgements Citation Contact: hyen@cs.princeton.edu Paper: https://arxiv.org/abs/2410.02694 Website: https://princeton-...", "url": "https://huggingface.co/blog/helmet", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition", "image": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png", "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition \ud83e\udd16", "content_text": "Back to Articles Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition \ud83e\udd16 Published April 14, 2025 Update on GitHub Upvote 46 +40 thomwolf Thomas Wolf clem Clem \ud83e\udd17 matthieu-lapeyre Matthieu Lapeyre pollen-robotics Hugging Face\u2019s Robotics Venture Timeline About Hugging Face About Pollen Robotics About Reachy 2 Simon Alibert and R\u00e9mi Cad\u00e8ne from the LeRobot team with Reachy 1 \u2014 Photo: L\u00e9a Crespi Since Hugging Face started the LeRobot library in 2024, led by ex-Tesla lead Remi Cadene, the Hugging Face Hub has quickly become the most widely used hub and software platform for open robotics with models, datasets, spaces and libraries. Today, we\u2019re excited to take it a step further by welcoming Pollen Robotics to Hugging Face, a team that's spent the last 9 years building open-source robots and hardware. We believe robotics could be the next frontier unlocked by AI \u2014 and it should be open, affordable, and private. Our vision: a future where everyone in the community,...", "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition", "date_published": "2025-04-14T00:00:00"}, {"id": "https://huggingface.co/blog/pai-6-month", "image": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png", "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In", "content_text": "Back to Articles 4M Models Scanned: Protect AI + Hugging Face 6 Months In Published April 14, 2025 Update on GitHub Upvote 29 +23 sean-pai Sean Morgan protectai Maintaining a Zero Trust Approach to Model Security Evolving Guardian\u2019s Model Vulnerability Detection Capabilities Common attack themes Delivering Comprehensive Threat Detection for Hugging Face Users It Only Gets Better from Here Hugging Face and Protect AI partnered in October 2024 to enhance machine learning (ML) model security through Guardian\u2019s scanning technology for the community of developers who explore and use models from the Hugging Face Hub. The partnership has been a natural fit from the start\u2014Hugging Face is on a mission to democratize the use of open source AI, with a commitment to safety and security; and Protect AI is building the guardrails to make open source models safe for all. 4 new threat detection modules launched Since October, Protect AI has significantly expanded Guardian's detection capabilities,...", "url": "https://huggingface.co/blog/pai-6-month", "date_published": "2025-04-14T00:00:00"}]}