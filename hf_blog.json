{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/transformers-v5", "image": "https://huggingface.co/blog/assets/transformers_v5/transformers-thumbnail.png", "title": "Transformers v5: Simple model definitions powering the AI ecosystem", "content_text": "Back to Articles Transformers v5: Simple model definitions powering the AI ecosystem Published December 1, 2025 Update on GitHub Upvote 178 +172 Lysandre lysandre Follow Arthur Zucker ArthurZ Follow Cyril Vallez cyrilvallez Follow Vaibhav Srivastav reach-vb Follow Simplicity Model Additions Code Reduction Training Pre-training at scale Fine-tuning & Post-training Inference Production & Local Quantization Conclusion Transformers' version v4.0.0rc-1, the initial release candidate for version 4, was released on November 19th, 2020. Five years later, we now release v5.0.0rc-0. Today, as we launch v5, Transformers is installed more than 3 million times each day via pip - up from 20,000/day in v4 \ud83e\udd2f. Altogether, it has now surpassed 1.2 billion installs ! The ecosystem has expanded from 40 model architectures in v4 to over 400 today , and the community has contributed more than 750,000 model checkpoints on the Hub compatible with Transformers, up from roughly 1,000 at the time of v4. This...", "url": "https://huggingface.co/blog/transformers-v5", "date_published": "2025-12-01T00:00:00"}, {"id": "https://huggingface.co/blog/flux-2", "image": "https://huggingface.co/blog/assets/flux2/thumbnail.png", "title": "Diffusers welcomes FLUX-2", "content_text": "Back to Articles Welcome FLUX.2 - BFL\u2019s new open image generation model \ud83e\udd17 Published November 25, 2025 Update on GitHub Upvote 148 +142 YiYi Xu YiYiXu Follow Daniel Gu dg845 Follow Sayak Paul sayakpaul Follow Alvaro Somoza OzzyGT Follow Dhruv Nair dn6 Follow Aritra Roy Gosthipaty ariG23498 Follow Linoy Tsaban linoyts Follow Apolin\u00e1rio from multimodal AI art multimodalart Follow FLUX.2: A Brief Introduction Text encoder DiT Misc Inference With Diffusers Installation and Authentication Regular Inference Resource-constrained Multiple images as reference Advanced Prompting LoRA fine-tuning Memory optimizations for fine-tuning Resources FLUX.2 is the recent series of image generation models from Black Forest Labs, preceded by the Flux.1 series. It is an entirely new model with a new architecture and pre-training done from scratch! In this post, we discuss the key changes introduced in FLUX.2, performing inference with it under various setups, and LoRA fine-tuning. \ud83d\udea8 FLUX.2 is not meant to...", "url": "https://huggingface.co/blog/flux-2", "date_published": "2025-11-25T00:00:00"}, {"id": "https://huggingface.co/blog/continuous_batching", "image": "https://huggingface.co/blog/assets/continuous_batching/thumbnail.png", "title": "Continuous batching from first principles", "content_text": "Back to Articles Continuous batching Published November 25, 2025 Update on GitHub Upvote 228 +222 R\u00e9mi Ouazan Reboul ror Follow Arthur Zucker ArthurZ Follow Luc Georges mcpotato Follow Attention KV-cache Chunked prefill Continuous batching Conclusion TL;DR: in this blog post, starting from attention mechanisms and KV caching, we derive continuous batching by optimizing for throughput. If you've ever used Qwen, Claude, or any other AI chatbot, you've probably noticed something: it takes a while for the first word of the response to appear, and then words appear one-by-one on your screen with (hopefully) a regular and fast-paced frequency. That's because at the heart of it, all LLMs are just fancy next token predictors. An LLM first processes your entire prompt to produce one new token. Then it keeps adding tokens one by one, each time reading everything that came before, until it decides generation is over. This generation process is computationally expensive: it requires passing the...", "url": "https://huggingface.co/blog/continuous_batching", "date_published": "2025-11-25T00:00:00"}, {"id": "https://huggingface.co/blog/rapidfireai", "image": "https://huggingface.co/blog/assets/rapidfireai/thumbnail.png", "title": "20x Faster TRL Fine-tuning with RapidFire AI", "content_text": "Back to Articles 20x Faster TRL Fine-tuning with RapidFire AI Published November 21, 2025 Update on GitHub Upvote 19 +13 Kamran Bigdely kbigdelysh Follow rapidfire-ai-inc Arun Kumar arunkk09 Follow rapidfire-ai-inc Quentin Gallou\u00e9dec qgallouedec Follow Why this matters What you get, out of the box How it works Getting Started Supported TRL trainers Minimal TRL SFT example Benchmarks: Real-World Speedups Get Started Today Hugging Face TRL now officially integrates with RapidFire AI to accelerate your fine-tuning and post-training experiments. TRL users can now discover, install, and run RapidFire AI as the fastest way to compare multiple fine-tuning/post-training configurations to customize LLMs without major code changes and without bloating GPU requirements. Why this matters When fine-tuning or post-training LLMs, teams often do not have the time and/or budget to compare multiple configs even though that can significantly boost eval metrics. RapidFire AI lets you launch multiple...", "url": "https://huggingface.co/blog/rapidfireai", "date_published": "2025-11-21T00:00:00"}, {"id": "https://huggingface.co/blog/open-asr-leaderboard", "image": "https://huggingface.co/blog/assets/open-asr-leaderboard/thumbnail.png", "title": "Open ASR Leaderboard: Trends and Insights with New Multilingual & Long-Form Tracks", "content_text": "Back to Articles Open ASR Leaderboard: Trends and Insights with New Multilingual & Long-Form Tracks Published November 21, 2025 Update on GitHub Upvote 19 +13 Eric Bezzam bezzam Follow Steven Zheng Steveeeeeeen Follow Eustache Le Bihan eustlb Follow Vaibhav Srivastav reach-vb Follow 1. Conformer encoder \ud83e\udd1d LLM decoder tops the charts \ud83d\udcc8 2. Speed\u2013accuracy tradeoffs \u2696\ufe0f 3. Multilingual \ud83c\udf0d 4. Long-form transcription is a different game \u23f3 While everyone (and their grandma \ud83d\udc75) is spinning up new ASR models, picking the right one for your use case can feel more overwhelming than choosing your next Netflix show. As of 21 Nov 2025, there are 150 Audio-Text-to-Text and 27K ASR models on the Hub \ud83e\udd2f Most benchmarks focus on short-form English transcription (<30s), and overlook other important tasks, such as (1) multilingual performance and (2) model throughput, which can a be deciding factor for long-form audio like meetings and podcasts. Over the past two years, the Open ASR Leaderboard has become...", "url": "https://huggingface.co/blog/open-asr-leaderboard", "date_published": "2025-11-21T00:00:00"}, {"id": "https://huggingface.co/blog/anylanguagemodel", "image": "https://huggingface.co/blog/assets/anylanguagemodel/banner.png", "title": "Introducing AnyLanguageModel: One API for Local and Remote LLMs on Apple Platforms", "content_text": "Back to Articles Introducing AnyLanguageModel: One API for Local and Remote LLMs on Apple Platforms Published November 20, 2025 Update on GitHub Upvote 25 +19 Mattt mattt Follow guest The Solution Why Foundation Models as the Base API Package Traits: Include Only What You Need Image Support (and API Design Trade-offs) Try It Out: chat-ui-swift What's Next Get Involved Links LLMs have become essential tools for building software. But for Apple developers, integrating them remains unnecessarily painful. Developers building AI-powered apps typically take a hybrid approach, adopting some combination of: Local models using Core ML or MLX for privacy and offline capability Cloud providers like OpenAI or Anthropic for frontier capabilities Apple's Foundation Models as a system-level fallback Each comes with different APIs, different requirements, different integration patterns. It's a lot, and it adds up quickly. When I interviewed developers about building AI-powered apps, friction with...", "url": "https://huggingface.co/blog/anylanguagemodel", "date_published": "2025-11-20T00:00:00"}, {"id": "https://huggingface.co/blog/build-rocm-kernels", "image": "https://huggingface.co/blog/assets/build-rocm-kernels/thumbnail.png", "title": "Easily Build and Share ROCm Kernels with Hugging Face", "content_text": "Back to Articles Easily Build and Share ROCm Kernels with Hugging Face Published November 17, 2025 Update on GitHub Upvote 32 +26 Abdennacer Badaoui badaoui Follow Daniel Huang daniehua Follow colorswind ColorsWind Follow Zesen Liu ftyghome Follow Intoduction Build Steps About the kernel Step 1: Project Structure Step 2: Configuration Files Setup Step 3: Building the Kernel Step 4: Uploading the kernel to the Hub Step 5: Let's use it :) Conclusion Related Libraries & Hub Intoduction Custom kernels are the backbone of high-performance deep learning, enabling GPU operations tailored precisely to your workload; whether that\u2019s image processing, tensor transformations, or other compute-heavy tasks. But compiling these kernels for the right architectures, wiring all the build flags, and integrating them cleanly into PyTorch extensions can quickly become a mess of CMake/Nix, compiler errors, and ABI issues, which is not fun. Hugging Face\u2019s kernel-builder and kernels libraries make it easy...", "url": "https://huggingface.co/blog/build-rocm-kernels", "date_published": "2025-11-17T00:00:00"}, {"id": "https://huggingface.co/blog/google-cloud", "image": "https://huggingface.co/blog/assets/google-cloud/google-cloud-thumbnail.png", "title": "Building for an Open Future - our new partnership with Google Cloud", "content_text": "Back to Articles Building for an Open Future - our new partnership with Google Cloud Published November 13, 2025 Update on GitHub Upvote 45 +39 Jeff Boudier jeffboudier Follow Simon Pagezy pagezyhf Follow A Partnership for Google Cloud customers The Gateway to Open Models - A Fast Lane for Google Cloud Customers A partnership for Hugging Face customers Building the open future of AI together Today, we are happy to announce a new and deeper partnership with Google Cloud, to enable companies to build their own AI with open models. \u201cGoogle has made some of the most impactful contributions to open AI, from the OG transformer to the Gemma models. I believe in a future where all companies will build and customize their own AI. With this new strategic partnership, we\u2019re making it easy to do on Google Cloud.\u201d says Jeff Boudier, at Hugging Face. \u201cHugging Face has been the driving force enabling companies large and small all over the world to access, use and customize now more than 2 million...", "url": "https://huggingface.co/blog/google-cloud", "date_published": "2025-11-13T00:00:00"}, {"id": "https://huggingface.co/blog/lerobotxnvidia-healthcare", "image": "https://huggingface.co/blog/assets/lerobotxnvidia-healthcare/thumbnail.png", "title": "Building a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac", "content_text": "Back to Articles Building a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac Published October 29, 2025 Update on GitHub Upvote 27 +21 Steven Palma imstevenpmwork Follow Andres Diaz-Pinto diazandr3s Follow TL;DR Table-of-Contents Introduction SO-ARM Starter Workflow; Building an Embodied Surgical Assistant Technical Implementation Sim2Real Mixed Training Approach Hardware Requirements Data Collection Implementation Simulation Teleoperation Controls Model Training Pipeline End-to-End Sim Collect\u2013Train\u2013Eval Pipelines Generate Synthetic Data in Simulation Train and Evaluate Policies Convert Models to TensorRT Getting Started Resources TL;DR A hands-on guide to collecting data, training policies, and deploying autonomous medical robotics workflows on real hardware Table-of-Contents Building a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac TL;DR Table-of-Contents Introduction SO-ARM Starter Workflow; Building an Embodied Surgical Assistant Technical...", "url": "https://huggingface.co/blog/lerobotxnvidia-healthcare", "date_published": "2025-10-29T00:00:00"}, {"id": "https://huggingface.co/blog/voice-consent-gate", "image": "https://huggingface.co/blog/assets/voice-consent-gate/thumbnail.png", "title": "Voice Cloning with Consent", "content_text": "Back to Articles Voice Cloning with Consent Published October 28, 2025 Update on GitHub Upvote 28 +22 Margaret Mitchell meg Follow Lucie-Aim\u00e9e Kaffee frimelle Follow Ethics in Practice: Consent as System Infrastructure The Technical Details Approach Unlocking the Voice Consent Gate In this blog post, we introduce the idea of a 'voice consent gate' to support voice cloning with consent. We provide an example Space and accompanying code to start the ball rolling on the idea. Realistic voice generation technology has gotten uncannily good in the past few years. In some situations, it\u2019s possible to generate a synthetic voice that sounds almost exactly like the voice of a real person. And today, what once felt like science fiction is reality: Voice cloning. With just a few seconds of recorded speech, anyone\u2019s voice can be made to say almost anything. Voice generation, and in particular the subtask of voice cloning, has notable risks and benefits. The risks of \u201cdeepfakes\u201d, such as the...", "url": "https://huggingface.co/blog/voice-consent-gate", "date_published": "2025-10-28T00:00:00"}, {"id": "https://huggingface.co/blog/streaming-datasets", "image": "https://huggingface.co/blog/assets/streaming_datasets/streaming_datasets.png", "title": "Streaming datasets: 100x More Efficient", "content_text": "Back to Articles Streaming datasets: 100x More Efficient Published October 27, 2025 Update on GitHub Upvote 69 +63 Andres Marafioti andito Follow Quentin Lhoest lhoestq Follow ben burtenshaw burtenshaw Follow Pedro Cuenca pcuenq Follow merve merve Follow TLDR Streaming: The Same Easy API The Challenge: Streaming at Scale Under the Hood: What We Improved How are we faster than plain S3: Xet Need a custom streaming pipeline ? Push streaming to the limit Get Started and See the Difference TLDR We boosted load_dataset('dataset', streaming=True) , streaming datasets without downloading them with one line of code! Start training on multi-TB datasets immediately, without complex setups, downloading, no \"disk out of space\", or 429 \u201cstop requesting!\u201d errors. It's super fast! Outrunning our local SSDs when training on 64xH100 with 256 workers downloading data. We've improved streaming to have 100x fewer requests, \u2192 10\u00d7 faster data resolution \u2192 2x sample/sec, \u2192 0 worker crashes at 256...", "url": "https://huggingface.co/blog/streaming-datasets", "date_published": "2025-10-27T00:00:00"}, {"id": "https://huggingface.co/blog/huggingface-hub-v1", "image": "https://huggingface.co/blog/assets/huggingface-hub-v1/thumbnail.png", "title": "huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning", "content_text": "Back to Articles huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning Published October 27, 2025 Update on GitHub Upvote 69 +63 Lucain Pouget Wauplin Follow C\u00e9lina Hanouti celinah Follow Lysandre lysandre Follow Julien Chaumond julien-c Follow The Story Behind the Library The Foundation Years (2020-2021) The Great Shift: Git to HTTP (2022) An Expanding API Surface (2022\u20132024) Ready. Xet. Go! (2024-2025) Measuring Growth and Impact Building for the Next Decade Modern HTTP Infrastructure with httpx and hf_xet Agents Made Simple with MCP and Tiny-Agents A Fully-Featured CLI for Modern Workflows Cleaning House for the Future The Migration Guide Acknowledgments TL;DR: After five years of development, huggingface_hub has reached v1.0 - a milestone that marks the library's maturity as the Python package powering 200,000 dependent libraries and providing core functionality for accessing over 2 million public models, 0.5 million public datasets, and 1 million...", "url": "https://huggingface.co/blog/huggingface-hub-v1", "date_published": "2025-10-27T00:00:00"}, {"id": "https://huggingface.co/blog/lerobot-release-v040", "image": "https://huggingface.co/blog/assets/lerobot-release-v040/thumbnail.png", "title": "LeRobot v0.4.0: Supercharging OSS Robot Learning", "content_text": "Back to Articles LeRobot v0.4.0: Supercharging OSS Robot Learning Published October 24, 2025 Update on GitHub Upvote 45 +39 Steven Palma imstevenpmwork Follow Michel Aractingi aractingi Follow Pepijn Kooijmans pepijn223 Follow Caroline Pascal CarolinePascal Follow Jade Choghari jadechoghari Follow Francesco Capuano fracapuano Follow Adil Zouitine AdilZtn Follow Martino Russi nepyope Follow Thomas Wolf thomwolf Follow TL;DR Table-of-Contents Datasets: Ready for the Next Wave of Large-Scale Robot Learning What's New in Datasets v3.0? New Feature: Dataset Editing Tools! Simulation Environments: Expanding Your Training Grounds LIBERO Support Meta-World Integration Codebase: Powerful Tools For Everyone The New Pipeline for Data Processing Multi-GPU Training Made Easy Policies: Unleashing Open-World Generalization PI0 and PI0.5 GR00T N1.5 Robots: A New Era of Hardware Integration with the Plugin System Key Benefits Reachy 2 Integration Phone Integration The Hugging Face Robot Learning...", "url": "https://huggingface.co/blog/lerobot-release-v040", "date_published": "2025-10-24T00:00:00"}, {"id": "https://huggingface.co/blog/openenv", "image": "https://huggingface.co/blog/assets/openenv/thumbnail.png", "title": "Building the Open Agent Ecosystem Together: Introducing OpenEnv", "content_text": "Back to Articles Building the Open Agent Ecosystem Together: Introducing OpenEnv Published October 23, 2025 Update on GitHub Upvote 134 +128 Joseph Spisak spisakjo Follow openenv Davide Testuggine darktex Follow guest Zach Wentz zkwentz Follow openenv Pierre Andrews mortimerp9 Follow openenv Sanyam Bhutani Sanyam Follow openenv Hamid Shojanazeri Hamid-Nazeri Follow openenv Pankit Thapar Pankit01 Follow openenv Emre Guven emre0 Follow openenv Lewis Tunstall lewtun Follow Vaibhav Srivastav reach-vb Follow The Problem The Solution The RFCs Use cases What\u2019s Next With tools like TRL , TorchForge and verl , the open-source community has shown how to scale AI across complex compute infrastructure. But compute is only one side of the coin. The other side is the developer community; the people and tools that make agentic systems possible. That\u2019s why Meta and Hugging Face are partnering to launch the OpenEnv Hub : a shared and open community hub for agentic environments. Agentic environments...", "url": "https://huggingface.co/blog/openenv", "date_published": "2025-10-23T00:00:00"}]}