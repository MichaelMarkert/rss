{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/gradio-mcp", "image": "https://huggingface.co/blog/assets/gradio-mcp/thumbnail.png", "title": "How to Build an MCP Server with Gradio", "content_text": "Back to Articles How to Build an MCP Server in 5 Lines of Python Published April 30, 2025 Update on GitHub Upvote 78 +72 abidlabs Abubakar Abid ysharma yuvraj sharma Why Build an MCP Server? Example: Counting Letters in a Word Key features of the Gradio <> MCP Integration Further Reading Gradio is a Python library used by more than 1 million developers each month to build interfaces for machine learning models. Beyond just creating UIs, Gradio also exposes API capabilities and \u2014 now! \u2014 Gradio apps can be launched Model Context Protocol (MCP) servers for LLMs. This means that your Gradio app, whether it's an image generator or a tax calculator or something else entirely, can be called as a tool by an LLM. This guide will show you how to use Gradio to build an MCP server in just a few lines of Python. Prerequisites If not already installed, please install Gradio with the MCP extra: pip install \"gradio[mcp]\" This will install the necessary dependencies, including the mcp package....", "url": "https://huggingface.co/blog/gradio-mcp", "date_published": "2025-04-30T00:00:00"}, {"id": "https://huggingface.co/blog/llama-guard-4", "image": "https://huggingface.co/blog/assets/llama-guard-4/thumbnail.png", "title": "Welcoming Llama Guard 4 on Hugging Face Hub", "content_text": "Back to Articles Welcoming Llama Guard 4 on Hugging Face Hub Published April 29, 2025 Update on GitHub Upvote 31 +25 merve Merve Noyan ariG23498 Aritra Roy Gosthipaty sergiopaniego Sergio Paniego pcuenq Pedro Cuenca Table-of-Contents What is Llama Guard 4? Model Details Llama Guard 4 Llama Prompt Guard 2 Getting Started using \ud83e\udd17 transformers Llama Prompt Guard 2 Useful Resources TL;DR: Today, Meta releases Llama Guard 4, a 12B dense (not a MoE!) multimodal safety model, and two new Llama Prompt Guard 2 models. This release comes with multiple open model checkpoints, along with an interactive notebook for you to get started easily \ud83e\udd17. Model checkpoints can be found in Llama 4 Collection . Table-of-Contents What is Llama Guard 4? Model Details Llama Guard 4 Llama Prompt Guard 2 Getting Started using \ud83e\udd17transformers Llama Guard 4 Llama Prompt Guard 2 Useful Resources What is Llama Guard 4? Vision and large language models deployed to production can be exploited to generate unsafe output...", "url": "https://huggingface.co/blog/llama-guard-4", "date_published": "2025-04-29T00:00:00"}, {"id": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive", "image": "https://huggingface.co/blog/assets/qwen-3-chat-template-deep-dive/thumbnail.png", "title": "The 4 Things Qwen-3's Chat Template Teaches Us", "content_text": "Back to Articles The 4 Things Qwen-3\u2019s Chat Template Teaches Us Published April 30, 2025 Update on GitHub Upvote 23 +17 cfahlgren1 Caleb Fahlgren What is a Chat Template? 1. Reasoning doesn't have to be forced 2. Context Management Should be Dynamic Example 3. Tool Arguments Need Better Serialization 4. There's No Need for a Default System Prompt Conclusion What a boring Jinja snippet tells us about the new Qwen-3 model. The new Qwen-3 model by Qwen ships with a much more sophisticated chat template than it's predecessors Qwen-2.5 and QwQ. By taking a look at the differences in the Jinja template, we can find interesting insights into the new model. Chat Templates Qwen-3 Chat Template Qwen-2.5 Chat Template Qwen-QwQ Chat Template What is a Chat Template? A chat template defines how conversations between users and models are structured and formatted. The template acts as a translator, converting a human-readable conversation: [ { role : \"user\" , content : \"Hi there!\" }, { role :...", "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive", "date_published": "2025-04-30T00:00:00"}, {"id": "https://huggingface.co/blog/tiny-agents", "image": "https://huggingface.co/blog/assets/tiny-agents/thumbnail.jpg", "title": "Tiny Agents: a MCP-powered agent in 50 lines of code", "content_text": "Back to Articles Tiny Agents: an MCP-powered agent in 50 lines of code Published April 25, 2025 Update on GitHub Upvote 216 +210 julien-c Julien Chaumond How to run the complete demo Default model and provider Where does the code live The foundation for this: tool calling native support in LLMs. Implementing an MCP client on top of InferenceClient How to use the tools Our 50-lines-of-code Agent \ud83e\udd2f The complete while loop Next steps Over the past few weeks, I've been diving into MCP ( Model Context Protocol ) to understand what the hype around it was all about. My TL;DR is that it's fairly simple, but still quite powerful: MCP is a standard API to expose sets of Tools that can be hooked to LLMs. It is fairly simple to extend an Inference Client \u2013 at HF, we have two official client SDKs: @huggingface/inference in JS, and huggingface_hub in Python \u2013 to also act as a MCP client and hook the available tools from MCP servers into the LLM inference. But while doing that, came my second...", "url": "https://huggingface.co/blog/tiny-agents", "date_published": "2025-04-25T00:00:00"}, {"id": "https://huggingface.co/blog/autoround", "image": "https://huggingface.co/blog/assets/autoround/thumbnail.png", "title": "Introducing AutoRound: Intel\u2019s Advanced Quantization for LLMs and VLMs", "content_text": "Back to Articles What is AutoRound? Published April 29, 2025 Update on GitHub Upvote 20 +14 wenhuach wenhua cheng Intel Haihao Haihao Shen Intel weiweiz1 weiweiz1 Intel n1ck-guo Heng Guo Intel isaacmac Huang, Tai Intel kding1 Ke Ding Intel IlyasMoutawwakil Ilyas Moutawwakil marcsun13 Marc Sun medmekk Mohamed Mekkouri Superior Accuracy at Low Bit Widths 2. Broad Compatibility Models Devices Quantization Configurations Export Formats 3. Flexible/Efficient Quantization Installation Quantization and Serialization Command Line Usage AutoRound API Usage Inference CPU/Intel GPU/CUDA Convert GPTQ/AWQ to AutoRound As large language models (LLMs) and vision-language models (VLMs) continue to grow in size and complexity, deploying them efficiently becomes increasingly challenging. Quantization offers a solution by reducing model size and inference latency. Intel's AutoRound emerges as a cutting-edge quantization tool that balances accuracy, efficiency, and compatibility. AutoRound is a weight-...", "url": "https://huggingface.co/blog/autoround", "date_published": "2025-04-29T00:00:00"}, {"id": "https://huggingface.co/blog/why-gradio-stands-out", "image": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png", "title": "17 Reasons Why Gradio Isn't Just Another UI Library", "content_text": "Back to Articles 17 Reasons Why Gradio Isn't Just Another UI Library Published April 16, 2025 Update on GitHub Upvote 29 +23 ysharma yuvraj sharma abidlabs Abubakar Abid Introduction 1. Universal API Access 2. Interactive API Recorder for Development 3. Fast ML Apps with Server-Side Rendering 4. Automatic Queue Management for ML Tasks 5. High-Performance Streaming for Real-Time ML Outputs 6. Integrated Multi-Page Application Support 7. New Client-Side Function Execution With Groovy 8. A Comprehensive Theming System and Modern UI Components 9. Gradio's Dynamic Interfaces 10. Visual Interface Development with Gradio Sketch 11. Progressive Web App (PWA) Support 12. In-Browser Execution with Gradio Lite 13. Accelerated Development with AI-Assisted Tooling 14. Hassle-Free App Sharing 15. Enterprise-Grade Security and Production Readiness 16. Enhanced Dataframe Component 17. Deep Links for Sharing App States Conclusion Introduction \"Oh, Gradio? That's a Python library for building UIs,...", "url": "https://huggingface.co/blog/why-gradio-stands-out", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/inference-providers-cohere", "image": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png", "title": "Cohere on Hugging Face Inference Providers \ud83d\udd25", "content_text": "Back to Articles Cohere on Hugging Face Inference Providers \ud83d\udd25 Published April 16, 2025 Update on GitHub Upvote 124 +118 reach-vb Vaibhav Srivastav burtenshaw ben burtenshaw merve Merve Noyan celinah C\u00e9lina Hanouti alexrs Alejandro Rodriguez CohereLabs julien-c Julien Chaumond sbrandeis Simon Brandeis Cohere Models CohereLabs/c4ai-command-a-03-2025 \ud83d\udd17 CohereLabs/aya-expanse-32b \ud83d\udd17 CohereLabs/c4ai-command-r7b-12-2024 \ud83d\udd17 CohereLabs/aya-vision-32b \ud83d\udd17 How it works In the website UI From the client SDKs From OpenAI client Tool Use with Cohere Models Billing We're thrilled to share that Cohere is now a supported Inference Provider on HF Hub! This also marks the first model creator to share and serve their models directly on the Hub. Cohere is committed to building and serving models purpose-built for enterprise use-cases. Their comprehensive suite of secure AI solutions, from cutting-edge Generative AI to powerful Embeddings and Ranking models, are designed to tackle real-world business...", "url": "https://huggingface.co/blog/inference-providers-cohere", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/helmet", "image": "https://huggingface.co/blog/assets/helmet/thumbnail.png", "title": "Introducing HELMET", "content_text": "Back to Articles Introducing HELMET : Holistically Evaluating Long-context Language Models Published April 16, 2025 Update on GitHub Upvote 23 +17 hyen Howard Yen guest gaotianyu1350 Tianyu Gao guest houminmin Minmin Hou Intel kding1 Ke Ding Intel danf Daniel Fleischer Intel moshew Moshe Wasserblat Intel cdq10131 Danqi Chen guest Evaluating long-context language models is challenging but important Existing evaluations overly rely on synthetic tasks Crafting diverse, controllable, and reliable evaluation for LCLMs Key improvements over existing benchmarks LCLMs still have a long way to go on real-world tasks Diverse evaluation is needed for assessing long-context abilities Models degrade with increasing lengths and task complexity Using HELMET for future developments How to run HELMET Faster development Quick comparison with existing models Looking ahead Acknowledgements Citation Contact: hyen@cs.princeton.edu Paper: https://arxiv.org/abs/2410.02694 Website: https://princeton-...", "url": "https://huggingface.co/blog/helmet", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition", "image": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png", "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition \ud83e\udd16", "content_text": "Back to Articles Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition \ud83e\udd16 Published April 14, 2025 Update on GitHub Upvote 42 +36 thomwolf Thomas Wolf clem Clem \ud83e\udd17 matthieu-lapeyre Matthieu Lapeyre pollen-robotics Hugging Face\u2019s Robotics Venture Timeline About Hugging Face About Pollen Robotics About Reachy 2 Simon Alibert and R\u00e9mi Cad\u00e8ne from the LeRobot team with Reachy 1 \u2014 Photo: L\u00e9a Crespi Since Hugging Face started the LeRobot library in 2024, led by ex-Tesla lead Remi Cadene, the Hugging Face Hub has quickly become the most widely used hub and software platform for open robotics with models, datasets, spaces and libraries. Today, we\u2019re excited to take it a step further by welcoming Pollen Robotics to Hugging Face, a team that's spent the last 9 years building open-source robots and hardware. We believe robotics could be the next frontier unlocked by AI \u2014 and it should be open, affordable, and private. Our vision: a future where everyone in the community,...", "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition", "date_published": "2025-04-14T00:00:00"}, {"id": "https://huggingface.co/blog/pai-6-month", "image": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png", "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In", "content_text": "Back to Articles 4M Models Scanned: Protect AI + Hugging Face 6 Months In Published April 14, 2025 Update on GitHub Upvote 28 +22 sean-pai Sean Morgan protectai Maintaining a Zero Trust Approach to Model Security Evolving Guardian\u2019s Model Vulnerability Detection Capabilities Common attack themes Delivering Comprehensive Threat Detection for Hugging Face Users It Only Gets Better from Here Hugging Face and Protect AI partnered in October 2024 to enhance machine learning (ML) model security through Guardian\u2019s scanning technology for the community of developers who explore and use models from the Hugging Face Hub. The partnership has been a natural fit from the start\u2014Hugging Face is on a mission to democratize the use of open source AI, with a commitment to safety and security; and Protect AI is building the guardrails to make open source models safe for all. 4 new threat detection modules launched Since October, Protect AI has significantly expanded Guardian's detection capabilities,...", "url": "https://huggingface.co/blog/pai-6-month", "date_published": "2025-04-14T00:00:00"}, {"id": "https://huggingface.co/blog/fastrtc-cloudflare", "image": "https://huggingface.co/blog/assets/fastrtc-cloudflare/fastrtc_cloudflare.png", "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC", "content_text": "Back to Articles Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC Published April 9, 2025 Update on GitHub Upvote 24 +18 freddyaboulton Freddy Boulton Meeting a Gap in the Toolbox of AI Developers Free Access with Your Hugging Face Account Why This Matters for AI Developers Getting Started What's Next? We're excited to announce a new partnership between Cloudflare and Hugging Face that gives FastRTC developers instant access to enterprise-grade WebRTC infrastructure with a Hugging Face token. As a preview of what you can build with FastRTC and Cloudflare, check out this voice chat app built with Meta's new Llama 4 model! Meeting a Gap in the Toolbox of AI Developers As conversational AI becomes a core interface for tools, products, and services, real-time communication infrastructure is increasingly essential to support natural, multimodal interactions. Hugging Face built FastRTC to let AI developers build low-latency AI-powered audio and...", "url": "https://huggingface.co/blog/fastrtc-cloudflare", "date_published": "2025-04-09T00:00:00"}, {"id": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval", "image": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png", "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More", "content_text": "Back to Articles Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More Published April 8, 2025 Update on GitHub Upvote 16 +10 alielfilali01 Ali El Filali inceptionai SarahAlBarri Sarah AlBarri inceptionai Arwa88 Abouelseoud inceptionai samta-kamboj samta kamboj inceptionai neha1710 Neha Sengupta inceptionai preslavnakov Preslav Nakov MBZUAI Arabic-Leaderboards Space Latest Updates in AraGen Leaderboard AraGen-03-25 Release Dynamic Evaluation and Ranking Analysis Instruction Following Leaderboard What is Instruction Following as a Benchmark? Dataset: Arabic IFEval Evaluation Methodology & Metrics Results & Analysis Upcoming Work At Inception, we have been working to enhance AI model evaluations within the Arabic language context. Previously, we introduced AraGen , one of the first generative Arabic leaderboards, serving as a benchmark for evaluating Arabic LLMs on generative tasks. As part of our ongoing efforts, we are excited to share the...", "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval", "date_published": "2025-04-08T00:00:00"}, {"id": "https://huggingface.co/blog/llama4-release", "image": "https://huggingface.co/blog/assets/llama_4.png", "title": "Welcome Llama 4 Maverick & Scout on Hugging Face!", "content_text": "Back to Articles Welcome Llama 4 Maverick & Scout on Hugging Face Published April 5, 2025 Update on GitHub Upvote 142 +136 burtenshaw ben burtenshaw reach-vb Vaibhav Srivastav pcuenq Pedro Cuenca clem Clem \ud83e\udd17 rajatarya Rajat Arya xet-team jsulz Jared Sulzdorf xet-team lysandre Lysandre What is Llama 4? Features and Integrations on Hugging Face Context Length and Architecture Choices How to Use with Transformers Evaluation Scores Pre-trained models Instruction tuned models Acknowledgments References We are incredibly excited to welcome the next generation of large language models from Meta to the Hugging Face Hub: Llama 4 Maverick (~400B) and Llama 4 Scout (~109B)! \ud83e\udd17 Both are Mixture of Experts (MoE) models with 17B active parameters. Released today, these powerful, natively multimodal models represent a significant leap forward. We've worked closely with Meta to ensure seamless integration into the Hugging Face ecosystem, including both transformers and TGI from day one. This is just...", "url": "https://huggingface.co/blog/llama4-release", "date_published": "2025-04-05T00:00:00"}, {"id": "https://huggingface.co/blog/gradio-1m", "image": "https://huggingface.co/blog/assets/gradio-1m/thumbnail.png", "title": "Journey to 1 Million Gradio Users!", "content_text": "Back to Articles Journey to 1 Million Gradio Users! Published April 4, 2025 Update on GitHub Upvote 26 +20 abidlabs Abubakar Abid 5 years ago, we launched Gradio as a simple Python library to let researchers at Stanford easily demo computer vision models with a web interface. Today, Gradio is used by >1 million developers each month to build and share AI web apps. This includes some of the most popular open-source projects of all time, like Automatic1111 , Oobabooga\u2019s Text Generation WebUI , Dall-E Mini , and LLaMA-Factory . How did we get here? How did Gradio keep growing in the very crowded field of open-source Python libraries? I get this question a lot from folks who are building their own open-source libraries. This post distills some of the lessons that I have learned over the past few years: Invest in good primitives, not high-level abstractions Embed virality directly into your library Focus on a (growing) niche Your only roadmap should be rapid iteration Maximize ways users...", "url": "https://huggingface.co/blog/gradio-1m", "date_published": "2025-04-04T00:00:00"}, {"id": "https://huggingface.co/blog/llm-course", "image": "https://huggingface.co/blog/assets/llm-course/llm-course-rename-thumbnail.png", "title": "The NLP Course is becoming the LLM Course!", "content_text": "Back to Articles The NLP Course is becoming the LLM Course! Published April 3, 2025 Update on GitHub Upvote 89 +83 burtenshaw ben burtenshaw reach-vb Vaibhav Srivastav lewtun Lewis Tunstall fdaudens Florent Daudens pcuenq Pedro Cuenca tomaarsen Tom Aarsen coyotte508 Eliott Coyac mishig Mishig Davaadorj sergiopaniego Sergio Paniego julien-c Julien Chaumond What\u2019s going to happen to the NLP course material? Will there be new chapters? Will there be interactive exercises and live sessions? What\u2019s next? Education has always been at the heart of Hugging Face\u2019s mission to democratize AI and we\u2019re doubling down on that by giving hf.co/learn a big upgrade! Our NLP course has been a go-to resource for the open-source AI community for the past 3 years, and it\u2019s now time for a refresh. We\u2019re updating and expanding it to keep up with all the exciting stuff happening in AI (which is not easy when there are breakthroughs every week!) We felt the excitement during the experimental smol-course and...", "url": "https://huggingface.co/blog/llm-course", "date_published": "2025-04-03T00:00:00"}]}