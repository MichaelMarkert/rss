{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/claude-and-mcp", "image": "https://huggingface.co/blog/assets/claude-and-mcp/thumbnail.png", "title": "Generate Images with Claude and Hugging Face", "content_text": "Back to Articles Generate Images with Claude and Hugging Face Published August 19, 2025 Update on GitHub Upvote 26 +20 shaun smith evalstate Follow Introduction Natural Images with Flux.1 Krea Dev Qwen Image Conclusion TL;DR: It's easier than ever to generate detailed pictures with state-of-the-art AI models by connecting Claude to Hugging Face Spaces. This article describes how and why, and introduces recently launched models which excel at producing natural images or images that include text. Introduction Recent advances in image generation models have improved their ability to produce realistic outputs and incorporate high quality text. It's easier than ever to use these models by connecting them directly to Claude. The advantages of generating pictures this way are: The AI can assist in building detailed prompts that may improve the quality of generated images. The AI can \"see\" the generated images, then help iterate on designs and techniques to get perfect results. You can...", "url": "https://huggingface.co/blog/claude-and-mcp", "date_published": "2025-08-19T00:00:00"}, {"id": "https://huggingface.co/blog/kernel-builder", "image": "https://huggingface.co/blog/assets/kernel-builder/kernel-builder.png", "title": "From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels", "content_text": "Back to Articles From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels Published August 18, 2025 Update on GitHub Upvote 44 +38 David Holtz drbh Follow Dani\u00ebl de Kok danieldk Follow What You\u2019ll Learn Part 1: Anatomy of a Modern CUDA Kernel Step 1: Project Structure Step 2: The build.toml Manifest Step 3: The flake.nix Reproducibility File Step 4: Writing the CUDA Kernel Step 5: Registering a Native PyTorch Operator Step 6: Building the Kernel Step 7: Sharing with the World Step 8: Loading and Testing Your Custom Op Part 2: From One Kernel to Many: Solving Production Challenges Kernel Versions Pre-downloading Locked Kernels Creating Legacy Python Wheels Custom CUDA kernels give your models a serious performance edge, but building them for the real world can feel daunting. How do you move beyond a simple GPU function to create a robust, scalable system without getting bogged down by endless build times and dependency nightmares? We created the kernel-builder...", "url": "https://huggingface.co/blog/kernel-builder", "date_published": "2025-08-18T00:00:00"}, {"id": "https://huggingface.co/blog/mcp-for-research", "image": "https://huggingface.co/blog/assets/mcp-for-research/thumbnail.png", "title": "MCP for Research: How to Connect AI to Research Tools", "content_text": "Back to Articles MCP for Research: How to Connect AI to Research Tools Published August 18, 2025 Update on GitHub Upvote 35 +29 Dylan Ebert dylanebert Follow Research Discovery: Three Layers of Abstraction 1. Manual Research 2. Scripted Tools 3. MCP Integration Setup and Usage Quick Setup Learn More Academic research involves frequent research discovery : finding papers, code, related models and datasets. This typically means switching between platforms like arXiv , GitHub , and Hugging Face , manually piecing together connections. The Model Context Protocol (MCP) is a standard that allows agentic models to communicate with external tools and data sources. For research discovery, this means AI can use research tools through natural language requests, automating platform switching and cross-referencing. Research Discovery: Three Layers of Abstraction Much like software development, research discovery can be framed in terms of layers of abstraction. 1. Manual Research At the lowest...", "url": "https://huggingface.co/blog/mcp-for-research", "date_published": "2025-08-18T00:00:00"}, {"id": "https://huggingface.co/blog/textquests", "image": "https://huggingface.co/blog/assets/textquests/thumbnail.gif", "title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "content_text": "Back to Articles TextQuests: How Good are LLMs at Text-Based Video Games? Published August 12, 2025 Update on GitHub Upvote 26 +20 Long Phan justinphan3110 Follow cais Cl\u00e9mentine Fourrier clefourrier Follow TextQuests Evaluations Discussion Citations The rapid advancement of Large Language Models (LLMs) has enabled remarkable progress on established academic and industrial benchmarks. Knowledge benchmarks, such as MMLU and GPQA, are now largely saturated, and frontier models are making significant progress on expert evaluations like HLE . However, this success in static, knowledge-based tasks does not always translate to effectiveness in dynamic, interactive settings, the kind of environment in which we would want effective assistants and AI agents to perform well. Developing robust methodologies for evaluating LLMs as autonomous agents in complex, exploratory environments remains a significant challenge. Two core avenues exist to evaluate autonomous agents: either use real-world...", "url": "https://huggingface.co/blog/textquests", "date_published": "2025-08-12T00:00:00"}, {"id": "https://huggingface.co/blog/aisheets", "image": "https://huggingface.co/blog/assets/aisheets/aisheets-thumb.gif", "title": "Introducing AI Sheets: a tool to work with datasets using open AI models!", "content_text": "Back to Articles Introducing AI Sheets: a tool to work with datasets using open AI models! Published August 8, 2025 Update on GitHub Upvote 73 +67 Daniel Vila dvilasuero Follow Ame Vi Ameeeee Follow Francisco Aranda frascuchon Follow Dami\u00e1n Pumar damianpumar Follow Leandro von Werra lvwerra Follow Thomas Wolf thomwolf Follow Useful links What is AI Sheets What can I use it for How to use it Getting started Working with your dataset Refining and expanding the dataset Exporting your final dataset to the Hub Running data generation scripts using HF Jobs Examples Vibe testing and comparing models Add categories to a Hub dataset Evaluate models with LLMs-as-Judge Next steps \ud83e\uddedTL;DR Hugging Face AI Sheets is a new, open-source tool for building, enriching, and transforming datasets using AI models with no code . The tool can be deployed locally or on the Hub. It lets you use thousands of open models from the Hugging Face Hub via Inference Providers or local models, including gpt-oss from...", "url": "https://huggingface.co/blog/aisheets", "date_published": "2025-08-08T00:00:00"}, {"id": "https://huggingface.co/blog/accelerate-nd-parallel", "image": "https://huggingface.co/blog/assets/accelerate-nd-parallel/thumbnail.png", "title": "Accelerate ND-Parallel: A Guide to Efficient Multi-GPU Training", "content_text": "Back to Articles Accelerate ND-Parallel: A guide to Efficient Multi-GPU Training Published August 8, 2025 Update on GitHub Upvote 55 +49 Salman Mohammadi smohammadi Follow axolotl-ai-co Matej Sirovatka siro1 Follow wing lian winglian Follow axolotl-ai-co Marc Sun marcsun13 Follow Dan Saunders djsaunde Follow axolotl-ai-co Contents Data Parallelism Fully Sharded Data Parallelism Tensor Parallelism Context Parallelism ND Parallelisms Hybrid Sharded Data Parallelism Fully Sharded Data Parallelism + Tensor Parallelism Fully Sharded Data Parallelism + Context Parallelism Hybrid Sharded Data Parallelism + Tensor Parallelism Usage notes Training large models across multiple GPUs can be challenging due to the complexities of different parallelism strategies. In Accelerate, together with Axolotl , we have integrated a quick and easy way to use any combination of parallelism strategies in your training script! Here is how to add it to your training script: from transformers import...", "url": "https://huggingface.co/blog/accelerate-nd-parallel", "date_published": "2025-08-08T00:00:00"}, {"id": "https://huggingface.co/blog/filbench", "image": "https://huggingface.co/blog/assets/filbench/thumbnail.png", "title": "\ud83c\uddf5\ud83c\udded FilBench - Can LLMs Understand and Generate Filipino?", "content_text": "Back to Articles \ud83c\uddf5\ud83c\udded FilBench - Can LLMs Understand and Generate Filipino? Published August 12, 2025 Update on GitHub Upvote 13 +7 Lj V. Miranda ljvmiranda921 Follow UD-Filipino Elyanah Aco acocodes Follow UD-Filipino Conner Manuel connermanuel Follow UD-Filipino Jan Christian Blaise Cruz jcblaise Follow UD-Filipino Jan Christian Blaise Cruz jcblaise Follow SEACrowd Joseph Imperial josephimperial Follow SEACrowd Daniel van Strien davanstrien Follow Nathan Habib SaylorTwift Follow Cl\u00e9mentine Fourrier clefourrier Follow FilBench What did we learn from FilBench? Finding #1: Although region-specific LLMs still lag behind GPT-4, collecting data to train these models is still a promising direction Finding #2: Filipino translation is still a difficult task for LLMs Finding #3: Open LLMs Remain a Cost-Effective Choice for Filipino Language Tasks Does your LLM work on Philippine Languages? Try it on FilBench! Acknowledgements Citation As large language models (LLMs) become increasingly...", "url": "https://huggingface.co/blog/filbench", "date_published": "2025-08-12T00:00:00"}, {"id": "https://huggingface.co/blog/trl-vlm-alignment", "image": "https://huggingface.co/blog/assets/trl_vlm/thumbnail.png", "title": "Vision Language Model Alignment in TRL \u26a1\ufe0f", "content_text": "Back to Articles Vision Language Model Alignment in TRL \u26a1\ufe0f Published August 7, 2025 Update on GitHub Upvote 75 +69 Sergio Paniego sergiopaniego Follow merve merve Follow Quentin Gallou\u00e9dec qgallouedec Follow Kashif Rasul kashif Follow Aritra Roy Gosthipaty ariG23498 Follow Introduction Table of Contents Alignment for Vision Language Models Mixed Preference Optimization (MPO) Multimodal Group Relative Policy Optimization (GRPO) Group Sequence Policy Optimization (GSPO) Comparison Native Supervised Fine-tuning Support vLLM Integration in TRL Useful Resources Introduction Vision Language Models (VLMs) are getting stronger, but aligning them to human preferences still matters. In TRL, we already showed how to post-train VLMs with Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) . This time, we\u2019re going further. tl;dr We have added two new multimodal alignment methods to TRL: Group Relative Policy Optimization (GRPO) , its variant Group Sequence Policy Optimization...", "url": "https://huggingface.co/blog/trl-vlm-alignment", "date_published": "2025-08-07T00:00:00"}, {"id": "https://huggingface.co/blog/welcome-openai-gpt-oss", "image": "https://huggingface.co/blog/assets/openai/openai-hf-thumbnail.png", "title": "Welcome GPT OSS, the new open-source model family from OpenAI!", "content_text": "Back to Articles Welcome GPT OSS, the new open-source model family from OpenAI! Published August 5, 2025 Update on GitHub Upvote 479 +473 Vaibhav Srivastav reach-vb Follow Pedro Cuenca pcuenq Follow Lewis Tunstall lewtun Follow Clem \ud83e\udd17 clem Follow Matthew Carrigan Rocketknight1 Follow Cl\u00e9mentine Fourrier clefourrier Follow C\u00e9lina Hanouti celinah Follow Lucain Pouget Wauplin Follow Marc Sun marcsun13 Follow Simon Pagezy pagezyhf Follow \u00c1kos Hadnagy ahadnagy Follow Joao Gante joaogante Follow Contents Overview of Capabilities and Architecture API access through Inference Providers Local Inference Using Transformers Llama.cpp vLLM transformers serve Fine-Tuning Deploy on Hugging Face Partners Azure Dell Evaluating the Model Chats and Chat Templates System and Developer Messages Tool Use With transformers Acknowledgements GPT OSS is a hugely anticipated open-weights release by OpenAI, designed for powerful reasoning, agentic tasks, and versatile developer use cases. It comprises two...", "url": "https://huggingface.co/blog/welcome-openai-gpt-oss", "date_published": "2025-08-05T00:00:00"}, {"id": "https://huggingface.co/blog/gradio-vton-mcp", "image": "https://huggingface.co/blog/assets/gradio-vton-mcp/AiAssistantTitle.png", "title": "Build an AI Shopping Assistant with Gradio MCP Servers", "content_text": "Back to Articles Implementing MCP Servers in Python: An AI Shopping Assistant with Gradio Published July 31, 2025 Update on GitHub Upvote 50 +44 Freddy Boulton freddyaboulton Follow The Goal: Your Personal AI Stylist Building the Gradio MCP Server Configuring VS Code Putting It All Together Conclusion Python Developers, want to give your LLM superpowers? Gradio is the fastest way to do it! With Gradio's Model Context Protocol (MCP) integration, your LLM can plug directly into the thousands of AI models and Spaces hosted on the Hugging Face Hub . By pairing the general reasoning capabilities of LLMs with the specialized abilities of models found on Hugging Face, your LLM can go beyond simply answering text questions to actually solving problems in your daily life. For Python developers, Gradio makes implementing powerful MCP servers a breeze, offering features like: Automatic conversion of python functions into LLM tools: Each API endpoint in your Gradio app is automatically...", "url": "https://huggingface.co/blog/gradio-vton-mcp", "date_published": "2025-07-31T00:00:00"}, {"id": "https://huggingface.co/blog/trackio", "image": "https://huggingface.co/blog/assets/trackio/thumbnail.gif", "title": "Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face", "content_text": "Back to Articles Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face Published July 29, 2025 Update on GitHub Upvote 163 +157 Abubakar Abid abidlabs Follow Zach Nation znation Follow Nouamane Tazi nouamanetazi Follow Sasha Luccioni sasha Follow Quentin Gallou\u00e9dec qgallouedec Follow Background Why We Switched to Trackio Using Trackio Installing Usage Visualizing Results Sharing with \ud83e\udd17 Spaces Integrated with \ud83e\udd17 Transformers and \ud83e\udd17 Accelerate Design Principles Next Steps TL;DR: Trackio is a new, open-source, and free experiment tracking Python library that provides a local dashboard and seamless integration with Hugging Face Spaces for easy sharing and collaboration. Since trackio is a drop-in replacement for wandb , you can get started with the syntax you already know! Background If you have trained your own machine learning model, you know how important it is to be able to track metrics, parameters, and hyperparameters during training and visualize them...", "url": "https://huggingface.co/blog/trackio", "date_published": "2025-07-29T00:00:00"}, {"id": "https://huggingface.co/blog/hf-cli", "image": "https://huggingface.co/blog/assets/hf-cli-thumbnail.png", "title": "Say hello to `hf`: a faster, friendlier Hugging Face CLI \u2728", "content_text": "Back to Articles Say hello to `hf`: a faster, friendlier Hugging Face CLI \u2728 Published July 25, 2025 Update on GitHub Upvote 80 +74 Lucain Pouget Wauplin Follow C\u00e9lina Hanouti celinah Follow Julien Chaumond julien-c Follow Getting started \ud83d\udd00 Migration One more thing... \ud83d\udca5 hf jobs We are glad to announce a long-awaited quality-of-life improvement: the Hugging Face CLI has been officially renamed from huggingface-cli to hf ! So... why this change? Typing huggingface-cli constantly gets old fast. More importantly, the CLI\u2019s command structure became messy as new features were added over time (upload, download, cache management, repo management, etc.). Renaming the CLI is a chance to reorganize commands into a clearer, more consistent format. We decided not to reinvent the wheel and instead follow a well-known CLI pattern: hf <resource> <action> . This predictable grammar makes the Hugging Face CLI more ergonomic and discoverable, while also setting the stage for upcoming features. Getting...", "url": "https://huggingface.co/blog/hf-cli", "date_published": "2025-07-25T00:00:00"}, {"id": "https://huggingface.co/blog/parquet-cdc", "image": "https://huggingface.co/blog/assets/parquet-cdc/thumbnail.png", "title": "Parquet Content-Defined Chunking", "content_text": "Back to Articles Parquet Content-Defined Chunking Published July 25, 2025 Update on GitHub Upvote 61 +55 Krisztian Szucs kszucs Follow Table of Contents Introduction Data Preparation Upload the table as a Parquet file to Hugging Face Hub Different Use Cases for Parquet Deduplication 1. Re-uploading Exact Copies of the Table 2. Adding and Removing Columns from the Table 3. Changing Column Types in the Table 4. Appending New Rows and Concatenating Tables 5. Inserting / Deleting Rows in the Table 6. Using Different Row-group Sizes 7. Using Varying File-Level Splits Using Parquet CDC feature with Pandas References Conclusion Reduce Parquet file upload and download times on Hugging Face Hub by leveraging the new Xet storage layer and Apache Arrow\u2019s Parquet Content-Defined Chunking (CDC) feature enabling more efficient and scalable data workflows. TL;DR: Parquet Content-Defined Chunking (CDC) is now available in PyArrow and Pandas, enabling efficient deduplication of Parquet files on...", "url": "https://huggingface.co/blog/parquet-cdc", "date_published": "2025-07-25T00:00:00"}, {"id": "https://huggingface.co/blog/timescope-video-lmm-benchmark", "image": "https://huggingface.co/blog/assets/timescope/thumbnail.png", "title": "TimeScope: How Long Can Your Video Large Multimodal Model Go?", "content_text": "Back to Articles TimeScope: How Long Can Your Video Large Multimodal Model Go? Published July 23, 2025 Update on GitHub Upvote 39 +33 Orr Zohar orrzohar Follow Stanford Rui Li ruili0 Follow guest Andres Marafioti andito Follow huggingface Xiaohan Wang nicholswang Follow Stanford TL;DR Table of Contents Why TimeScope? Motivating a Better Benchmark for Video Benchmark Design 1. Localized Retrieval 2. Information Synthesis 3. Fine-Grained Temporal Perception Evaluations & Leaderboard What did we learn? Conclusion \u2013 Let\u2019s Raise the Bar for Long-Video AI TL;DR TimeScope is an open-source benchmark designed to measure how well vision-language models understand long videos. By adding short \u201cneedle\u201d clips into videos ranging from 1 minute to 8 hours, it evaluates three skills: localized retrieval, information synthesis, fine-grained temporal perception. Timescope reveals that many state-of-the-art models still struggle with true temporal comprehension. Table of Contents Why TimeScope?...", "url": "https://huggingface.co/blog/timescope-video-lmm-benchmark", "date_published": "2025-07-23T00:00:00"}, {"id": "https://huggingface.co/blog/lora-fast", "image": "https://huggingface.co/blog/assets/lora-fast/thumbnail.png", "title": "Fast LoRA inference for Flux with Diffusers and PEFT", "content_text": "Back to Articles Fast LoRA inference for Flux with Diffusers and PEFT Published July 23, 2025 Update on GitHub Upvote 47 +41 Sayak Paul sayakpaul Follow Benjamin Bossan BenjaminB Follow Technical details of hotswapping Resources LoRA adapters provide a great deal of customization for models of all shapes and sizes. When it comes to image generation, they can empower the models with different styles, different characters, and much more . Sometimes, they can also be leveraged to reduce inference latency . Hence, their importance is paramount, particularly when it comes to customizing and fine-tuning models. In this post, we take the Flux.1-Dev model for text-to-image generation because of its widespread popularity and adoption, and how to optimize its inference speed when using LoRAs (~2.3x). It has over 30k adapters trained with it ( as reported on the Hugging Face Hub platform). Therefore, its importance to the community is significant. Note that even though we demonstrate speedups...", "url": "https://huggingface.co/blog/lora-fast", "date_published": "2025-07-23T00:00:00"}]}