{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Blog", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_blog.json", "items": [{"id": "https://huggingface.co/blog/why-gradio-stands-out", "image": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png", "title": "17 Reasons Why Gradio Isn't Just Another UI Library", "content_text": "Back to Articles 17 Reasons Why Gradio Isn't Just Another UI Library Published April 16, 2025 Update on GitHub Upvote 15 +9 ysharma yuvraj sharma abidlabs Abubakar Abid Introduction 1. Universal API Access 2. Interactive API Recorder for Development 3. Fast ML Apps with Server-Side Rendering 4. Automatic Queue Management for ML Tasks 5. High-Performance Streaming for Real-Time ML Outputs 6. Integrated Multi-Page Application Support 7. New Client-Side Function Execution With Groovy 8. A Comprehensive Theming System and Modern UI Components 9. Gradio's Dynamic Interfaces 10. Visual Interface Development with Gradio Sketch 11. Progressive Web App (PWA) Support 12. In-Browser Execution with Gradio Lite 13. Accelerated Development with AI-Assisted Tooling 14. Hassle-Free App Sharing 15. Enterprise-Grade Security and Production Readiness 16. Enhanced Dataframe Component 17. Deep Links for Sharing App States Conclusion Introduction \"Oh, Gradio? That's a Python library for building UIs,...", "url": "https://huggingface.co/blog/why-gradio-stands-out", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/inference-providers-cohere", "image": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png", "title": "Cohere on Hugging Face Inference Providers \ud83d\udd25", "content_text": "Back to Articles Cohere on Hugging Face Inference Providers \ud83d\udd25 Published April 16, 2025 Update on GitHub Upvote 88 +82 reach-vb Vaibhav Srivastav burtenshaw ben burtenshaw merve Merve Noyan celinah C\u00e9lina Hanouti alexrs Alejandro Rodriguez CohereLabs julien-c Julien Chaumond sbrandeis Simon Brandeis Cohere Models CohereLabs/c4ai-command-a-03-2025 \ud83d\udd17 CohereLabs/aya-expanse-32b \ud83d\udd17 CohereLabs/c4ai-command-r7b-12-2024 \ud83d\udd17 CohereLabs/aya-vision-32b \ud83d\udd17 How it works In the website UI From the client SDKs From OpenAI client Tool Use with Cohere Models Billing We're thrilled to share that Cohere is now a supported Inference Provider on HF Hub! This also marks the first model creator to share and serve their models directly on the Hub. Cohere is committed to building and serving models purpose-built for enterprise use-cases. Their comprehensive suite of secure AI solutions, from cutting-edge Generative AI to powerful Embeddings and Ranking models, are designed to tackle real-world business...", "url": "https://huggingface.co/blog/inference-providers-cohere", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/helmet", "image": "https://huggingface.co/blog/assets/helmet/thumbnail.png", "title": "Introducing HELMET", "content_text": "Back to Articles Introducing HELMET : Holistically Evaluating Long-context Language Models Published April 16, 2025 Update on GitHub Upvote 21 +15 hyen Howard Yen guest gaotianyu1350 Tianyu Gao guest houminmin Minmin Hou Intel kding1 Ke Ding Intel danf Daniel Fleischer Intel moshew Moshe Wasserblat Intel cdq10131 Danqi Chen guest Evaluating long-context language models is challenging but important Existing evaluations overly rely on synthetic tasks Crafting diverse, controllable, and reliable evaluation for LCLMs Key improvements over existing benchmarks LCLMs still have a long way to go on real-world tasks Diverse evaluation is needed for assessing long-context abilities Models degrade with increasing lengths and task complexity Using HELMET for future developments How to run HELMET Faster development Quick comparison with existing models Looking ahead Acknowledgements Citation Contact: hyen@cs.princeton.edu Paper: https://arxiv.org/abs/2410.02694 Website: https://princeton-...", "url": "https://huggingface.co/blog/helmet", "date_published": "2025-04-16T00:00:00"}, {"id": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition", "image": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png", "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition \ud83e\udd16", "content_text": "Back to Articles Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition \ud83e\udd16 Published April 14, 2025 Update on GitHub Upvote 36 +30 thomwolf Thomas Wolf clem Clem \ud83e\udd17 matthieu-lapeyre Matthieu Lapeyre pollen-robotics Hugging Face\u2019s Robotics Venture Timeline About Hugging Face About Pollen Robotics About Reachy 2 Simon Alibert and R\u00e9mi Cad\u00e8ne from the LeRobot team with Reachy 1 \u2014 Photo: L\u00e9a Crespi Since Hugging Face started the LeRobot library in 2024, led by ex-Tesla lead Remi Cadene, the Hugging Face Hub has quickly become the most widely used hub and software platform for open robotics with models, datasets, spaces and libraries. Today, we\u2019re excited to take it a step further by welcoming Pollen Robotics to Hugging Face, a team that's spent the last 9 years building open-source robots and hardware. We believe robotics could be the next frontier unlocked by AI \u2014 and it should be open, affordable, and private. Our vision: a future where everyone in the community,...", "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition", "date_published": "2025-04-14T00:00:00"}, {"id": "https://huggingface.co/blog/pai-6-month", "image": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png", "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In", "content_text": "Back to Articles 4M Models Scanned: Protect AI + Hugging Face 6 Months In Published April 14, 2025 Update on GitHub Upvote 25 +19 sean-pai Sean Morgan protectai Maintaining a Zero Trust Approach to Model Security Evolving Guardian\u2019s Model Vulnerability Detection Capabilities Common attack themes Delivering Comprehensive Threat Detection for Hugging Face Users It Only Gets Better from Here Hugging Face and Protect AI partnered in October 2024 to enhance machine learning (ML) model security through Guardian\u2019s scanning technology for the community of developers who explore and use models from the Hugging Face Hub. The partnership has been a natural fit from the start\u2014Hugging Face is on a mission to democratize the use of open source AI, with a commitment to safety and security; and Protect AI is building the guardrails to make open source models safe for all. 4 new threat detection modules launched Since October, Protect AI has significantly expanded Guardian's detection capabilities,...", "url": "https://huggingface.co/blog/pai-6-month", "date_published": "2025-04-14T00:00:00"}, {"id": "https://huggingface.co/blog/fastrtc-cloudflare", "image": "https://huggingface.co/blog/assets/fastrtc-cloudflare/fastrtc_cloudflare.png", "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC", "content_text": "Back to Articles Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC Published April 9, 2025 Update on GitHub Upvote 21 +15 freddyaboulton Freddy Boulton Meeting a Gap in the Toolbox of AI Developers Free Access with Your Hugging Face Account Why This Matters for AI Developers Getting Started What's Next? We're excited to announce a new partnership between Cloudflare and Hugging Face that gives FastRTC developers instant access to enterprise-grade WebRTC infrastructure with a Hugging Face token. As a preview of what you can build with FastRTC and Cloudflare, check out this voice chat app built with Meta's new Llama 4 model! Meeting a Gap in the Toolbox of AI Developers As conversational AI becomes a core interface for tools, products, and services, real-time communication infrastructure is increasingly essential to support natural, multimodal interactions. Hugging Face built FastRTC to let AI developers build low-latency AI-powered audio and...", "url": "https://huggingface.co/blog/fastrtc-cloudflare", "date_published": "2025-04-09T00:00:00"}, {"id": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval", "image": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png", "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More", "content_text": "Back to Articles Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More Published April 8, 2025 Update on GitHub Upvote 15 +9 alielfilali01 Ali El Filali inceptionai SarahAlBarri Sarah AlBarri inceptionai Arwa88 Abouelseoud inceptionai samta-kamboj samta kamboj inceptionai neha1710 Neha Sengupta inceptionai preslavnakov Preslav Nakov MBZUAI Arabic-Leaderboards Space Latest Updates in AraGen Leaderboard AraGen-03-25 Release Dynamic Evaluation and Ranking Analysis Instruction Following Leaderboard What is Instruction Following as a Benchmark? Dataset: Arabic IFEval Evaluation Methodology & Metrics Results & Analysis Upcoming Work At Inception, we have been working to enhance AI model evaluations within the Arabic language context. Previously, we introduced AraGen , one of the first generative Arabic leaderboards, serving as a benchmark for evaluating Arabic LLMs on generative tasks. As part of our ongoing efforts, we are excited to share the following...", "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval", "date_published": "2025-04-08T00:00:00"}, {"id": "https://huggingface.co/blog/llama4-release", "image": "https://huggingface.co/blog/assets/llama_4.png", "title": "Welcome Llama 4 Maverick & Scout on Hugging Face!", "content_text": "Back to Articles Welcome Llama 4 Maverick & Scout on Hugging Face Published April 5, 2025 Update on GitHub Upvote 140 +134 burtenshaw ben burtenshaw reach-vb Vaibhav Srivastav pcuenq Pedro Cuenca clem Clem \ud83e\udd17 rajatarya Rajat Arya xet-team jsulz Jared Sulzdorf xet-team lysandre Lysandre What is Llama 4? Features and Integrations on Hugging Face Context Length and Architecture Choices How to Use with Transformers Evaluation Scores Pre-trained models Instruction tuned models Acknowledgments References We are incredibly excited to welcome the next generation of large language models from Meta to the Hugging Face Hub: Llama 4 Maverick (~400B) and Llama 4 Scout (~109B)! \ud83e\udd17 Both are Mixture of Experts (MoE) models with 17B active parameters. Released today, these powerful, natively multimodal models represent a significant leap forward. We've worked closely with Meta to ensure seamless integration into the Hugging Face ecosystem, including both transformers and TGI from day one. This is just...", "url": "https://huggingface.co/blog/llama4-release", "date_published": "2025-04-05T00:00:00"}, {"id": "https://huggingface.co/blog/gradio-1m", "image": "https://huggingface.co/blog/assets/gradio-1m/thumbnail.png", "title": "Journey to 1 Million Gradio Users!", "content_text": "Back to Articles Journey to 1 Million Gradio Users! Published April 4, 2025 Update on GitHub Upvote 16 +10 abidlabs Abubakar Abid 5 years ago, we launched Gradio as a simple Python library to let researchers at Stanford easily demo computer vision models with a web interface. Today, Gradio is used by >1 million developers each month to build and share AI web apps. This includes some of the most popular open-source projects of all time, like Automatic1111 , Oobabooga\u2019s Text Generation WebUI , Dall-E Mini , and LLaMA-Factory . How did we get here? How did Gradio keep growing in the very crowded field of open-source Python libraries? I get this question a lot from folks who are building their own open-source libraries. This post distills some of the lessons that I have learned over the past few years: Invest in good primitives, not high-level abstractions Embed virality directly into your library Focus on a (growing) niche Your only roadmap should be rapid iteration Maximize ways users...", "url": "https://huggingface.co/blog/gradio-1m", "date_published": "2025-04-04T00:00:00"}, {"id": "https://huggingface.co/blog/llm-course", "image": "https://huggingface.co/blog/assets/llm-course/llm-course-rename-thumbnail.png", "title": "The NLP Course is becoming the LLM Course!", "content_text": "Back to Articles The NLP Course is becoming the LLM Course! Published April 3, 2025 Update on GitHub Upvote 81 +75 burtenshaw ben burtenshaw reach-vb Vaibhav Srivastav lewtun Lewis Tunstall fdaudens Florent Daudens pcuenq Pedro Cuenca tomaarsen Tom Aarsen coyotte508 Eliott Coyac mishig Mishig Davaadorj sergiopaniego Sergio Paniego julien-c Julien Chaumond What\u2019s going to happen to the NLP course material? Will there be new chapters? Will there be interactive exercises and live sessions? What\u2019s next? Education has always been at the heart of Hugging Face\u2019s mission to democratize AI and we\u2019re doubling down on that by giving hf.co/learn a big upgrade! Our NLP course has been a go-to resource for the open-source AI community for the past 3 years, and it\u2019s now time for a refresh. We\u2019re updating and expanding it to keep up with all the exciting stuff happening in AI (which is not easy when there are breakthroughs every week!) We felt the excitement during the experimental smol-course and...", "url": "https://huggingface.co/blog/llm-course", "date_published": "2025-04-03T00:00:00"}, {"id": "https://huggingface.co/blog/scaling-secrets-management", "image": "https://huggingface.co/blog/assets/infisical/thumbnail.png", "title": "How Hugging Face Scaled Secrets Management for AI Infrastructure", "content_text": "Back to Articles How Hugging Face Scaled Secrets Management for AI Infrastructure Published March 31, 2025 Update on GitHub Upvote 5 segudev Thomas Segura Infisical Background Implementation Kubernetes Integration Local Development Security and Access Management CI/CD and Infrastructure Integration Technical Outcomes & Insights Conclusion Resources Hugging Face has become synonymous with advancing AI at scale. With over 4 million builders deploying models on the Hub, the rapid growth of the platform necessitated a rethinking of how sensitive configuration data \u2014secrets\u2014 are managed. Last year, the engineering teams set out to improve the handling of their secrets and credentials. After evaluating tools like HashiCorp Vault, they ultimately chose Infisical . This case study details their migration to Infisical, explains how they integrated its powerful features, and highlights how it enabled engineers to work more efficiently and securely. Background As Hugging Face's infrastructure...", "url": "https://huggingface.co/blog/scaling-secrets-management", "date_published": "2025-03-31T00:00:00"}, {"id": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi", "image": "https://huggingface.co/blog/assets/intel-gaudi-backend-for-tgi/tgi-gaudi-thumbnail.png", "title": "Accelerating LLM Inference with TGI on Intel Gaudi", "content_text": "Back to Articles \ud83d\ude80 Accelerating LLM Inference with TGI on Intel Gaudi Published March 28, 2025 Update on GitHub Upvote 13 +7 baptistecolle Baptiste Colle regisss R\u00e9gis Pierrard IlyasMoutawwakil Ilyas Moutawwakil echarlaix Ella Charlaix kding1 Ke Ding Intel \u2728 What's New? \ud83c\udf1f Why This Matters \ud83d\udea6 Getting Started with TGI on Gaudi \ud83c\udf89 Top features \ud83d\udcaa Getting Involved We're excited to announce the native integration of Intel Gaudi hardware support directly into Text Generation Inference (TGI), our production-ready serving solution for Large Language Models (LLMs). This integration brings the power of Intel's specialized AI accelerators to our high-performance inference stack, enabling more deployment options for the open-source AI community \ud83c\udf89 \u2728 What's New? We've fully integrated Gaudi support into TGI's main codebase in PR #3091 . Previously, we maintained a separate fork for Gaudi devices at tgi-gaudi . This was cumbersome for users and prevented us from supporting the latest TGI features at...", "url": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi", "date_published": "2025-03-28T00:00:00"}, {"id": "https://huggingface.co/blog/train-reranker", "image": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png", "title": "Training and Finetuning Reranker Models with Sentence Transformers v4", "content_text": "Back to Articles Training and Finetuning Reranker Models with Sentence Transformers v4 Published March 26, 2025 Update on GitHub Upvote 113 +107 tomaarsen Tom Aarsen Table of Contents What are Reranker models? Why Finetune? Training Components Dataset Data on the Hugging Face Hub Local Data (CSV, JSON, Parquet, Arrow, SQL) Local Data that requires pre-processing Dataset Format Hard Negatives Mining Loss Function Training Arguments Evaluator CrossEncoderCorrelationEvaluator with STSb CrossEncoderRerankingEvaluator with GooAQ mined negatives Trainer Callbacks Multi-Dataset Training Training Tips Evaluation Additional Resources Training Examples Documentation Sentence Transformers is a Python library for using and training embedding and reranker models for a wide range of applications, such as retrieval augmented generation, semantic search, semantic textual similarity, paraphrase mining, and more. Its v4.0 update introduces a new training approach for rerankers, also known as cross-...", "url": "https://huggingface.co/blog/train-reranker", "date_published": "2025-03-26T00:00:00"}, {"id": "https://huggingface.co/blog/gradio-dataframe-upgrade", "image": "https://huggingface.co/blog/assets/gradio-dataframe-update/thumbnail.png", "title": "Introducing Gradio's new Dataframe!", "content_text": "Back to Articles Introducing Gradio's new Dataframe! Published March 24, 2025 Update on GitHub Upvote 23 +17 hmb hannah abidlabs Abubakar Abid What\u2019s next? Try it yourself! Gradio\u2019s gr.Dataframe component is one of our most popular components, we've seen it used in a variety of awesome apps, like leaderboards, dashboards, and interactive visualisations. Although we hadn't made any changes to the dataframe in quite some time, our backlog of issues had been growing, and some improvements had been in demand for a while. Well \u2014 we\u2019re now super excited to release a host of new updates to Gradio\u2019s dataframe component. Over the last 6 weeks, we\u2019ve closed over 70 dataframe issues - including bugs, improvements and enhancements. 1. Multi-Cell Selection You can select multiple cells at once! Copy or delete values across your selection with ease. 2. Row Numbers & Column Pinning Add row number columns and keep critical columns in view while navigating wide datasets using the pinned_columns...", "url": "https://huggingface.co/blog/gradio-dataframe-upgrade", "date_published": "2025-03-24T00:00:00"}, {"id": "https://huggingface.co/blog/endpoint-analytics", "image": "https://huggingface.co/blog/assets/endpoint-analytics/thumbnail.png", "title": "The New and Fresh analytics in Inference Endpoints", "content_text": "Back to Articles Analytics is important Published March 21, 2025 Update on GitHub Upvote 19 +13 erikkaum Erik Kaunism\u00e4ki beurkinger Thibault Goehringer rtrm Remy co42 Corentin Regal michellehbn Michelle Habonneau Analytics and metrics are the cornerstone of understanding what's happening with your deployment. Are your Inference Endpoints overloaded? How many requests are they handling? Having well-visualized, relevant metrics displayed in real-time is crucial for monitoring and debugging. We realized that our analytics dashboard needed a refresh. Since we debug a lot of endpoints ourselves, we\u2019ve felt the same pain as our users. That\u2019s why we sat down to plan and make several improvements to provide a better experience for you. What\u2019s New? \u23f0 Real-Time Metrics: Data now updates in real-time, ensuring you get an accurate and up-to-the-second view of your endpoint\u2019s performance. Whether you\u2019re monitoring request latency, response times, or error rates, you can now see the events as...", "url": "https://huggingface.co/blog/endpoint-analytics", "date_published": "2025-03-21T00:00:00"}]}