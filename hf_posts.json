{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/fdaudens/121352437859372", "image": "", "title": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses.", "content_text": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses. Check it out: perplexity-ai/r1-1776 Blog post: https://perplexity.ai/hub/blog/open-sourcing-r1-1776 See translation", "url": "https://huggingface.co/posts/fdaudens/121352437859372", "date_published": "2025-02-20T05:20:00.997717"}, {"id": "https://huggingface.co/posts/burtenshaw/189514834246661", "image": "", "title": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts:", "content_text": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts: 1\ufe0f\u20e3 New Supervised Fine-tuning unit in the NLP Course https://huggingface.co/learn/nlp-course/en/chapter11/1 2\ufe0f\u20e3New Finetuning for agents bonus module in the Agents Course https://huggingface.co/learn/agents-course/bonus-unit1/introduction Fine-tuning will squeeze everything out of your model for how you\u2019re using it, more than any prompt. See translation", "url": "https://huggingface.co/posts/burtenshaw/189514834246661", "date_published": "2025-02-20T05:20:00.998070"}, {"id": "https://huggingface.co/posts/AdinaY/709023807759284", "image": "", "title": "\ud83d\ude80 StepFun\u9636\u8dc3\u661f\u8fb0 is making BIG open moves!", "content_text": "\ud83d\ude80 StepFun\u9636\u8dc3\u661f\u8fb0 is making BIG open moves! Last year, their GOT-OCR 2.0 took the community by storm \ud83d\udd25but many didn\u2019t know they were also building some amazing models. Now, they\u2019ve just dropped something huge on the hub! \ud83d\udcfa Step-Video-T2V: a 30B bilingual open video model that generates 204 frames (8-10s) at 540P resolution with high information density & consistency. stepfun-ai/stepvideo-t2v \ud83d\udd0a Step-Audio-TTS-3B : a TTS trained with the LLM-Chat paradigm on a large synthetic dataset, capable of generating RAP & Humming stepfun-ai/step-audio-67b33accf45735bb21131b0b See translation", "url": "https://huggingface.co/posts/AdinaY/709023807759284", "date_published": "2025-02-20T05:20:00.998446"}, {"id": "https://huggingface.co/posts/prithivMLmods/874083632338295", "image": "", "title": "Dino: The Minimalist Multipurpose Chat System \ud83c\udf20", "content_text": "Dino: The Minimalist Multipurpose Chat System \ud83c\udf20 Agent-Dino : prithivMLmods/Agent-Dino By default, it performs the following tasks: {Text-to-Text Generation}, {Image-Text-Text Generation} @image : Generates an image using Stable Diffusion xL. @3d : Generates a 3D mesh. @web : Web search agents. @rAgent : Initiates a reasoning chain using Llama mode for coding explanations. @tts1-\u2640 , @tts2-\u2642 : Voice generation (Female and Male voices). See translation", "url": "https://huggingface.co/posts/prithivMLmods/874083632338295", "date_published": "2025-02-20T05:20:00.998770"}, {"id": "https://huggingface.co/posts/ginipick/141662077994282", "image": "", "title": "\ud83d\ude80 FLUX Workflow Canvas", "content_text": "\ud83d\ude80 FLUX Workflow Canvas Welcome to Workflow Canvas, your ultimate AI-driven platform for crafting stunning design concepts and intricate workflow diagrams that empower your business! \ud83e\udd16\u2728 ginigen/Workflow-Canvas Features Product Design \ud83d\udee0\ufe0f Transform your ideas into reality with sleek, industrial product designs that blend modern aesthetics with advanced technology. Mindmap \ud83e\udde0 Generate vibrant, educational mind maps that outline your strategies and processes in a clear, visually engaging layout. Mockup \ud83d\udcf1 Quickly prototype intuitive app interfaces and web designs using clean, hand-drawn wireframes that capture your vision. Infographic \ud83d\udcca Build polished, data-rich infographics that communicate complex corporate metrics and trends with style and clarity. Diagram \ud83d\udcc8 Illustrate comprehensive, end-to-end business workflows\u2014from market analysis to implementation\u2014with detailed and organized diagrams. Flowchart \ud83d\udd04 Design easy-to-follow, hand-drawn style flowcharts that map out your operational...", "url": "https://huggingface.co/posts/ginipick/141662077994282", "date_published": "2025-02-20T05:20:00.999398"}, {"id": "https://huggingface.co/posts/clem/219492053181381", "image": "", "title": "What are the best organizations to follow on", "content_text": "What are the best organizations to follow on @ huggingface ? On top of my head: - Deepseek (35,000 followers): https://huggingface.co/deepseek-ai - Meta Llama (27,000 followers): https://huggingface.co/meta-llama - Black Forrest Labs (11,000 followers): https://huggingface.co/black-forest-labs - OpenAI (5,000 followers): https://huggingface.co/openai - Nvidia (16,000 followers): https://huggingface.co/nvidia - MIcrosoft (9,000 followers): https://huggingface.co/microsoft - AllenAI (2,000 followers): https://huggingface.co/allenai - Mistral (5,000 followers): https://huggingface.co/mistralai - XAI (600 followers): https://huggingface.co/xai-org - Stability AI (16,000 followers): https://huggingface.co/stabilityai - Qwen (16,000 followers): https://huggingface.co/Qwen - GoogleAI (8,000 followers): https://huggingface.co/google - Unsloth (3,000 followers): https://huggingface.co/unsloth - Bria AI (4,000 followers): https://huggingface.co/briaai - NousResearch (1,300 followers):...", "url": "https://huggingface.co/posts/clem/219492053181381", "date_published": "2025-02-20T05:20:00.999775"}, {"id": "https://huggingface.co/posts/sayakpaul/418493639663017", "image": "", "title": "Inference-time scaling meets Flux.1-Dev (and others) \ud83d\udd25", "content_text": "Inference-time scaling meets Flux.1-Dev (and others) \ud83d\udd25 Presenting a simple re-implementation of \"Inference-time scaling diffusion models beyond denoising steps\" by Ma et al. I did the simplest random search strategy, but results can potentially be improved with better-guided search methods. Supports Gemini 2 Flash & Qwen2.5 as verifiers for \"LLMGrading\" \ud83e\udd17 The steps are simple: For each round: 1> Starting by sampling 2 starting noises with different seeds. 2> Score the generations w.r.t a metric. 3> Obtain the best generation from the current round. If you have more compute budget, go to the next search round. Scale the noise pool ( 2 ** search_round ) and repeat 1 - 3. This constitutes the random search method as done in the paper by Google DeepMind. Code, more results, and a bunch of other stuff are in the repository. Check it out here: https://github.com/sayakpaul/tt-scale-flux/ \ud83e\udd17 See translation", "url": "https://huggingface.co/posts/sayakpaul/418493639663017", "date_published": "2025-02-20T05:20:01.000216"}, {"id": "https://huggingface.co/posts/merterbak/134010141714846", "image": "", "title": "\ud83d\udd25 Meet Muse: that can generate a game environment based on visuals or players\u2019 controller actions. It was developed by Microsoft Research in collaboration with Ninja Theory (Hellblade developer). It\u2019s built on something called the World and Human Action Model (WHAM-1.6B model). They trained on 7 years of Bleeding Edge gameplay and it can generate 2 minute long 3D game sequences with consistent physics and character behaviors all from just a second of input. They\u2019ve gone and open-sourced it too. Open weights, the WHAM Demonstrator, and sample data on Azure AI Foundry for anyone to play with. Hope so soon on huggingface \ud83e\udd17.", "content_text": "\ud83d\udd25 Meet Muse: that can generate a game environment based on visuals or players\u2019 controller actions. It was developed by Microsoft Research in collaboration with Ninja Theory (Hellblade developer). It\u2019s built on something called the World and Human Action Model (WHAM-1.6B model). They trained on 7 years of Bleeding Edge gameplay and it can generate 2 minute long 3D game sequences with consistent physics and character behaviors all from just a second of input. They\u2019ve gone and open-sourced it too. Open weights, the WHAM Demonstrator, and sample data on Azure AI Foundry for anyone to play with. Hope so soon on huggingface \ud83e\udd17. \ud83d\udcc4 Paper: https://www.nature.com/articles/s41586-025-08600-3 Blog Post: https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/ See translation", "url": "https://huggingface.co/posts/merterbak/134010141714846", "date_published": "2025-02-20T05:20:01.000621"}, {"id": "https://huggingface.co/posts/ShafeeqmohdCMA/932906129553008", "image": "", "title": "\ud83d\ude80 Build AI Agents to Automate Bookkeeping \u2013 Join Finanshels!", "content_text": "\ud83d\ude80 Build AI Agents to Automate Bookkeeping \u2013 Join Finanshels! SMEs waste billions on manual accounting. We\u2019re fixing this with AI agents that handle bookkeeping & tax\u2014fully automated, zero friction. \ud83d\udca1 The Mission: Make accounting invisible. \u26a1 The Challenge: AI + WhatsApp + real-world finance workflows. \ud83d\udd0d Who We Need: A+ engineers who build fast, own big. Ready to ship? DM me or hit Shafeekh@finanshels.com. See translation", "url": "https://huggingface.co/posts/ShafeeqmohdCMA/932906129553008", "date_published": "2025-02-20T05:20:01.000921"}, {"id": "https://huggingface.co/posts/AdinaY/586092411565297", "image": "", "title": "The latest paper of DeepSeek is now available on the Daily Papers page \ud83d\ude80", "content_text": "The latest paper of DeepSeek is now available on the Daily Papers page \ud83d\ude80 You can reach out to the authors directly on this page\ud83d\udc47 Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention (2502.11089) See translation", "url": "https://huggingface.co/posts/AdinaY/586092411565297", "date_published": "2025-02-20T05:20:01.001181"}]}