{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/sergiopaniego/319778709690075", "image": "", "title": "gpt-oss was possible thanks to new engineering efforts in \ud83e\udd17 transformers. We just dropped a blog covering them:", "content_text": "gpt-oss was possible thanks to new engineering efforts in \ud83e\udd17 transformers. We just dropped a blog covering them: - Kernels from the Hub - MXFP4 Quantization - Tensor & Expert Parallelism - Dynamic Sliding Window & Cache - Continuous Batching & Paged Attention Grab a coffee & dive in! \u2615\ufe0f https://huggingface.co/blog/faster-transformers See translation", "url": "https://huggingface.co/posts/sergiopaniego/319778709690075", "date_published": "2025-09-13T13:22:40.270111"}, {"id": "https://huggingface.co/posts/salma-remyx/853424776483426", "image": "", "title": "Most apps don't have great full-text search over their assets.", "content_text": "Most apps don't have great full-text search over their assets. We've developed an agent to automate the environment building and testing of experimental codebases sourced from arXiv. We push these containerized reproductions daily to Docker Hub: https://hub.docker.com/u/remyxai However, searching for them can be challenging unless you know the specific arXiv ID associated with each paper. We are currently working on implementing a search feature in Remyx, which will make these assets easily discoverable and ready for testing \ud83d\udd0d Stay tuned! Discover your next best idea to experiment with here: https://engine.remyx.ai See translation", "url": "https://huggingface.co/posts/salma-remyx/853424776483426", "date_published": "2025-09-13T13:22:40.270532"}, {"id": "https://huggingface.co/posts/yjernite/185479802142810", "image": "", "title": "Tremendous quality of life upgrade on the Hugging Face Hub - we now have auto-complete emojis \ud83e\udd17 \ud83e\udd73 \ud83d\udc4f \ud83d\ude4c \ud83c\udf89", "content_text": "Tremendous quality of life upgrade on the Hugging Face Hub - we now have auto-complete emojis \ud83e\udd17 \ud83e\udd73 \ud83d\udc4f \ud83d\ude4c \ud83c\udf89 Get ready for lots more very serious analysis on a whole range of topics from yours truly now that we have unlocked this full range of expression \ud83d\ude04 \ud83e\udd14 \ud83d\udde3 \ud83d\ude4a See translation", "url": "https://huggingface.co/posts/yjernite/185479802142810", "date_published": "2025-09-13T13:22:40.270945"}, {"id": "https://huggingface.co/posts/drvsbrkcn/494150147788454", "image": "", "title": "Hello everyone,", "content_text": "Hello everyone, It is my first time using Hugging Face. It is hella nice. Take care. See translation", "url": "https://huggingface.co/posts/drvsbrkcn/494150147788454", "date_published": "2025-09-13T13:22:40.271205"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/831958361085352", "image": "", "title": "\ud83c\udf89 Big congratulations to the winners of the \"Synthetic 2 Real Object Detection Challenge 2\", the second Kaggle challenge that Duality AI hosted. This competition was more fierce than the last one, but these users managed to clench the win!", "content_text": "\ud83c\udf89 Big congratulations to the winners of the \"Synthetic 2 Real Object Detection Challenge 2\", the second Kaggle challenge that Duality AI hosted. This competition was more fierce than the last one, but these users managed to clench the win! \ud83e\udd47 1st place: @ sergio-sanz-rodriguez (see the blog he produced with us outlining how he achieved his results: https://tinyurl.com/mreunr98 ) \ud83e\udd48 2nd place: Kaggle user Diana Shilova - https://tinyurl.com/yjjz3szm \ud83e\udd49 3rd place: Kaggle user \u7709\u95f4\u5c3a - https://tinyurl.com/ycxskfzv View the entire leaderboard at - https://tinyurl.com/jm2ery7w Join our current Multi-Class Object Detection Synthetic2Real Kaggle competition here: https://tinyurl.com/y224rttu And we will soon be launching a new competition in a new domain! Hint: \ud83c\udf04 \ud83c\udfe0 \ud83c\udf33 \u2708\ufe0f See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/831958361085352", "date_published": "2025-09-13T13:22:40.271607"}, {"id": "https://huggingface.co/posts/pagezyhf/845836724116614", "image": "", "title": "\ud83e\udd1d Collaborating with AMD to ensure Hugging Face Transformers runs smoothly on AMD GPUs!", "content_text": "\ud83e\udd1d Collaborating with AMD to ensure Hugging Face Transformers runs smoothly on AMD GPUs! We run daily CI on AMD MI325 to track the health of the most important model architectures and we\u2019ve just made our internal dashboard public. By making this easily accessible, we hope to spark community contributions and improve support for everyone! See translation", "url": "https://huggingface.co/posts/pagezyhf/845836724116614", "date_published": "2025-09-13T13:22:40.271882"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/330916531424120", "image": "", "title": "Hunyuan Image 2.1 by Tencent Full Tutorial and 1-Click to Install Ultra Advanced App to Use Locally :", "content_text": "Hunyuan Image 2.1 by Tencent Full Tutorial and 1-Click to Install Ultra Advanced App to Use Locally : https://youtu.be/dNeA5mJ36hA Tutorial video : https://youtu.be/dNeA5mJ36hA Check the below screenshots Hunyuan Image 2.1 just published by Tencent and I have been working on developing the very best app to let you use HunyuanImage-2.1 with easiest and most accurate way. In this tutorial video, I will show you how to literally 1-click to install this model and our app on Windows (locally), Massed Compute (cloud) and RunPod (cloud). The images are all raw 2560x1440 pixels with 8-steps Refiner of Hunyuan Image 2.1 model This model native resolution is 2048x2048 pixels See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/330916531424120", "date_published": "2025-09-13T13:22:40.272211"}, {"id": "https://huggingface.co/posts/vansin/596257741318226", "image": "", "title": "A cute Intern With Hugging Face", "content_text": "A cute Intern With Hugging Face See translation", "url": "https://huggingface.co/posts/vansin/596257741318226", "date_published": "2025-09-13T13:22:40.272409"}, {"id": "https://huggingface.co/posts/sanaka87/107769277937246", "image": "", "title": "Excited to share our Unified Multimodal Models new work Reconstruction Alignment (RecA)! \ud83d\ude80 Just 6 \u00d7 80GB A100s \u00d7 4.5 hours to boost BAGEL performance across all tasks! Outperforms FLUX-Kontext in image editing capabilities!", "content_text": "Excited to share our Unified Multimodal Models new work Reconstruction Alignment (RecA)! \ud83d\ude80 Just 6 \u00d7 80GB A100s \u00d7 4.5 hours to boost BAGEL performance across all tasks! Outperforms FLUX-Kontext in image editing capabilities! \ud83d\udcc4 Paper: https://alphaxiv.org/abs/2509.07295 \ud83d\udcbb Code: https://github.com/HorizonWind2004/reconstruction-alignment \ud83e\udd17 HF Models: sanaka87/reca-68ad2176380355a3dcedc068 \u270d\ufe0f DEMO: sanaka87/BAGEL-RecA \ud83c\udf10 Project Page: https://reconstruction-alignment.github.io \ud83d\udd25 X: https://x.com/XDWang101/status/1965908302581420204 \ud83d\udcf0 Zhihu: https://zhuanlan.zhihu.com/p/1947584568187159814 \ud83e\udd17 HF Daily Paper: Reconstruction Alignment Improves Unified Multimodal Models (2509.07295) \u26a1 <10k images & 27 GPU hours (no-arch-changes) \u2192 SOTA, surpassing much larger open-source & private models: \ud83d\udcca GenEval: 0.73 \u2192 0.90 | \ud83d\udcca DPGBench: 80.93 \u2192 88.15 \ud83d\uddbc\ufe0f ImgEdit: 3.38 \u2192 3.75 | \ud83d\udd8c\ufe0f GEdit: 6.94 \u2192 7.25 \u2705 RecA trains UMMs to reconstruct images from their own visual understanding encoder embeddings \u2192 big gains...", "url": "https://huggingface.co/posts/sanaka87/107769277937246", "date_published": "2025-09-13T13:22:40.272839"}, {"id": "https://huggingface.co/posts/ehristoforu/878870828428356", "image": "", "title": "\ud83d\ude80Hello from the Project Fluently team!", "content_text": "\ud83d\ude80Hello from the Project Fluently team! \u2728 We are happy to share with you our new universal LLM models based on Qwen3 1.7B and 4B \u2014 powerful, multilingual and ready to solve a wide range of problems! \ud83d\udee0\ufe0f We have conducted additional training and carefully merged them to achieve even better results and maximize the potential of the models. \ud83c\udd93 And most importantly \u2014 the models are completely open and free under the Apache-2.0 license! \ud83d\udd17 Links to repositories: - FluentlyQwen3-4B: fluently/FluentlyQwen3-4B - FluentlyQwen3-1.7B: fluently/FluentlyQwen3-1.7B \ud83d\ude0d We will be very glad to hear your feedback and impressions! Your opinion is very important to us! See translation", "url": "https://huggingface.co/posts/ehristoforu/878870828428356", "date_published": "2025-09-13T13:22:40.273201"}]}