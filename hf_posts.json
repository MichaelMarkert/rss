{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/198818765852761", "image": "", "title": "\ud83d\ude80 DeepSeek V3-0324 + Real-time Research Power! \ud83c\udf10", "content_text": "\ud83d\ude80 DeepSeek V3-0324 + Real-time Research Power! \ud83c\udf10 Hello there! Today I'm excited to introduce an amazing tool based on the DeepSeek V3-0324 latest model. This isn't just another AI chatbot\u2014it's a true \"research assistant\" capable of real-time information retrieval and analysis! openfree/Deepseek-v3-0324-Research \ud83e\udde0 Key Strengths of DeepSeek V3-0324 DeepSeek V3-0324, provided by Fireworks AI, comes with these powerful advantages: \ud83c\udfaf Superior Reasoning: Excellent ability to solve complex problems step-by-step \ud83d\udcda Extensive Knowledge: Deep understanding across various topics from comprehensive training \ud83e\udde9 Context Awareness: Maintains long conversation contexts for consistent responses \ud83c\udf0d Multilingual Support: Processes various languages effectively \ud83d\udd0e Added Real-time \"Deep Research\" Capability! The most exciting feature of this project is the implementation of real-time search functionality similar to ChatGPT's Browse with Bing or Perplexity AI! \ud83c\udf1f How does it work? \ud83d\udccb Query Analysis: Analyzes...", "url": "https://huggingface.co/posts/openfree/198818765852761", "date_published": "2025-03-27T05:21:21.978657"}, {"id": "https://huggingface.co/posts/giadap/214321702054817", "image": "", "title": "We've all become experts at clicking \"I agree\" without a second thought. In my latest blog post, I explore why these traditional consent models are increasingly problematic in the age of generative AI.", "content_text": "We've all become experts at clicking \"I agree\" without a second thought. In my latest blog post, I explore why these traditional consent models are increasingly problematic in the age of generative AI. I found three fundamental challenges: - Scope problem: how can you know what you're agreeing to when AI could use your data in different ways? - Temporality problem: once an AI system learns from your data, good luck trying to make it \"unlearn\" it. - Autonomy trap: the data you share today could create systems that pigeonhole you tomorrow. Individual users shouldn't bear all the responsibility, while big tech holds all the cards. We need better approaches to level the playing field, from collective advocacy and stronger technological safeguards to establishing \"data fiduciaries\" with a legal duty to protect our digital interests. Available here: https://huggingface.co/blog/giadap/beyond-consent See translation", "url": "https://huggingface.co/posts/giadap/214321702054817", "date_published": "2025-03-27T05:21:21.979060"}, {"id": "https://huggingface.co/posts/chansung/621792589205071", "image": "", "title": "simple guide on the recipe for GRPO on Open-R1 which is built on top of TRL", "content_text": "simple guide on the recipe for GRPO on Open-R1 which is built on top of TRL I think FastAPI wrapper of vLLM with WeightSyncWorker is pretty cool feature. Also, we have many predefined reward functions out of the box! See translation", "url": "https://huggingface.co/posts/chansung/621792589205071", "date_published": "2025-03-27T05:21:21.979307"}, {"id": "https://huggingface.co/posts/tomaarsen/443265255291103", "image": "", "title": "\u203c\ufe0fSentence Transformers v4.0 is out! You can now train and finetune reranker models with multi-GPU training, bf16 support, loss logging, callbacks & much more. I also prove that finetuning on your domain helps much more than you might think.", "content_text": "\u203c\ufe0fSentence Transformers v4.0 is out! You can now train and finetune reranker models with multi-GPU training, bf16 support, loss logging, callbacks & much more. I also prove that finetuning on your domain helps much more than you might think. 1\ufe0f\u20e3 Reranker Training Refactor Reranker models can now be trained using an extensive trainer with a lot of powerful features: - MultiGPU Training (Data Parallelism (DP) and Distributed Data Parallelism (DDP)) - bf16 training support; loss logging - Evaluation datasets + evaluation loss - Improved callback support + an excellent Weights & Biases integration - Gradient checkpointing, gradient accumulation - Model card generation - Resuming from a training checkpoint without performance loss - Hyperparameter Optimization and much more! Read my detailed blogpost to learn about the components that make up this new training approach: https://huggingface.co/blog/train-reranker Notably, the release is fully backwards compatible: all deprecations are...", "url": "https://huggingface.co/posts/tomaarsen/443265255291103", "date_published": "2025-03-27T05:21:21.979952"}, {"id": "https://huggingface.co/posts/nroggendorff/410679759202527", "image": "", "title": "I'm not really doing much on HuggingFace right now due to their new Docker space policies, so if you want to keep up with most of what I'm up to, follow my [instagram](", "content_text": "I'm not really doing much on HuggingFace right now due to their new Docker space policies, so if you want to keep up with most of what I'm up to, follow my [instagram]( https://sly.sh/ig ) See translation", "url": "https://huggingface.co/posts/nroggendorff/410679759202527", "date_published": "2025-03-27T05:21:21.980198"}, {"id": "https://huggingface.co/posts/ZennyKenny/895817584228018", "image": "", "title": "Besides being the coolest named benchmark in the game, HellaSwag is an important measurement of \u0437\u0434\u0440\u0430\u0432\u044b\u0439 \u0441\u043c\u044b\u0441\u043b\u044c (or common sense) in LLMs.", "content_text": "Besides being the coolest named benchmark in the game, HellaSwag is an important measurement of \u0437\u0434\u0440\u0430\u0432\u044b\u0439 \u0441\u043c\u044b\u0441\u043b\u044c (or common sense) in LLMs. - More on HellaSwag: https://github.com/rowanz/hellaswag I spent the afternoon benchmarking YandexGPT Pro 4th Gen, one of the Russian tech giant's premier models. - Yandex HF Org: https://huggingface.co/yandex - More on Yandex models: https://yandex.cloud/ru/docs/foundation-models/concepts/yandexgpt/models The eval notebook is available on GitHub and the resulting dataset is already on the HF Hub! - Eval Notebook: https://github.com/kghamilton89/ai-explorer/blob/main/yandex-hellaswag/hellaswag-assess.ipynb - Eval Dataset: ZennyKenny/yandexgptpro_4th_gen-hellaswag And of course, everyone wants to see the results so have a look at the results in the context of other zero-shot experiments that I was able to find! See translation", "url": "https://huggingface.co/posts/ZennyKenny/895817584228018", "date_published": "2025-03-27T05:21:21.980604"}, {"id": "https://huggingface.co/posts/luigi12345/403914274386316", "image": "", "title": "\ud83d\udd25 ULTRA VIDEO COMPRESSION (300MB \u2192 3MB!)", "content_text": "\ud83d\udd25 ULTRA VIDEO COMPRESSION (300MB \u2192 3MB!) ffmpeg - i input .mp4 -vcodec libx264 -crf 28 -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" -y output.mp4 -i \u2192 Input \u26a1\ufe0f -vcodec libx264 \u2192 H.264 codec \u26a1\ufe0f -crf 28 \u2192 Compression (lower = better quality) \u26a1\ufe0f-vf pad=... \u2192 Even dimensions \u26a1\ufe0f -y \u2192 Overwrite See translation", "url": "https://huggingface.co/posts/luigi12345/403914274386316", "date_published": "2025-03-27T05:21:21.980883"}, {"id": "https://huggingface.co/posts/wassemgtk/397348237653076", "image": "", "title": "For fun, a new project: SuperTokenizer! A BPE tokenizer trained on C4 to beat GPT-4. Byte-level, A100-powered, and open-source. Messing around with tokens!", "content_text": "For fun, a new project: SuperTokenizer! A BPE tokenizer trained on C4 to beat GPT-4. Byte-level, A100-powered, and open-source. Messing around with tokens! https://github.com/wassemgtk/SuperTokenizer See translation", "url": "https://huggingface.co/posts/wassemgtk/397348237653076", "date_published": "2025-03-27T05:21:21.981115"}, {"id": "https://huggingface.co/posts/MikeDoes/814156384414808", "image": "", "title": "\ud83d\ude80 We are quite excited to announce the Ai4Privacy Python library! \ud83c\udf89", "content_text": "\ud83d\ude80 We are quite excited to announce the Ai4Privacy Python library! \ud83c\udf89 pip install ai4privacy to anonymize short english text with OpenPII Masking 500k labels \ud83d\udcca Day 5/7 of PII Masking 1M announcements complete! \u23f0 See translation", "url": "https://huggingface.co/posts/MikeDoes/814156384414808", "date_published": "2025-03-27T05:21:21.981361"}, {"id": "https://huggingface.co/posts/AdinaY/110456133360984", "image": "", "title": "A new OPEN Omni model just dropped by @Alibaba_Qwen on the hub\ud83d\udd25\ud83e\udd2f", "content_text": "A new OPEN Omni model just dropped by @Alibaba_Qwen on the hub\ud83d\udd25\ud83e\udd2f Qwen2.5-Omni: a 7B end-to-end multimodal model Qwen/Qwen2.5-Omni-7B \u2728 Thinker-Talker architecture \u2728 Real-time voice & video chat \u2728 Natural speech generation \u2728 Handles text, image, audio & video See translation", "url": "https://huggingface.co/posts/AdinaY/110456133360984", "date_published": "2025-03-27T05:21:21.981640"}]}