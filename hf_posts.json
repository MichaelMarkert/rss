{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Kseniase/484268922176188", "image": "", "title": "6 Free resources on Reinforcement Learning (RL)", "content_text": "6 Free resources on Reinforcement Learning (RL) RL now is where the real action is, it's the engine behind autonomous tech, robots, and the next wave of AI that thinks, moves and solves problems on its own. To stay up to date with what\u2019s happening in RL, we offer some fresh materials on it: 1. \"Reinforcement Learning from Human Feedback\" by Nathan Lambert -> https://rlhfbook.com/ It's a short introduction to RLHF, explaining instruction tuning, reward modeling, alignment methods, synthetic data, evaluation, and more 2. \"A Course in Reinforcement Learning (2nd Edition)\" by Dimitri P. Bertsekas -> https://www.mit.edu/~dimitrib/RLbook.html Explains dynamic programming (DP) and RL, diving into rollout algorithms, neural networks, policy learning, etc. It\u2019s packed with solved exercises and real-world examples 3. \"Mathematical Foundations of Reinforcement Learning\" video course by Shiyu Zhao -> https://www.youtube.com/playlist?list=PLEhdbSEZZbDaFWPX4gehhwB9vJZJ1DNm8 Offers a mathematical...", "url": "https://huggingface.co/posts/Kseniase/484268922176188", "date_published": "2025-04-28T10:52:03.978834"}, {"id": "https://huggingface.co/posts/danielhanchen/766411311755038", "image": "", "title": "\ud83e\udda5  Introducing Unsloth Dynamic v2.0 GGUFs!", "content_text": "\ud83e\udda5 Introducing Unsloth Dynamic v2.0 GGUFs! Our v2.0 quants set new benchmarks on 5-shot MMLU and KL Divergence, meaning you can now run & fine-tune quantized LLMs while preserving as much accuracy as possible. Llama 4: unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF DeepSeek-R1: unsloth/DeepSeek-R1-GGUF-UD Gemma 3: unsloth/gemma-3-27b-it-GGUF We made selective layer quantization much smarter. Instead of modifying only a subset of layers, we now dynamically quantize all layers so every layer has a different bit. Now, our dynamic method can be applied to all LLM architectures, not just MoE's. Blog with Details: https://docs.unsloth.ai/basics/dynamic-v2.0 All our future GGUF uploads will leverage Dynamic 2.0 and our hand curated 300K\u20131.5M token calibration dataset to improve conversational chat performance. For accurate benchmarking, we built an evaluation framework to match the reported 5-shot MMLU scores of Llama 4 and Gemma 3. This allowed apples-to-apples comparisons between full-...", "url": "https://huggingface.co/posts/danielhanchen/766411311755038", "date_published": "2025-04-28T10:52:03.979313"}, {"id": "https://huggingface.co/posts/DawnC/336452242310313", "image": "", "title": "I'm excited to introduce VisionScout \u2014an interactive vision tool that makes computer vision both accessible and powerful! \ud83d\udc40\ud83d\udd0d", "content_text": "I'm excited to introduce VisionScout \u2014an interactive vision tool that makes computer vision both accessible and powerful! \ud83d\udc40\ud83d\udd0d What can VisionScout do right now? \ud83d\uddbc\ufe0f Upload any image and detect 80 different object types using YOLOv8. \ud83d\udd04 Instantly switch between Nano, Medium, and XLarge models depending on your speed vs. accuracy needs. \ud83c\udfaf Filter specific classes (people, vehicles, animals, etc.) to focus only on what matters to you. \ud83d\udcca View detailed statistics about detected objects, confidence levels, and spatial distribution. \ud83c\udfa8 Enjoy a clean, intuitive interface with responsive design and enhanced visualizations. What's next? I'm working on exciting updates: - Support for more models - Video processing and object tracking across frames - Faster real-time detection - Improved mobile responsiveness The goal is to build a complete but user-friendly vision toolkit for both beginners and advanced users. Try it yourself! \ud83d\ude80 DawnC/VisionScout I'd love to hear your feedback , what features would...", "url": "https://huggingface.co/posts/DawnC/336452242310313", "date_published": "2025-04-28T10:52:03.979801"}, {"id": "https://huggingface.co/posts/jasoncorkill/653065305581211", "image": "", "title": "\ud83d\ude80 Building Better Evaluations: 32K Image Annotations Now Available", "content_text": "\ud83d\ude80 Building Better Evaluations: 32K Image Annotations Now Available Today, we're releasing an expanded version: 32K images annotated with 3.7M responses from over 300K individuals which was completed in under two weeks using the Rapidata Python API. Rapidata/text-2-image-Rich-Human-Feedback-32k A few months ago, we published one of our most liked dataset with 13K images based on the @ data-is-better-together 's dataset, following Google's research on \"Rich Human Feedback for Text-to-Image Generation\" ( https://arxiv.org/abs/2312.10240 ). It collected over 1.5M responses from 150K+ participants. Rapidata/text-2-image-Rich-Human-Feedback In the examples below, users highlighted words from prompts that were not correctly depicted in the generated images. Higher word scores indicate more frequent issues. If an image captured the prompt accurately, users could select [No_mistakes]. We're continuing to work on large-scale human feedback and model evaluation. If you're working on related...", "url": "https://huggingface.co/posts/jasoncorkill/653065305581211", "date_published": "2025-04-28T10:52:03.980243"}, {"id": "https://huggingface.co/posts/ProCreations/966463038154493", "image": "", "title": "Post of the Day", "content_text": "Post of the Day I\u2019m fine-tuning Qwen 2.5-0.5B to be extremely good at math, using high-quality datasets and some smart training strategies. The logs are looking really promising so far! Expected release: Tomorrow morning? I\u2019ll post as soon as it\u2019s ready \u2014 stay tuned. If you want faster updates or just wanna chat about it, come join my Discord: https://discord.gg/EXsug2Ux29 (Heads up: we might ask a couple quick questions when you join \u2014 just making sure we keep the server safe.) Also, check out one of the datasets we\u2019re using: ProCreations/SimpleMath This project is also helping shape the future of IntellIte. The insights and techniques we\u2019re developing here \u2014 better dataset curation, fine-tuning tricks, and evaluation methods \u2014 will directly contribute to making IntellIte even sharper, faster, and more reliable, especially for math and reasoning tasks. Big progress ahead. Can\u2019t wait to share it with you all! See translation", "url": "https://huggingface.co/posts/ProCreations/966463038154493", "date_published": "2025-04-28T10:52:03.980656"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/127802170120239", "image": "", "title": "ComfyUI 1-click Installers updated for latest official Torch 2.7 with CUDA 12.8 (RTX 5000 series support + older GPUs) - Automatically installs xFormers, Flash Attention, Sage Attention, Triton, DeepSpeed, insightface, accelerate, onnxruntime-gpu for Windows", "content_text": "ComfyUI 1-click Installers updated for latest official Torch 2.7 with CUDA 12.8 (RTX 5000 series support + older GPUs) - Automatically installs xFormers, Flash Attention, Sage Attention, Triton, DeepSpeed, insightface, accelerate, onnxruntime-gpu for Windows 1-click Installers zip file is here : https://www.patreon.com/posts/105023709 xFormers compiled by me for Windows (Python 3.10, 3.11 and 3.12) and Linux (Python 3.10 only) Flash Attention compiled by me for Windows (Python 3.10, 3.11 and 3.12) and Linux (Python 3.10 only) Sage Attention compiled by me for Linux (Python 3.10 only) insightface compiled by me for Windows (Python 3.10, 3.11 and 3.12) Pre-compiled Triton + Sage Attention + DeepSpeed installed for Windows You must have pre-installed Python on your system manually Tutorial for Python + CUDA 12.8 installation : https://youtu.be/DrhUHnYfwC0 See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/127802170120239", "date_published": "2025-04-28T10:52:03.980983"}, {"id": "https://huggingface.co/posts/julien-c/991263782380176", "image": "", "title": "BOOOOM: Today I'm dropping TINY AGENTS", "content_text": "BOOOOM: Today I'm dropping TINY AGENTS the 50 lines of code Agent in Javascript \ud83d\udd25 I spent the last few weeks working on this, so I hope you will like it. I've been diving into MCP (Model Context Protocol) to understand what the hype was all about. It is fairly simple, but still quite powerful: MCP is a standard API to expose sets of Tools that can be hooked to LLMs. But while doing that, came my second realization: Once you have a MCP Client, an Agent is literally just a while loop on top of it. \ud83e\udd2f \u27a1\ufe0f read it exclusively on the official HF blog: https://huggingface.co/blog/tiny-agents See translation", "url": "https://huggingface.co/posts/julien-c/991263782380176", "date_published": "2025-04-28T10:52:03.981310"}, {"id": "https://huggingface.co/posts/ImranzamanML/972513852482559", "image": "", "title": "\ud83d\ude80 New paper out: \"Improving Arabic Multi-Label Emotion Classification using Stacked Embeddings and Hybrid Loss Function\"", "content_text": "\ud83d\ude80 New paper out: \"Improving Arabic Multi-Label Emotion Classification using Stacked Embeddings and Hybrid Loss Function\" Improving Arabic Multi-Label Emotion Classification using Stacked Embeddings and Hybrid Loss Function (2410.03979) In this work, we tackle some major challenges in Arabic multi-label emotion classification especially the issues of class imbalance and label correlation that often hurt model performance, particularly for minority emotions. Our approach: Stacked contextual embeddings from fine-tuned ArabicBERT, MarBERT, and AraBERT models. A meta-learning strategy that builds richer representations. A hybrid loss function combining class weighting, label correlation matrices, and contrastive learning to better handle class imbalances. \ud83e\udde0 Model pipeline: stacked embeddings \u2192 meta-learner \u2192 Bi-LSTM \u2192 fully connected network \u2192 multi-label classification. \ud83d\udd0d Extensive experiments show significant improvements across Precision, Recall, F1-Score, Jaccard Accuracy, and...", "url": "https://huggingface.co/posts/ImranzamanML/972513852482559", "date_published": "2025-04-28T10:52:03.981854"}, {"id": "https://huggingface.co/posts/nicolay-r/458849172237757", "image": "", "title": "\ud83d\ude80 Delighted to share a major milestone in adapting reasoning techniques for data collections augmentation!", "content_text": "\ud83d\ude80 Delighted to share a major milestone in adapting reasoning techniques for data collections augmentation! Introducing bulk-chain 1.0.0 -- the first major release of a no-string API for adapting your LLM for Chain-of-Thought alike reasoning over records with large amount of parameters across large datasets. \u2b50 Check it out: https://github.com/nicolay-r/bulk-chain What\u2019s new and why it matters: \ud83d\udce6 Fully no-string API for easy client deployment \ud83d\udd25 Demos are now standalone projects: Demos: \ud83d\udcfa bash / shell (dispatched): https://github.com/nicolay-r/bulk-chain-shell \ud83d\udcfa tksheet: https://github.com/nicolay-r/bulk-chain-tksheet-client Using nlp-thirdgate to host the supported providers: \ud83c\udf0c LLM providers: https://github.com/nicolay-r/nlp-thirdgate See translation", "url": "https://huggingface.co/posts/nicolay-r/458849172237757", "date_published": "2025-04-28T10:52:03.982215"}, {"id": "https://huggingface.co/posts/ginipick/433098376713304", "image": "", "title": "# \u2728 Dream of IKEA: The Future of AI Interior Design \u2728", "content_text": "# \u2728 Dream of IKEA: The Future of AI Interior Design \u2728 Hello, AI interior design enthusiasts! \ud83c\udfe0 Today I'm thrilled to introduce you to **\"Dream of IKEA\"** - an amazing project that will completely transform your living spaces! ## \ud83c\udf1f What Can It Do? **Dream of IKEA** is a magical tool that uses artificial intelligence to transform your ordinary spaces into the interior design of your dreams! \ud83e\ude84 - \ud83d\udcf8 Simply upload a photo of your room - \ud83d\udcad Describe your desired style or concept - \ud83c\udfa8 The AI will redesign your space with stunning results! ## \ud83c\udfc6 Key Features - **Diverse Style Selection** - Over 20 design styles including Minimalist, Bohemian, Japanese, Scandinavian, and more - **User-Friendly Interface** - Beautiful, intuitive UI that anyone can use - **High-Quality Image Generation** - Amazing quality powered by ControlNet and Stable Diffusion - **Customizable Prompts** - Create completely personalized designs with your own prompts ## \ud83d\udee0\ufe0f Technical Highlights This project utilizes cutting-edge...", "url": "https://huggingface.co/posts/ginipick/433098376713304", "date_published": "2025-04-28T10:52:03.982829"}]}