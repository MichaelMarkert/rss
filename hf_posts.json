{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/KaiChen1998/260621109030490", "image": "", "title": "\ud83d\udce2 Our EMOVA paper has been accepted by CVPR 2025, and we are glad to release all resources, including code (training & inference), datasets (training & evaluation), and checkpoints (EMOVA-3B/7B/72B)!", "content_text": "\ud83d\udce2 Our EMOVA paper has been accepted by CVPR 2025, and we are glad to release all resources, including code (training & inference), datasets (training & evaluation), and checkpoints (EMOVA-3B/7B/72B)! \ud83e\udd17 EMOVA is a novel end-to-end omni-modal LLM that can see, hear and speak. Given omni-modal (i.e., textual, visual and speech) inputs, EMOVA can generate both textual and speech responses with vivid emotional controls by utilizing the speech decoder and a style controller. \u2728 EMOVA Highlights \u2705 State-of-the-art omni-modality: EMOVA achieves SoTA comparable results on both vision-language and speech benchmarks simultaneously. \u2705 Device adaptation: our codebase supports training/inference on both NVIDIA GPUs (e.g., A800 & H20) and Ascend NPUs (e.g., 910B3)! \u2705 Modular design: we integrate multiple implementations of vision encoder, vision projector, and language model, even including the most recent DeepSeekMoE-tiny! \ud83d\udd25 You are all welcome to try and star! - Project page: https://emova-...", "url": "https://huggingface.co/posts/KaiChen1998/260621109030490", "date_published": "2025-03-17T13:31:01.251515"}, {"id": "https://huggingface.co/posts/Kseniase/624548696865407", "image": "", "title": "15 types of attention mechanisms", "content_text": "15 types of attention mechanisms Attention mechanisms allow models to dynamically focus on specific parts of their input when performing tasks. In our recent article, we discussed Multi-Head Latent Attention (MLA) in detail and now it's time to summarize other existing types of attention. Here is a list of 15 types of attention mechanisms used in AI models: 1. Soft attention (Deterministic attention) -> Neural Machine Translation by Jointly Learning to Align and Translate (1409.0473) Assigns a continuous weight distribution over all parts of the input. It produces a weighted sum of the input using attention weights that sum to 1. 2. Hard attention (Stochastic attention) -> Effective Approaches to Attention-based Neural Machine Translation (1508.04025) Makes a discrete selection of some part of the input to focus on at each step, rather than attending to everything. 3. Self-attention -> Attention Is All You Need (1706.03762) Each element in the sequence \"looks\" at other elements and...", "url": "https://huggingface.co/posts/Kseniase/624548696865407", "date_published": "2025-03-17T13:31:01.252221"}, {"id": "https://huggingface.co/posts/hanzla/186651630886849", "image": "", "title": "Hello community,", "content_text": "Hello community, I want to share my work of creating a reasoning mamba model I used GRPO over Falcon3 Mamba Instruct to make this model. It generates blazing fast response while building good logic to answer challenging questions. Give it a try: Model repo: hanzla/Falcon3-Mamba-R1-v0 Space: hanzla/Falcon3MambaReasoner Looking forward to community feedback. See translation", "url": "https://huggingface.co/posts/hanzla/186651630886849", "date_published": "2025-03-17T13:31:01.252515"}, {"id": "https://huggingface.co/posts/AtAndDev/784658782191587", "image": "", "title": "There seems to multiple paid apps shared here that are based on models on hf, but some ppl sell their wrappers as \"products\" and promote them here. For a long time, hf was the best and only platform to do oss model stuff but with the recent AI website builders anyone can create a product (really crappy ones btw) and try to sell it with no contribution to oss stuff. Please dont do this, or try finetuning the models you use...", "content_text": "There seems to multiple paid apps shared here that are based on models on hf, but some ppl sell their wrappers as \"products\" and promote them here. For a long time, hf was the best and only platform to do oss model stuff but with the recent AI website builders anyone can create a product (really crappy ones btw) and try to sell it with no contribution to oss stuff. Please dont do this, or try finetuning the models you use... Sorry for filling yall feed with this bs but yk... See translation", "url": "https://huggingface.co/posts/AtAndDev/784658782191587", "date_published": "2025-03-17T13:31:01.252814"}, {"id": "https://huggingface.co/posts/m-ric/783111989290994", "image": "", "title": "smolagents now support vLLM! \ud83e\udd73", "content_text": "smolagents now support vLLM! \ud83e\udd73 As one of the most popular local inference solutions, the community had been asking us to integrate vLLM: after a heavy refactoring of our LLM classes, we've just released smolagents 1.11.0, with a brand new VLLMModel class. Go try it and tell us what you think! https://github.com/huggingface/smolagents/blob/45b2c86857b7f7657daaa74e4d17d347e9e2c4a4/src/smolagents/models.py#L497 See translation", "url": "https://huggingface.co/posts/m-ric/783111989290994", "date_published": "2025-03-17T13:31:01.253102"}, {"id": "https://huggingface.co/posts/openfree/269373246432749", "image": "", "title": "\ud83d\ude80 Idea Transformer:", "content_text": "\ud83d\ude80 Idea Transformer: Idea Transformer: Infinity is an innovative tool that unlocks infinite creativity by generating unique transformation ideas and design images from up to three keywords and a chosen category. Leveraging a state-of-the-art diffusion pipeline, real-time translation, and a powerful LLM, it delivers fresh ideas every time. \ud83c\udfa8\u2728 openfree/Idea-Transformer Key Features Diverse Ideas: Randomly selects creative variations from your keywords and category \u2014 the possibilities are nearly endless! \ud83c\udfb2 Unique Design Images: Your text prompt produces striking, varied design images via the diffusion model. \ud83d\uddbc\ufe0f Real-Time Translation & Expansion: Korean inputs are automatically translated and enriched using an advanced LLM for high-quality output. \ud83d\udd04 Dual-Language Support: Enjoy an intuitive Gradio interface with separate English and Korean tabs for a global audience. \ud83c\udf0d Explore a Wide Range of Categories: Sensor Functions \ud83d\udce1: Creative changes in sensor technologies. Size & Shape Change \ud83d\udccf:...", "url": "https://huggingface.co/posts/openfree/269373246432749", "date_published": "2025-03-17T13:31:01.253752"}, {"id": "https://huggingface.co/posts/vansin/329603150202451", "image": "", "title": "\ud83d\udd25MedAgentBench Amazing Work\ud83d\ude80", "content_text": "\ud83d\udd25MedAgentBench Amazing Work\ud83d\ude80 Just explored #MedAgentBench from @ Yale researchers and it's mind-blowing! They've created a cutting-edge benchmark that finally exposes the true capabilities of LLMs in complex medical reasoning. \u26a1 Key discoveries: DeepSeek R1 & OpenAI O3 dominate clinical reasoning tasks Agent-based frameworks deliver exceptional performance-cost balance Open-source alternatives are closing the gap at fraction of the cost This work shatters previous benchmarks that failed to challenge today's advanced models. The future of medical AI is here: https://github.com/gersteinlab/medagents-benchmark #MedicalAI #MachineLearning #AIinHealthcare \ud83d\udd25 See translation", "url": "https://huggingface.co/posts/vansin/329603150202451", "date_published": "2025-03-17T13:31:01.254110"}, {"id": "https://huggingface.co/posts/clem/238420842235482", "image": "", "title": "We just crossed 1,500,000 public models on Hugging Face (and 500k spaces, 330k datasets, 50k papers). One new repository is created every 15 seconds. Congratulations all!", "content_text": "We just crossed 1,500,000 public models on Hugging Face (and 500k spaces, 330k datasets, 50k papers). One new repository is created every 15 seconds. Congratulations all! See translation", "url": "https://huggingface.co/posts/clem/238420842235482", "date_published": "2025-03-17T13:31:01.254351"}, {"id": "https://huggingface.co/posts/mlabonne/443122762320210", "image": "", "title": "\u2702\ufe0f Gemma 3 Abliterated", "content_text": "\u2702\ufe0f Gemma 3 Abliterated I noticed that Gemma 3 was much more resilient to refusal removal than other models like Qwen 2.5. I experimented with different recipes and improved the abliteration technique I wrote about last year. It's still experimental but the refusal rate is super low in my tests. Enjoy! mlabonne/gemma-3-4b-it-abliterated mlabonne/gemma-3-12b-it-abliterated mlabonne/gemma-3-27b-it-abliterated See translation", "url": "https://huggingface.co/posts/mlabonne/443122762320210", "date_published": "2025-03-17T13:31:01.254652"}, {"id": "https://huggingface.co/posts/onekq/890797314182369", "image": "", "title": "Common formula to DIY a LLM:", "content_text": "Common formula to DIY a LLM: Post train a Qwen model with a dataset distilled from DeepSeek \ud83d\ude02 See translation", "url": "https://huggingface.co/posts/onekq/890797314182369", "date_published": "2025-03-17T13:31:01.254870"}]}