{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/141662077994282", "image": "", "title": "\ud83d\ude80 FLUX Workflow Canvas", "content_text": "\ud83d\ude80 FLUX Workflow Canvas Welcome to Workflow Canvas, your ultimate AI-driven platform for crafting stunning design concepts and intricate workflow diagrams that empower your business! \ud83e\udd16\u2728 ginigen/Workflow-Canvas Features Product Design \ud83d\udee0\ufe0f Transform your ideas into reality with sleek, industrial product designs that blend modern aesthetics with advanced technology. Mindmap \ud83e\udde0 Generate vibrant, educational mind maps that outline your strategies and processes in a clear, visually engaging layout. Mockup \ud83d\udcf1 Quickly prototype intuitive app interfaces and web designs using clean, hand-drawn wireframes that capture your vision. Infographic \ud83d\udcca Build polished, data-rich infographics that communicate complex corporate metrics and trends with style and clarity. Diagram \ud83d\udcc8 Illustrate comprehensive, end-to-end business workflows\u2014from market analysis to implementation\u2014with detailed and organized diagrams. Flowchart \ud83d\udd04 Design easy-to-follow, hand-drawn style flowcharts that map out your operational...", "url": "https://huggingface.co/posts/ginipick/141662077994282", "date_published": "2025-02-19T05:19:45.498420"}, {"id": "https://huggingface.co/posts/Jaward/905904518817417", "image": "", "title": "Finally here it is: a faster, custom, scalable GRPO trainer for smaller models with < 500M params, can train on 8gb ram cpu,  also supports gpu for sanity sake (includes support for vllm + flash attention). Using smolLM2-135M/360M-instructs as ref & base models. Experience your own \u201caha\u201d moment \ud83d\udc33 on 8gb ram.", "content_text": "Finally here it is: a faster, custom, scalable GRPO trainer for smaller models with < 500M params, can train on 8gb ram cpu, also supports gpu for sanity sake (includes support for vllm + flash attention). Using smolLM2-135M/360M-instructs as ref & base models. Experience your own \u201caha\u201d moment \ud83d\udc33 on 8gb ram. Code: https://github.com/Jaykef/ai-algorithms/blob/main/smollm2_360M_135M_grpo_gsm8k.ipynb See translation", "url": "https://huggingface.co/posts/Jaward/905904518817417", "date_published": "2025-02-19T05:19:45.498748"}, {"id": "https://huggingface.co/posts/prithivMLmods/874083632338295", "image": "", "title": "Dino: The Minimalist Multipurpose Chat System \ud83c\udf20", "content_text": "Dino: The Minimalist Multipurpose Chat System \ud83c\udf20 Agent-Dino : prithivMLmods/Agent-Dino By default, it performs the following tasks: {Text-to-Text Generation}, {Image-Text-Text Generation} @image : Generates an image using Stable Diffusion xL. @3d : Generates a 3D mesh. @web : Web search agents. @rAgent : Initiates a reasoning chain using Llama mode for coding explanations. @tts1-\u2640 , @tts2-\u2642 : Voice generation (Female and Male voices). See translation", "url": "https://huggingface.co/posts/prithivMLmods/874083632338295", "date_published": "2025-02-19T05:19:45.499075"}, {"id": "https://huggingface.co/posts/clem/679572962523651", "image": "", "title": "We crossed 1B+ tokens routed to inference providers partners on HF, that we released just a few days ago.", "content_text": "We crossed 1B+ tokens routed to inference providers partners on HF, that we released just a few days ago. Just getting started of course but early users seem to like it & always happy to be able to partner with cool startups in the ecosystem. Have you been using any integration and how can we make it better? https://huggingface.co/blog/inference-providers See translation", "url": "https://huggingface.co/posts/clem/679572962523651", "date_published": "2025-02-19T05:19:45.499337"}, {"id": "https://huggingface.co/posts/burtenshaw/487500789798849", "image": "", "title": "NEW COURSE! We\u2019re cooking hard on Hugging Face courses, and it\u2019s not just agents. The NLP course is getting the same treatment with a new chapter on Supervised Fine-Tuning!", "content_text": "NEW COURSE! We\u2019re cooking hard on Hugging Face courses, and it\u2019s not just agents. The NLP course is getting the same treatment with a new chapter on Supervised Fine-Tuning! \ud83d\udc49 Follow to get more updates https://huggingface.co/nlp-course The new SFT chapter will guide you through these topics: 1\ufe0f\u20e3 Chat Templates: Master the art of structuring AI conversations for consistent and helpful responses. 2\ufe0f\u20e3 Supervised Fine-Tuning (SFT): Learn the core techniques to adapt pre-trained models to your specific outputs. 3\ufe0f\u20e3 Low Rank Adaptation (LoRA): Discover efficient fine-tuning methods that save memory and resources. 4\ufe0f\u20e3 Evaluation: Measure your model's performance and ensure top-notch results. This is the first update in a series, so follow along if you\u2019re upskilling in AI. See translation", "url": "https://huggingface.co/posts/burtenshaw/487500789798849", "date_published": "2025-02-19T05:19:45.499738"}, {"id": "https://huggingface.co/posts/schuler/523097349867184", "image": "", "title": "\ud83d\udd2e GPT-3 implemented in pure Free Pascal!", "content_text": "\ud83d\udd2e GPT-3 implemented in pure Free Pascal! https://github.com/joaopauloschuler/gpt-3-for-pascal This implementation follows the GPT-3 Small architecture from the landmark paper \"Language Models are Few-Shot Learners\": \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Input Layer \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Token & Positional \u2502 \u2502 Embedding \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 12x Transformer \u2502 \u2502 Blocks \u2502 \u2502 - 12 heads \u2502 \u2502 - 768 hidden dims \u2502 \u2502 - 3072 intermediate \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Output Layer \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Clean Pascal Implementation for CntLayer := 1 to {Layers=} 12 do begin Result .AddTransformerBlockCAI( {Heads=} 12 , {intermediate dimensions=} 4 * 768 , {NoForward=} true , {HasNorm=} true , false ) ; end ; See translation", "url": "https://huggingface.co/posts/schuler/523097349867184", "date_published": "2025-02-19T05:19:45.500142"}, {"id": "https://huggingface.co/posts/jasoncorkill/578148904408624", "image": "", "title": "This dataset was collected in roughly 4 hours using the Rapidata Python API, showcasing how quickly large-scale annotations can be performed with the right tooling!", "content_text": "This dataset was collected in roughly 4 hours using the Rapidata Python API, showcasing how quickly large-scale annotations can be performed with the right tooling! All that at less than the cost of a single hour of a typical ML engineer in Zurich! The new dataset of ~22,000 human annotations evaluating AI-generated videos based on different dimensions, such as Prompt-Video Alignment, Word for Word Prompt Alignment, Style, Speed of Time flow and Quality of Physics. Rapidata/text-2-video-Rich-Human-Feedback See translation", "url": "https://huggingface.co/posts/jasoncorkill/578148904408624", "date_published": "2025-02-19T05:19:45.500435"}, {"id": "https://huggingface.co/posts/tianchez/384417618281589", "image": "", "title": "Introducing VLM-R1!", "content_text": "Introducing VLM-R1! GRPO has helped DeepSeek R1 to learn reasoning. Can it also help VLMs perform stronger for general computer vision tasks? The answer is YES and it generalizes better than SFT. We trained Qwen 2.5 VL 3B on RefCOCO (a visual grounding task) and eval on RefCOCO Val and RefGTA (an OOD task). https://github.com/om-ai-lab/VLM-R1 See translation", "url": "https://huggingface.co/posts/tianchez/384417618281589", "date_published": "2025-02-19T05:19:45.500712"}, {"id": "https://huggingface.co/posts/AdinaY/709023807759284", "image": "", "title": "\ud83d\ude80 StepFun\u9636\u8dc3\u661f\u8fb0 is making BIG open moves!", "content_text": "\ud83d\ude80 StepFun\u9636\u8dc3\u661f\u8fb0 is making BIG open moves! Last year, their GOT-OCR 2.0 took the community by storm \ud83d\udd25but many didn\u2019t know they were also building some amazing models. Now, they\u2019ve just dropped something huge on the hub! \ud83d\udcfa Step-Video-T2V: a 30B bilingual open video model that generates 204 frames (8-10s) at 540P resolution with high information density & consistency. stepfun-ai/stepvideo-t2v \ud83d\udd0a Step-Audio-TTS-3B : a TTS trained with the LLM-Chat paradigm on a large synthetic dataset, capable of generating RAP & Humming stepfun-ai/step-audio-67b33accf45735bb21131b0b See translation", "url": "https://huggingface.co/posts/AdinaY/709023807759284", "date_published": "2025-02-19T05:19:45.501053"}, {"id": "https://huggingface.co/posts/sayakpaul/418493639663017", "image": "", "title": "Inference-time scaling meets Flux.1-Dev (and others) \ud83d\udd25", "content_text": "Inference-time scaling meets Flux.1-Dev (and others) \ud83d\udd25 Presenting a simple re-implementation of \"Inference-time scaling diffusion models beyond denoising steps\" by Ma et al. I did the simplest random search strategy, but results can potentially be improved with better-guided search methods. Supports Gemini 2 Flash & Qwen2.5 as verifiers for \"LLMGrading\" \ud83e\udd17 The steps are simple: For each round: 1> Starting by sampling 2 starting noises with different seeds. 2> Score the generations w.r.t a metric. 3> Obtain the best generation from the current round. If you have more compute budget, go to the next search round. Scale the noise pool ( 2 ** search_round ) and repeat 1 - 3. This constitutes the random search method as done in the paper by Google DeepMind. Code, more results, and a bunch of other stuff are in the repository. Check it out here: https://github.com/sayakpaul/tt-scale-flux/ \ud83e\udd17 See translation", "url": "https://huggingface.co/posts/sayakpaul/418493639663017", "date_published": "2025-02-19T05:19:45.501478"}]}