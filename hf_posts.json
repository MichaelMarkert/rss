{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/905523908666849", "image": "", "title": "\ud83c\udf0a CycleNavigator: Visualizing Economic and Political Cycles Through AI at a Glance! \ud83e\udde0\ud83d\udcb9", "content_text": "\ud83c\udf0a CycleNavigator: Visualizing Economic and Political Cycles Through AI at a Glance! \ud83e\udde0\ud83d\udcb9 \ud83d\udcab Strategic Intelligence Tool for Navigating Historical Waves and Forecasting the Future Hello there! \ud83d\ude4c CycleNavigator brings you an innovative fusion of economic history, data visualization, and generative AI. This open-source project revolutionizes decision-making by displaying four major economic and political cycles through interactive visualizations! \ud83d\udcca Experience Four Major Cycles in One View: Business Cycle (\u22489 years) \u23f1\ufe0f - The 'heartbeat' of investment and inventory Kondratiev Wave (\u224850 years) \ud83c\udf10 - Long technological innovation waves Finance Cycle (\u224880 years) \ud83d\udcb0 - Rhythm of debt and financial crises Hegemony Cycle (\u2248250 years) \ud83c\udfdb\ufe0f - Transitions in global order \u2728 Cutting-Edge Features: Interactive Wave Visualization \ud83c\udfaf - Intuitive graphs powered by Plotly AI-Powered Historical Similarity Mapping \ud83e\udde9 - Connecting past events via SBERT embeddings Real-time News Integration \ud83d\udcf0 - Linking current issues...", "url": "https://huggingface.co/posts/openfree/905523908666849", "date_published": "2025-05-15T13:32:53.784557"}, {"id": "https://huggingface.co/posts/ArturoNereu/644085701737970", "image": "", "title": "I\u2019ve been learning AI for several years (coming from the games industry), and along the way, I curated a list of the tools, courses, books, papers, and models that actually helped me understand things.", "content_text": "I\u2019ve been learning AI for several years (coming from the games industry), and along the way, I curated a list of the tools, courses, books, papers, and models that actually helped me understand things. I turned this into a GitHub repo: https://github.com/ArturoNereu/AI-Study-Group If you\u2019re just getting started, I recommend: \ud83d\udcd8 Deep Learning \u2013 A Visual Approach: https://www.glassner.com/portfolio/deep-learning-a-visual-approach \ud83c\udfa5 Dive into LLMs with Andrej Karpathy: https://youtu.be/7xTGNNLPyMI?si=aUTq_qUzyUx36BsT \ud83e\udde0 The \ud83e\udd17 Agents course]( https://huggingface.co/learn/agents-course/ The repo has grown with help from the community (Reddit, Discord, etc.) and I\u2019ll keep updating it. If you have any favorite resources, I\u2019d love to include them. See translation", "url": "https://huggingface.co/posts/ArturoNereu/644085701737970", "date_published": "2025-05-15T13:32:53.784951"}, {"id": "https://huggingface.co/posts/fdaudens/617387724043904", "image": "", "title": "Tried something new: an AI-generated podcast that breaks down the top research paper each day. Fully automated, now live on Spotify.", "content_text": "Tried something new: an AI-generated podcast that breaks down the top research paper each day. Fully automated, now live on Spotify. I built this prototype to help keep up with the rapid pace of AI developments and, hopefully, make cutting-edge research more accessible. I don\u2019t know about you, but just listening to a conversation about a paper really helps the content sink in for me. This build taught me a lot about full automation. If you\u2019re into the technical weeds: Qwen3 runs on Inference to handle the script, Kokoro does the voice, and the whole thing gets published automatically thanks to the Hugging Face Jobs API and Gradio deployment. It\u2019s not perfect yet \u2014 I\u2019ll be monitoring for hallucinations and incoherence. The voice model still needs polish, but it\u2019s a promising start. Would love to build this with the community \u2014 submit a PR or send feedback. It\u2019s just a beta of an experimental idea! Big kudos to @ m-ric , whose Open NotebookLM this is based on, and to @ nielsr for his...", "url": "https://huggingface.co/posts/fdaudens/617387724043904", "date_published": "2025-05-15T13:32:53.785472"}, {"id": "https://huggingface.co/posts/dhruv3006/465197265329383", "image": "", "title": "Lumier \u2013 Run macOS & Linux VMs in a Docker", "content_text": "Lumier \u2013 Run macOS & Linux VMs in a Docker Lumier is an open-source tool for running macOS virtual machines in Docker containers on Apple Silicon Macs. When building virtualized environments for AI agents, we needed a reliable way to package and distribute macOS VMs. Inspired by projects like dockur/macos that made macOS running in Docker possible, we wanted to create something similar but optimized for Apple Silicon. The existing solutions either didn't support M-series chips or relied on KVM/Intel emulation, which was slow and cumbersome. We realized we could leverage Apple's Virtualization Framework to create a much better experience. Lumier takes a different approach: It uses Docker as a delivery mechanism (not for isolation) and connects to a lightweight virtualization service (lume) running on your Mac. Lumier is 100% open-source under MIT license and part of C/ua. Github : https://github.com/trycua/cua/tree/main/libs/lumier Join the discussion here :...", "url": "https://huggingface.co/posts/dhruv3006/465197265329383", "date_published": "2025-05-15T13:32:53.785887"}, {"id": "https://huggingface.co/posts/clem/170733821735878", "image": "", "title": "Very cool to see", "content_text": "Very cool to see pytorch contributing on Hugging Face. Time to follow them to see what they're cooking! See translation", "url": "https://huggingface.co/posts/clem/170733821735878", "date_published": "2025-05-15T13:32:53.786086"}, {"id": "https://huggingface.co/posts/jasoncorkill/313090798327696", "image": "", "title": "\ud83d\udd25 Hidream I1 is online! \ud83d\udd25", "content_text": "\ud83d\udd25 Hidream I1 is online! \ud83d\udd25 We just added Hidream I1 to our T2I leaderboard ( https://www.rapidata.ai/leaderboard/image-models ) benchmarked using 195k+ human responses from 38k+ annotators, all collected in under 24 hours. It landed #3 overall, right behind: - @ openai 4o - @ black-forest-labs Flux 1 Pro ...and just ahead of @ black-forest-labs Flux 1.1 Pro, @ xai-org Aurora and @ google Imagen3. Want to dig into the data? Check out our dataset here: Rapidata/Hidream_t2i_human_preference What model should we benchmark next? See translation", "url": "https://huggingface.co/posts/jasoncorkill/313090798327696", "date_published": "2025-05-15T13:32:53.786418"}, {"id": "https://huggingface.co/posts/jeffboudier/904543868043384", "image": "", "title": "Transcribing 1 hour of audio for less than $0.01 \ud83e\udd2f", "content_text": "Transcribing 1 hour of audio for less than $0.01 \ud83e\udd2f @ mfuntowicz cooked with 8x faster Whisper speech recognition - whisper-large-v3-turbo transcribes at 100x real time on a $0.80/hr L4 GPU! How they did it: https://huggingface.co/blog/fast-whisper-endpoints 1-click deploy with HF Inference Endpoints: https://endpoints.huggingface.co/new?repository=openai%2Fwhisper-large-v3-turbo&vendor=aws&region=us-east&accelerator=gpu&instance_id=aws-us-east-1-nvidia-l4-x1&task=automatic-speech-recognition&no_suggested_compute=true See translation", "url": "https://huggingface.co/posts/jeffboudier/904543868043384", "date_published": "2025-05-15T13:32:53.786736"}, {"id": "https://huggingface.co/posts/m-ric/402808163323191", "image": "", "title": "\ud835\uddd4\ud835\uddef\ud835\ude00\ud835\uddfc\ud835\uddf9\ud835\ude02\ud835\ude01\ud835\uddf2 \ud835\udded\ud835\uddf2\ud835\uddff\ud835\uddfc: \ud835\udddf\ud835\udddf\ud835\udde0\ud835\ude00 \ud835\uddf0\ud835\uddee\ud835\uddfb \ud835\ude01\ud835\uddff\ud835\uddee\ud835\uddf6\ud835\uddfb \ud835\ude04\ud835\uddf6\ud835\ude01\ud835\uddf5\ud835\uddfc\ud835\ude02\ud835\ude01 \ud835\uddee\ud835\uddfb\ud835\ude06 \ud835\uddf2\ud835\ude05\ud835\ude01\ud835\uddf2\ud835\uddff\ud835\uddfb\ud835\uddee\ud835\uddf9 \ud835\uddf1\ud835\uddee\ud835\ude01\ud835\uddee \ud83e\udd2f", "content_text": "\ud835\uddd4\ud835\uddef\ud835\ude00\ud835\uddfc\ud835\uddf9\ud835\ude02\ud835\ude01\ud835\uddf2 \ud835\udded\ud835\uddf2\ud835\uddff\ud835\uddfc: \ud835\udddf\ud835\udddf\ud835\udde0\ud835\ude00 \ud835\uddf0\ud835\uddee\ud835\uddfb \ud835\ude01\ud835\uddff\ud835\uddee\ud835\uddf6\ud835\uddfb \ud835\ude04\ud835\uddf6\ud835\ude01\ud835\uddf5\ud835\uddfc\ud835\ude02\ud835\ude01 \ud835\uddee\ud835\uddfb\ud835\ude06 \ud835\uddf2\ud835\ude05\ud835\ude01\ud835\uddf2\ud835\uddff\ud835\uddfb\ud835\uddee\ud835\uddf9 \ud835\uddf1\ud835\uddee\ud835\ude01\ud835\uddee \ud83e\udd2f Has the \"data wall\" just been breached? Recent RL paradigms often relied on a set of questions an answers that needs to be manually curated. Researchers from Tsinghua University went like \"why though\". \ud83e\udd14 Indeed, why learn from question designed by a human teacher, when the model can start from their base knowledge and learn by experimenting in a code environment, proposing coding tasks themselves and trying to solve them? Thus they created \u201cAbsolute Zero Reasoning\u201d (AZR), an approach that removes any need for human curated data. \ud83c\udfad \ud835\uddd7\ud835\ude02\ud835\uddee\ud835\uddf9 \ud835\uddff\ud835\uddfc\ud835\uddf9\ud835\uddf2\ud835\ude00: \u2023 Proposer: Generates challenging but solvable coding tasks \u2023 Solver: Attempts to solve those self-proposed tasks \ud83e\uddea \ud835\udde7\ud835\uddf5\ud835\uddff\ud835\uddf2\ud835\uddf2 \ud835\ude01\ud835\uddee\ud835\ude00\ud835\uddf8 \ud835\ude01\ud835\ude06\ud835\uddfd\ud835\uddf2\ud835\ude00: all types are defined as triplets of program, input and output \u2023 Deduction: Give model an input and program, it must deduce the output \u2023 Abduction: Give model an program and output, it must find the input that gave said output \u2023 Induction: Synthesize a...", "url": "https://huggingface.co/posts/m-ric/402808163323191", "date_published": "2025-05-15T13:32:53.787377"}, {"id": "https://huggingface.co/posts/codys12/705081891087680", "image": "", "title": "Introducing bitnet-r1-llama-8b and bitnet-r1-qwen-32b preview! These models are the first successful sub 1-billion-token finetune to BitNet architecture. We discovered that by adding an aditional input RMSNorm to each linear, you can finetune directly to BitNet with fast convergence to original model performance!", "content_text": "Introducing bitnet-r1-llama-8b and bitnet-r1-qwen-32b preview! These models are the first successful sub 1-billion-token finetune to BitNet architecture. We discovered that by adding an aditional input RMSNorm to each linear, you can finetune directly to BitNet with fast convergence to original model performance! We are working on a pull request to use this extra RMS for any model. To test these models now, install this fork of transformers: pip install git+https://github.com /Codys12/ transformers.git Then load the models and test: from transformers import ( AutoModelForCausalLM , AutoTokenizer ) model_id = \"codys12/bitnet-r1-qwen-32b\" model = AutoModelForCausalLM .from_pretrained( model_id, device_map= \"cuda\" , ) tokenizer = AutoTokenizer .from_pretrained(model_id, padding_side= \"left\" ) bitnet-r1-llama-8b and bitnet-r1-llama-32b were trained on ~ 300M and 200M tokens of the open-thoughts/OpenThoughts-114k dataset respectively, and were still significantly improving at the end of...", "url": "https://huggingface.co/posts/codys12/705081891087680", "date_published": "2025-05-15T13:32:53.787811"}, {"id": "https://huggingface.co/posts/hesamation/190820854172664", "image": "", "title": "60+ Generative AI projects for your resume. grind this GitHub repo if you want to level up:", "content_text": "60+ Generative AI projects for your resume. grind this GitHub repo if you want to level up: > LLM fine-tuning and applications > advanced RAG apps > Agentic AI projects > MCP and A2A (new) GitHub: https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/resources/60_ai_projects.md See translation", "url": "https://huggingface.co/posts/hesamation/190820854172664", "date_published": "2025-05-15T13:32:53.788037"}]}