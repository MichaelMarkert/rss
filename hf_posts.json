{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/YatharthS/729508768545264", "image": "", "title": "I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second!", "content_text": "I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second! NovaSR can - Enhance TTS model quality. - Restore poor quality datasets. - Work on any device(just 52kb which is smaller than a 3 second audio file!) Model: YatharthS/NovaSR Space to try it: YatharthS/NovaSR Github repo: https://github.com/ysharma3501/NovaSR See translation", "url": "https://huggingface.co/posts/YatharthS/729508768545264", "date_published": "2026-01-16T09:32:06.118940"}, {"id": "https://huggingface.co/posts/zc277584121/729228721948980", "image": "", "title": "We've open-sourced a bilingual Semantic Highlighting model that can power multiple production scenarios:", "content_text": "We've open-sourced a bilingual Semantic Highlighting model that can power multiple production scenarios: 1) RAG Answer Highlighting \u2014 Automatically highlight the exact sentences that answer user queries, improving interpretability and helping users quickly locate relevant information. 2) RAG Noise Filtering \u2014 Prune irrelevant context before sending to LLMs, achieving 70-80% token cost reduction while improving answer quality by letting the model focus on what matters. 3) Search System Highlighting \u2014 Add semantic highlighting features to recommendation systems, e-commerce search, or any retrieval system where users need to see why a result is relevant. Try it out: zilliz/semantic-highlight-bilingual-v1 Read our article: https://huggingface.co/blog/zilliz/zilliz-semantic-highlight-model See translation", "url": "https://huggingface.co/posts/zc277584121/729228721948980", "date_published": "2026-01-16T09:32:06.119395"}, {"id": "https://huggingface.co/posts/mmhamdy/849671126846274", "image": "", "title": "The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable length\ud83d\ude04", "content_text": "The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable length\ud83d\ude04 Here's a nice short summary from Gemini See translation", "url": "https://huggingface.co/posts/mmhamdy/849671126846274", "date_published": "2026-01-16T09:32:06.119678"}, {"id": "https://huggingface.co/posts/sergiopaniego/454747936446679", "image": "", "title": "New REPL environment in OpenEnv available! \u2728", "content_text": "New REPL environment in OpenEnv available! \u2728 Used in the Recursive Language Models (RLM) paper by Alex Zhang. Ready for inference & post-training using trajectories. Handles long contexts: > Run Python code in a sandbox > Make recursive calls to LMs > Explore data programmatically > Return final result Docs: https://meta-pytorch.org/OpenEnv/environments/repl/ Inference script: https://github.com/meta-pytorch/OpenEnv/blob/main/examples/repl_oolong_simple.py See translation", "url": "https://huggingface.co/posts/sergiopaniego/454747936446679", "date_published": "2026-01-16T09:32:06.120013"}, {"id": "https://huggingface.co/posts/danielhanchen/641905091288769", "image": "", "title": "You can now do reinforcement learning training with 7\u00d7 longer context and no accuracy loss, via our new batching algorithms.", "content_text": "You can now do reinforcement learning training with 7\u00d7 longer context and no accuracy loss, via our new batching algorithms. Long reasoning chains in RL are costly, but now we enable you to train gpt-oss with GRPO & reach 380K context on a 192GB GPU. Blog: https://unsloth.ai/docs/new/grpo-long-context See translation", "url": "https://huggingface.co/posts/danielhanchen/641905091288769", "date_published": "2026-01-16T09:32:06.120306"}, {"id": "https://huggingface.co/posts/sequelbox/836146471898656", "image": "", "title": "NEW RELEASE: it's here! Meet the newest member of the Valiant crew: Guardpoint, our new medical reasoning model!", "content_text": "NEW RELEASE: it's here! Meet the newest member of the Valiant crew: Guardpoint, our new medical reasoning model! - Trained on medical knowledge, management, diagnosis, and tasks from DeepSeek-V3.2-Speciale! - Structured medical reasoning responses are efficient and informative, cutting token costs for faster inference! - Wide-ranging knowledge base: trained on a wide variety of medical disciplines, patient types, and query structures! - High quality medical responses emphasize performance, brevity, specificity, statistical rationality, and openness. Get it now: Guardpoint for Qwen 3 32B: ValiantLabs/Qwen3-32B-Guardpoint Guardpoint for Qwen 3 14B: ValiantLabs/Qwen3-14B-Guardpoint Powered by our new structured medical reasoning dataset: sequelbox/Superpotion-DeepSeek-V3.2-Speciale We've been working hard on Guardpoint; we're really excited to share it with everyone! We'll be bringing Guardpoint to more models soon, along with further releases for the Shining Valiant and Esper series!...", "url": "https://huggingface.co/posts/sequelbox/836146471898656", "date_published": "2026-01-16T09:32:06.120798"}, {"id": "https://huggingface.co/posts/AdinaY/245167368794687", "image": "", "title": "From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding up\ud83d\ude80", "content_text": "From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding up\ud83d\ude80 Now BaichuanAI joins with Baichuan-M3 \ud83c\udfe5 an open medical LLM trained for clinical decision-making https://huggingface.co/collections/baichuan-inc/baichuan-m3 \u2728 235B - Apache2.0 \u2728 Lower hallucinations via Fact-Aware RL \u2728 Built for long medical chats See translation", "url": "https://huggingface.co/posts/AdinaY/245167368794687", "date_published": "2026-01-16T09:32:06.121919"}, {"id": "https://huggingface.co/posts/hypothetical/126420354848703", "image": "", "title": "We thought it would be easier, but finally we have integrated CuDNN Paged Attention to our models!", "content_text": "We thought it would be easier, but finally we have integrated CuDNN Paged Attention to our models! Read article here: https://app.thestage.ai/blog/Integrating-cuDNN-Paged-Attention-to-TheStage-AI-Inference?id=8 Llama-8B with CuDNN paged attention, including B200 support: TheStageAI/Elastic-Llama-3.1-8B-Instruct Mistral-Small-24B with CuDNN paged attention, including B200 support: TheStageAI/Elastic-Mistral-Small-3.1-24B-Instruct-2503 See translation", "url": "https://huggingface.co/posts/hypothetical/126420354848703", "date_published": "2026-01-16T09:32:06.122190"}, {"id": "https://huggingface.co/posts/Ujjwal-Tyagi/164908864894846", "image": "", "title": "I am very excited to see the release of", "content_text": "I am very excited to see the release of nyuuzyou/gitee-code . This is exactly what I have been looking for. Thank you to @ nyuuzyou for his hard work on this. See translation", "url": "https://huggingface.co/posts/Ujjwal-Tyagi/164908864894846", "date_published": "2026-01-16T09:32:06.122410"}, {"id": "https://huggingface.co/posts/wangbuer999/651831586227530", "image": "", "title": "HY-MT1.5-1.8B Lightweight Translation Model  Open-Source Game-Changer", "content_text": "HY-MT1.5-1.8B Lightweight Translation Model Open-Source Game-Changer Tencent raised the bar for lightweight translation! Supports bidirectional translation across 36 languages total\u201433 mainstream languages + 5 ethnic/minority dialects With only 1.8B parameters (less than 1/3 the size of HY-MT1.5-7B), it delivers performance on par with the 7B counterpart and outperforms most commercial translation APIs. \u2705 Quantized versions (FP8/GPTQ-Int4) available for edge device deployment, perfect for real-time translation \u2705 Full support for terminology intervention, context-aware translation, and formatted output \u2705 Ready-to-use prompt templates + seamless integration with Hugging Face Transformers \u2705 Recommended transformers \u2265 4.56.0 (FP8 model requires compressed-tensors 0.11.0) 10+ Hugging Face Spaces already integrated this model! \ud83d\udc49 Model Repo: tencent/HY-MT1.5-1.8B \ud83d\udc49 Technical Report: https://arxiv.org/abs/2512.24092 See translation", "url": "https://huggingface.co/posts/wangbuer999/651831586227530", "date_published": "2026-01-16T09:32:06.122866"}]}