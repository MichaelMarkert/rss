{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/paulml/601253280118572", "image": "", "title": "Qwen3-VL-4B is incredibly easy to fine-tune!", "content_text": "Qwen3-VL-4B is incredibly easy to fine-tune! We've trained the first DSE model based on this model, and it's already performing at the same level as Jina v4! While Jina Embeddings v4 is built on Qwen2.5-VL-3B (which has a non-commercial license), our model is based on Qwen3-VL-4B and released under Apache 2.0\u2014making it fully commercially permissive. Check out our DSE model here: racineai/QwenAmann-4B-dse See translation", "url": "https://huggingface.co/posts/paulml/601253280118572", "date_published": "2025-10-22T09:27:17.160914"}, {"id": "https://huggingface.co/posts/appvoid/680866662633308", "image": "", "title": "today is going to be a great day for small models, are you ready?", "content_text": "today is going to be a great day for small models, are you ready? See translation", "url": "https://huggingface.co/posts/appvoid/680866662633308", "date_published": "2025-10-22T09:27:17.161141"}, {"id": "https://huggingface.co/posts/merve/349000009530858", "image": "", "title": "deepseek-ai/DeepSeek-OCR", "content_text": "deepseek-ai/DeepSeek-OCR is out! \ud83d\udd25 my take \u2935\ufe0f > pretty insane it can parse and re-render charts in HTML > it uses CLIP and SAM features concatenated, so better grounding > very efficient per vision tokens/performance ratio > covers 100 languages See translation", "url": "https://huggingface.co/posts/merve/349000009530858", "date_published": "2025-10-22T09:27:17.161395"}, {"id": "https://huggingface.co/posts/codelion/654123549897898", "image": "", "title": "\ud83e\udde0 Introducing Ellora Recipe #6: Execution-Aware World Model for Qwen3-4B-Thinking", "content_text": "\ud83e\udde0 Introducing Ellora Recipe #6: Execution-Aware World Model for Qwen3-4B-Thinking Teaching LLMs to understand not just what code does, but HOW it executes at runtime! Inspired by Meta's CWM (Code World Model) research, this LoRA adapter adds execution awareness to Qwen3-4B-Thinking-2507. The model learns to predict variable states, trace program execution step-by-step, and debug code by understanding runtime behavior. \ud83d\udd0d Key Innovation: We combine Qwen3's native thinking capabilities with real Python execution traces captured via sys.settrace(). The model is trained using GRPO with a custom reward function that scores execution prediction accuracy. \ud83d\udcca Training Approach: - Hybrid Magpie-style code generation - Real execution tracing for ground truth - Self-supervised learning (no manual annotations!) - 298 training samples with execution traces \u2728 What it does: - Predicts variable states at each line of code - Explains execution flow with thinking tags - Helps debug by understanding...", "url": "https://huggingface.co/posts/codelion/654123549897898", "date_published": "2025-10-22T09:27:17.161964"}, {"id": "https://huggingface.co/posts/branikita/979883770066556", "image": "", "title": "\ud83e\udd16 New article: In-depth testing of the Feetech STS3215 servomotor \u2014 the popular choice for open-source robotic projects like SO-ARM 100 and others. We've conducted comprehensive performance analysis covering backlash, repeatability, torque characteristics, and thermal behavior. Discover how this affordable servo performs in real-world robotic applications, including its 12-bit magnetic encoder, metal gearbox design, and overload protection mechanisms.", "content_text": "https://robonine.com/testing-of-feetech-sts3215-servomotor-backlash-repeatability-and-torque/ \ud83e\udd16 New article: In-depth testing of the Feetech STS3215 servomotor \u2014 the popular choice for open-source robotic projects like SO-ARM 100 and others. We've conducted comprehensive performance analysis covering backlash, repeatability, torque characteristics, and thermal behavior. Discover how this affordable servo performs in real-world robotic applications, including its 12-bit magnetic encoder, metal gearbox design, and overload protection mechanisms. #Robotics #Servomotor #EngineeringTesting #Automation #FeetechSTS3215 #OpenSourceRobotics #SOArm #RoboticSystems #ControlSystems #MotorTesting #AffordableRobotics #ClosedLoopControl See translation", "url": "https://huggingface.co/posts/branikita/979883770066556", "date_published": "2025-10-22T09:27:17.162326"}, {"id": "https://huggingface.co/posts/adlumal/408694709656049", "image": "", "title": "I benchmarked embedding APIs for speed, compared local vs hosted models, and tuned USearch for sub-millisecond retrieval on 143k chunks using only CPU. The post walks through the results, trade-offs, and what I learned about embedding API terms of service.", "content_text": "I benchmarked embedding APIs for speed, compared local vs hosted models, and tuned USearch for sub-millisecond retrieval on 143k chunks using only CPU. The post walks through the results, trade-offs, and what I learned about embedding API terms of service. The main motivation for using USearch is that CPU compute is cheap and easy to scale. Blog post: https://huggingface.co/blog/adlumal/lightning-fast-vector-search-for-legal-documents See translation", "url": "https://huggingface.co/posts/adlumal/408694709656049", "date_published": "2025-10-22T09:27:17.162587"}, {"id": "https://huggingface.co/posts/Kseniase/152348317273822", "image": "", "title": "5 Lectures and keynotes defining AI right now", "content_text": "5 Lectures and keynotes defining AI right now If you want to understand the multifaceted AI landscape in 2025 and see where the field is heading \u2013 start with (or revisit) these legendary talks. They can help you capture what\u2019s happening in AI from multiple angles: 1. Andrej Karpathy: Software Is Changing (Again) \u2192 https://www.youtube.com/watch?v=LCEmiRjPEtQ Unveils Software 3.0 \u2013 a paradigm where LLMs are the new computers, programmed with prompts instead of code. The key: developers must now master coding, training, and prompting as AI becomes the heart of software building 2. Richard Sutton, The OaK Architecture: A Vision of SuperIntelligence from Experience \u2192 https://www.youtube.com/watch?v=gEbbGyNkR2U Unveils the OaK (Options and Knowledge) architecture \u2013 a model-based RL framework for continual intelligence, where every component learns, meta-learns & builds hierarchical abstractions 3. GTC March 2025 Keynote with NVIDIA CEO Jensen Huang \u2192...", "url": "https://huggingface.co/posts/Kseniase/152348317273822", "date_published": "2025-10-22T09:27:17.163233"}, {"id": "https://huggingface.co/posts/mitkox/331863384538017", "image": "", "title": "I see all Chinese labs are turning TL;DR into TL;DRGB", "content_text": "I see all Chinese labs are turning TL;DR into TL;DRGB Problem: 1M text tokens == 1 M opportunities for your GPU to file worker-comp Solution: don\u2019t feed the model War & Peace\u2014feed it the movie poster. This is Glyph, Zai\u2019s new visual-text compression voodoo: \u2022 10 k words \u2192 3 PNGs \u2248 3 k visual tokens \u2022 Compression ratio: 4.3\u00d7 \u2022 Throughput: 40-60 tok/s i.e. your context window now finishes before my coffee does So I did the only reasonable thing: asked GLM-4.6 to port Glyph for Qwen3-VL-8B-Thinking. Translation: I made one model compress a novel into a comic strip, then made another model read the comic strip and still ace QA. It\u2019s basically passing notes in class, except the note is a 1920\u00d71080 meme and the teacher is a transformer. We've gone from \"Attention is All You Need\" to \"Attention is Too Expensive, Just Use Your Eyes.\" Remember kids: in 2025 literacy is optional, but JPEG is forever. See translation", "url": "https://huggingface.co/posts/mitkox/331863384538017", "date_published": "2025-10-22T09:27:17.163659"}, {"id": "https://huggingface.co/posts/sequelbox/934890543066201", "image": "", "title": "NEW RELEASE: Esper 3.1 for gpt-oss-20b!", "content_text": "NEW RELEASE: Esper 3.1 for gpt-oss-20b! - Esper is our full-stack, full-cycle coding, DevOps, and architecture specialist! - Our newest, best DeepSeek technical datasets emphasize more challenging queries and tough real-world coding tasks across a variety of programming languages and development paradigms: - Titanium 3 for coding and reasoning in DevOps and architecture: sequelbox/Titanium3-DeepSeek-V3.1-Terminus - Tachibana 3 for high-difficulty code production in a variety of topics and programming languages: - sequelbox/Tachibana3-Part1-DeepSeek-V3.1-Terminus - sequelbox/Tachibana3-Part2-DeepSeek-V3.2 - Mitakihara for MLOps, AI building, use, expertise, and research: sequelbox/Mitakihara-DeepSeek-R1-0528 GET IT NOW, FOR EVERYONE: ValiantLabs/gpt-oss-20b-Esper3.1 We'll have more releases of Esper coming up, plus more experimental open-source releases :) find open source datasets and experimental models at @ sequelbox Help us keep working for open source AI with a donation:...", "url": "https://huggingface.co/posts/sequelbox/934890543066201", "date_published": "2025-10-22T09:27:17.164033"}, {"id": "https://huggingface.co/posts/piercus/315056772255613", "image": "", "title": "\ud83d\udea7 Reproducing LBM-Eraser\u2026 in progress! [1]", "content_text": "\ud83d\udea7 Reproducing LBM-Eraser\u2026 in progress! [1] When repurposing a T2I model into a pure I2I model, there\u2019s always that orphaned text path \u2014 what do we do with it? \ud83e\udd14 You can reuse it as learnable embeddings in multi-task setups [2], freeze an empty text prompt, distillate or prune the corresponding part. In LBM, they take a clever route \u2014 zeroing [3] and reshaping [4] the text-related cross-attentions into self-attentions. This gives you fresh weights for I2I computation, nicely integrated into your SD architecture. \ud83d\udcce References [1] Our LBM Fork: https://github.com/finegrain-ai/LBM [2] OmniPaint: OmniPaint: Mastering Object-Oriented Editing via Disentangled Insertion-Removal Inpainting (2503.08677) [3] LBM Zeroing: https://github.com/gojasper/LBM/blob/cafebc46a9ac16dcc61691d289cc4676b5c75380/examples/training/train_lbm_surface.py#L147-L148 [4] LBM Reshaping: https://github.com/gojasper/LBM/blob/cafebc46a9ac16dcc61691d289cc4676b5c75380/examples/training/train_lbm_surface.py#L100 See...", "url": "https://huggingface.co/posts/piercus/315056772255613", "date_published": "2025-10-22T09:27:17.164456"}]}