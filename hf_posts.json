{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/174131256400578", "image": "", "title": "\ud83d\udd25 Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities \ud83d\ude80", "content_text": "\ud83d\udd25 Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities \ud83d\ude80 openfree/qwen3-30b-a3b-research openfree/qwen3-235b-a22b-research Hello AI researchers! \ud83d\udc4b Today I'm introducing a powerful chatbot implementation with real-time web search capabilities. \u2728 Key Features \ud83e\udde0 Chatbot based on qwen3-30b-a3b and llama4-maverick models \ud83d\udd0d LLM-based optimal keyword extraction \ud83c\udf10 Real-time web search using SerpHouse API \ud83d\udcac Streaming responses for natural conversation experience \ud83d\udee0\ufe0f Technology Stack Gradio: Implementation of intuitive web interface Fireworks.ai API: Access to high-performance LLM models SerpHouse API: Collection of real-time search results \ud83c\udf1f Application Areas Question answering systems requiring up-to-date information Providing current information beyond training data Delivering reliable information with accurate sources Add real-time search capabilities to your AI applications with this project! \ud83c\udf89 Leave your questions or suggestions in the comments! Let's...", "url": "https://huggingface.co/posts/openfree/174131256400578", "date_published": "2025-05-05T17:20:19.296097"}, {"id": "https://huggingface.co/posts/ginipick/917789522887291", "image": "", "title": "\ud83d\udd2e Mistral Perflexity AI - Local LLM Space with Web Search Capabilities \ud83c\udf10", "content_text": "\ud83d\udd2e Mistral Perflexity AI - Local LLM Space with Web Search Capabilities \ud83c\udf10 Hello AI enthusiasts! Today I'm excited to introduce my special Hugging Face space! \ud83d\ude80 ginigen/Mistral-Perflexity \u2728 Key Features Powerful Model: Using Private-BitSix-Mistral-Small-3.1-24B-Instruct-2503, optimized through 6-bit quantization to run smoothly on local 4090 GPUs! \ud83d\udcaa Web Search Integration: Leveraging the Brave Search API to provide real-time web search results for user queries! \ud83d\udd0d Customizable Responses: Shape AI personality and response format through system messages \u2699\ufe0f Multilingual Support: Perfect handling of both English and Korean! \ud83c\uddfa\ud83c\uddf8\ud83c\uddf0\ud83c\uddf7 \ud83d\udee0\ufe0f Technical Highlights GGUF Format: Optimized quantized model with excellent memory efficiency Flash Attention: Applied optimization technology for faster inference speeds 8K Context Window: Capable of handling lengthy conversations and complex queries Streaming Responses: Watch text being generated in real-time \ud83d\udca1 Use Cases Complex Q&A requiring real-time...", "url": "https://huggingface.co/posts/ginipick/917789522887291", "date_published": "2025-05-05T17:20:19.296665"}, {"id": "https://huggingface.co/posts/fdaudens/694548457778636", "image": "", "title": "Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me!", "content_text": "Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me! Just tested it with Steve Jobs' Stanford speech and was speechless (pun intended). The video isn\u2019t sped up. 3 things that floored me: - Transcription took just 10 seconds for a 15-min file - Got a CSV with perfect timestamps, punctuation & capitalization - Stunning accuracy (correctly captured \"Reed College\" and other specifics) NVIDIA also released a demo where you can click any transcribed segment to play it instantly. The improvement is significant: number 1 on the ASR Leaderboard, 6% error rate (best in class) with complete commercial freedom (cc-by-4.0 license). Time to update those Whisper pipelines! H/t @ Steveeeeeeen for the finding! Model: nvidia/parakeet-tdt-0.6b-v2 Demo: nvidia/parakeet-tdt-0.6b-v2 ASR Leaderboard: hf-audio/open_asr_leaderboard See translation", "url": "https://huggingface.co/posts/fdaudens/694548457778636", "date_published": "2025-05-05T17:20:19.297075"}, {"id": "https://huggingface.co/posts/samihalawa/966135943196710", "image": "", "title": "HELLO GUYS \ud83d\ude80 Just released my first MCP: VUDA \u2013 Visual UI Debug Agent", "content_text": "HELLO GUYS \ud83d\ude80 Just released my first MCP: VUDA \u2013 Visual UI Debug Agent Ever been stuck debugging buttons that don\u2019t work? Broken flows? Inconsistent UI behavior? VUDA sees it, clicks it, fixes it. An automated visual debug agent that inspects, validates, and repairs your UI \u2014 like magic \ud83e\udde0\u2728 Better that any other playwright / puppeteer. \ud83d\udd27 Install now via Smithery: npx -y @ smithery /cli@latest install @ samihalawa /visual-ui-debug-agent-mcp --client cursor \u2e3b Want a shorter alt for social media too? See translation", "url": "https://huggingface.co/posts/samihalawa/966135943196710", "date_published": "2025-05-05T17:20:19.297396"}, {"id": "https://huggingface.co/posts/nyuuzyou/896622962900908", "image": "", "title": "\ud83d\uddbc\ufe0f PublicDomainFiles.com Collection -", "content_text": "\ud83d\uddbc\ufe0f PublicDomainFiles.com Collection - nyuuzyou/publicdomainfiles Collection of 206,204 Public Domain multimedia files featuring: - Comprehensive metadata: title, description, creator name, keywords, original page URL, and more. - Contains various media types including images, clip art, artwork, fonts, videos, and TV shows. - All content explicitly released into the public domain under the CC0 license. - Organized in a single train split with 206,204 entries. See translation", "url": "https://huggingface.co/posts/nyuuzyou/896622962900908", "date_published": "2025-05-05T17:20:19.297684"}, {"id": "https://huggingface.co/posts/Kseniase/864305548620639", "image": "", "title": "10 new Chain-of-Thoughts (CoT) methods", "content_text": "10 new Chain-of-Thoughts (CoT) methods CoT has long been one of the hottest techniques in AI thanks to its effectiveness and compelling core idea: encouraging models to solve complex problems through explicit intermediate reasoning steps. But usually researchers modify original CoT approach, finding tips that further improve LLMs' reasoning. That's what we're going to talk about today. Here's a list of 10 latest enhanced CoT approaches: 1. Chain-of-Defensive-Thought -> Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption (2504.20769) Provides a few structured, defensive reasoning exemplars to improve the robustness of LLMs 2. Hybrid-CoT -> AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization (2504.21659) Proposes using Adaptive Hybrid Reasoning Model (AdaR1) that combines Long- and Short-CoT, and applying bi-level preference training to select effective reasoning styles 3. Semantic-level...", "url": "https://huggingface.co/posts/Kseniase/864305548620639", "date_published": "2025-05-05T17:20:19.298384"}, {"id": "https://huggingface.co/posts/sanaka87/102647382067427", "image": "", "title": "Our ICEdit's video is below~", "content_text": "Our ICEdit's video is below~ \ud83d\udd25 \ud83d\udd25\ud83d\udd25Huggingface DEMO: RiverZ/ICEdit \ud83c\udf10 Project Website: https://river-zhang.github.io/ICEdit-gh-pages/ \ud83c\udfe0 GitHub Repository: https://github.com/River-Zhang/ICEdit/blob/main/scripts/gradio_demo.py \ud83e\udd17 Huggingface: sanaka87/ICEdit-MoE-LoRA \ud83d\udcc4 arxiv Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) See translation", "url": "https://huggingface.co/posts/sanaka87/102647382067427", "date_published": "2025-05-05T17:20:19.298660"}, {"id": "https://huggingface.co/posts/Jaward/719018577686619", "image": "", "title": "late submission but managed to cook up a nascent Feynman-inspired agent app for Microsoft\u2019s AI Agent hackathon, wish me luck lol.", "content_text": "late submission but managed to cook up a nascent Feynman-inspired agent app for Microsoft\u2019s AI Agent hackathon, wish me luck lol. @ clem ps I need this on gpu, thank you:) Try Demo: Jaward/Professor-AI-Feynman Code: https://github.com/Jaykef/professor-ai-feynman See translation", "url": "https://huggingface.co/posts/Jaward/719018577686619", "date_published": "2025-05-05T17:20:19.298924"}, {"id": "https://huggingface.co/posts/RiverZ/535015681556179", "image": "", "title": "\ud83d\ude80 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer\uff5e", "content_text": "\ud83d\ude80 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer\uff5e \ud83c\udfa8 Daily Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) \ud83d\udd13 Code is now open source! \ud83d\udd25 Huggingface DEMO: RiverZ/ICEdit \ud83c\udf10 Project Website: https://river-zhang.github.io/ICEdit-gh-pages/ \ud83c\udfe0 GitHub Repository: https://github.com/River-Zhang/ICEdit/blob/main/scripts/gradio_demo.py \ud83e\udd17 Huggingface: sanaka87/ICEdit-MoE-LoRA \ud83d\udcc4 arxiv Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) \ud83d\udd25 Why it\u2019s cool: - Achieves high-quality, multi-task image editing. - Uses only 1% of the training parameters and 0.1% of the training data compared to existing methods \u2014 extremely efficient - Beats several commercial models on background preservation, ID control, and consistency - Open-...", "url": "https://huggingface.co/posts/RiverZ/535015681556179", "date_published": "2025-05-05T17:20:19.299391"}, {"id": "https://huggingface.co/posts/Raahulthakur/638579217973846", "image": "", "title": "FinSightX: Your AI Financial Co-Pilot", "content_text": "FinSightX: Your AI Financial Co-Pilot FinSightX is a multi-agent financial assistant powered by language models. Designed for analysts, investors, and fintech developers, it combines insights from multiple domains into a single, sleek Streamlit interface. Features Equity Analyst Agent \u2192 Ask questions about stocks, indicators, performance. Macro Strategist Agent \u2192 Get macroeconomic insights using language models. News Summarizer Agent \u2192 Summarizes market headlines instantly. Quant Backtester Agent \u2192 Run basic backtests using bt. Regulatory Radar Agent \u2192 Monitor policy shifts and alerts. Client Advisor Agent \u2192 Assist with client queries or hypothetical portfolios. Tech Stack transformers, sentence-transformers torch, scikit-learn, neuralprophet bt for strategy backtesting chromadb for vector storage Streamlit + FastAPI for UI/backend Developed and maintained by @ Raahul-Thakur Live Space: Raahulthakur/FinsightX Built using open-source tools and financial domain knowledge....", "url": "https://huggingface.co/posts/Raahulthakur/638579217973846", "date_published": "2025-05-05T17:20:19.299799"}]}