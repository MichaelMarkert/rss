{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Tanaybh/360553614352968", "image": "", "title": "The Bias is YOU - LLMs Mirror Your Own Assumptions", "content_text": "The Bias is YOU - LLMs Mirror Your Own Assumptions AI doesn't just have bias - it reflects yours. When you ask a question with positive framing, you get positive answers. Ask with negative framing, you get negative answers. The AI becomes a mirror of your own assumptions. Your framing determines the answer - The same topic yields opposite responses based on how you ask AIs amplify your sentiment - Negative questions often get even MORE negative responses This affects everyone - From students doing research to professionals making decisions Why This Matters This isn't a technical glitch - it's fundamental to how these systems work. They're trained on human language, and humans frame things with bias. The AI learned to match that framing. Think about the implications: - Medical professionals seeking second opinions - Students researching controversial topics - Business leaders evaluating strategies - Anyone using AI for important decisions The Stochastic Mirror Effect Let's call this...", "url": "https://huggingface.co/posts/Tanaybh/360553614352968", "date_published": "2025-09-21T09:19:54.562602"}, {"id": "https://huggingface.co/posts/vikhyatk/428307575853218", "image": "", "title": "Just released a preview of Moondream 3!", "content_text": "Just released a preview of Moondream 3! moondream/moondream3-preview This is a 9B parameter, 2B active MoE VLM with state of the art visual reasoning capabilities. More details in the release blog post: https://moondream.ai/blog/moondream-3-preview See translation", "url": "https://huggingface.co/posts/vikhyatk/428307575853218", "date_published": "2025-09-21T09:19:54.562849"}, {"id": "https://huggingface.co/posts/Monica997/115477940297105", "image": "", "title": "Turn Your Dog\u2019s Photo into a 3D Figurine with Nano Banana \ud83d\udc36\u2728", "content_text": "Turn Your Dog\u2019s Photo into a 3D Figurine with Nano Banana \ud83d\udc36\u2728 Just tested out the new Nano Banana feature, and I\u2019m honestly impressed. I uploaded a single photo of my corgi, and within minutes, it generated a detailed 3D figurine model. What makes this really interesting for tech and design folks: AI-powered 2D \u2192 3D conversion (no manual modeling required) Preserves character consistency even with multiple images Export options for 3D printing or digital use (OBJ, FBX, STL) Works with pets, people, and even illustrated characters For anyone into 3D modeling, collectibles, or architecture visualization, this is a game-changer. Imagine transforming static photos into tangible 3D assets with just a few clicks. Here\u2019s the link if you want to try it out: https://imini.com/nano-banana Has anyone else here tested Nano Banana for pets or other personal projects? Would love to hear your results! See translation", "url": "https://huggingface.co/posts/Monica997/115477940297105", "date_published": "2025-09-21T09:19:54.563278"}, {"id": "https://huggingface.co/posts/salma-remyx/977986978639462", "image": "", "title": "Trustworthy AI evals has been an industry challenge for the last few years, so what's missing?", "content_text": "Trustworthy AI evals has been an industry challenge for the last few years, so what's missing? Causal Reasoning. Model based eval frameworks can't tell you if your changes actually improved user outcomes - you need to take a systems level approach. At Remyx, we\u2019re building the intelligence layer for AI experimentation. Check out this example on how we start laying the scaffolding to launch controlled experiments to turn your hypotheses into insights on what drives performance for your application. Check out the latest at Remyx in our docs: https://docs.remyx.ai Try your first experiment today! https://engine.remyx.ai See translation", "url": "https://huggingface.co/posts/salma-remyx/977986978639462", "date_published": "2025-09-21T09:19:54.563618"}, {"id": "https://huggingface.co/posts/salma-remyx/494327094243098", "image": "", "title": "Reproducing research code shouldn't take longer than reading the paper.", "content_text": "Reproducing research code shouldn't take longer than reading the paper. For papers that include code, setting up the right environment often means hours of dependency hell and configuration debugging. At Remyx AI, we built an agent that automatically creates and tests Docker images for research papers, then shares them publicly so anyone can reproduce results with a single command. We just submitted PR #908 to integrate this directly into arXiv Labs. If you believe in making reproducible research accessible to everyone, give it a bump!: https://github.com/arXiv/arxiv-browse/pull/908 See translation", "url": "https://huggingface.co/posts/salma-remyx/494327094243098", "date_published": "2025-09-21T09:19:54.563897"}, {"id": "https://huggingface.co/posts/YerbaPage/735409135497339", "image": "", "title": "Announcing our new work on \"Repository Level Question Answering\"! \ud83c\udf89", "content_text": "Announcing our new work on \"Repository Level Question Answering\"! \ud83c\udf89 We introduce SWE-QA, a repository-level code QA benchmark with 576 real-world questions that require a deep understanding of the entire codebase to answer. Curious about the limits of today's LLMs on complex codebases? Check out our paper and open-source data! \ud83d\udcbb\ud83e\udde0 Link \ud83d\udc47 https://arxiv.org/pdf/2509.14635 https://github.com/peng-weihan/SWE-QA-Bench #LLM #AI #SoftwareEngineering #Benchmark See translation", "url": "https://huggingface.co/posts/YerbaPage/735409135497339", "date_published": "2025-09-21T09:19:54.564202"}, {"id": "https://huggingface.co/posts/onekq/332042657908085", "image": "", "title": "Claude Opus 4.1 is slightly better than Opus 4, but still behind GPT-5", "content_text": "Claude Opus 4.1 is slightly better than Opus 4, but still behind GPT-5 onekq-ai/WebApp1K-models-leaderboard See translation", "url": "https://huggingface.co/posts/onekq/332042657908085", "date_published": "2025-09-21T09:19:54.564395"}, {"id": "https://huggingface.co/posts/codelion/536269233496700", "image": "", "title": "\ud83d\ude80 Adaptive Classifier v0.0.17 Released - Major Accuracy Improvements!", "content_text": "\ud83d\ude80 Adaptive Classifier v0.0.17 Released - Major Accuracy Improvements! We've just released a major update fixing critical bugs that were causing 40-50% accuracy drops in our enterprise classifiers! Key Fixes: \u2022 Fixed k-parameter prediction bug causing massive accuracy loss \u2022 Improved incremental learning for new classes \u2022 Enhanced weight preservation during model updates Dramatic Results: \u2022 fraud-detection: 43.9% \u2192 92.7% (+48.8%) adaptive-classifier/fraud-detection \u2022 business-sentiment: 88.9% \u2192 98.8% (+9.9%) adaptive-classifier/business-sentiment expense-category: 26.7% \u2192 84.2% (+57.5%) adaptive-classifier/expense-category \u2022 language-detection: 98.8% \u2192 100% (+1.2%) adaptive-classifier/language-detection 15/17 enterprise classifiers now maintain \u22645% accuracy difference from original performance! Other High-Performing Models: \u2022 email-security (93.8%): adaptive-classifier/email-security \u2022 content-moderation (100%): adaptive-classifier/content-moderation \u2022 pii-detection (100%): adaptive-...", "url": "https://huggingface.co/posts/codelion/536269233496700", "date_published": "2025-09-21T09:19:54.564934"}, {"id": "https://huggingface.co/posts/takarajordan/879360274479598", "image": "", "title": "Are we really back to storing access tokens in plain text again?", "content_text": "Are we really back to storing access tokens in plain text again? { \"mcpServers\" : { \"hf-mcp-server\" : { \"url\" : \"https://huggingface.co/mcp\" , \"headers\" : { \"Authorization\" : \"Bearer <YOUR_HF_TOKEN>\" } } } } See translation", "url": "https://huggingface.co/posts/takarajordan/879360274479598", "date_published": "2025-09-21T09:19:54.565177"}, {"id": "https://huggingface.co/posts/kanaria007/393105836303562", "image": "", "title": "\u2705 New Article: *PoC \u2014 Structural Processing Unit (SPU)*", "content_text": "\u2705 New Article: *PoC \u2014 Structural Processing Unit (SPU)* Title: \u2699\ufe0f PoC Design: Structural Processing Unit (SPU) \ud83d\udd17 https://huggingface.co/blog/kanaria007/spu-poc --- Summary: CPUs execute numbers. The *SPU (Structural Processing Unit)* executes *protocols*. This PoC proposes a next-generation processor designed to natively handle rollback, reflexia, failure-trace, and ethics enforcement \u2014 not as software add-ons, but as *core instructions*. > The CPU powered arithmetic. > *The SPU powers cognition.* --- Why It Matters: \u2022 Establishes the *logic core* of Structured Intelligence Computers \u2022 Ensures resilience and ethical safeguards are enforced at hardware level \u2022 Provides the substrate for AGI-grade computation --- What\u2019s Inside: \u2022 Native ISA for RLBK , MLOOP , ETHC , FTLG \u2022 Structural pipelines replacing arithmetic pipelines \u2022 Evaluation metrics: recovery latency, ethical alignment index, causal audit coverage \u2022 Roadmap from FPGA prototypes \u2192 general-purpose SPU chips --- \ud83d\udcd6 PoC Series...", "url": "https://huggingface.co/posts/kanaria007/393105836303562", "date_published": "2025-09-21T09:19:54.565693"}]}