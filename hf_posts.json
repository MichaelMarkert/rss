{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mahimairaja/451884860016905", "image": "", "title": "Happy New Years 2026!", "content_text": "Happy New Years 2026! For next 365 days I will be commit to work on: - Document AI and OCR Automations - Voice Agents - Long Running Tasks - Durable Agents See translation", "url": "https://huggingface.co/posts/mahimairaja/451884860016905", "date_published": "2026-01-02T13:36:10.777760"}, {"id": "https://huggingface.co/posts/mike-ravkine/983643024828039", "image": "", "title": "Happy 2026 everyone!", "content_text": "Happy 2026 everyone! I've been busy working on some new ranking/position methodologies and excited to start sharing some results. Plot legends: - X = truncation rate (low = good) - ? = confusion rate (low = good) - blue bars = average completion tokens (low = good) - black diamonds = CI-banded performance (high = good) - cluster squares = models inside this group are equivalent openai/gpt-oss-120b remains the king in all dimensions of interest: truncation rates, completion lengths and performance. If I had but one complaint it's the reason_effort does not seem to actually work - more on this soon. Second is a 3-way tie in performance between the Qwen3-235B-2507 we all know and love with an unexpected entrant - ByteDance-Seed/Seed-OSS-36B-Instruct This is a very capable model and it's reasoning effort controls actually works, but you should absolutely not leave it on the default \"unlimited\" - enable a sensible limit (4k works well for 8k context length). Third place is another 3-way...", "url": "https://huggingface.co/posts/mike-ravkine/983643024828039", "date_published": "2026-01-02T13:36:10.778214"}, {"id": "https://huggingface.co/posts/dhruv3006/444530398664756", "image": "", "title": "gRPC support in Voiden", "content_text": "gRPC support in Voiden gRPC has become a popular choice for building high-performance, scalable APIs, especially in microservices and real-time systems. Unlike traditional REST APIs, gRPC uses HTTP/2 and Protocol Buffers to deliver fast, efficient communication with strong typing and contract enforcement. Many developers in our community asked for it, so we have now added gRPC support in the latest Voiden release.You can now test and document gRPC APIs side-by-side with your REST and WebSocket APIs. Keep everything in one file-centric, Git-native workflow. Use reusable blocks and version control for gRPC requests, just like any other API call. Download the latest Voiden beta here: https://voiden.md/download See translation", "url": "https://huggingface.co/posts/dhruv3006/444530398664756", "date_published": "2026-01-02T13:36:10.778549"}, {"id": "https://huggingface.co/posts/MikeDoes/647817712633860", "image": "", "title": "Anonymizing a prompt is half the battle. Reliably de-anonymizing the response is the other.", "content_text": "Anonymizing a prompt is half the battle. Reliably de-anonymizing the response is the other. To build a truly reliable privacy pipeline, you have to test it. A new Master's thesis does just that, and our data was there for every step. We're excited to showcase this work on handling confidential data in LLM prompts from Nedim Karavdic at M\u00e4lardalen University. To build their PII anonymization pipeline, they first trained a custom NER model. We're proud that the Ai4Privacy pii-masking-200k dataset was used as the foundational training data for this critical first step. But it didn't stop there. The research also used our dataset to create the parallel data needed to train and test the generative \"Seek\" models for de-anonymization. It's a win-win when our open-source data not only helps build the proposed \"better solution\" but also helps prove why it's better by enabling a rigorous, data-driven comparison. \ud83d\udd17 Check out the full thesis for a great deep-dive into building a practical, end-...", "url": "https://huggingface.co/posts/MikeDoes/647817712633860", "date_published": "2026-01-02T13:36:10.779069"}, {"id": "https://huggingface.co/posts/Reubencf/502627640855049", "image": "", "title": "As 2025 is ending i would like to thank everyone for trying out", "content_text": "As 2025 is ending i would like to thank everyone for trying out Reubencf/Nano_Banana_Editor looking forward to build and release more in the future for the open source community See translation", "url": "https://huggingface.co/posts/Reubencf/502627640855049", "date_published": "2026-01-02T13:36:10.779337"}, {"id": "https://huggingface.co/posts/Kseniase/637856294883643", "image": "", "title": "What we learned about memory in 2025: 8 comprehensive resources", "content_text": "What we learned about memory in 2025: 8 comprehensive resources If models forget everything, how can they be reliable? AI systems need to remember past interactions, update knowledge, stay consistent over time, and work beyond a single prompt. That's why many start to talk more about memory in AI. Here\u2019s a useful set of studies and videos on where AI memory stands today: 1. Memory in the Age of AI Agents (2512.13564) A great survey that organizes agent memory research. It gives concrete taxonomies across memory form, function, and dynamics, summarizes benchmarks, frameworks, and emerging directions for building systematic agent memory systems 2.When Will We Give AI True Memory? A conversation with Edo Liberty, CEO and founder @ Pinecone -> https://youtu.be/ITbwVFZYepc?si=_lAbRHciC740dNz0 Edo Liberty discusses what real memory in LLMs requires beyond RAG - from scalable vector storage to reliable knowledge systems - and why storage, not compute, is becoming the key bottleneck for...", "url": "https://huggingface.co/posts/Kseniase/637856294883643", "date_published": "2026-01-02T13:36:10.779989"}, {"id": "https://huggingface.co/posts/branikita/824421158823011", "image": "", "title": "We tested the maximum dynamic payload of the SO-ARM101 with our parallel gripper and a base servo replaced by a Feetech STS3250. The maximum load before failure was 630 g, at which point the Feetech STS3215 in joint 3 failed \u2014 its large brass output gear was completely worn down.", "content_text": "We tested the maximum dynamic payload of the SO-ARM101 with our parallel gripper and a base servo replaced by a Feetech STS3250. The maximum load before failure was 630 g, at which point the Feetech STS3215 in joint 3 failed \u2014 its large brass output gear was completely worn down. The Feetech STS3250 in the base with a metal gear train withstood a significantly higher load. See translation", "url": "https://huggingface.co/posts/branikita/824421158823011", "date_published": "2026-01-02T13:36:10.780282"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/448164360090025", "image": "", "title": "Happy New Year, Hugging Face!", "content_text": "Happy New Year, Hugging Face! It's been a crazy year for me! This year I launched VANTA Research as a solo operator and managed to push out 14 original open source finetunes and 5 datasets in the span of about 4 months, completely on my own. The reception has been much higher than I ever anticipated and sincerely appreciate everyone that's checked out my work thus far. The good news is, I'm just getting started! In 2026 you can expect even more original models from VANTA Research, more open source datasets, and maybe some other cool things as well? \ud83d\udc40 2026 is gonna be big for AI in general, and I can't wait to experience it with all of you! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/448164360090025", "date_published": "2026-01-02T13:36:10.780643"}, {"id": "https://huggingface.co/posts/omarkamali/313633076135960", "image": "", "title": "New year, new dataset \ud83d\ude80", "content_text": "New year, new dataset \ud83d\ude80 I just released omarkamali/wikipedia-labels , with all the structural labels and namespace from wikipedia in 300+ languages. A gift for the data preprocessors and cleaners among us. Happy new year 2026 everyone! \ud83c\udf86 See translation", "url": "https://huggingface.co/posts/omarkamali/313633076135960", "date_published": "2026-01-02T13:36:10.780889"}, {"id": "https://huggingface.co/posts/sadpig70/884733187066075", "image": "", "title": "**HAO (Human AI Orchestra)** is a next-generation collaborative development framework that maximizes synergy between **human intuition** and the **diverse strengths of multiple LLMs**\u2014turning the human from a \u201ccoder\u201d into a **conductor**.", "content_text": "**HAO (Human AI Orchestra)** is a next-generation collaborative development framework that maximizes synergy between **human intuition** and the **diverse strengths of multiple LLMs**\u2014turning the human from a \u201ccoder\u201d into a **conductor**. At its core is an **11-step workflow** you can run immediately: divergence for wild ideas \u2192 convergence into architecture \u2192 critique & voting \u2192 synthesis \u2192 blueprinting (Gantree) \u2192 prototyping (PPR) \u2192 cross-review \u2192 refinement \u2192 roadmap \u2192 implementation. The philosophy is intentionally **anti-standardization**, treats **conflict as a resource**, and keeps **orchestration** (human-in-control) as the center. This repo includes the **developer manual** (with concrete prompt templates), plus real artifact histories from two full runs: **Dancing with Noise** and **Dancing with Time**. **GitHub:** [sadpig70/HAO]( https://github.com/sadpig70/HAO ) See translation", "url": "https://huggingface.co/posts/sadpig70/884733187066075", "date_published": "2026-01-02T13:36:10.781287"}]}