{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/abidlabs/941146046599374", "image": "", "title": "Why I think local, open-source models will eventually win.", "content_text": "Why I think local, open-source models will eventually win. The most useful AI applications are moving toward multi-turn agentic behavior: systems that take hundreds or even thousands of iterative steps to complete a task, e.g. Claude Code, computer-control agents that click, type, and test repeatedly. In these cases, the power of the model is not how smart it is per token, but in how quickly it can interact with its environment and tools across many steps. In that regime, model quality becomes secondary to latency. An open-source model that can call tools quickly, check that the right thing was clicked, or verify that a code change actually passes tests can easily outperform a slightly \u201csmarter\u201d closed model that has to make remote API calls for every move. Eventually, the balance tips: it becomes impractical for an agent to rely on remote inference for every micro-action. Just as no one would tolerate a keyboard that required a network request per keystroke, users won\u2019t accept...", "url": "https://huggingface.co/posts/abidlabs/941146046599374", "date_published": "2025-11-05T09:27:26.898383"}, {"id": "https://huggingface.co/posts/sergiopaniego/990279445625588", "image": "", "title": "fine-tuning a 14B model with TRL + SFT on a free Colab (T4 GPU)?", "content_text": "fine-tuning a 14B model with TRL + SFT on a free Colab (T4 GPU)? thanks to the latest TRL optimizations, you actually can! sharing a new notebook showing how to do it \ud83d\ude0e colab: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/sft_trl_lora_qlora.ipynb notebooks in TRL: https://github.com/huggingface/trl/tree/main/examples/notebooks See translation", "url": "https://huggingface.co/posts/sergiopaniego/990279445625588", "date_published": "2025-11-05T09:27:26.898675"}, {"id": "https://huggingface.co/posts/wang12390/323744389614625", "image": "", "title": "Experience the future of fashion with our AI-powered virtual try-on technology. See how clothes look on anyone instantly, create realistic outfit visualizations, and mix-and-match styles with unprecedented accuracy.", "content_text": "Experience the future of fashion with our AI-powered virtual try-on technology. See how clothes look on anyone instantly, create realistic outfit visualizations, and mix-and-match styles with unprecedented accuracy. https://miragic.ai/products/virtual-try-on See translation", "url": "https://huggingface.co/posts/wang12390/323744389614625", "date_published": "2025-11-05T09:27:26.898902"}, {"id": "https://huggingface.co/posts/Kseniase/468043722468280", "image": "", "title": "11 Fascinating new Policy Optimization techniques", "content_text": "11 Fascinating new Policy Optimization techniques Policy optimization (PO) algorithms are central to training AI models with preference-based feedback. In recent weeks, numerous new PO methods have emerged that build on or replace the popular PPO and GRPO, solving their issues. Here are 11 of them: 1. BAlanced Policy Optimization (BAPO) \u2192 BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping (2510.18927) Dynamically adjusting the clipping bounds in PPO-style updates to balance positive and negative gradients and prevent entropy collapse 2. Training-Free GRPO \u2192 Training-Free Group Relative Policy Optimization (2510.08191) Instead of using numeric rewards, it compares rollouts semantically to distill useful knowledge as a token prior, which is then applied during inference to guide the model\u2019s behavior 3. Asymmetric Importance Sampling Policy Optimization (ASPO) \u2192 ASPO: Asymmetric Importance Sampling Policy Optimization...", "url": "https://huggingface.co/posts/Kseniase/468043722468280", "date_published": "2025-11-05T09:27:26.899587"}, {"id": "https://huggingface.co/posts/flozi00/890663421107803", "image": "", "title": "Some weeks ago, i've just decide its time to leave LinkedIn for me.", "content_text": "Some weeks ago, i've just decide its time to leave LinkedIn for me. It got silent around my open source activities the last year, so i thought something has to change. That's why my focus will move to share experiences and insights about hardware, drivers, kernels and linux. I won't post about how to use models, built agents or do prompting. I want to share about some deeper layers the actual hypes are built on. I will start posting summarizations of my articles here on the hub. English version: https://flozi.net/en German translated version: https://flozi.net/de Feel free to reach me if you want to read something specific. See translation", "url": "https://huggingface.co/posts/flozi00/890663421107803", "date_published": "2025-11-05T09:27:26.899884"}, {"id": "https://huggingface.co/posts/nouamanetazi/972464132222376", "image": "", "title": "After training \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25\ud835\udc0b\ud835\udc0c\ud835\udfd1 on \ud835\udfd1\ud835\udfd6\ud835\udfd2 \ud835\udc07\ud835\udfcf\ud835\udfce\ud835\udfce\ud835\udc2c for nearly a month, I've come to realize something most people overlook: \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc26\ud835\udc1a\ud835\udc24\ud835\udc1e-\ud835\udc28\ud835\udc2b-\ud835\udc1b\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc24 \ud835\udc1f\ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc22\ud835\udc27 \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20. \ud83d\udd25", "content_text": "After training \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25\ud835\udc0b\ud835\udc0c\ud835\udfd1 on \ud835\udfd1\ud835\udfd6\ud835\udfd2 \ud835\udc07\ud835\udfcf\ud835\udfce\ud835\udfce\ud835\udc2c for nearly a month, I've come to realize something most people overlook: \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc26\ud835\udc1a\ud835\udc24\ud835\udc1e-\ud835\udc28\ud835\udc2b-\ud835\udc1b\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc24 \ud835\udc1f\ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc22\ud835\udc27 \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20. \ud83d\udd25 Everyone talks about model architecture and data quality. And yes, those matter immensely. But here's what nobody tells you: when your training run fails at 2 AM because of mysterious \ud835\udc0d\ud835\udc02\ud835\udc02\ud835\udc0b \ud835\udc1e\ud835\udc2b\ud835\udc2b\ud835\udc28\ud835\udc2b\ud835\udc2c, or when your expensive GPU cluster is running at \ud835\udfd4\ud835\udfce% \ud835\udc1e\ud835\udc1f\ud835\udc1f\ud835\udc22\ud835\udc1c\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc32, the problem isn't your model. It's most probably a \ud835\udc26\ud835\udc22\ud835\udc2c\ud835\udc2e\ud835\udc2c\ud835\udc1e \ud835\udc28\ud835\udc1f \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc21\ud835\udc1a\ud835\udc2b\ud835\udc1d\ud835\udc30\ud835\udc1a\ud835\udc2b\ud835\udc1e. \ud83d\udee0\ufe0f Questions that seemed simple but had no clear answers: Why is \ud835\udc0c\ud835\udc28\ud835\udc04 \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2c\ud835\udc25\ud835\udc28\ud835\udc30\ud835\udc1e\ud835\udc2b \ud835\udc2d\ud835\udc21\ud835\udc1a\ud835\udc27 \ud835\udc1d\ud835\udc1e\ud835\udc27\ud835\udc2c\ud835\udc1e \ud835\udc26\ud835\udc28\ud835\udc1d\ud835\udc1e\ud835\udc25\ud835\udc2c? Which \ud835\udc0d\ud835\udc02\ud835\udc02\ud835\udc0b \ud835\udc1f\ud835\udc25\ud835\udc1a\ud835\udc20\ud835\udc2c should we actually set? How often should we checkpoint without killing throughput? That's why we built \ud835\udc13\ud835\udc21\ud835\udc1e \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25 \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0f\ud835\udc25\ud835\udc1a\ud835\udc32\ud835\udc1b\ud835\udc28\ud835\udc28\ud835\udc24 \ud83d\udcd6: a complete guide covering everything from model architecture and data curation to the SmolLM3 training marathon, post-training techniques, and crucially, the \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc25\ud835\udc1a\ud835\udc32\ud835\udc1e\ud835\udc2b that most teams get wrong. We validated real vs...", "url": "https://huggingface.co/posts/nouamanetazi/972464132222376", "date_published": "2025-11-05T09:27:26.900487"}, {"id": "https://huggingface.co/posts/codelion/382097318111878", "image": "", "title": "On this day in 2019, OpenAI released the final GPT-2 model as part of their staged release. I still remember that November well - so much was happening, but GPT-2's release felt like a watershed moment for the field. It showed us what was possible with carefully trained language models.", "content_text": "On this day in 2019, OpenAI released the final GPT-2 model as part of their staged release. I still remember that November well - so much was happening, but GPT-2's release felt like a watershed moment for the field. It showed us what was possible with carefully trained language models. To recreate some of that GPT-2 magic, I recently tackled an interesting challenge: can you pretrain a language model with just 1 billion tokens - roughly 1/10th of what GPT-2 used - and still get comparable performance? After 50+ systematic experiments testing different dataset mixtures, the answer is yes. The result is **codelion/gpt-2-70m** ( codelion/gpt-2-70m ), which achieves over 90% of GPT-2's benchmark performance despite being trained on 10x less data. The key was finding the optimal dataset composition: 50% high-quality textbook PDFs, 30% filtered web content, and 20% educational resources. It even beats GPT-2 on TruthfulQA (47.31% vs 40.69%). If you're interested in the full story of how...", "url": "https://huggingface.co/posts/codelion/382097318111878", "date_published": "2025-11-05T09:27:26.900883"}, {"id": "https://huggingface.co/posts/DmitryRyumin/716491468051168", "image": "", "title": "\ud83d\ude80\ud83d\udc41\ufe0f\ud83c\udf1f New Research Alert - ICCV 2025 (Oral)! \ud83c\udf1f\ud83d\udc41\ufe0f\ud83d\ude80", "content_text": "\ud83d\ude80\ud83d\udc41\ufe0f\ud83c\udf1f New Research Alert - ICCV 2025 (Oral)! \ud83c\udf1f\ud83d\udc41\ufe0f\ud83d\ude80 \ud83d\udcc4 Title: Diving into the Fusion of Monocular Priors for Generalized Stereo Matching \ud83d\udd1d \ud83d\udcdd Description: The proposed method enhances stereo matching by efficiently combining unbiased monocular priors from vision foundation models. This method addresses misalignment and local optima issues using a binary local ordering map and pixel-wise linear regression. \ud83d\udc65 Authors: Chengtang Yao, Lidong Yu, Zhidan Liu, Jiaxi Zeng, Yuwei Wu, and Yunde Jia \ud83d\udcc5 Conference: ICCV, 19 \u2013 23 Oct, 2025 | Honolulu, Hawai'i, USA \ud83c\uddfa\ud83c\uddf8 \ud83d\udcc4 Paper: Diving into the Fusion of Monocular Priors for Generalized Stereo Matching (2505.14414) \ud83d\udcc1 Repository: https://github.com/YaoChengTang/Diving-into-the-Fusion-of-Monocular-Priors-for-Generalized-Stereo-Matching \ud83d\ude80 ICCV-2023-25-Papers: https://github.com/DmitryRyumin/ICCV-2023-25-Papers \ud83d\ude80 Added to the 3D Pose Understanding Section: https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/3d-pose-...", "url": "https://huggingface.co/posts/DmitryRyumin/716491468051168", "date_published": "2025-11-05T09:27:26.901381"}, {"id": "https://huggingface.co/posts/Ihor/565863655331711", "image": "", "title": "Hey builders \ud83d\udc77\u200d\u2640\ufe0f", "content_text": "Hey builders \ud83d\udc77\u200d\u2640\ufe0f We\u2019re Knowledgator, the team behind open-source NLP models like GLiNER, GLiClass, and many other used for zero-shot text classification and information extraction. If you\u2019ve explored them on Hugging Face or used our frameworks from GitHub, we\u2019d love your input: \ud83e\udde9 Which of our models, like GLiNER or zero-shot classifiers, do you find helpful in your practical workflows? \ud83e\udde9 How\u2019s the setup, performance, and accuracy been for you? \ud83e\udde9 Anything confusing, buggy, or missing that would make your workflow smoother? Your feedback helps us improve speed, clarity, and stability for everyone in the open-source community. \ud83d\udcac Comment directly here or join the discussion. We read every one \ud83d\ude09: GitHub: https://github.com/Knowledgator Discord: https://discord.gg/GXRcAVJQ HuggingFace: knowledgator \ud83d\udcdd Want to shape our next release? Click here to complete this 2-min survey: https://docs.google.com/forms/d/e/1FAIpQLSdyz2UMHrMDX8S9stpBk0wyfngtKSYzwk-02mN1VNYDdTw8OQ/viewform See translation", "url": "https://huggingface.co/posts/Ihor/565863655331711", "date_published": "2025-11-05T09:27:26.901802"}, {"id": "https://huggingface.co/posts/prithivMLmods/374605520852651", "image": "", "title": "A week ago, I shared a post about the latest transformers test implementation of DeepSeek-OCR Compatibility (", "content_text": "A week ago, I shared a post about the latest transformers test implementation of DeepSeek-OCR Compatibility ( https://tinyurl.com/ykc4mm66 ). Now, I\u2019m dropping the most compatible version of it to support the model with the latest transformers. \ud83e\udd17\ud83d\udd25 \u27a0 DeepSeek-OCR-Latest-BF16.I64: prithivMLmods/DeepSeek-OCR-Latest-BF16.I64 \u27a0 DeepSeek OCR [exp] : prithivMLmods/DeepSeek-OCR-experimental \u2705Supports the latest transformers v4.57.1 \u2705torch: 2.6.0+cu124 (or) the latest version (i.e., torch 2.9.0) \u2705cuda version: 12.4 \u2705users can also opt out of specific attention implementations if desired. \u2728Previous version: strangervisionhf/deepseek-ocr-latest-transformers \u2197\ufe0fRelated Blog: https://huggingface.co/blog/prithivMLmods/multimodal-ocr-vlms \u2728Community Page: strangervisionhf \u2728Original Model Page: deepseek-ai/DeepSeek-OCR To know more about it, visit the app page or the respective model page! See translation", "url": "https://huggingface.co/posts/prithivMLmods/374605520852651", "date_published": "2025-11-05T09:27:26.902217"}]}