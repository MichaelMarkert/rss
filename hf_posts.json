{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/sergiopaniego/454747936446679", "image": "", "title": "New REPL environment in OpenEnv available! \u2728", "content_text": "New REPL environment in OpenEnv available! \u2728 Used in the Recursive Language Models (RLM) paper by Alex Zhang. Ready for inference & post-training using trajectories. Handles long contexts: > Run Python code in a sandbox > Make recursive calls to LMs > Explore data programmatically > Return final result Docs: https://meta-pytorch.org/OpenEnv/environments/repl/ Inference script: https://github.com/meta-pytorch/OpenEnv/blob/main/examples/repl_oolong_simple.py See translation", "url": "https://huggingface.co/posts/sergiopaniego/454747936446679", "date_published": "2026-01-15T13:43:35.027870"}, {"id": "https://huggingface.co/posts/AdinaY/245167368794687", "image": "", "title": "From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding up\ud83d\ude80", "content_text": "From ChatGPT Healthcare to Claude for healthcare, AI in medicine is speeding up\ud83d\ude80 Now BaichuanAI joins with Baichuan-M3 \ud83c\udfe5 an open medical LLM trained for clinical decision-making https://huggingface.co/collections/baichuan-inc/baichuan-m3 \u2728 235B - Apache2.0 \u2728 Lower hallucinations via Fact-Aware RL \u2728 Built for long medical chats See translation", "url": "https://huggingface.co/posts/AdinaY/245167368794687", "date_published": "2026-01-15T13:43:35.028182"}, {"id": "https://huggingface.co/posts/YatharthS/729508768545264", "image": "", "title": "I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second!", "content_text": "I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second! NovaSR can - Enhance TTS model quality. - Restore poor quality datasets. - Work on any device(just 52kb which is smaller than a 3 second audio file!) Model: YatharthS/NovaSR Space to try it: YatharthS/NovaSR Github repo: https://github.com/ysharma3501/NovaSR See translation", "url": "https://huggingface.co/posts/YatharthS/729508768545264", "date_published": "2026-01-15T13:43:35.028467"}, {"id": "https://huggingface.co/posts/TravisMuhlestein/396736901039998", "image": "", "title": "Agentic AI doesn\u2019t fail because it lacks intelligence \u2014 it fails because it lacks context.", "content_text": "Agentic AI doesn\u2019t fail because it lacks intelligence \u2014 it fails because it lacks context. As agents become more autonomous, the real challenge shifts from generation to governance: understanding when, why, and under what constraints an agent should act. At GoDaddy, we\u2019ve been treating context as a first-class primitive for agentic systems \u2014 combining identity, intent, permissions, and environment so agents can operate responsibly in production. Context is what turns automation into judgment. Without it, autonomy becomes risk. This post outlines how we\u2019re thinking about the transition from task execution to context-aware agentic systems, and what that means for building AI that can be trusted at scale. \ud83d\udc49 How we build context for agentic AI: https://www.godaddy.com/resources/news/how-godaddy-builds-context-for-agentic-ai Curious how others here are modeling context, trust boundaries, and decision constraints in agentic architectures. See translation", "url": "https://huggingface.co/posts/TravisMuhlestein/396736901039998", "date_published": "2026-01-15T13:43:35.028940"}, {"id": "https://huggingface.co/posts/Ujjwal-Tyagi/164908864894846", "image": "", "title": "I am very excited to see the release of", "content_text": "I am very excited to see the release of nyuuzyou/gitee-code . This is exactly what I have been looking for. Thank you to @ nyuuzyou for his hard work on this. See translation", "url": "https://huggingface.co/posts/Ujjwal-Tyagi/164908864894846", "date_published": "2026-01-15T13:43:35.029174"}, {"id": "https://huggingface.co/posts/nyuuzyou/833296977798194", "image": "", "title": "\ud83c\udde8\ud83c\uddf3 Gitee Code Dataset - The Missing Piece of the Stack", "content_text": "\ud83c\udde8\ud83c\uddf3 Gitee Code Dataset - The Missing Piece of the Stack nyuuzyou/gitee-code Gitee is not included in the Software Heritage archive, meaning it is currently missing from datasets like The Stack. This release fills that massive gap, serving as the largest Chinese code dataset and one of the largest code corpuses overall. - 819,472,785 files from 3,105,923 repositories - 536 GB compressed Parquet storage - 554 programming languages - Extensive quality filtering: Removed vendor code, artifacts, and generated files - Rich Chinese language understanding: High volume of Chinese comments and docs Huge thanks to Hugging Face for the storage grant that made hosting this (and all my other datasets) possible! I have also already dropped several other new code datasets and rolled out QoL improvements for older ones. I will be dropping posts on those throughout the week. See translation", "url": "https://huggingface.co/posts/nyuuzyou/833296977798194", "date_published": "2026-01-15T13:43:35.029607"}, {"id": "https://huggingface.co/posts/mmhamdy/849671126846274", "image": "", "title": "The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable length\ud83d\ude04", "content_text": "The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable length\ud83d\ude04 Here's a nice short summary from Gemini See translation", "url": "https://huggingface.co/posts/mmhamdy/849671126846274", "date_published": "2026-01-15T13:43:35.029900"}, {"id": "https://huggingface.co/posts/sequelbox/836146471898656", "image": "", "title": "NEW RELEASE: it's here! Meet the newest member of the Valiant crew: Guardpoint, our new medical reasoning model!", "content_text": "NEW RELEASE: it's here! Meet the newest member of the Valiant crew: Guardpoint, our new medical reasoning model! - Trained on medical knowledge, management, diagnosis, and tasks from DeepSeek-V3.2-Speciale! - Structured medical reasoning responses are efficient and informative, cutting token costs for faster inference! - Wide-ranging knowledge base: trained on a wide variety of medical disciplines, patient types, and query structures! - High quality medical responses emphasize performance, brevity, specificity, statistical rationality, and openness. Get it now: Guardpoint for Qwen 3 32B: ValiantLabs/Qwen3-32B-Guardpoint Guardpoint for Qwen 3 14B: ValiantLabs/Qwen3-14B-Guardpoint Powered by our new structured medical reasoning dataset: sequelbox/Superpotion-DeepSeek-V3.2-Speciale We've been working hard on Guardpoint; we're really excited to share it with everyone! We'll be bringing Guardpoint to more models soon, along with further releases for the Shining Valiant and Esper series!...", "url": "https://huggingface.co/posts/sequelbox/836146471898656", "date_published": "2026-01-15T13:43:35.030341"}, {"id": "https://huggingface.co/posts/dhruv3006/646294229241708", "image": "", "title": "Voiden gives you two ways to work with GraphQL - so you can focus on writing and testing queries with confidence.", "content_text": "Voiden gives you two ways to work with GraphQL - so you can focus on writing and testing queries with confidence. 1. Importing a GraphQL Schema File You can import a GraphQL schema file such as .graphql or .gql directly into Voiden. When you do this: - Voiden reads all types, queries, mutations, and subscriptions from the schema - The schema becomes available locally and works well in offline scenarios - You get a stable, version-controlled setup that aligns nicely with Git workflows This approach is ideal when you already have the schema file and want full control over it. 2. Using GraphQL Introspection Alternatively, you can provide a GraphQL endpoint URL to Voiden. In this case : - Voiden make an introspection query to the GraphQL server - The server returns all available types, queries, mutations, and subscriptions - Voiden automatically loads this information so you can start querying immediately This option is perfect for quickly exploring a live GraphQL API or when the schema...", "url": "https://huggingface.co/posts/dhruv3006/646294229241708", "date_published": "2026-01-15T13:43:35.030732"}, {"id": "https://huggingface.co/posts/kanaria007/596222805860445", "image": "", "title": "\u2705 New Article: Designing Semantic Memory (v0.1)", "content_text": "\u2705 New Article: Designing Semantic Memory (v0.1) Title: \ud83e\udde0 Designing Semantic Memory: SIM/SIS Patterns for Real Systems \ud83d\udd17 https://huggingface.co/blog/kanaria007/designing-semantic-memory --- Summary: Semantic Compression is about *what meaning to keep*. This article is about *where that meaning lives*\u2014and how to keep it *queryable, explainable, and governable* using two layers: * *SIM*: operational semantic memory (low-latency, recent, jump-loop-adjacent) * *SIS*: archival/analytic semantic store (long retention, heavy queries, audits) Core idea: store \u201cmeaning\u201d as *typed semantic units* with scope, provenance, goal tags, retention, and *backing_refs* (URI/hash/ledger anchors) so you can answer *\u201cwhy did we do X?\u201d* without turning memory into a blob. --- Why It Matters: \u2022 Prevents \u201csemantic junk drawer\u201d memory: *units become contracts*, not vibes \u2022 Makes audits and incidents tractable: *reconstruct semantic context* (L3-grade) \u2022 Preserves reversibility/accountability with...", "url": "https://huggingface.co/posts/kanaria007/596222805860445", "date_published": "2026-01-15T13:43:35.031320"}]}