{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Javedalam/795050655622219", "image": "", "title": "KittenTTS Nano \u2014 Tiny, Expressive, Practical", "content_text": "KittenTTS Nano \u2014 Tiny, Expressive, Practical KittenTTS Nano is a lightweight, CPU-only text-to-speech model designed to prove that natural, expressive voices don\u2019t require massive cloud stacks or GPUs. At roughly ~15M parameters, it runs fast on modest hardware, supports multiple expressive voices, and exposes simple controls for pacing and tone. This makes it ideal for edge devices, demos, and anyone who wants full control over TTS without latency, lock-in, or infrastructure overhead. Try it here Javedalam/KittenTTS The model page KittenML/kitten-tts-nano-0.2 See translation", "url": "https://huggingface.co/posts/Javedalam/795050655622219", "date_published": "2026-01-31T17:27:34.159907"}, {"id": "https://huggingface.co/posts/prithivMLmods/617850685706562", "image": "", "title": "Daggr UI version of the Qwen3-TTS demo.\ud83d\udd25", "content_text": "Daggr UI version of the Qwen3-TTS demo.\ud83d\udd25 (custom voice, voice design, qwen3-asr and voice cloning) nodes. No remote spaces used for API inference; all functions run in-app fn . Powered by t4-m and built with daggr@0.5.2 and gradio@6. \ud83d\udc49Demo: prithivMLmods/Qwen3-TTS-Daggr-UI \u2b50Github: https://github.com/PRITHIVSAKTHIUR/Qwen3-TTS-Daggr-UI See translation", "url": "https://huggingface.co/posts/prithivMLmods/617850685706562", "date_published": "2026-01-31T17:27:34.160233"}, {"id": "https://huggingface.co/posts/marksverdhei/322290772927588", "image": "", "title": "Dear Hugging Face team, can we please have a way to archive hf repositories / spaces? I have a bunch of spaces that used to work but don't any more due to the hf space implementations changing and i think it would be good if I could archive those like in GitHub.", "content_text": "Dear Hugging Face team, can we please have a way to archive hf repositories / spaces? I have a bunch of spaces that used to work but don't any more due to the hf space implementations changing and i think it would be good if I could archive those like in GitHub. React to this post if you want to see this feature! \ud83d\udca1 See translation", "url": "https://huggingface.co/posts/marksverdhei/322290772927588", "date_published": "2026-01-31T17:27:34.160502"}, {"id": "https://huggingface.co/posts/RakshitAralimatti/297622038982343", "image": "", "title": "Just built my entire AI Engineer portfolio by pasting 2 links (GitHub and LinkedIn)  into", "content_text": "Just built my entire AI Engineer portfolio by pasting 2 links (GitHub and LinkedIn) into moonshotai Kimi 2.5. That's it. That's the workflow. Zero coding. Zero iteration. Zero \"make the button bigger.\" See for yourself: https://rakshit2020.github.io/rakshitaralimatti.github.io/ The model: \u2705 Scraped my GitHub repos automatically \u2705 Pulled my experience from LinkedIn \u2705 Designed an Aurora Glass theme \u2705 Mapped every skill to projects \u2705 Added animations I'd never code myself See translation", "url": "https://huggingface.co/posts/RakshitAralimatti/297622038982343", "date_published": "2026-01-31T17:27:34.160802"}, {"id": "https://huggingface.co/posts/danielhanchen/602916263790271", "image": "", "title": "You can now run Kimi K2.5 locally! \ud83d\udd25", "content_text": "You can now run Kimi K2.5 locally! \ud83d\udd25 We shrank the 1T model to 240GB (-60%) via Dynamic 1-bit. Get >40 tok/s on 242GB or 622GB VRAM/RAM for near full precision. GGUF: unsloth/Kimi-K2.5-GGUF Guide: https://unsloth.ai/docs/models/kimi-k2.5 See translation", "url": "https://huggingface.co/posts/danielhanchen/602916263790271", "date_published": "2026-01-31T17:27:34.161063"}, {"id": "https://huggingface.co/posts/raincandy-u/348219893520522", "image": "", "title": "Introducing Rain-v2: Democratizing LLM training on gaming GPUs! \u26a1", "content_text": "Introducing Rain-v2: Democratizing LLM training on gaming GPUs! \u26a1 \u200bFollowing Rain-100M, we\u2019re scaling up. Rain-v2 features a larger training dataset. We\u2019ve published a comprehensive blog covering the end-to-end journey\u2014from raw data collection to rigorous evaluation and safety testing. \u200bHF Repo: \ud83e\udd17 raincandy-u/Rain-v2 \u200bBlog: \ud83d\udcda https://angelkawaii.xyz/2026/01/29/rain-v2/ \u200bSpecial thanks to the open-source community and the SmolLM2 team for their foundational work! \ud83d\ude80 HuggingFaceTB SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model (2502.02737) See translation", "url": "https://huggingface.co/posts/raincandy-u/348219893520522", "date_published": "2026-01-31T17:27:34.161401"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/896019753498554", "image": "", "title": "Hey Hugging Face!", "content_text": "Hey Hugging Face! Type 2 in Project Enneagram just came out: vanta-research/PE-Type-2-Alma-4B PE-Type-2-Alma-4B is the second release in Project Enneagram, where I'm finetuning each of the 9 Enneagram types onto Gemma 3 4B Type 2-Alma is designed to exhibit the \"helper\" profile: - Empathetic Support: Emotional attunement - managing bad days, anxiety, grief, rejection, or feeling unseen - Interpersonal Connections: Relationship building - making friends, listening, conflict, reciprocity, apologies - Generous Guidance: Going above and beyond - cover letters, meal prep, gardening, wedding speeches, etc - Identity: Alma's name, tone, and conversational style Type 3 soon! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/896019753498554", "date_published": "2026-01-31T17:27:34.161708"}, {"id": "https://huggingface.co/posts/Csplk/934898193054995", "image": "", "title": "Was tinkering with a Daggr node generator script earlier today (", "content_text": "Was tinkering with a Daggr node generator script earlier today ( Csplk/DaggrGenerator )and started on a GUI for it for folks who are not comfy with writing code and like a GUI instead for something to motivate working on some Daggr stuff. *Will have time later to keep working on it so don\u2019t hesitate to comment with bugs or issues found if trying it out.* Csplk/DaggrGenerator Thanks @ merve @ ysharma @ abidlabs and team daggr for making daggr :) See translation", "url": "https://huggingface.co/posts/Csplk/934898193054995", "date_published": "2026-01-31T17:27:34.162029"}, {"id": "https://huggingface.co/posts/mahimairaja/504743674237860", "image": "", "title": "\ud83d\udd25 Qwen is dominating the SLM space right now.", "content_text": "\ud83d\udd25 Qwen is dominating the SLM space right now. We all know this year 2026 is the year of Small Models, but Alibaba team took it bit serious it seems! Qwen3-TTS \u2014 3-sec voice cloning, 10 languages, beats ElevenLabs Qwen3-ASR \u2014 Just dropped TODAY! 52 languages, <8% WER, SOTA open-source ASR Qwen-Image \u2014 #1 open-source image model on AI Arena All Apache 2.0. The most complete open-source AI stack, period. So, what do you think now, what next release could be? an Language Model? Comment below See translation", "url": "https://huggingface.co/posts/mahimairaja/504743674237860", "date_published": "2026-01-31T17:27:34.162350"}, {"id": "https://huggingface.co/posts/tegridydev/468392803773601", "image": "", "title": "\u2728 Research-Papers (various topics across AI/LLM research areas)", "content_text": "\u2728 Research-Papers (various topics across AI/LLM research areas) tegridydev/research-papers Currently building out the foundation topics and raw .pdf research paper files Will be processing and cleaning up and converting into high quality training datasets Check it out, give it a like and leave a comment below or join community discussion and suggest what fields and research topics you want to see included! See translation", "url": "https://huggingface.co/posts/tegridydev/468392803773601", "date_published": "2026-01-31T17:27:34.162635"}]}