{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/sergiopaniego/463161503197574", "image": "", "title": "you gotta go fast and go read the latest blog by", "content_text": "you gotta go fast and go read the latest blog by @ ror et al. explaining Continuous Batching in depth https://huggingface.co/blog/continuous_batching See translation", "url": "https://huggingface.co/posts/sergiopaniego/463161503197574", "date_published": "2025-11-27T09:27:46.174782"}, {"id": "https://huggingface.co/posts/Nymbo/982136402285178", "image": "", "title": "\ud83d\ude80 I've just shipped a major update to the", "content_text": "\ud83d\ude80 I've just shipped a major update to the Nymbo/Tools MCP server: the Agent_Terminal , a single \"master tool\" that cuts token usage by over 90%! Anthropic found 98.7% context savings using code execution with MCP, Cloudflare published similar findings. This is my open-source implementation of the same idea. # The Problem Traditional MCP exposes every tool definition directly to the model. With 12 tools, that's thousands of tokens consumed *before the conversation even starts*. Each tool call also passes intermediate results through the context window \u2014 a 10,000-row spreadsheet? That's all going into context just to sum a column. # The Solution: One Tool to Rule Them All Agent_Terminal wraps all 12 tools ( Web_Search , Web_Fetch , File_System , Generate_Image , Generate_Speech , Generate_Video , Deep_Research , Memory_Manager , Obsidian_Vault , Shell_Command , Code_Interpreter ) into a single Python code execution gateway. Instead of the model making individual tool calls, it writes...", "url": "https://huggingface.co/posts/Nymbo/982136402285178", "date_published": "2025-11-27T09:27:46.175437"}, {"id": "https://huggingface.co/posts/asigalov61/839437202675249", "image": "", "title": "\ud83d\udd25\ud83c\udfb5 \u2795 \ud83d\uddb9 \ud83d\udd25Check out my new large-scale MIDI + Lyrics dataset!!!", "content_text": "\ud83d\udd25\ud83c\udfb5 \u2795 \ud83d\uddb9 \ud83d\udd25Check out my new large-scale MIDI + Lyrics dataset!!! asigalov61/Lyrics-MIDI-Dataset ~179k MIDIs with corresponding Lyrics to play with!!! \ud83e\udd17 If you liked the dataset, please \u2764\ufe0f Any feedback and/or suggestions are also appreciated \ud83e\udd17 See translation", "url": "https://huggingface.co/posts/asigalov61/839437202675249", "date_published": "2025-11-27T09:27:46.175741"}, {"id": "https://huggingface.co/posts/takarajordan/457583486458611", "image": "", "title": "Two weeks ago I had an engaging discussion with locals in Cockermouth about AI and the broader industry, a reminder that hearing candid perspectives beyond our professional circles is invaluable and something anyone working full-time in this field should make time for.", "content_text": "Two weeks ago I had an engaging discussion with locals in Cockermouth about AI and the broader industry, a reminder that hearing candid perspectives beyond our professional circles is invaluable and something anyone working full-time in this field should make time for. Thank you! See translation", "url": "https://huggingface.co/posts/takarajordan/457583486458611", "date_published": "2025-11-27T09:27:46.176004"}, {"id": "https://huggingface.co/posts/sergiopaniego/841067327080467", "image": "", "title": "Interested in RL training environments?", "content_text": "Interested in RL training environments? We just released a beginner-friendly walkthrough notebook! Train a model to play Wordle using TRL + OpenEnv (TextArena) + GRPO + vLLM. happy learning! \ud83c\udf31 Notebook: https://github.com/huggingface/trl/blob/main/examples/notebooks/openenv_wordle_grpo.ipynb OpenEnv guide in TRL: https://huggingface.co/docs/trl/main/en/openenv See translation", "url": "https://huggingface.co/posts/sergiopaniego/841067327080467", "date_published": "2025-11-27T09:27:46.176294"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/938257136422472", "image": "", "title": "FLUX 2 vs FLUX SRPO, New FLUX Training Kohya SS GUI Premium App With Presets & Features :", "content_text": "FLUX 2 vs FLUX SRPO, New FLUX Training Kohya SS GUI Premium App With Presets & Features : https://youtu.be/RQHmyJVOHXo FLUX 2 has been published and I have compared it to the very best FLUX base model known as FLUX SRPO. Moreover, we have updated our FLUX Training APP and presets to the next level. Massive speed up gaings with 0 quality loss and lots of new features. I will show all of the new features we have with new SECourses Kohya SS GUI Premium app and compare FLUX SRPO trained model results with FLUX 2. https://youtu.be/RQHmyJVOHXo Get the SECourses Premium Kohya Trainer DreamBooth / Fine Tuning : [ https://www.patreon.com/posts/Kohya-FLUX-DreamBooth-Trainer-App-112099700 ] Get the SECourses Premium Kohya Trainer LoRA : [ https://www.patreon.com/posts/Kohya-FLUX-LoRA-Trainer-App-110879657 ] DreamBooth Training Tutorial: [ https://www.youtube.com/watch?v=FvpWy1x5etM ] LoRA Training Tutorial: [ https://www.youtube.com/watch?v=nySGu12Y05k ] Qwen Image Realism Tutorial: [...", "url": "https://huggingface.co/posts/MonsterMMORPG/938257136422472", "date_published": "2025-11-27T09:27:46.176950"}, {"id": "https://huggingface.co/posts/flozi00/715911271022864", "image": "", "title": "When models get too large for a single GPU, simply stacking layers vertically (Pipeline Parallelism) isn't always the answer. Sometimes, you need to slice the matrices themselves.", "content_text": "When models get too large for a single GPU, simply stacking layers vertically (Pipeline Parallelism) isn't always the answer. Sometimes, you need to slice the matrices themselves. My latest guide breaks down the hardware mechanics of Tensor Parallelism (TP). We look at how to shard individual operations across devices to make a cluster function as one massive accelerator. This isn't high-level theory\u2014it is a look at the bare metal implementation. Here is what is covered in the deep dive: The Strategies: Column vs. Row Parallelism We analyze how to split weight matrices (W) and inputs (X). Column-Linear: Splits weights by columns. Requires an All-Gather to reconstruct the output. Row-Linear: Splits weights by rows. Requires an All-Reduce to sum partial results. The \"Megatron-LM\" Optimization Efficiency comes from minimizing communication. By sandwiching the non-linearity (GeLU) between a Column-Parallel layer and a Row-Parallel layer, we can skip synchronization entirely during the...", "url": "https://huggingface.co/posts/flozi00/715911271022864", "date_published": "2025-11-27T09:27:46.177544"}, {"id": "https://huggingface.co/posts/ronantakizawa/796142001232258", "image": "", "title": "Introducing the japanese-trending-words dataset: a dataset consisting 593 words from Japan\u2019s annual trending word rankings (\u6d41\u884c\u8a9e\u5927\u8cde) from 2006-2025. This dataset provides the top 30 words from each year and its meaning in Japanese and english. This resource is awesome for NLP tasks understanding recent Japanese culture and history.", "content_text": "Introducing the japanese-trending-words dataset: a dataset consisting 593 words from Japan\u2019s annual trending word rankings (\u6d41\u884c\u8a9e\u5927\u8cde) from 2006-2025. This dataset provides the top 30 words from each year and its meaning in Japanese and english. This resource is awesome for NLP tasks understanding recent Japanese culture and history. ronantakizawa/japanese-trending-words #japanese #japanesedataset #trending See translation", "url": "https://huggingface.co/posts/ronantakizawa/796142001232258", "date_published": "2025-11-27T09:27:46.177838"}, {"id": "https://huggingface.co/posts/grimjim/634931502597925", "image": "", "title": "I wanted to call attention to Arli Ai's success in applying my recent modifications to refusal ablation to a MoE model successfully. Nice work,", "content_text": "I wanted to call attention to Arli Ai's success in applying my recent modifications to refusal ablation to a MoE model successfully. Nice work, @ OwenArli ! ArliAI/GLM-4.5-Air-Derestricted Ablation on a MoE model is no small thing; I expect preserving norms/magnitudes during intervention better respects routing compared to naive refusal ablation. (I would have tagged their org earlier, but that feature seemed to be broken via \"@\") ArliAI See translation", "url": "https://huggingface.co/posts/grimjim/634931502597925", "date_published": "2025-11-27T09:27:46.178107"}, {"id": "https://huggingface.co/posts/DawnC/810522223628641", "image": "", "title": "SceneWeaver \u2014 AI-Powered Background Generation & Image Composition \ud83c\udfa8\u2728", "content_text": "SceneWeaver \u2014 AI-Powered Background Generation & Image Composition \ud83c\udfa8\u2728 Transform ordinary portraits into professional studio shots with just one click! What can SceneWeaver do? - \ud83d\udcf8 Upload any portrait photo and instantly generate stunning, professional-quality backgrounds - \ud83c\udfad Smart Subject Detection \u2014 Automatically identifies and extracts people, pets, or objects from your photos, even handling tricky cases like dark clothing and cartoon characters. - \ud83c\udf04 Creative Scene Library \u2014 Choose from 24 professionally curated backgrounds spanning offices, nature landscapes, urban settings, artistic styles, and seasonal themes, or describe your own custom vision. - \u2699\ufe0f Professional Results \u2014 Delivers studio-quality compositions in seconds, saving hours of manual editing work while maintaining natural lighting and color harmony. What's next? \ud83c\udfac Enhanced context-aware generation \ud83c\udfa8 Batch processing for multiple style variations \ud83d\udd27 Higher resolution output support \ud83c\udf10 Accessible cloud deployment Current...", "url": "https://huggingface.co/posts/DawnC/810522223628641", "date_published": "2025-11-27T09:27:46.178693"}]}