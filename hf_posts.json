{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/953705052271600", "image": "", "title": "\ud83e\udde0 ThinkFlow: The Revolutionary Platform That Gives LLMs the Power to Think \ud83d\ude80", "content_text": "\ud83e\udde0 ThinkFlow: The Revolutionary Platform That Gives LLMs the Power to Think \ud83d\ude80 Hello AI community! We're excited to introduce you to ThinkFlow, an innovative service that transforms how language models solve problems. \ud83c\udf89 VIDraft/ThinkFlow-llama \u2728 What is ThinkFlow? ThinkFlow is a groundbreaking platform that automatically applies step-by-step reasoning capabilities to existing LLM models without any modifications. It makes complex problem-solving transparent, allowing you to witness the model's thought process in real-time. \ud83d\udd0d Key Features Reasoning Without Model Modifications: Add step-by-step reasoning while utilizing existing LLMs as they are \u2699\ufe0f Visualized Thinking Process: See exactly how the model analyzes and solves problems \ud83d\udc41\ufe0f Before & After Comparison: Compare standard responses with reasoning-enhanced outputs in real-time \ud83d\udcca Improved Accuracy: Deliver more accurate solutions for complex math and logic problems \ud83d\udcc8 Educational Value: Teach students systematic approaches to problem-...", "url": "https://huggingface.co/posts/openfree/953705052271600", "date_published": "2025-04-19T17:18:13.492617"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/401294184812659", "image": "", "title": "FramePack Full Tutorial: 1-Click to Install on Windows - Up to 120 Second Image-to-Videos with 6GB >", "content_text": "FramePack Full Tutorial: 1-Click to Install on Windows - Up to 120 Second Image-to-Videos with 6GB > https://youtu.be/HwMngohRmHg Tutorial video : https://youtu.be/HwMngohRmHg FramePack from legendary lllyasviel full Windows local tutorial with a very advanced Gradio app to generate consistent videos from images with as long as 120 seconds and as low as 6 GB GPUs. This tutorial will show you step by step how to install and use FramePack locall with a very advanced Graido app. Moreover, I have published installers for cloud services such as RunPod and Massed Compute for those GPU poor and who wants to scale. \ud83d\udd17 Full Instructions, Installers and Links Shared Post (the one used in the tutorial) \u2935\ufe0f \u25b6\ufe0f https://www.patreon.com/posts/click-to-open-post-used-in-tutorial-126855226 \ud83d\udd17 SECourses Official Discord 10500+ Members \u2935\ufe0f \u25b6\ufe0f https://discord.com/servers/software-engineering-courses-secourses-772774097734074388 \ud83d\udd17 Stable Diffusion, FLUX, Generative AI Tutorials and Resources GitHub \u2935\ufe0f \u25b6\ufe0f...", "url": "https://huggingface.co/posts/MonsterMMORPG/401294184812659", "date_published": "2025-04-19T17:18:13.493272"}, {"id": "https://huggingface.co/posts/prithivMLmods/567717355691306", "image": "", "title": "Dropping an entire collection of Style Intermixing Adapters on StrangerZone HF \u2014 including Realism, Anime, Sketch, Texture-Rich 3D Experimentals, Automotive Concept Images, and LoRA models based on Flux.1, SD 3.5 Turbo/Large, Stable Diffusion XL \ud83c\udfa8", "content_text": "Dropping an entire collection of Style Intermixing Adapters on StrangerZone HF \u2014 including Realism, Anime, Sketch, Texture-Rich 3D Experimentals, Automotive Concept Images, and LoRA models based on Flux.1, SD 3.5 Turbo/Large, Stable Diffusion XL \ud83c\udfa8 \u2570\u2508\u27a4Collection : \u279c sketch : strangerzonehf/sketch-fav-675ba869c7ceaec7e652ee1c \u279c sketch2 : strangerzonehf/q-series-sketch-678e3503bf3a661758429717 \u279c automotive : strangerzonehf/automotive-3d-675bb31a491d8c264d45d843 \u279c texture 3d : strangerzonehf/flux-3dxl-engine-674833c14a001d5b1fdb5139 \u279c super 3d : strangerzonehf/super-3d-engine-6743231d69f496df97addd2b \u279c style mix : strangerzonehf/mixer-engine-673582c9c5939d8aa5bf9533 \u279c realism : strangerzonehf/realism-engine-67343495b6daf0fbdb904cc1 \u2570\u2508\u27a4The Entire Collection : \u279c flux.1 : prithivMLmods/flux-lora-collections-66dd5908be2206cfaa8519be \u279c flux-ultimate-lora-collection : strangerzonehf/Flux-Ultimate-LoRA-Collection \u279c sd 3.5 large / turbo : prithivMLmods/sd-35-large-lora-671b39d7bc2e7f71a446b163...", "url": "https://huggingface.co/posts/prithivMLmods/567717355691306", "date_published": "2025-04-19T17:18:13.493768"}, {"id": "https://huggingface.co/posts/hesamation/750913380201236", "image": "", "title": "OpenAI just released a 34-page practical guide to building agents,", "content_text": "OpenAI just released a 34-page practical guide to building agents, Here's 10 things it teaches us: 1\u279c agents are different from workflows: they are complete autonomous systems that perform tasks on your behalf. many applications use LLMs for workflows, but this is not an agent. 2\u279c use them for tricky stuff: complex decision making, dynamic rules, unstructured data 3\u279c core recipe: each agent has three main components: Model (the brain), Tools, Instructions on how to behave 4\u279c choose the right brain: set up evals to get a baseline performance, use a smart model to see what's possible, gradually downgrade the model for cost and speed 5\u279c tools are key: choose well-defined and tested tools. an agent needs tools to retrieve data and context, and take actions. 6\u279c instruction matters A LOT: be super clear telling the agent its goals, steps, and rules. Vague instructions = unpredictable agent. Be explicit. 7\u279c start simple, then scale: often a single agent with several tools is ok. don't jump...", "url": "https://huggingface.co/posts/hesamation/750913380201236", "date_published": "2025-04-19T17:18:13.494326"}, {"id": "https://huggingface.co/posts/m-ric/531366391123392", "image": "", "title": "New king of open VLMs: InternVL3 takes Qwen 2.5's crown! \ud83d\udc51", "content_text": "New king of open VLMs: InternVL3 takes Qwen 2.5's crown! \ud83d\udc51 InternVL have been a wildly successful series of model : and the latest iteration has just taken back their crown thanks to their superior, natively multimodal vision training pipeline. \u27a1\ufe0f Most of the vision language models (VLMs) these days are built like Frankenstein : take a good text-only Large Language Model (LLM) backbone, stitch a specific vision transformer (ViT) on top of it. Then the training is sequential \ud83d\udd22 : 1. Freeze the LLM weights while you train the ViT only to work with the LLM part, then 2. Unfreeze all weights to train all weights in order to work together. \ud83d\udcab The Shanghai Lab decided to challenge this paradigm and chose this approach that they call \"native\". For each of their model sizes, they still start from a good LLM (mostly Qwen-2.5 series, did I tell you I'm a huge fan of Qwen? \u2764\ufe0f), and stitch the ViT, but they don't freeze anything : they train all weights together with interleaved text and image...", "url": "https://huggingface.co/posts/m-ric/531366391123392", "date_published": "2025-04-19T17:18:13.494847"}, {"id": "https://huggingface.co/posts/philschmid/318540305385241", "image": "", "title": "Gemini 2.5 Flash is here! We excited launch our first hybrid reasoning Gemini model. In Flash 2.5 developer can turn thinking off.", "content_text": "Gemini 2.5 Flash is here! We excited launch our first hybrid reasoning Gemini model. In Flash 2.5 developer can turn thinking off. **TL;DR:** - \ud83e\udde0 Controllable \"Thinking\" with thinking budget with up to 24k token - \ud83c\udf0c 1 Million multimodal input context for text, image, video, audio, and pdf - \ud83d\udee0\ufe0f Function calling, structured output, google search & code execution. - \ud83c\udfe6 $0.15 1M input tokens; $0.6 or $3.5 (thinking on) per million output tokens (thinking tokens are billed as output tokens) - \ud83d\udca1 Knowledge cut of January 2025 - \ud83d\ude80 Rate limits - Free 10 RPM 500 req/day - \ud83c\udfc5Outperforms 2.0 Flash on every benchmark Try it \u2b07\ufe0f https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-04-17 See translation", "url": "https://huggingface.co/posts/philschmid/318540305385241", "date_published": "2025-04-19T17:18:13.495236"}, {"id": "https://huggingface.co/posts/eugenesiow/891114817044097", "image": "", "title": "GPT-4.1 dropped this week - and it puts OpenAI back in the race for coding & agentic leadership.", "content_text": "GPT-4.1 dropped this week - and it puts OpenAI back in the race for coding & agentic leadership. \u2699\ufe0f API only - no ChatGPT toggle for this. \ud83d\udcbb Coding performance is back on par with Claude 3.7 Sonnet & Gemini 2.5 Pro (though Gemini still leads). \ud83d\udcb8 Pricing: \u2022 Full: $3.50 / 1M tokens \u2022 Mini: $0.70 / 1M \u2022 Nano: $0.17 / 1M \ud83d\udc49 Gemini 2.5 Pro = best price/perf ($3.44 / 1M) \ud83d\ude35 Claude 3.5 Sonnet = $6 / 1M (!) \ud83e\udde0 Not a \"thinking\" model. \ud83d\udcca Mini shines on general reasoning tasks (e.g. GPQA), but only the full model holds up in SWE-bench-verified (GitHub issue solving). See translation", "url": "https://huggingface.co/posts/eugenesiow/891114817044097", "date_published": "2025-04-19T17:18:13.495594"}, {"id": "https://huggingface.co/posts/AdinaY/926684469376880", "image": "", "title": "Wan2.1-FLF2V\ud83c\udfa5  a 14B start-end frame video generation model just released by Alibaba_Wan\ud83d\udd25", "content_text": "Wan2.1-FLF2V\ud83c\udfa5 a 14B start-end frame video generation model just released by Alibaba_Wan\ud83d\udd25 Wan-AI/Wan2.1-FLF2V-14B-720P \u2728 Give it two images (start & end), it generates a smooth, high-quality video in between. \u2728 Apache 2.0 licensed \u2728 Built on DiT + Flow Matching See translation", "url": "https://huggingface.co/posts/AdinaY/926684469376880", "date_published": "2025-04-19T17:18:13.495907"}, {"id": "https://huggingface.co/posts/educrpg/528156241277720", "image": "", "title": "anyone have all their spaces stuck in building now?", "content_text": "anyone have all their spaces stuck in building now? See translation", "url": "https://huggingface.co/posts/educrpg/528156241277720", "date_published": "2025-04-19T17:18:13.496118"}, {"id": "https://huggingface.co/posts/davidberenstein1957/707396604835513", "image": "", "title": "\ud83e\uddd1\u200d\ud83c\udfeb I wrote a brief blogpost to give An Introduction to AI Model Optimization Techniques!", "content_text": "\ud83e\uddd1\u200d\ud83c\udfeb I wrote a brief blogpost to give An Introduction to AI Model Optimization Techniques! URL: https://huggingface.co/blog/PrunaAI/introduction-to-ai-model-optimization-techniques See translation", "url": "https://huggingface.co/posts/davidberenstein1957/707396604835513", "date_published": "2025-04-19T17:18:13.496352"}]}