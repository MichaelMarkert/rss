{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/prithivMLmods/284574267701705", "image": "", "title": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea", "content_text": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea \ud83e\udd17 Space/App: prithivMLmods/Tiny-VLMs-Lab \u2726\ufe0e Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. \u2726\ufe0e Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 \u2726\ufe0e GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or...", "url": "https://huggingface.co/posts/prithivMLmods/284574267701705", "date_published": "2025-08-19T13:33:26.744588"}, {"id": "https://huggingface.co/posts/RakshitAralimatti/207934490136479", "image": "", "title": "When you ask ChatGPT, Claude, or Gemini a really tough question,", "content_text": "When you ask ChatGPT, Claude, or Gemini a really tough question, you might notice that little \"thinking...\" moment before it answers. But what does it actually mean when an LLM is \u201cthinking\u201d? Imagine a chess player pausing before their next move not because they don\u2019t know how to play, but because they\u2019re running through possibilities, weighing options, and choosing the best one. LLMs do something similar\u2026 except they\u2019re not really thinking like us. Here\u2019s the surprising part :- You might think these reasoning skills come from futuristic architectures or alien neural networks. In reality, most reasoning LLMs still use the same transformer decoder-only architecture as other models The real magic? It\u2019s in how they\u2019re trained and what data they learn from. Can AI actually think, or is it just insanely good at faking it? I broke it down in a simple, 4-minute Medium read. Bet you\u2019ll walk away with at least one \u201caha!\u201d moment. \ud83d\ude80 Read here - https://lnkd.in/edZ8Ceyg See translation", "url": "https://huggingface.co/posts/RakshitAralimatti/207934490136479", "date_published": "2025-08-19T13:33:26.745067"}, {"id": "https://huggingface.co/posts/LPX55/307818881554669", "image": "", "title": "Qwen's latest Image Edit model has been implemented with lightx2v's LoRA for 8-step lightning fast inferencing. Still a WIP, so YMMV.", "content_text": "Qwen's latest Image Edit model has been implemented with lightx2v's LoRA for 8-step lightning fast inferencing. Still a WIP, so YMMV. https://huggingface.co/spaces/LPX55/Qwen-Image-Edit-Lightning-Fast See translation", "url": "https://huggingface.co/posts/LPX55/307818881554669", "date_published": "2025-08-19T13:33:26.745292"}, {"id": "https://huggingface.co/posts/ginipick/955296677233221", "image": "", "title": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728", "content_text": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728 \ud83c\udf8a Free Trial for Hugging Face Launch! Hurry! \u23f0 Hello! Introducing an innovative AI service that helps you choose the perfect hairstyle without any regrets before visiting the salon! \ud83c\udfaf Try It Now ginigen/Hair-Pick \ud83d\udd04 What Makes HairPick Special? 360\u00b0 Complete Preview! Other hair simulators only show the front view? \ud83d\ude11 HairPick is different! \u2705 Front + 4 random angles = Total 5 multi-angle images generated \u2705 Perfect check from side profile \ud83d\udc64 diagonal \ud83d\udcd0 back view \ud83d\udc65! \u2705 100+ trendy hairstyle library \ud83d\udc87\u200d\u2640\ufe0f \ud83d\udca1 Highly Recommended For: \ud83c\udfaf \"I really don't want to fail this time!\" \u2192 Check side volume and back lines thoroughly \ud83c\udfaf \"It's hard to explain exactly to my stylist\" \u2192 Perfect communication with 360\u00b0 result images! \ud83c\udfaf \"I have a profile photo/photoshoot coming up\" \u2192 Preview your best look from every angle \ud83d\ude80 Super Simple Usage (Just 1 Minute!) 1\ufe0f\u20e3 One Selfie \ud83d\udcf8 Take a front-facing photo in bright light (show your forehead and face...", "url": "https://huggingface.co/posts/ginipick/955296677233221", "date_published": "2025-08-19T13:33:26.745967"}, {"id": "https://huggingface.co/posts/etemiz/891816438009932", "image": "", "title": "benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :(", "content_text": "benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :( See translation", "url": "https://huggingface.co/posts/etemiz/891816438009932", "date_published": "2025-08-19T13:33:26.746174"}, {"id": "https://huggingface.co/posts/prithivMLmods/366249407896156", "image": "", "title": "Added plug-and-play support for Qwen Image LoRA!  \ud83e\udd17\u26a1", "content_text": "Added plug-and-play support for Qwen Image LoRA! \ud83e\udd17\u26a1 Try it here: \u2726\ufe0e Qwen-Image (with LoRA): prithivMLmods/Qwen-Image-Diffusion \u2726\ufe0e Collection: prithivMLmods/image-gen-apps-diffusion-lastupdated-08-18-68a2f4c5ef3e5e394eacc20a See translation", "url": "https://huggingface.co/posts/prithivMLmods/366249407896156", "date_published": "2025-08-19T13:33:26.746409"}, {"id": "https://huggingface.co/posts/openfree/413087646131051", "image": "", "title": "\ud83e\udd16 AI-Generated 6-Nation Military Simulator in a Single HTML File", "content_text": "\ud83e\udd16 AI-Generated 6-Nation Military Simulator in a Single HTML File \ud83d\ude80 Project Highlight A full-scale military strategy simulator that runs in a single HTML file! This AI-generated wargame implements real military equipment and tactical doctrines from 6 nations (\ud83c\uddf0\ud83c\uddf7,\ud83c\uddf0\ud83c\uddf5,\ud83c\uddfa\ud83c\uddf8,\ud83c\uddf7\ud83c\uddfa,\ud83c\uddfa\ud83c\udde6,\ud83c\udde8\ud83c\uddf3) using pure JavaScript only, without any external libraries. openfree/WAR-Game-Simul \ud83d\udca1 Amazing Achievement of AI Auto-Generation \ud83d\udcc1 Single File Magic One-Click Launch: Just open the HTML file and play instantly Zero Dependencies: No npm, webpack, or external libraries Pure Vanilla JS: Implemented with Canvas API only, no frameworks All-in-One: Rendering, physics engine, AI, and UI in a single file \ud83c\udfae Advanced Features AI Implemented \u2705 Perlin Noise terrain generation algorithm \u2705 Marching Squares contour rendering \u2705 Lanchester combat equations \u2705 A* pathfinding algorithm \u2705 Real-time Line of Sight (LOS) calculations \u2705 40-second battlefield sound loop \ud83c\udf96\ufe0f Implemented Military Systems \ud83d\udd25 Real Weapon Systems from 6...", "url": "https://huggingface.co/posts/openfree/413087646131051", "date_published": "2025-08-19T13:33:26.747040"}, {"id": "https://huggingface.co/posts/anakin87/751707976654130", "image": "", "title": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac", "content_text": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac I made a simple Space to do that: anakin87/gemma-3-270m-it \u26a1 Fast: Flash Attention, Zero GPU \u2699\ufe0f Configurable See translation", "url": "https://huggingface.co/posts/anakin87/751707976654130", "date_published": "2025-08-19T13:33:26.747272"}, {"id": "https://huggingface.co/posts/ovi054/657358125503535", "image": "", "title": "Image-to-Prompt\u26a1", "content_text": "Image-to-Prompt\u26a1 ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 \ud83d\udc49 Try it now: ovi054/image-to-prompt See translation", "url": "https://huggingface.co/posts/ovi054/657358125503535", "date_published": "2025-08-19T13:33:26.747527"}, {"id": "https://huggingface.co/posts/etemiz/710778843328598", "image": "", "title": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.", "content_text": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really \"free\": they are costing you your freedom if you know what i mean. See translation", "url": "https://huggingface.co/posts/etemiz/710778843328598", "date_published": "2025-08-19T13:33:26.747754"}]}