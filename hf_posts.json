{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/burtenshaw/697123415535373", "image": "", "title": "Inference for generative ai models looks like a mine field, but there\u2019s a simple protocol for picking the best inference:", "content_text": "Inference for generative ai models looks like a mine field, but there\u2019s a simple protocol for picking the best inference: \ud83c\udf0d 95% of users >> If you\u2019re using open (large) models and need fast online inference, then use Inference providers on auto mode, and let it choose the best provider for the model. https://huggingface.co/docs/inference-providers/index \ud83d\udc77 fine-tuners/ bespoke >> If you\u2019ve got custom setups, use Inference Endpoints to define a configuration from AWS, Azure, GCP. https://endpoints.huggingface.co/ \ud83e\uddab Locals >> If you\u2019re trying to stretch everything you can out of a server or local machine, use Llama.cpp, Jan, LMStudio or vLLM. https://huggingface.co/settings/local-apps#local-apps \ud83e\ude9f Browsers >> If you need open models running right here in the browser, use transformers.js. https://github.com/huggingface/transformers.js Let me know what you\u2019re using, and if you think it\u2019s more complex than this. See translation", "url": "https://huggingface.co/posts/burtenshaw/697123415535373", "date_published": "2025-07-02T13:35:30.998356"}, {"id": "https://huggingface.co/posts/Abhaykoul/404767027882987", "image": "", "title": "\ud83c\udf89 Dhanishtha 2.0 Preview is Now Open Source!", "content_text": "\ud83c\udf89 Dhanishtha 2.0 Preview is Now Open Source! The world's first Intermediate Thinking Model is now available to everyone! Dhanishtha 2.0 Preview brings revolutionary intermediate thinking capabilities to the open-source community. Unlike traditional reasoning models that think once, Dhanishtha can think, answer, rethink, answer again, and continue rethinking as needed using multiple blocks between responses. \ud83d\ude80 Key Features - Intermediate thinking: Think \u2192 Answer \u2192 Rethink \u2192 Answer \u2192 Rethink if needed... - Token efficient: Uses up to 79% fewer tokens than DeepSeek R1 on similar queries - Transparent thinking: See the model's reasoning process in real-time - Open source: Freely available for research and development HelpingAI/Dhanishtha-2.0-preview https://helpingai.co/chat See translation", "url": "https://huggingface.co/posts/Abhaykoul/404767027882987", "date_published": "2025-07-02T13:35:30.998759"}, {"id": "https://huggingface.co/posts/blaise-tk/599826348587266", "image": "", "title": "A few months ago, I shared that I was building with", "content_text": "A few months ago, I shared that I was building with @ deeivihh something like \"the Steam for open source apps\"... \ud83d\ude80 Today, I\u2019m excited to announce that Dione is now open source and live in public beta! Our mission is simple: make it easier to discover, use, and contribute to open source applications. \ud83d\udd17 GitHub: https://github.com/dioneapp/dioneapp \ud83d\udcac Join the community: https://discord.gg/JDFJp33vrM Want to give it a try? I\u2019d love your feedback! \ud83d\udc40 See translation", "url": "https://huggingface.co/posts/blaise-tk/599826348587266", "date_published": "2025-07-02T13:35:30.999066"}, {"id": "https://huggingface.co/posts/merve/587280854326828", "image": "", "title": "so many multimodal releases these days \ud83e\udd20", "content_text": "so many multimodal releases these days \ud83e\udd20 > ERNIE-4.5-VL: new vision language MoE models by Baidu https://huggingface.co/models?search=ernie-4.5-vl > new visual document retrievers by NVIDIA (sota on ViDoRe!) nvidia/llama-nemoretriever-colembed-3b-v1 nvidia/llama-nemoretriever-colembed-1b-v1 > Ovis-3b: new image-text in image-text out models by Alibaba \u2935\ufe0f https://huggingface.co/spaces/AIDC-AI/Ovis-U1- See translation", "url": "https://huggingface.co/posts/merve/587280854326828", "date_published": "2025-07-02T13:35:30.999363"}, {"id": "https://huggingface.co/posts/sequelbox/523631078445392", "image": "", "title": "The full Celestia 3 science-reasoning dataset is here!", "content_text": "The full Celestia 3 science-reasoning dataset is here! - 91k high-quality synthetic science prompts answered by DeepSeek-R1-0528 - subjects include physics, biology, chemistry, computer science, Earth science, astronomy, and information theory - one of the reasoning datasets powering the upcoming Shining Valiant 3 :) coming soon! GET IT NOW, FOR EVERYONE: sequelbox/Celestia3-DeepSeek-R1-0528 SUPPORT OUR RELEASES: sequelbox/SupportOpenSource with love, allegra See translation", "url": "https://huggingface.co/posts/sequelbox/523631078445392", "date_published": "2025-07-02T13:35:30.999634"}, {"id": "https://huggingface.co/posts/asigalov61/301808424415801", "image": "", "title": "Check out new symbolic music AI front end and CLI training app", "content_text": "Check out new symbolic music AI front end and CLI training app https://webchatappai.github.io/midi-gen/ https://github.com/WebChatAppAi/Orpheus-Midi-Model-Maker @ Timzoid @ Csplk @ not-lain @ victor @ bartowski @ John6666 See translation", "url": "https://huggingface.co/posts/asigalov61/301808424415801", "date_published": "2025-07-02T13:35:30.999863"}, {"id": "https://huggingface.co/posts/salma-remyx/520178128759841", "image": "", "title": "I'm auto-generating Docker Images to smoke-test new research repos \ud83d\udd25", "content_text": "I'm auto-generating Docker Images to smoke-test new research repos \ud83d\udd25 Shared to Docker Hub daily! \ud83d\udc33 Today's featured paper+Image: LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs https://hub.docker.com/repository/docker/remyxai/2506.21862v1/general See translation", "url": "https://huggingface.co/posts/salma-remyx/520178128759841", "date_published": "2025-07-02T13:35:31.000103"}, {"id": "https://huggingface.co/posts/anakin87/460502915743038", "image": "", "title": "\ud83e\uddf0 Free up space on the Hub with", "content_text": "\ud83e\uddf0 Free up space on the Hub with super_squash_history \ud83e\uddf9 As you may know, Hugging Face Hub has storage limits on private repos (100 GB for free users, 1 TB for PROs). This weekend I did some cleanup on my private repos I went 1.58 TB down to 1 GB. \ud83d\ude05 Besides deleting old, unused models, the main tool I used was a lesser-known command: super_squash_history . When you train a model, you often push multiple checkpoints to the Hub. Each checkpoint = a commit. A 2.6B model in BF16 is ~5 GB. So 10 checkpoints = 50 GB. That adds up fast. While full commit history can be useful for rollbacks, it's often unnecessary for older experiments where only the final model matters. In these cases, you can use super_squash_history : it reduces your entire repo history to a single commit. https://huggingface.co/docs/huggingface_hub/main/en/package_reference/hf_api#huggingface_hub.HfApi.super_squash_history \u26a0\ufe0f super_squash_history is a non-revertible operation. Once squashed, the commit history cannot be...", "url": "https://huggingface.co/posts/anakin87/460502915743038", "date_published": "2025-07-02T13:35:31.000564"}, {"id": "https://huggingface.co/posts/pagezyhf/189638803943526", "image": "", "title": "In case you missed it, Hugging Face expanded its collaboration with Azure a few weeks ago with a curated catalog of 10,000 models, accessible from Azure AI Foundry and Azure ML!", "content_text": "In case you missed it, Hugging Face expanded its collaboration with Azure a few weeks ago with a curated catalog of 10,000 models, accessible from Azure AI Foundry and Azure ML! @ alvarobartt cooked during these last days to prepare the one and only documentation you need, if you wanted to deploy Hugging Face models on Azure. It comes with an FAQ, great guides and examples on how to deploy VLMs, LLMs, smolagents and more to come very soon. We need your feedback: come help us and let us know what else you want to see, which model we should add to the collection, which model task we should prioritize adding, what else we should build a tutorial for. You\u2019re just an issue away on our GitHub repo! https://huggingface.co/docs/microsoft-azure/index See translation", "url": "https://huggingface.co/posts/pagezyhf/189638803943526", "date_published": "2025-07-02T13:35:31.000934"}, {"id": "https://huggingface.co/posts/sergiopaniego/945882073606324", "image": "", "title": "\ud83d\udce3 CALL FOR CONTRIBUTORS! \ud83d\udce3", "content_text": "\ud83d\udce3 CALL FOR CONTRIBUTORS! \ud83d\udce3 Following last week\u2019s full release of Gemma 3n, we launched a dedicated recipes repo to explore and share use cases. We already added some! \ud83e\uddd1\u200d\ud83c\udf73 Now we\u2019re inviting the community to contribute and showcase how these models shine! \u2728 Let them cook. Check it out: https://github.com/huggingface/huggingface-gemma-recipes/issues/4 See translation", "url": "https://huggingface.co/posts/sergiopaniego/945882073606324", "date_published": "2025-07-02T13:35:31.001208"}]}