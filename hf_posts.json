{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mike-ravkine/324105560308241", "image": "", "title": "Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13:", "content_text": "Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13: aquif-ai/aquif-3.5-8B-Think Built on top of the solid Qwen3-8B foundation, aquif-3.5-8B-Think successfully preserves the high performance of the original model while consuming 30-50% less reasoning tokens. The most notable regression vs the base model here is in arithmetic - if your workload is math heavy this model demonstrates an unfortunate collapse with performance under growing complexity. The interesting combination of awesome overall performance on SVG simple shapes identification coupled with a total inability to recognize more complex shapes like 'House' or 'Arrow' is a behavior directly inherited from the base model (but with a ~20% improvement in token utilization). If you like your reasoning models token-efficient, Aquif-3.5-8B-Think is well worth a spin. Higher resolution, more detailed, interactive plots are available at the m12X explorer: https://reasonscape.com/m12x/explorer/...", "url": "https://huggingface.co/posts/mike-ravkine/324105560308241", "date_published": "2025-10-17T05:21:59.510855"}, {"id": "https://huggingface.co/posts/abdurrahmanbutler/994710514786612", "image": "", "title": "\ud83c\udf89 I am excited to share news of a project my brother, Umar Butler, and I have been working on for what feels like an eternity now.", "content_text": "\ud83c\udf89 I am excited to share news of a project my brother, Umar Butler, and I have been working on for what feels like an eternity now. \ud835\udc08\ud835\udc27\ud835\udc2d\ud835\udc2b\ud835\udc28\ud835\udc1d\ud835\udc2e\ud835\udc1c\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0c\ud835\udc0b\ud835\udc04\ud835\udc01 \u2014 \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc0c\ud835\udc1a\ud835\udc2c\ud835\udc2c\ud835\udc22\ud835\udc2f\ud835\udc1e \ud835\udc0b\ud835\udc1e\ud835\udc20\ud835\udc1a\ud835\udc25 \ud835\udc04\ud835\udc26\ud835\udc1b\ud835\udc1e\ud835\udc1d\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc01\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc21\ud835\udc26\ud835\udc1a\ud835\udc2b\ud835\udc24. A suite of 10 high-quality English legal IR datasets, designed by legal experts to set a new standard for comparing embedding models. Whether you\u2019re exploring legal RAG on your home computer, or running enterprise-scale retrieval, apples-to-apples evaluation is crucial. That\u2019s why we\u2019ve open-sourced everything - including our 7 brand-new, hand-crafted retrieval datasets. All of these datasets are now live on Hugging Face. Any guesses which embedding model leads on legal retrieval? \ud835\udc07\ud835\udc22\ud835\udc27\ud835\udc2d: it\u2019s not OpenAI or Google - they place 7th and 9th on our leaderboard. To do well on MLEB, embedding models must demonstrate both extensive legal domain knowledge and strong legal reasoning skills. https://huggingface.co/blog/isaacus/introducing-mleb See translation", "url": "https://huggingface.co/posts/abdurrahmanbutler/994710514786612", "date_published": "2025-10-17T05:21:59.511288"}, {"id": "https://huggingface.co/posts/adlumal/955872232459431", "image": "", "title": "MLEB  is the largest, most diverse, and most comprehensive benchmark for legal text embedding models.", "content_text": "MLEB is the largest, most diverse, and most comprehensive benchmark for legal text embedding models. https://huggingface.co/blog/isaacus/introducing-mleb See translation", "url": "https://huggingface.co/posts/adlumal/955872232459431", "date_published": "2025-10-17T05:21:59.511497"}, {"id": "https://huggingface.co/posts/sergiopaniego/524517454338742", "image": "", "title": "@Qwen", "content_text": "@ Qwen released their new small and dense VLMs (Qwen3-VL). They're incredibly capable and one of my all-time favourite VLMs. \ud83e\udd17 We\u2019ve prepared some resources to help you get started. > Fine-tune Qwen3-VL-4B with SFT or GRPO (free Colab notebooks): > SFT: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/sft_qwen_vl.ipynb > GRPO: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_qwen3_vl.ipynb > Compare object detection vs. Moondream3: sergiopaniego/vlm_object_understanding > Fine-tune from the CLI using TRL: https://github.com/kashif/Qwen3-VL/blob/trl-sft/qwen-vl-finetune/README.md#trl-based-training-single-gpu See translation", "url": "https://huggingface.co/posts/sergiopaniego/524517454338742", "date_published": "2025-10-17T05:21:59.511846"}, {"id": "https://huggingface.co/posts/ronantakizawa/301388923540512", "image": "", "title": "Released an AWQ quantized version of BosonAI\u2019s Higgs-Llama-3-70B model! \ud83c\udf89", "content_text": "Released an AWQ quantized version of BosonAI\u2019s Higgs-Llama-3-70B model! \ud83c\udf89 The Higgs-Llama-3-70B is an LLM specialized in role-playing, useful for game characters. Using an NVIDIA B200 GPU, I was able to compress the huge 140GB model into 37GB while keeping minimal perplexity \ud83d\udc4d ronantakizawa/higgs-llama-3-70b-awq See translation", "url": "https://huggingface.co/posts/ronantakizawa/301388923540512", "date_published": "2025-10-17T05:21:59.512111"}, {"id": "https://huggingface.co/posts/TravisMuhlestein/661240541677725", "image": "", "title": "Building AI Agents from First Principles at GoDaddy", "content_text": "Building AI Agents from First Principles at GoDaddy Everyone\u2019s talking about AI agents lately, and for good reason. But at GoDaddy, we\u2019re going deeper: starting from first principles to explore what makes an agent truly robust and usable in real-world scenarios. Instead of asking \u201cWhat can we build fast?\u201d we\u2019re asking \u201cWhat design choices make agents flexible, testable, and reliable long term?\u201d Core Concepts \u2022 Tool-centric design: everything an agent does is a tool call, with precise APIs and granularity. \u2022 Decision vs. delivery: agents decide what to do; tools handle how to do it\u2014keeping systems modular. \u2022 Structured outputs & reflection: LLMs output both the tool call and the reason behind it, making debugging and iteration easier. \u2022 Universal tools: even user interactions (inform, confirm, request) are abstracted as tools, clarifying boundaries between logic and interface. Real-world use cases \u2192 Not just theory \u2705Routing and responding to support messages \u2705Surfacing emerging...", "url": "https://huggingface.co/posts/TravisMuhlestein/661240541677725", "date_published": "2025-10-17T05:21:59.512674"}, {"id": "https://huggingface.co/posts/ZennyKenny/876142925777221", "image": "", "title": "Did Hugging Face just ban hammer a bunch of bot accounts or am I just so uninteresting that 30% of my subs dropped me overnight?", "content_text": "Did Hugging Face just ban hammer a bunch of bot accounts or am I just so uninteresting that 30% of my subs dropped me overnight? \ud83d\ude2c Wait, don't answer that. See translation", "url": "https://huggingface.co/posts/ZennyKenny/876142925777221", "date_published": "2025-10-17T05:21:59.512906"}, {"id": "https://huggingface.co/posts/kanaria007/662291776092926", "image": "", "title": "\u2705 New Article: *Humor as Structured Protocol*", "content_text": "\u2705 New Article: *Humor as Structured Protocol* Title: \ud83c\udfad Humor as Structured Protocol: Joke-Protocols as Emotion Regulation and AGI Design Resource \ud83d\udd17 https://huggingface.co/blog/kanaria007/humor-as-structured-protocol --- Summary: Humor isn\u2019t a distraction \u2014 it\u2019s a *protocol*. By framing paradox as *benign*, humor vents overload, resets attention, and enables safe re-entry to difficult topics. In Structured Intelligence terms, jokes are *bounded anomalies* that discharge tension without breaking identity or trust. > Laughter is relief. > *Humor is the design that makes relief safe.* --- Why It Matters: \u2022 Turns \u201ccomic timing\u201d into *recoverable state transitions* (no denial, no collapse) \u2022 Gives teams and products a *de-escalation primitive* that preserves dignity \u2022 Informs *AI/UX safety*: sandboxed incongruity, ethical gates, clear exit paths --- What\u2019s Inside: \u2022 The Humor Protocol: trigger \u2192 incongruity \u2192 benign boundary \u2192 release \u2192 re-entry \u2022 Patterns: irony, self-deprecation,...", "url": "https://huggingface.co/posts/kanaria007/662291776092926", "date_published": "2025-10-17T05:21:59.513426"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/140461476722015", "image": "", "title": "I just set up the new Ollama integration in VS Code, so I wanted to test it. I hooked up glm-4.6, and asked it to build a full stack Ollama chat interface.", "content_text": "I just set up the new Ollama integration in VS Code, so I wanted to test it. I hooked up glm-4.6, and asked it to build a full stack Ollama chat interface. In only 3 prompts, glm-4.6 built the app, and debugged it successfully. One prompt for the build, two for debugging -> fully functional app. I was genuinely impressed! It's really cool to see how powerful open source tools have become. The future is exciting and I'm here for it! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/140461476722015", "date_published": "2025-10-17T05:21:59.513685"}, {"id": "https://huggingface.co/posts/mike-ravkine/370448674179433", "image": "", "title": "There are two very interesting reasoning models from", "content_text": "There are two very interesting reasoning models from ServiceNow-AI that I think are flying under everyone's radar - lets take a closer look at ServiceNow-AI/Apriel-1.5-15b-Thinker (#10 on the ReasonScape rankings) and ServiceNow-AI/Apriel-Nemotron-15b-Thinker (landing just below its brother at #12). A rather interesting attribute of these models is I have absolutely no idea what they are fine-tuned from, other then some kind of pre-small Mistrals! The non-nemo 15b looks like Mistral Pixtral 12B, but with 8 more layers while the nemo 15b analogously looks like Mistral NeMo 12B but with 10 more layers and a smaller max context length. The performance trade-offs between these two models are quite clear: the Nemotron provides ~30% shorter answers but at the expense of totally collapsing under difficulty on 4 of the 12 tasks ... which all just happen to have \"Math\" in common, so it's pretty easy to point the finger at exactly what the price for the lower reasoning token usage is here. In...", "url": "https://huggingface.co/posts/mike-ravkine/370448674179433", "date_published": "2025-10-17T05:21:59.514096"}]}