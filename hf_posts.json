{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/burtenshaw/189514834246661", "image": "", "title": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts:", "content_text": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts: 1\ufe0f\u20e3 New Supervised Fine-tuning unit in the NLP Course https://huggingface.co/learn/nlp-course/en/chapter11/1 2\ufe0f\u20e3New Finetuning for agents bonus module in the Agents Course https://huggingface.co/learn/agents-course/bonus-unit1/introduction Fine-tuning will squeeze everything out of your model for how you\u2019re using it, more than any prompt. See translation", "url": "https://huggingface.co/posts/burtenshaw/189514834246661", "date_published": "2025-02-21T17:17:51.653703"}, {"id": "https://huggingface.co/posts/merve/467807900895850", "image": "", "title": "Google just released PaliGemma 2 Mix: new versatile instruction vision language models \ud83d\udd25", "content_text": "Google just released PaliGemma 2 Mix: new versatile instruction vision language models \ud83d\udd25 > Three new models: 3B, 10B, 28B with res 224, 448 \ud83d\udc99 > Can do vision language tasks with open-ended prompts, understand documents, and segment or detect anything \ud83e\udd2f Read more https://huggingface.co/blog/paligemma2mix Try the demo google/paligemma2-10b-mix All models are here google/paligemma-2-mix-67ac6a251aaf3ee73679dcc4 See translation", "url": "https://huggingface.co/posts/merve/467807900895850", "date_published": "2025-02-21T17:17:51.654051"}, {"id": "https://huggingface.co/posts/smirki/311150694603392", "image": "", "title": "UIGEN for Tailwind v4 is coming soon!", "content_text": "UIGEN for Tailwind v4 is coming soon! See translation", "url": "https://huggingface.co/posts/smirki/311150694603392", "date_published": "2025-02-21T17:17:51.654265"}, {"id": "https://huggingface.co/posts/lysandre/966361810633890", "image": "", "title": "SmolVLM-2 and SigLIP-2 are now part of", "content_text": "SmolVLM-2 and SigLIP-2 are now part of transformers in dedicated releases! They're added on top of the v4.49.0 release, and can be installed from the following tags: v4.49.0-SmolVLM-2 and v4.49.0-SigLIP-2 . This marks a new beginning for the release process of transformers. For the past five years, we've been doing monthly releases featuring many models (v4.49.0, the latest release, features 9 new architectures). Starting with SmolVLM-2 & SigLIP2, we'll now additionally release tags supporting new models on a stable branch. These models are therefore directly available for use by installing from the tag itself. These tags will continue to be updated with fixes applied to these models. Going forward, continue expecting software releases following semantic versioning: v4.50.0 will have ~10 new architectures compared to v4.49.0, as well as a myriad of new features, improvements and bug fixes. Accompanying these software releases, we'll release tags offering brand new models as fast as...", "url": "https://huggingface.co/posts/lysandre/966361810633890", "date_published": "2025-02-21T17:17:51.654646"}, {"id": "https://huggingface.co/posts/DmitryRyumin/189065722993769", "image": "", "title": "\ud83d\ude80\ud83c\udfad\ud83c\udf1f New Research Alert - WACV 2025 (Avatars Collection)! \ud83c\udf1f\ud83c\udfad\ud83d\ude80", "content_text": "\ud83d\ude80\ud83c\udfad\ud83c\udf1f New Research Alert - WACV 2025 (Avatars Collection)! \ud83c\udf1f\ud83c\udfad\ud83d\ude80 \ud83d\udcc4 Title: EmoVOCA: Speech-Driven Emotional 3D Talking Heads \ud83d\udd1d \ud83d\udcdd Description: EmoVOCA is a data-driven method for generating emotional 3D talking heads by combining speech-driven lip movements with expressive facial dynamics. This method has been developed to overcome the limitations of corpora and to achieve state-of-the-art animation quality. \ud83d\udc65 Authors: @ FedeNoce , Claudio Ferrari, and Stefano Berretti \ud83d\udcc5 Conference: WACV, 28 Feb \u2013 4 Mar, 2025 | Arizona, USA \ud83c\uddfa\ud83c\uddf8 \ud83d\udcc4 Paper: https://arxiv.org/abs/2403.12886 \ud83c\udf10 Github Page: https://fedenoce.github.io/emovoca/ \ud83d\udcc1 Repository: https://github.com/miccunifi/EmoVOCA \ud83d\ude80 CVPR-2023-24-Papers: https://github.com/DmitryRyumin/CVPR-2023-24-Papers \ud83d\ude80 WACV-2024-Papers: https://github.com/DmitryRyumin/WACV-2024-Papers \ud83d\ude80 ICCV-2023-Papers: https://github.com/DmitryRyumin/ICCV-2023-Papers \ud83d\udcda More Papers: more cutting-edge research presented at other conferences in the DmitryRyumin/NewEraAI-Papers...", "url": "https://huggingface.co/posts/DmitryRyumin/189065722993769", "date_published": "2025-02-21T17:17:51.655152"}, {"id": "https://huggingface.co/posts/merterbak/134010141714846", "image": "", "title": "\ud83d\udd25 Meet Muse: that can generate a game environment based on visuals or players\u2019 controller actions. It was developed by Microsoft Research in collaboration with Ninja Theory (Hellblade developer). It\u2019s built on something called the World and Human Action Model (WHAM-1.6B model). They trained on 7 years of Bleeding Edge gameplay and it can generate 2 minute long 3D game sequences with consistent physics and character behaviors all from just a second of input. They\u2019ve gone and open-sourced it too. Open weights, the WHAM Demonstrator, and sample data on Azure AI Foundry for anyone to play with. Hope so soon on Hugging Face \ud83e\udd17.", "content_text": "\ud83d\udd25 Meet Muse: that can generate a game environment based on visuals or players\u2019 controller actions. It was developed by Microsoft Research in collaboration with Ninja Theory (Hellblade developer). It\u2019s built on something called the World and Human Action Model (WHAM-1.6B model). They trained on 7 years of Bleeding Edge gameplay and it can generate 2 minute long 3D game sequences with consistent physics and character behaviors all from just a second of input. They\u2019ve gone and open-sourced it too. Open weights, the WHAM Demonstrator, and sample data on Azure AI Foundry for anyone to play with. Hope so soon on Hugging Face \ud83e\udd17. \ud83d\udcc4 Paper: https://www.nature.com/articles/s41586-025-08600-3 Blog Post: https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/ See translation", "url": "https://huggingface.co/posts/merterbak/134010141714846", "date_published": "2025-02-21T17:17:51.655548"}, {"id": "https://huggingface.co/posts/fdaudens/121352437859372", "image": "", "title": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses.", "content_text": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses. Check it out: perplexity-ai/r1-1776 Blog post: https://perplexity.ai/hub/blog/open-sourcing-r1-1776 See translation", "url": "https://huggingface.co/posts/fdaudens/121352437859372", "date_published": "2025-02-21T17:17:51.655819"}, {"id": "https://huggingface.co/posts/jasoncorkill/138106605710984", "image": "", "title": "Integrating human feedback is vital for evolving AI models. Boost quality, scalability, and cost-effectiveness with our crowdsourcing tool!", "content_text": "Integrating human feedback is vital for evolving AI models. Boost quality, scalability, and cost-effectiveness with our crowdsourcing tool! ..Or run A/B tests and gather thousands of responses in minutes. Upload two images, ask a question, and watch the insights roll in! Check it out here and let us know your feedback: https://app.rapidata.ai/compare See translation", "url": "https://huggingface.co/posts/jasoncorkill/138106605710984", "date_published": "2025-02-21T17:17:51.656087"}, {"id": "https://huggingface.co/posts/cogwheelhead/360341725112136", "image": "", "title": "Me and my team have performed an in-depth investigation comparing o1 to R1 (and other reasoning models)", "content_text": "Me and my team have performed an in-depth investigation comparing o1 to R1 (and other reasoning models) Link: https://toloka.ai/blog/r1-is-not-on-par-with-o1-and-the-difference-is-qualitative-not-quantitative It started with us evaluating them on our own university-math benchmarks: U-MATH for problem-solving and \u03bc-MATH for judging solution correctness (see the HF leaderboard: toloka/u-math-leaderboard ) tl;dr: R1 sure is amazing, but what we find is that it lags behind in novelty adaptation and reliability: * performance drops when updating benchmarks with fresh unseen tasks (e.g. AIME 2024 -> 2025) * R1-o1 gap widens when evaluating niche subdomains (e.g. university-specific math instead of the more common Olympiad-style contests) * same with going into altogether unconventional domains (e.g. chess) or skills (e.g. judgment instead of problem-solving) * R1 also runs into failure modes way more often (e.g. making illegal chess moves or falling into endless generation loops) Our...", "url": "https://huggingface.co/posts/cogwheelhead/360341725112136", "date_published": "2025-02-21T17:17:51.656570"}, {"id": "https://huggingface.co/posts/dreamerdeo/426313569382827", "image": "", "title": "\ud83d\ude80 Excited to share our technical report on the Southeast Asian multilingual model Sailor2 and its latest updates!", "content_text": "\ud83d\ude80 Excited to share our technical report on the Southeast Asian multilingual model Sailor2 and its latest updates! Our 49-page report details Sailor2's development journey, including multilingual data cleaning, small model data mixture simulations, multi-stage continual pre-training, multi-stage post-training, and multi-cultural multi-lingual evaluations. Sailor2 aims to streamline the multilingual model pre-training process efficiently for the community. \ud83e\udded We highlight Sailor2's impressive performance in low-resource language translation scenarios and its cultural understanding advantages in Southeast Asia, promoting practical applications for regional languages. Model updates include: \ud83d\udca1 More precise outputs: Reduced redundancy in model outputs through refined post-training data and optimization techniques. \ud83c\udf08 Handling longer texts: Expanded to handle up to 128K context length in Southeast Asian languages through long-text training. \u26a1\ufe0f Faster inference: Achieved 2.5x faster inference...", "url": "https://huggingface.co/posts/dreamerdeo/426313569382827", "date_published": "2025-02-21T17:17:51.657108"}]}