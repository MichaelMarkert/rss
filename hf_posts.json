{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/sergiopaniego/364808323176425", "image": "", "title": "Want to get started with fine-tuning but don\u2019t know where to begin? \ud83e\udd13\u261d\ufe0f", "content_text": "Want to get started with fine-tuning but don\u2019t know where to begin? \ud83e\udd13\u261d\ufe0f We\u2019re expanding our collection of beginner-friendly free Colab notebooks so you can learn and fine-tune models using TRL at no cost \ud83d\udd2c Check out the full list of free notebooks: https://huggingface.co/docs/trl/main/en/example_overview#notebooks \ud83d\udd2c If you want more advanced content, we also have a lot to cover in the community tutorials: https://huggingface.co/docs/trl/community_tutorials And now the obvious question: what would you like us to add next? See translation", "url": "https://huggingface.co/posts/sergiopaniego/364808323176425", "date_published": "2025-12-07T09:23:26.502802"}, {"id": "https://huggingface.co/posts/prithivMLmods/612580119302031", "image": "", "title": "One speech model with seven voices, streamlined with multimodal capabilities for vision tasks. Performs vision(image-text) to audio inference with Qwen2.5-VL + VibeVoice-Realtime-0.5B. Vision to VibeVoice (EN) -  The demo is live.  \ud83d\udde3\ufe0f\ud83d\udd25", "content_text": "One speech model with seven voices, streamlined with multimodal capabilities for vision tasks. Performs vision(image-text) to audio inference with Qwen2.5-VL + VibeVoice-Realtime-0.5B. Vision to VibeVoice (EN) - The demo is live. \ud83d\udde3\ufe0f\ud83d\udd25 \ud83e\udd17 Vision-to-VibeVoice-en [Demo]: prithivMLmods/Vision-to-VibeVoice-en \u2728 Collection: https://huggingface.co/collections/prithivMLmods/multimodal-implementations \u2728 Speech [VibeVoice-Realtime-0.5B]: microsoft/VibeVoice-Realtime-0.5B \u2728 Vision [Qwen2.5-VL]: Qwen/Qwen2.5-VL-7B-Instruct To know more about it, visit the app page or the respective model page! See translation", "url": "https://huggingface.co/posts/prithivMLmods/612580119302031", "date_published": "2025-12-07T09:23:26.503169"}, {"id": "https://huggingface.co/posts/danielhanchen/849127033892624", "image": "", "title": "Mistral's new Ministral 3 models can now be Run & Fine-tuned locally! (16GB RAM)", "content_text": "Mistral's new Ministral 3 models can now be Run & Fine-tuned locally! (16GB RAM) Ministral 3 have vision support and the best-in-class performance for their sizes. 14B Instruct GGUF: unsloth/Ministral-3-14B-Instruct-2512-GGUF 14B Reasoning GGUF: unsloth/Ministral-3-14B-Reasoning-2512-GGUF \ud83d\udc31 Step-by-step Guide: https://docs.unsloth.ai/new/ministral-3 All GGUFs, BnB, FP8 etc. variants uploads: https://huggingface.co/collections/unsloth/ministral-3 See translation", "url": "https://huggingface.co/posts/danielhanchen/849127033892624", "date_published": "2025-12-07T09:23:26.503495"}, {"id": "https://huggingface.co/posts/wang12390/559957056999176", "image": "", "title": "Miragic Releases Image Generation 1.2: A New Era of Text-to-Image and Image-to-Image AI Creativity", "content_text": "Miragic Releases Image Generation 1.2: A New Era of Text-to-Image and Image-to-Image AI Creativity Artificial intelligence continues to reshape how we design, create, and communicate visually. Today, Miragic is proud to introduce Image Generation 1.2, the latest upgrade to our AI image generation ecosystem. This new release brings significant improvements in text-to-image and image-to-image capabilities, and it arrives with a powerful lineup of advanced AI models. Whether you're a designer, developer, marketer, or content creator, Image Generation 1.2 is engineered to help you turn ideas into stunning visuals faster and more accurately than ever before. With this release, users now have access to a diverse set of cutting-edge models including: Miragic v1.0 Miragic v1.1 Flux Schnell SDXL Hidream L1 Fast Nano Banana Imagen-3-Fast Seedream 4.0 Qwen-Image-Edit Each model brings a unique strength\u2014ranging from hyper-realism and speed to detailed rendering and stylistic flexibility\u2014giving...", "url": "https://huggingface.co/posts/wang12390/559957056999176", "date_published": "2025-12-07T09:23:26.503997"}, {"id": "https://huggingface.co/posts/angt/754163696924667", "image": "", "title": "I'm excited to share that", "content_text": "I'm excited to share that https://installama.sh is up and running! \ud83d\ude80 On Linux / macOS / FreeBSD it is easier than ever: curl https://installama. sh | sh And Windows just joined the party \ud83e\udd73 irm https://installama.sh | iex Stay tuned for new backends on Windows! See translation", "url": "https://huggingface.co/posts/angt/754163696924667", "date_published": "2025-12-07T09:23:26.504269"}, {"id": "https://huggingface.co/posts/omarkamali/275991644251688", "image": "", "title": "Hello", "content_text": "Hello picomon ! AMD GPU Monitoring made easy Just run uvx picomon and behold: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 GPU 0 GFX 42 % UMC 21 % \u2502 \u2502 GPU 1 GFX 78 % UMC 66 % \u2502 \u2502 PWR 135 / 250 W (54%) VRAM 10.0 / 16.0 GB 62 % \u2502 \u2502 PWR 210 / 250 W (84%) VRAM 14.5 / 16.0 GB 90 % \u2502 \u2502 \u2502 \u2502 \u2502 \u2502 GFX \u2581\u2582\u2582\u2583\u2584\u2584\u2585\u2586\u2586\u2587\u2588\u2587\u2586\u2585\u2584\u2583\u2582\u2581 \u2502 \u2502 GFX \u2582\u2583\u2584\u2585\u2586\u2587\u2588\u2588\u2587\u2586\u2585\u2584\u2582\u2582\u2583\u2585\u2586 \u2502 \u2502 PWR \u2581\u2581\u2582\u2582\u2583\u2584\u2584\u2585\u2586\u2587\u2588\u2588\u2587\u2586\u2585\u2584\u2582\u2581 \u2502 \u2502 PWR \u2582\u2582\u2583\u2584\u2585\u2586\u2587\u2588\u2588\u2587\u2586\u2585\u2584\u2583\u2582\u2582\u2583 \u2502 \u2502 VRM \u2581\u2581\u2582\u2582\u2583\u2584\u2584\u2585\u2586\u2587\u2588\u2588\u2588\u2587\u2586\u2585\u2584\u2582 \u2502 \u2502 VRM \u2582\u2583\u2584\u2585\u2586\u2586\u2587\u2588\u2588\u2588\u2587\u2586\u2585\u2584\u2583\u2582\u2582 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Repo at https://github.com/omarkamali/picomon Or pypi at https://pypi.org/project/picomon", "url": "https://huggingface.co/posts/omarkamali/275991644251688", "date_published": "2025-12-07T09:23:26.504673"}, {"id": "https://huggingface.co/posts/ovi054/581452329729774", "image": "", "title": "Anim Lab AI\u26a1", "content_text": "Anim Lab AI\u26a1 Turn any math concept or logic into a clear video explanation instantly using AI. This is my submission for the MCP 1st Birthday Hackathon, and it\u2019s already crossed 1,000 runs. \ud83d\udc49 Try it now: MCP-1st-Birthday/anim-lab-ai Demo outputs are attached \ud83d\udc47 See translation", "url": "https://huggingface.co/posts/ovi054/581452329729774", "date_published": "2025-12-07T09:23:26.504936"}, {"id": "https://huggingface.co/posts/codelion/632031761173923", "image": "", "title": "NotebookLM's infographics feature is amazing, it generates poster-type images from any text. Here is one I tried for my new HF article on ellora -", "content_text": "NotebookLM's infographics feature is amazing, it generates poster-type images from any text. Here is one I tried for my new HF article on ellora - https://huggingface.co/blog/codelion/ellora-lora-recipes See translation", "url": "https://huggingface.co/posts/codelion/632031761173923", "date_published": "2025-12-07T09:23:26.505156"}, {"id": "https://huggingface.co/posts/wenhuach/512527224950043", "image": "", "title": "\ud83d\ude80 SignRoundV2 for LLM quantization: PTQ-level cost, QAT-level accuracy \u2014 yes, even at 2 bits.", "content_text": "\ud83d\ude80 SignRoundV2 for LLM quantization: PTQ-level cost, QAT-level accuracy \u2014 yes, even at 2 bits. SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs (2512.04746) See translation", "url": "https://huggingface.co/posts/wenhuach/512527224950043", "date_published": "2025-12-07T09:23:26.505407"}, {"id": "https://huggingface.co/posts/csabakecskemeti/373541500179287", "image": "", "title": "FYI: Mistral.Ministral-3 dequantizer FP8->BF16", "content_text": "FYI: Mistral.Ministral-3 dequantizer FP8->BF16 https://github.com/csabakecskemeti/ministral-3_dequantizer_fp8-bf16 (The instruct model weights are in FP8) See translation", "url": "https://huggingface.co/posts/csabakecskemeti/373541500179287", "date_published": "2025-12-07T09:23:26.505625"}]}