{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/nroggendorff/580094805938772", "image": "", "title": "Since when are H200s on ZeroGPU?", "content_text": "Since when are H200s on ZeroGPU? See translation", "url": "https://huggingface.co/posts/nroggendorff/580094805938772", "date_published": "2025-07-12T09:24:10.924361"}, {"id": "https://huggingface.co/posts/mlabonne/882001725108546", "image": "", "title": "LiquidAI", "content_text": "LiquidAI open-sources a new generation of edge LLMs! \ud83e\udd73 Based on a new hybrid architecture, these 350M, 700M, and 1.2B models are both fast and performant, ideal for on-device deployment. I recommend fine-tuning them to power your next edge application. We already provide Colab notebooks to guide you. More to come soon! \ud83d\udcdd Blog post: https://www.liquid.ai/blog/liquid-foundation-models-v2-our-second-series-of-generative-ai-models \ud83e\udd17 Models: LiquidAI/lfm2-686d721927015b2ad73eaa38 See translation", "url": "https://huggingface.co/posts/mlabonne/882001725108546", "date_published": "2025-07-12T09:24:10.924710"}, {"id": "https://huggingface.co/posts/hba123/547491071894207", "image": "", "title": "I am happy to announce that Ark now supports the following robots:", "content_text": "I am happy to announce that Ark now supports the following robots: 1. Franka Panda 2. Kuka LWR 3. UFactory XArm 4. Husky Robot Everything is done in Python. You can even control your robot from a Jupiter notebook. Check out the tutorials: https://arkrobotics.notion.site/ARK-Home-22be053d9c6f8096bcdbefd6276aba61 Check out the code: https://github.com/orgs/Robotics-Ark/repositories Check out the documentation: https://robotics-ark.github.io/ark_robotics.github.io/docs/html/index.html Check out the paper: https://robotics-ark.github.io/ark_robotics.github.io/static/images/ark_framework_2025.pdf Hope you find it useful. Let us know if you want a specific feature! We would love to support you \ud83d\ude04 See translation", "url": "https://huggingface.co/posts/hba123/547491071894207", "date_published": "2025-07-12T09:24:10.925061"}, {"id": "https://huggingface.co/posts/kanaria007/210554569109150", "image": "", "title": "\u2705 New Article on Hugging Face: Teaching AI to Think Like a System \u2014 Not a Toolkit", "content_text": "\u2705 New Article on Hugging Face: Teaching AI to Think Like a System \u2014 Not a Toolkit Title: \ud83c\udfd7\ufe0f Understanding Structured Cognitive Architecture: A Unified Framework for AI Reasoning Systems \ud83d\udd17 Read it here: https://huggingface.co/blog/kanaria007/understanding-structured-cognitive-architecture Summary: After exploring how AI can select reasoning modes or learn from failure, this new article zooms out: *How do all these capabilities form a single mind, not just a menu of functions?* The **Structured Cognitive Architecture** defines a unified framework where protocols interact coherently \u2014 forming a self-organizing, reflective, and ethically grounded reasoning system. This architecture enables agents to: \u2022 Integrate memory, ethics, reasoning, and identity across layers \u2022 Select and execute reasoning jumps with traceable structure \u2022 Coordinate failure recovery and adaptive learning \u2022 Maintain cross-session identity and self-editing capability It\u2019s not modular stacking. It\u2019s **structured...", "url": "https://huggingface.co/posts/kanaria007/210554569109150", "date_published": "2025-07-12T09:24:10.925680"}, {"id": "https://huggingface.co/posts/AdinaY/423045666935241", "image": "", "title": "Kimi-K2 is now available on the hub\ud83d\udd25\ud83d\ude80", "content_text": "Kimi-K2 is now available on the hub\ud83d\udd25\ud83d\ude80 This is a trillion-parameter MoE model focused on long context, code, reasoning, and agentic behavior. moonshotai/kimi-k2-6871243b990f2af5ba60617d \u2728 Base & Instruct \u2728 1T total / 32B active - Modified MIT License \u2728 128K context length \u2728 Muon optimizer for stable trillion-scale training See translation", "url": "https://huggingface.co/posts/AdinaY/423045666935241", "date_published": "2025-07-12T09:24:10.925962"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/753734380960763", "image": "", "title": "MultiTalk (from MeiGen) Full Tutorial With 1-Click Installer - Make Talking and Singing Videos From Static Images - Moreover shows how to setup and use on RunPod and Massed Compute private cheap cloud services as well", "content_text": "MultiTalk (from MeiGen) Full Tutorial With 1-Click Installer - Make Talking and Singing Videos From Static Images - Moreover shows how to setup and use on RunPod and Massed Compute private cheap cloud services as well Tutorial video link > https://youtu.be/8cMIwS9qo4M Video Chapters 0:00 Intro & MultiTalk Showcase 0:28 Singing Animation Showcase 0:57 Tutorial Structure Overview (Windows, Massed Compute, RunPod) 1:10 Windows - Step 1: Download & Extract the Main ZIP File 1:43 Windows - Prerequisites (Python, Git, CUDA, FFmpeg) 2:12 Windows - How to Perform a Fresh Installation (Deleting venv & custom_nodes) 2:42 Windows - Step 2: Running the Main ComfyUI Installer Script 4:24 Windows - Step 3: Installing MultiTalk Nodes & Dependencies 5:05 Windows - Step 4: Downloading Models with the Unified Downloader 6:18 Windows - Tip: Setting Custom Model Paths in ComfyUI 7:18 Windows - Step 5: Updating ComfyUI to the Latest Version 7:39 Windows - Step 6: Launching ComfyUI 7:53 Workflow Usage -...", "url": "https://huggingface.co/posts/MonsterMMORPG/753734380960763", "date_published": "2025-07-12T09:24:10.926465"}, {"id": "https://huggingface.co/posts/sergiopaniego/321784447889589", "image": "", "title": "Test SmolLM3, the newest fully open model released by", "content_text": "Test SmolLM3, the newest fully open model released by @ HuggingFaceTB ! It's smol (3B), multilingual (6 languages), comes with dual mode reasoning (think/no_think modes) and supports long-context (128k). Try it now in the notebook below!! \u2b07\ufe0f Colab notebook: https://colab.research.google.com/github/sergiopaniego/samples/blob/main/smollm3_3b_inference.ipynb notebook: https://github.com/sergiopaniego/samples/blob/main/smollm3_3b_inference.ipynb blog: https://huggingface.co/blog/smollm3 See translation", "url": "https://huggingface.co/posts/sergiopaniego/321784447889589", "date_published": "2025-07-12T09:24:10.926775"}, {"id": "https://huggingface.co/posts/3LC/827651059369427", "image": "", "title": "\ud83d\ude80 Announcing the Synthetic-to-Real Multi-Class Object Detection Challenge!", "content_text": "\ud83d\ude80 Announcing the Synthetic-to-Real Multi-Class Object Detection Challenge! We\u2019re excited to announce the launch of the Synthetic-to-Real Multi-Class Object Detection Challenge\u2014now live on Kaggle! This exciting competition is brought to you by 3LC in partnership with Duality AI, creators of the powerful FalconCloud tool for generating targeted synthetic data. Together, we're offering a unique opportunity to push the boundaries of object detection through high-fidelity, simulation-to-real workflows. \ud83e\uddea What Makes This Challenge Special? \ud83d\udcbb Create customized training data with Duality\u2019s cloud-based scenario \ud83e\udde0 Analyze data weaknesses and take precise, data-driven actions using 3LC's robust tooling \u2699\ufe0f Optimize data for peak model training \ud83c\udfc6 Why Join? \u2022 Win cash prizes, certificates, and global recognition \u2022 Gain exposure to real-world simulation workflows used in top AI companies \u2022 Collaborate and compete with leading minds in computer vision, ML, and AI Whether you're a student,...", "url": "https://huggingface.co/posts/3LC/827651059369427", "date_published": "2025-07-12T09:24:10.927250"}, {"id": "https://huggingface.co/posts/CultriX/969512018114620", "image": "", "title": "New Space: Generate Knowledge Graphs from input data using LLM's (OpenRouter). It's a trial project but seems to be working alright so far!", "content_text": "New Space: Generate Knowledge Graphs from input data using LLM's (OpenRouter). It's a trial project but seems to be working alright so far! CultriX/Generate-Knowledge-Graphs Below is an example after feeding it the wikipedia page about Elon Musk: See translation", "url": "https://huggingface.co/posts/CultriX/969512018114620", "date_published": "2025-07-12T09:24:10.927468"}, {"id": "https://huggingface.co/posts/jbilcke-hf/967618646971244", "image": "", "title": "Are you looking to run a robot simulator, maybe run long robot policy training tasks, but you don't have the GPU at home?", "content_text": "Are you looking to run a robot simulator, maybe run long robot policy training tasks, but you don't have the GPU at home? Well.. you can run MuJoCo inside a Hugging Face space! All you have to do is to clone this space: jbilcke-hf/train-robots-with-mujoco Don't forget to a pick a Nvidia GPU for your space, to be able to get some nice OpenGL renders! Are you new to MuJoCo and/or JupyterLab notebooks? You can get started with this tutorial (select \"Open from URL\" then paste the URL to this notebook): jbilcke-hf/train-robots-with-mujoco Happy robot hacking! \ud83e\uddbe See translation", "url": "https://huggingface.co/posts/jbilcke-hf/967618646971244", "date_published": "2025-07-12T09:24:10.927803"}]}