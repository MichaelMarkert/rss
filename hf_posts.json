{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/burtenshaw/724732252831042", "image": "", "title": "new smol course", "content_text": "new smol course If you\u2019re building with or learning about post training AI models right now, we have a new FREE and CERTIFIED course. \ud83d\udd17 Follow the org to join in smol-course The course builds on smol course v1 which was the fastest way to learn to train your custom AI models. It now has: - A leaderboard for students to submit models to - Certification based on exams and leaderboards - Prizes based on Leaderboards - Up to date content on TRL and SmolLM3 - Deep integration with the Hub\u2019s compute for model training and evaluation We will release chapters every few weeks, so you can follow the org to stay updated. See translation", "url": "https://huggingface.co/posts/burtenshaw/724732252831042", "date_published": "2025-09-10T17:18:42.811796"}, {"id": "https://huggingface.co/posts/tomaarsen/906557413568289", "image": "", "title": "ModernBERT goes MULTILINGUAL! One of the most requested models I've seen, The Johns Hopkins University's CLSP has trained state-of-the-art massively multilingual encoders using the ModernBERT architecture: mmBERT.", "content_text": "ModernBERT goes MULTILINGUAL! One of the most requested models I've seen, The Johns Hopkins University's CLSP has trained state-of-the-art massively multilingual encoders using the ModernBERT architecture: mmBERT. Model details: - 2 model sizes: - jhu-clsp/mmBERT-small - jhu-clsp/mmBERT-base - Uses the ModernBERT architecture, but with the Gemma2 multilingual tokenizer (so: flash attention, alternating global/local attention, unpadding/sequence packing, etc.) - Maximum sequence length of 8192 tokens, on the high end for encoders - Trained on 1833 languages using DCLM, FineWeb2, and many more sources - 3 training phases: 2.3T tokens pretraining on 60 languages, 600B tokens mid-training on 110 languages, and 100B tokens decay training on all 1833 languages. - Both models are MIT Licensed, and the full datasets and intermediary checkpoints are also publicly released Evaluation details: - Very competitive with ModernBERT at equivalent sizes on English (GLUE, MTEB v2 English after...", "url": "https://huggingface.co/posts/tomaarsen/906557413568289", "date_published": "2025-09-10T17:18:42.812302"}, {"id": "https://huggingface.co/posts/Reubencf/961832649483016", "image": "", "title": "Introducing the Nano Banana Node Editor! \ud83c\udf4c", "content_text": "Introducing the Nano Banana Node Editor! \ud83c\udf4c Now you can control and manipulate Nano Banana images with a powerful, intuitive node-based system. Explore the creative possibilities at: Reubencf/Nano_Banana_Editor This version is clearer, more inviting, and emphasizes the creative potential of your tool. See translation", "url": "https://huggingface.co/posts/Reubencf/961832649483016", "date_published": "2025-09-10T17:18:42.812558"}, {"id": "https://huggingface.co/posts/andywu-kby/346535541829962", "image": "", "title": "Hello everyone", "content_text": "Hello everyone Good day! We have launched the product - Virtual Try On \ud83d\ude80 Say goodbye to the uncertainty of online shopping with Miragic\u2019s Virtual Try-On solution! Our cutting-edge AI technology lets you try on clothes virtually, offering a seamless and interactive shopping experience. Whether you're exploring new outfits or simply trying before you buy, Miragic gives you a realistic view of how items will look on you\u2014without ever stepping into a store. Miragic-AI/Miragic-Virtual-Try-On \ud83c\udf1f Key Features: - Realistic 3D Try-On: See how clothes fit and look on your virtual self in real-time. - Personalized Fit: Using advanced body-scanning tech, Miragic adjusts the fit based on your unique measurements. - Wide Fashion Selection: Browse through various brands and styles, all available for a virtual try-on. - Sustainable Shopping: Reduce the need for returns and make more eco-friendly choices with a virtual experience that helps you shop smarter. \ud83d\udc5a Why Virtual Try-On? - Save time and money...", "url": "https://huggingface.co/posts/andywu-kby/346535541829962", "date_published": "2025-09-10T17:18:42.813056"}, {"id": "https://huggingface.co/posts/Kseniase/304021452230579", "image": "", "title": "10 Latest Preference Optimization Techniques", "content_text": "10 Latest Preference Optimization Techniques Models need feedback on what makes outputs \u201cgood\u201d or \u201cbad.\u201d Policy optimization (PO) turns preferences and rewards into actual training signals. This field is evolving quickly, moving far beyond classics like PPO and GRPO. So here is our overview of 10 newest PO methods: 1. Pref-GRPO \u2192 Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning (2508.20751) Stabilizes text-to-image reinforcement learning (RL) with pairwise preference rewards and a unified UNIGENBENCH benchmark 2. PVPO (Policy with Value Preference Optimization) \u2192 PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning (2508.21104) This critic-free RL method uses a pre-trained model as a reference anchor to reduce bias and guide learning, selecting high-value examples through data pre-sampling 3. DCPO (Dynamic Clipping Policy Optimization) \u2192 DCPO: Dynamic Clipping Policy Optimization (2509.02333) Uses dynamic clipping,...", "url": "https://huggingface.co/posts/Kseniase/304021452230579", "date_published": "2025-09-10T17:18:42.813671"}, {"id": "https://huggingface.co/posts/prithivMLmods/195813965636174", "image": "", "title": "Build something cool with Nano Banana aka Gemini 2.5 Flash Image AIO [All-in-One]. Draw and transform on canvas, edit images, and generate images\u2014all in one place!\ud83c\udf4c", "content_text": "Build something cool with Nano Banana aka Gemini 2.5 Flash Image AIO [All-in-One]. Draw and transform on canvas, edit images, and generate images\u2014all in one place!\ud83c\udf4c \u2726\ufe0e Constructed with the Gemini API (GCP). Try it here: https://nano-banana-aio-op72ohwdda-uw.a.run.app/ \u26a0\ufe0f Note: The server\u2019s health status is currently stable, but this may change at any time. If you experience network issues, please refresh the current app tab or trigger the discussion below. See translation", "url": "https://huggingface.co/posts/prithivMLmods/195813965636174", "date_published": "2025-09-10T17:18:42.813985"}, {"id": "https://huggingface.co/posts/merve/916342597592275", "image": "", "title": "upgrade your transformers \ud83d\udd25", "content_text": "upgrade your transformers \ud83d\udd25 it comes with insanely capable models like merve/sam2-66ac9deac6fca3bc5482fe30 , microsoft/kosmos-2.5 , and more \ud83e\udee1 I built a notebook you can run with free Colab T4 to walk through the API for new models \ud83d\ude4b\ud83c\udffb\u200d\u2640\ufe0f merve/smol-vision fine-tuning will follow-up soon! See translation", "url": "https://huggingface.co/posts/merve/916342597592275", "date_published": "2025-09-10T17:18:42.814239"}, {"id": "https://huggingface.co/posts/salma-remyx/619394412045148", "image": "", "title": "Science is the vibe-killer", "content_text": "Science is the vibe-killer Some critique on the state of the technology Presenting an alternative vision for scaling the scientific method in AI engineering https://remyxai.substack.com/p/vibes-dont-scale See translation", "url": "https://huggingface.co/posts/salma-remyx/619394412045148", "date_published": "2025-09-10T17:18:42.814452"}, {"id": "https://huggingface.co/posts/hesamation/792197182072762", "image": "", "title": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns.", "content_text": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns. the table of contents looks like everything you need to know about agents + code: > advanced prompt techniques > multi-agent patterns > tool use and MCP > you name it read it here: https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0#heading=h.pxcur8v2qagu you can also pre-order on Amazon (published by Springer) and the royalties goes to Save the Children: https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/ See translation", "url": "https://huggingface.co/posts/hesamation/792197182072762", "date_published": "2025-09-10T17:18:42.814735"}, {"id": "https://huggingface.co/posts/burtenshaw/833511511767176", "image": "", "title": "Smol course has a distinctive approach to teaching post-training, so I'm posting about how it\u2019s different to other post-training courses, including the llm course that\u2019s already available.", "content_text": "Smol course has a distinctive approach to teaching post-training, so I'm posting about how it\u2019s different to other post-training courses, including the llm course that\u2019s already available. In short, the smol course is just more direct that any of the other course, and intended for semi-pro post trainers. - It\u2019s a minimal set of instructions on the core parts. - It\u2019s intended to bootstrap real projects you're working on. - The material handsover to existing documentation for details - Likewise, it handsover to the LLM course for basics. - Assessment is based on a leaderboard, without reading all the material. To start the smol course, follow here: smol-course See translation", "url": "https://huggingface.co/posts/burtenshaw/833511511767176", "date_published": "2025-09-10T17:18:42.815078"}]}