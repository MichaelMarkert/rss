{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/807578740801859", "image": "", "title": "\ud83c\udfef Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! \u2728", "content_text": "\ud83c\udfef Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! \u2728 Hello AI enthusiasts! \ud83d\ude4b\u200d\u2640\ufe0f Today I'm introducing a truly magical project: Open Ghibli Studio \ud83c\udfa8 ginigen/FLUX-Open-Ghibli-Studio \ud83c\udf1f What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! \ud83c\udfde\ufe0f\u2728 \ud83d\udd27 How Does It Work? \ud83d\udcf8 Upload your photo \ud83e\udd16 Florence-2 AI analyzes the image and generates a description \u270f\ufe0f \"Ghibli style\" is added to the description \ud83c\udfad Magic transformation happens using the FLUX.1 model and Ghibli LoRA! \u2699\ufe0f Customization Options Want more control? Adjust these in the advanced settings: \ud83c\udfb2 Set a seed (for reproducible results) \ud83d\udccf Adjust image dimensions \ud83d\udd0d Guidance scale (prompt adherence) \ud83d\udd04 Number of generation steps \ud83d\udcab Ghibli style intensity \ud83d\ude80 Try It Now! Click the \"Transform to Ghibli Style\" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? \ud83c\udf08 \ud83c\udf3f Note: For best results,...", "url": "https://huggingface.co/posts/ginipick/807578740801859", "date_published": "2025-04-03T09:24:07.834308"}, {"id": "https://huggingface.co/posts/openfree/925352420925810", "image": "", "title": "\ud83d\udd25 'Open Meme Studio': Your Creative Meme Factory \ud83c\udfad\u2728", "content_text": "\ud83d\udd25 'Open Meme Studio': Your Creative Meme Factory \ud83c\udfad\u2728 Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. \ud83d\ude80 VIDraft/Open-Meme-Studio \ud83c\udfaf Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! \ud83d\udee0\ufe0f Features You'll Love \ud83d\udcf8 Transform and reinterpret existing meme templates \ud83c\udfad Freely change expressions and poses \ud83d\udc53 Add props (sunglasses, hats, etc.) \ud83c\udfde\ufe0f Change backgrounds and composite characters \ud83c\udfa8 Apply various artistic styles \ud83d\udcaa Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...", "url": "https://huggingface.co/posts/openfree/925352420925810", "date_published": "2025-04-03T09:24:07.834980"}, {"id": "https://huggingface.co/posts/seawolf2357/883323339740165", "image": "", "title": "\ud83c\udfa8 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition \ud83c\udf0f\u2728", "content_text": "\ud83c\udfa8 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition \ud83c\udf0f\u2728 Hello creators! Today I'm introducing a special image generator that combines the beautiful aesthetics of Studio Ghibli with multilingual text integration! \ud83d\ude0d seawolf2357/Ghibli-Multilingual-Text-rendering \u2728 Key Features Ghibli-Style Image Generation - High-quality animation-style images based on FLUX.1 Multilingual Text Rendering - Support for Korean, Japanese, English, and all languages! \ud83c\uddf0\ud83c\uddf7\ud83c\uddef\ud83c\uddf5\ud83c\uddec\ud83c\udde7 Automatic Image Editing with Simple Prompts - Just input your desired text and you're done! Two Stylistic Variations Provided - Get two different results from a single prompt Full Hugging Face Spaces Support - Deploy and share instantly! \ud83d\ude80 How Does It Work? Enter a prompt describing your desired image (e.g., \"a cat sitting by the window\") Input the text you want to add (any language works!) Select the text position, size, and color Two different versions are automatically generated! \ud83d\udcaf...", "url": "https://huggingface.co/posts/seawolf2357/883323339740165", "date_published": "2025-04-03T09:24:07.835618"}, {"id": "https://huggingface.co/posts/clem/267300235555885", "image": "", "title": "Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possible\u2014just look at the \u201cT\u201d in ChatGPT, which comes from the Transformer architecture openly shared by Google.", "content_text": "Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possible\u2014just look at the \u201cT\u201d in ChatGPT, which comes from the Transformer architecture openly shared by Google. Then came the myth that AI was too dangerous to share, and companies started optimizing for short-term revenue. That led many major AI labs and researchers to stop sharing and collaborating. With OAI and sama now saying they're willing to share open weights again, we have a real chance to return to a golden age of AI progress and democratization\u2014powered by openness and collaboration, in the US and around the world. This is incredibly exciting. Let\u2019s go, open science and open-source AI! See translation", "url": "https://huggingface.co/posts/clem/267300235555885", "date_published": "2025-04-03T09:24:07.835975"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/493599242742163", "image": "", "title": "Curious how Duality AI crafts synthetic data that can bridge the sim2real gap?", "content_text": "Curious how Duality AI crafts synthetic data that can bridge the sim2real gap? We just published an article here on HuggingFace outlining our process, with bonus dataset releases! Read it here: https://huggingface.co/blog/DualityAI-RebekahBogdanoff/training-yolov8-with-synthetic-data-from-falcon See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/493599242742163", "date_published": "2025-04-03T09:24:07.836204"}, {"id": "https://huggingface.co/posts/ZhiyuanthePony/617713430689574", "image": "", "title": "\ud83c\udf89 Thrilled to share our #CVPR2025 accepted work:", "content_text": "\ud83c\udf89 Thrilled to share our #CVPR2025 accepted work: Progressive Rendering Distillation: Adapting Stable Diffusion for Instant Text-to-Mesh Generation without 3D Data (2503.21694) \ud83d\udd25 \u200bKey Innovations: 1\ufe0f\u20e3 First to adapt SD for \u200bdirect textured mesh generation (1-2s inference) 2\ufe0f\u20e3 Novel teacher-student framework leveraging multi-view diffusion models ([MVDream]( https://arxiv.org/abs/2308.16512 ) & [RichDreamer]( https://arxiv.org/abs/2311.16918) ) 3\ufe0f\u20e3 \u200bParameter-efficient tuning - \u200bonly +2.6% params over base SD 4\ufe0f\u20e3 \u200b3D data-free training liberates model from dataset constraints \ud83d\udca1 Why matters? \u2192 A novel \u200b3D-Data-Free paradigm \u2192 Outperforms data-driven methods on creative concept generation \u2192 Unlocks web-scale text corpus for 3D content creation \ud83c\udf10 Project: https://theericma.github.io/TriplaneTurbo/ \ud83c\udfae Demo: ZhiyuanthePony/TriplaneTurbo \ud83d\udcbb Code: https://github.com/theEricMa/TriplaneTurbo See translation", "url": "https://huggingface.co/posts/ZhiyuanthePony/617713430689574", "date_published": "2025-04-03T09:24:07.836585"}, {"id": "https://huggingface.co/posts/Reality123b/155118307932581", "image": "", "title": "ok, there must be a problem. HF charged me 0.12$ for 3 inference requests to text models", "content_text": "ok, there must be a problem. HF charged me 0.12$ for 3 inference requests to text models See translation", "url": "https://huggingface.co/posts/Reality123b/155118307932581", "date_published": "2025-04-03T09:24:07.836797"}, {"id": "https://huggingface.co/posts/hesamation/178289696524550", "image": "", "title": "What, How, Where, and How Well? This paper reviews test-time scaling methods and all you need to know about them:", "content_text": "What, How, Where, and How Well? This paper reviews test-time scaling methods and all you need to know about them: > parallel, sequential, hybrid, internal scaling > how to scale (SFT, RL, search, verification) > metrics and evals of test-time scaling \ud83d\udd17paper: What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models (2503.24235) If you want to learn what inference-time compute scaling is @ rasbt has a great blog post on that: https://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling See translation", "url": "https://huggingface.co/posts/hesamation/178289696524550", "date_published": "2025-04-03T09:24:07.837108"}, {"id": "https://huggingface.co/posts/zamal/271014113300033", "image": "", "title": "DeepGit: Your GitHub Gold Digger! \ud83d\udcb0\ud83d\ude80", "content_text": "DeepGit: Your GitHub Gold Digger! \ud83d\udcb0\ud83d\ude80 Hey Hugging Face gang! Meet DeepGit\u2014my open-source sidekick that rips through GitHub to snag repos that fit you. Done with dead-end searches? Me too. Built it with LangGraph and some dope tricks: Embeddings grab the good stuff (HF magic, baby!) Re-ranking nails the best picks Snoops docs, code, and buzz in one slick flow Drops a clean list of hidden gems \ud83d\udc8e Unearth that sneaky ML lib or Python gem\u2014run python app.py or langgraph dev and boom! Peek it at https://github.com/zamalali/DeepGit . Fork it, tweak it, love it\u2014Docker\u2019s in, HF vibes are strong. Drop a \ud83c\udf1f or a crazy idea\u2014I\u2019m pumped to jam with you all! \ud83e\ude82 See translation", "url": "https://huggingface.co/posts/zamal/271014113300033", "date_published": "2025-04-03T09:24:07.837444"}, {"id": "https://huggingface.co/posts/danielhanchen/465464088880734", "image": "", "title": "You can now run DeepSeek-V3-0324 on your own local device!", "content_text": "You can now run DeepSeek-V3-0324 on your own local device! Run our Dynamic 2.42 and 2.71-bit DeepSeek GGUFs: unsloth/DeepSeek-V3-0324-GGUF You can run them on llama.cpp and other inference engines. See our guide here: https://docs.unsloth.ai/basics/tutorial-how-to-run-deepseek-v3-0324-locally See translation", "url": "https://huggingface.co/posts/danielhanchen/465464088880734", "date_published": "2025-04-03T09:24:07.837692"}]}