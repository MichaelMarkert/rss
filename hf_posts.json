{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/etemiz/710778843328598", "image": "", "title": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.", "content_text": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really \"free\": they are costing you your freedom if you know what i mean. See translation", "url": "https://huggingface.co/posts/etemiz/710778843328598", "date_published": "2025-08-17T09:23:33.824650"}, {"id": "https://huggingface.co/posts/fdaudens/770107969696647", "image": "", "title": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:", "content_text": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines & specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup \u2014 just open-weight GPT-OSS models via Hugging Face If you\u2019ve been wanting to try agents but weren\u2019t sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation", "url": "https://huggingface.co/posts/fdaudens/770107969696647", "date_published": "2025-08-17T09:23:33.825006"}, {"id": "https://huggingface.co/posts/ovi054/657358125503535", "image": "", "title": "Image-to-Prompt\u26a1", "content_text": "Image-to-Prompt\u26a1 ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 \ud83d\udc49 Try it now: ovi054/image-to-prompt See translation", "url": "https://huggingface.co/posts/ovi054/657358125503535", "date_published": "2025-08-17T09:23:33.825271"}, {"id": "https://huggingface.co/posts/anakin87/751707976654130", "image": "", "title": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac", "content_text": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac I made a simple Space to do that: anakin87/gemma-3-270m-it \u26a1 Fast: Flash Attention, Zero GPU \u2699\ufe0f Configurable See translation", "url": "https://huggingface.co/posts/anakin87/751707976654130", "date_published": "2025-08-17T09:23:33.825493"}, {"id": "https://huggingface.co/posts/prithivMLmods/284574267701705", "image": "", "title": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea", "content_text": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea \ud83e\udd17 Space: prithivMLmods/Tiny-VLMs-Lab \u2726\ufe0e Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. \u2726\ufe0e Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 \u2726\ufe0e GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or the...", "url": "https://huggingface.co/posts/prithivMLmods/284574267701705", "date_published": "2025-08-17T09:23:33.825908"}, {"id": "https://huggingface.co/posts/appvoid/589674942896129", "image": "", "title": "suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source?", "content_text": "suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source? keep in mind everybody will have access to it: scientists, governments, terrorists, average people, etc... See translation", "url": "https://huggingface.co/posts/appvoid/589674942896129", "date_published": "2025-08-17T09:23:33.826142"}, {"id": "https://huggingface.co/posts/asigalov61/289707289100732", "image": "", "title": "\ud83d\udd25Check out new SOTA Orpheus Auto-Continuations Generator\ud83d\udd25", "content_text": "\ud83d\udd25Check out new SOTA Orpheus Auto-Continuations Generator\ud83d\udd25 asigalov61/Orpheus-Music-Transformer Now you can generate good music with Orpheus without supervision!!! @ Timzoid @ John6666 @ alvanalrakib See translation", "url": "https://huggingface.co/posts/asigalov61/289707289100732", "date_published": "2025-08-17T09:23:33.826370"}, {"id": "https://huggingface.co/posts/openfree/904316268987326", "image": "", "title": "\ud83e\uddec DNA Diffusion Suite: AI-Powered Revolution in Life Science Research", "content_text": "\ud83e\uddec DNA Diffusion Suite: AI-Powered Revolution in Life Science Research \ud83d\ude80 Transformative Innovation Through AI Technology DNA Diffusion Suite is a next-generation platform that leverages cutting-edge Diffusion models to generate biologically meaningful DNA sequences. By reducing sequence design time from weeks to mere seconds, we're revolutionizing research productivity and accelerating scientific discovery. VIDraft/DNA-Diffusion \ud83d\udca1 Real-World Benefits of AI Technology \ud83c\udfaf Research Acceleration Instant Hypothesis Testing: Pre-validate experimental designs with AI-generated sequence variants Cost Reduction: Test hundreds of sequences virtually before expensive synthesis Time Efficiency: 1000x faster sequence generation compared to manual design \ud83e\udde0 Intelligent Sequence Optimization Cell-Type Specific Learning: AI trained on real ChIP-seq data from K562, GM12878, and HepG2 cells Context-Aware Generation: Fine-tune biological context with precision Guidance Scale control Automated Pattern...", "url": "https://huggingface.co/posts/openfree/904316268987326", "date_published": "2025-08-17T09:23:33.826973"}, {"id": "https://huggingface.co/posts/ginipick/955296677233221", "image": "", "title": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728", "content_text": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728 \ud83c\udf8a Free Trial for Hugging Face Launch! Hurry! \u23f0 Hello! Introducing an innovative AI service that helps you choose the perfect hairstyle without any regrets before visiting the salon! \ud83c\udfaf Try It Now ginigen/Hair-Pick \ud83d\udd04 What Makes HairPick Special? 360\u00b0 Complete Preview! Other hair simulators only show the front view? \ud83d\ude11 HairPick is different! \u2705 Front + 4 random angles = Total 5 multi-angle images generated \u2705 Perfect check from side profile \ud83d\udc64 diagonal \ud83d\udcd0 back view \ud83d\udc65! \u2705 100+ trendy hairstyle library \ud83d\udc87\u200d\u2640\ufe0f \ud83d\udca1 Highly Recommended For: \ud83c\udfaf \"I really don't want to fail this time!\" \u2192 Check side volume and back lines thoroughly \ud83c\udfaf \"It's hard to explain exactly to my stylist\" \u2192 Perfect communication with 360\u00b0 result images! \ud83c\udfaf \"I have a profile photo/photoshoot coming up\" \u2192 Preview your best look from every angle \ud83d\ude80 Super Simple Usage (Just 1 Minute!) 1\ufe0f\u20e3 One Selfie \ud83d\udcf8 Take a front-facing photo in bright light (show your forehead and face...", "url": "https://huggingface.co/posts/ginipick/955296677233221", "date_published": "2025-08-17T09:23:33.827614"}, {"id": "https://huggingface.co/posts/Nymbo/410324855187602", "image": "", "title": "Anyone using Jan-v1-4B for local MCP-based web search, I highly recommend you try out", "content_text": "Anyone using Jan-v1-4B for local MCP-based web search, I highly recommend you try out Intelligent-Internet/II-Search-4B Very impressed with this lil guy and it deserves more downloads. It's based on the original version of Qwen3-4B but find that it questions reality way less often. Jan-v1 seems to think that everything it sees is synthetic data and constantly gaslights me See translation", "url": "https://huggingface.co/posts/Nymbo/410324855187602", "date_published": "2025-08-17T09:23:33.827856"}]}