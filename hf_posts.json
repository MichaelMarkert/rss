{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mike-ravkine/324105560308241", "image": "", "title": "Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13:", "content_text": "Let's talk about one of the hidden gems in the ReasonScape evaluation results, lucky #13: aquif-ai/aquif-3.5-8B-Think Built on top of the solid Qwen3-8B foundation, aquif-3.5-8B-Think successfully preserves the high performance of the original model while consuming 30-50% less reasoning tokens. The most notable regression vs the base model here is in arithmetic - if your workload is math heavy this model demonstrates an unfortunate collapse with performance under growing complexity. The interesting combination of awesome overall performance on SVG simple shapes identification coupled with a total inability to recognize more complex shapes like 'House' or 'Arrow' is a behavior directly inherited from the base model (but with a ~20% improvement in token utilization). If you like your reasoning models token-efficient, Aquif-3.5-8B-Think is well worth a spin. Higher resolution, more detailed, interactive plots are available at the m12X explorer: https://reasonscape.com/m12x/explorer/...", "url": "https://huggingface.co/posts/mike-ravkine/324105560308241", "date_published": "2025-10-17T13:31:09.213172"}, {"id": "https://huggingface.co/posts/abdurrahmanbutler/994710514786612", "image": "", "title": "\ud83c\udf89 I am excited to share news of a project my brother, Umar Butler, and I have been working on for what feels like an eternity now.", "content_text": "\ud83c\udf89 I am excited to share news of a project my brother, Umar Butler, and I have been working on for what feels like an eternity now. \ud835\udc08\ud835\udc27\ud835\udc2d\ud835\udc2b\ud835\udc28\ud835\udc1d\ud835\udc2e\ud835\udc1c\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0c\ud835\udc0b\ud835\udc04\ud835\udc01 \u2014 \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc0c\ud835\udc1a\ud835\udc2c\ud835\udc2c\ud835\udc22\ud835\udc2f\ud835\udc1e \ud835\udc0b\ud835\udc1e\ud835\udc20\ud835\udc1a\ud835\udc25 \ud835\udc04\ud835\udc26\ud835\udc1b\ud835\udc1e\ud835\udc1d\ud835\udc1d\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc01\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc21\ud835\udc26\ud835\udc1a\ud835\udc2b\ud835\udc24. A suite of 10 high-quality English legal IR datasets, designed by legal experts to set a new standard for comparing embedding models. Whether you\u2019re exploring legal RAG on your home computer, or running enterprise-scale retrieval, apples-to-apples evaluation is crucial. That\u2019s why we\u2019ve open-sourced everything - including our 7 brand-new, hand-crafted retrieval datasets. All of these datasets are now live on Hugging Face. Any guesses which embedding model leads on legal retrieval? \ud835\udc07\ud835\udc22\ud835\udc27\ud835\udc2d: it\u2019s not OpenAI or Google - they place 7th and 9th on our leaderboard. To do well on MLEB, embedding models must demonstrate both extensive legal domain knowledge and strong legal reasoning skills. https://huggingface.co/blog/isaacus/introducing-mleb See translation", "url": "https://huggingface.co/posts/abdurrahmanbutler/994710514786612", "date_published": "2025-10-17T13:31:09.243115"}, {"id": "https://huggingface.co/posts/adlumal/955872232459431", "image": "", "title": "MLEB  is the largest, most diverse, and most comprehensive benchmark for legal text embedding models.", "content_text": "MLEB is the largest, most diverse, and most comprehensive benchmark for legal text embedding models. https://huggingface.co/blog/isaacus/introducing-mleb See translation", "url": "https://huggingface.co/posts/adlumal/955872232459431", "date_published": "2025-10-17T13:31:09.243378"}, {"id": "https://huggingface.co/posts/wenhuach/917073841450527", "image": "", "title": "AutoRound keeps evolving its LLM quantization algorithm! \ud83d\ude80", "content_text": "AutoRound keeps evolving its LLM quantization algorithm! \ud83d\ude80 After enhancing W2A16 quantization, we now offer a fast algorithm to generate mixed bits/data-type schemes (~2mins for 8B models), great for MXFP4 and W2A16. Learn more: https://github.com/intel/auto-round/blob/main/docs/step_by_step.md#autoscheme See translation", "url": "https://huggingface.co/posts/wenhuach/917073841450527", "date_published": "2025-10-17T13:31:09.243641"}, {"id": "https://huggingface.co/posts/ZennyKenny/876142925777221", "image": "", "title": "Did Hugging Face just ban hammer a bunch of bot accounts or am I just so uninteresting that 30% of my subs dropped me overnight?", "content_text": "Did Hugging Face just ban hammer a bunch of bot accounts or am I just so uninteresting that 30% of my subs dropped me overnight? \ud83d\ude2c Wait, don't answer that. See translation", "url": "https://huggingface.co/posts/ZennyKenny/876142925777221", "date_published": "2025-10-17T13:31:09.243873"}, {"id": "https://huggingface.co/posts/sergiopaniego/524517454338742", "image": "", "title": "@Qwen", "content_text": "@ Qwen released their new small and dense VLMs (Qwen3-VL). They're incredibly capable and one of my all-time favourite VLMs. \ud83e\udd17 We\u2019ve prepared some resources to help you get started. > Fine-tune Qwen3-VL-4B with SFT or GRPO (free Colab notebooks): > SFT: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/sft_qwen_vl.ipynb > GRPO: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_qwen3_vl.ipynb > Compare object detection vs. Moondream3: sergiopaniego/vlm_object_understanding > Fine-tune from the CLI using TRL: https://github.com/kashif/Qwen3-VL/blob/trl-sft/qwen-vl-finetune/README.md#trl-based-training-single-gpu See translation", "url": "https://huggingface.co/posts/sergiopaniego/524517454338742", "date_published": "2025-10-17T13:31:09.244217"}, {"id": "https://huggingface.co/posts/prithivMLmods/967861422994938", "image": "", "title": "Now you can try all the latest state-of-the-art multimodal vision-language models from the Qwen3-VL series demo on Hugging Face Spaces \u2014 including 4B, 8B, and 30B (Instruct, 4B-Thinking) variants. I\u2019ve also uploaded the weights for the Abliterated variants of these models, up to 30B parameters. Check out the Spaces and model links below! \ud83e\udd17\ud83d\udd25", "content_text": "Now you can try all the latest state-of-the-art multimodal vision-language models from the Qwen3-VL series demo on Hugging Face Spaces \u2014 including 4B, 8B, and 30B (Instruct, 4B-Thinking) variants. I\u2019ve also uploaded the weights for the Abliterated variants of these models, up to 30B parameters. Check out the Spaces and model links below! \ud83e\udd17\ud83d\udd25 \u2728 Qwen3-VL[4B,8B]: prithivMLmods/Qwen3-VL-Outpost \u2728 Qwen3-VL-30B-A3B-Demo: prithivMLmods/Qwen3-VL-HF-Demo \u2728 Collection: prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 Qwen3-VL Abliterated Model Collection [ Version 1.0 ] \u2728 Qwen3-VL-8B-Instruct-abliterated: prithivMLmods/Qwen3-VL-8B-Instruct-abliterated \u2728 Qwen3-VL-4B-Instruct-abliterated: prithivMLmods/Qwen3-VL-4B-Instruct-abliterated \u2728 Qwen3-VL-8B-Thinking-abliterated: prithivMLmods/Qwen3-VL-8B-Thinking-abliterated \u2728 Qwen3-VL-4B-Thinking-abliterated: prithivMLmods/Qwen3-VL-4B-Thinking-abliterated \u2728 Qwen3-VL-30B-A3B-Instruct-abliterated: prithivMLmods/Qwen3-VL-30B-A3B-Instruct-...", "url": "https://huggingface.co/posts/prithivMLmods/967861422994938", "date_published": "2025-10-17T13:31:09.244698"}, {"id": "https://huggingface.co/posts/nick007x/296214873413452", "image": "", "title": "\ud83d\udc4b Hey i have Just uploaded 2 new datasets for code and scientific reasoning models:", "content_text": "\ud83d\udc4b Hey i have Just uploaded 2 new datasets for code and scientific reasoning models: 1. ArXiv Papers (4.6TB) A massive scientific corpus with papers and metadata across all domains.Perfect for training models on academic reasoning, literature review, and scientific knowledge mining. \ud83d\udd17Link: nick007x/arxiv-papers 2. GitHub Code 2025 (1 TB)a comprehensive code dataset for code generation and analysis tasks. mostly contains GitHub's high quality top 1 million repos above 2 stars \ud83d\udd17Link: nick007x/github-code-2025 See translation", "url": "https://huggingface.co/posts/nick007x/296214873413452", "date_published": "2025-10-17T13:31:09.245035"}, {"id": "https://huggingface.co/posts/TravisMuhlestein/661240541677725", "image": "", "title": "Building AI Agents from First Principles at GoDaddy", "content_text": "Building AI Agents from First Principles at GoDaddy Everyone\u2019s talking about AI agents lately, and for good reason. But at GoDaddy, we\u2019re going deeper: starting from first principles to explore what makes an agent truly robust and usable in real-world scenarios. Instead of asking \u201cWhat can we build fast?\u201d we\u2019re asking \u201cWhat design choices make agents flexible, testable, and reliable long term?\u201d Core Concepts \u2022 Tool-centric design: everything an agent does is a tool call, with precise APIs and granularity. \u2022 Decision vs. delivery: agents decide what to do; tools handle how to do it\u2014keeping systems modular. \u2022 Structured outputs & reflection: LLMs output both the tool call and the reason behind it, making debugging and iteration easier. \u2022 Universal tools: even user interactions (inform, confirm, request) are abstracted as tools, clarifying boundaries between logic and interface. Real-world use cases \u2192 Not just theory \u2705Routing and responding to support messages \u2705Surfacing emerging...", "url": "https://huggingface.co/posts/TravisMuhlestein/661240541677725", "date_published": "2025-10-17T13:31:09.245621"}, {"id": "https://huggingface.co/posts/ronantakizawa/301388923540512", "image": "", "title": "Released an AWQ quantized version of BosonAI\u2019s Higgs-Llama-3-70B model! \ud83c\udf89", "content_text": "Released an AWQ quantized version of BosonAI\u2019s Higgs-Llama-3-70B model! \ud83c\udf89 The Higgs-Llama-3-70B is an LLM specialized in role-playing, useful for game characters. Using an NVIDIA B200 GPU, I was able to compress the huge 140GB model into 37GB while keeping minimal perplexity \ud83d\udc4d ronantakizawa/higgs-llama-3-70b-awq See translation", "url": "https://huggingface.co/posts/ronantakizawa/301388923540512", "date_published": "2025-10-17T13:31:09.245897"}]}