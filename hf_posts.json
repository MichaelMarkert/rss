{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/prithivMLmods/284574267701705", "image": "", "title": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea", "content_text": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea \ud83e\udd17 Space/App: prithivMLmods/Tiny-VLMs-Lab \u2726\ufe0e Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. \u2726\ufe0e Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 \u2726\ufe0e GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or...", "url": "https://huggingface.co/posts/prithivMLmods/284574267701705", "date_published": "2025-08-18T13:38:57.810860"}, {"id": "https://huggingface.co/posts/etemiz/710778843328598", "image": "", "title": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.", "content_text": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really \"free\": they are costing you your freedom if you know what i mean. See translation", "url": "https://huggingface.co/posts/etemiz/710778843328598", "date_published": "2025-08-18T13:38:57.811102"}, {"id": "https://huggingface.co/posts/ovi054/657358125503535", "image": "", "title": "Image-to-Prompt\u26a1", "content_text": "Image-to-Prompt\u26a1 ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 \ud83d\udc49 Try it now: ovi054/image-to-prompt See translation", "url": "https://huggingface.co/posts/ovi054/657358125503535", "date_published": "2025-08-18T13:38:57.811367"}, {"id": "https://huggingface.co/posts/anakin87/751707976654130", "image": "", "title": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac", "content_text": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac I made a simple Space to do that: anakin87/gemma-3-270m-it \u26a1 Fast: Flash Attention, Zero GPU \u2699\ufe0f Configurable See translation", "url": "https://huggingface.co/posts/anakin87/751707976654130", "date_published": "2025-08-18T13:38:57.811586"}, {"id": "https://huggingface.co/posts/RakshitAralimatti/207934490136479", "image": "", "title": "When you ask ChatGPT, Claude, or Gemini a really tough question,", "content_text": "When you ask ChatGPT, Claude, or Gemini a really tough question, you might notice that little \"thinking...\" moment before it answers. But what does it actually mean when an LLM is \u201cthinking\u201d? Imagine a chess player pausing before their next move not because they don\u2019t know how to play, but because they\u2019re running through possibilities, weighing options, and choosing the best one. LLMs do something similar\u2026 except they\u2019re not really thinking like us. Here\u2019s the surprising part :- You might think these reasoning skills come from futuristic architectures or alien neural networks. In reality, most reasoning LLMs still use the same transformer decoder-only architecture as other models The real magic? It\u2019s in how they\u2019re trained and what data they learn from. Can AI actually think, or is it just insanely good at faking it? I broke it down in a simple, 4-minute Medium read. Bet you\u2019ll walk away with at least one \u201caha!\u201d moment. \ud83d\ude80 Read here - https://lnkd.in/edZ8Ceyg See translation", "url": "https://huggingface.co/posts/RakshitAralimatti/207934490136479", "date_published": "2025-08-18T13:38:57.812018"}, {"id": "https://huggingface.co/posts/etemiz/891816438009932", "image": "", "title": "benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :(", "content_text": "benchmarked 9 models in 3 days. they were mostly below average in AHA score. p(doom) probably increased :( See translation", "url": "https://huggingface.co/posts/etemiz/891816438009932", "date_published": "2025-08-18T13:38:57.812218"}, {"id": "https://huggingface.co/posts/appvoid/589674942896129", "image": "", "title": "suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source?", "content_text": "suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source? keep in mind everybody will have access to it: scientists, governments, terrorists, average people, etc... See translation", "url": "https://huggingface.co/posts/appvoid/589674942896129", "date_published": "2025-08-18T13:38:57.812433"}, {"id": "https://huggingface.co/posts/kanaria007/576453037371058", "image": "", "title": "\u2705 New Article: *Memory as Structured Time*", "content_text": "\u2705 New Article: *Memory as Structured Time* Title: \ud83e\udde0 History: Memory Loops as Civilization Structure \ud83d\udd17 https://huggingface.co/blog/kanaria007/memory-loops-as-civilization-structure --- Summary: Memory is often treated as *storage and retrieval*. Structured Intelligence reframes it as *time\u2011shaping architecture*: * *Loops that preserve context and continuity* * *Rollback paths that enable reflection and correction* * *Patterns that turn experience into adaptive structure* > Memory isn\u2019t static \u2014 > *it\u2019s how intelligence edits time.* --- Why It Matters: \u2022 Reveals *how memory enables learning, identity, and adaptation* \u2022 Supports *AI that can reflect, revise, and self\u2011align* \u2022 Connects *personal cognition and collective history* as structural processes --- What\u2019s Inside: \u2022 Memory as *recursive structural loop* \u2022 *Failure and recovery* as part of adaptive recall \u2022 How *history and record\u2011keeping mirror cognitive memory* \u2022 Implications for *resilient AI and social knowledge systems* --- \ud83d\udcd6...", "url": "https://huggingface.co/posts/kanaria007/576453037371058", "date_published": "2025-08-18T13:38:57.812997"}, {"id": "https://huggingface.co/posts/ginipick/955296677233221", "image": "", "title": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728", "content_text": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728 \ud83c\udf8a Free Trial for Hugging Face Launch! Hurry! \u23f0 Hello! Introducing an innovative AI service that helps you choose the perfect hairstyle without any regrets before visiting the salon! \ud83c\udfaf Try It Now ginigen/Hair-Pick \ud83d\udd04 What Makes HairPick Special? 360\u00b0 Complete Preview! Other hair simulators only show the front view? \ud83d\ude11 HairPick is different! \u2705 Front + 4 random angles = Total 5 multi-angle images generated \u2705 Perfect check from side profile \ud83d\udc64 diagonal \ud83d\udcd0 back view \ud83d\udc65! \u2705 100+ trendy hairstyle library \ud83d\udc87\u200d\u2640\ufe0f \ud83d\udca1 Highly Recommended For: \ud83c\udfaf \"I really don't want to fail this time!\" \u2192 Check side volume and back lines thoroughly \ud83c\udfaf \"It's hard to explain exactly to my stylist\" \u2192 Perfect communication with 360\u00b0 result images! \ud83c\udfaf \"I have a profile photo/photoshoot coming up\" \u2192 Preview your best look from every angle \ud83d\ude80 Super Simple Usage (Just 1 Minute!) 1\ufe0f\u20e3 One Selfie \ud83d\udcf8 Take a front-facing photo in bright light (show your forehead and face...", "url": "https://huggingface.co/posts/ginipick/955296677233221", "date_published": "2025-08-18T13:38:57.813641"}, {"id": "https://huggingface.co/posts/asigalov61/289707289100732", "image": "", "title": "\ud83d\udd25Check out new SOTA Orpheus Auto-Continuations Generator\ud83d\udd25", "content_text": "\ud83d\udd25Check out new SOTA Orpheus Auto-Continuations Generator\ud83d\udd25 asigalov61/Orpheus-Music-Transformer Now you can generate good music with Orpheus without supervision!!! @ Timzoid @ John6666 @ alvanalrakib See translation", "url": "https://huggingface.co/posts/asigalov61/289707289100732", "date_published": "2025-08-18T13:38:57.813884"}]}