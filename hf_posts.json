{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/766230066345476", "image": "", "title": "# \ud83c\udf1f 3D Model to Video: Easy GLB Conversion Tool \ud83c\udf1f", "content_text": "# \ud83c\udf1f 3D Model to Video: Easy GLB Conversion Tool \ud83c\udf1f demo link: ginigen/3D-VIDEO Hello there! Would you like to transform your 3D models into stunning animations? This space can help you! \u2728 ## \ud83d\udd0d What Can It Do? This tool converts your uploaded GLB model into: 1. \ud83c\udfae A transformed GLB file 2. \ud83c\udfac An animated GIF preview 3. \ud83d\udccb A metadata JSON file ## \u2705 Key Features * \ud83d\udda5\ufe0f Works in headless server environments (EGL + pyglet-headless \u2192 pyrender fallback) * \ud83d\udd0d Objects in GIFs appear 3x larger (global scale \u00d73) * \ud83c\udfa8 Clean interface with pastel background ## \ud83c\udfae Animation Types * \ud83d\udd04 Rotate - Object rotates around the Y-axis * \u2b06\ufe0f Float - Object moves smoothly up and down * \ud83d\udca5 Explode - Object moves sideways * \ud83e\udde9 Assemble - Object returns to its original position * \ud83d\udc93 Pulse - Object changes in size * \ud83d\udd04 Swing - Object swings around the Z-axis ## \ud83d\udee0\ufe0f How to Use 1. Upload your GLB model \ud83d\udce4 2. Select your desired animation type \ud83c\udfac 3. Adjust the duration and FPS \u23f1\ufe0f 4. Click the \"Generate Animation\" button \u25b6\ufe0f 5....", "url": "https://huggingface.co/posts/ginipick/766230066345476", "date_published": "2025-05-12T17:20:09.042666"}, {"id": "https://huggingface.co/posts/blaise-tk/108431169603656", "image": "", "title": "Today we launch Dione.", "content_text": "Today we launch Dione. A few months ago it was just a wild idea I shared with @ bygimenez , now it's real. Dione (Beta) is here, the easiest way to discover and install open-source apps, especially AI ones. Think of it as the Steam of open source. Installing open-source tools is often a mess. Dione fixes that. Beautiful UI and workflow. Soon multi-platform, multilingual & fully open-source. Users can even write and share their own installation scripts. This is just the beginning. \ud83d\ude80 Join our exclusive Beta \u2192 https://getdione.app/beta/join See translation", "url": "https://huggingface.co/posts/blaise-tk/108431169603656", "date_published": "2025-05-12T17:20:09.043028"}, {"id": "https://huggingface.co/posts/Kseniase/849940009274643", "image": "", "title": "11 Alignment and Optimization Algorithms for LLMs", "content_text": "11 Alignment and Optimization Algorithms for LLMs When we need to align models' behavior with the desired objectives, we rely on specialized algorithms that support helpfulness, accuracy, reasoning, safety, and alignment with user preferences. Much of a model\u2019s usefulness comes from post-training optimization methods. Here are the main optimization algorithms (both classic and new) in one place: 1. PPO (Proximal Policy Optimization) -> Proximal Policy Optimization Algorithms (1707.06347) Clips the probability ratio to prevent the new policy from diverging too far from the old one. It helps keep everything stable 2. DPO (Direct Preference Optimization) -> Direct Preference Optimization: Your Language Model is Secretly a Reward Model (2305.18290) It's a non RL method, where an LM is an implicit reward model. It uses a simple loss to boost the preferred answer\u2019s probability over the less preferred one 3. GRPO (Group Relative Policy Optimization) -> DeepSeekMath: Pushing the Limits of...", "url": "https://huggingface.co/posts/Kseniase/849940009274643", "date_published": "2025-05-12T17:20:09.043697"}, {"id": "https://huggingface.co/posts/ProCreations/529551865318111", "image": "", "title": "What do you think of Intellite\u2019s new icons/logo? Let us know!", "content_text": "What do you think of Intellite\u2019s new icons/logo? Let us know! Also Intellite chat technically does work! But we decided to scale it up a bit (same parameter count at 100m, but we went from trained on 4b tokens to 200b tokens, big upgrade!) for max quality. See translation", "url": "https://huggingface.co/posts/ProCreations/529551865318111", "date_published": "2025-05-12T17:20:09.043961"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/718201459901945", "image": "", "title": "TRELLIS is still the lead Open Source AI model to generate high-quality 3D Assets from static images \u2014 Some mind blowing examples \u2014 Supports multi-angle improved image to 3D as well \u2014 Works as low as 6 GB GPUs", "content_text": "TRELLIS is still the lead Open Source AI model to generate high-quality 3D Assets from static images \u2014 Some mind blowing examples \u2014 Supports multi-angle improved image to 3D as well \u2014 Works as low as 6 GB GPUs Tutorial link : https://www.youtube.com/watch?v=EhU7Jil9WAk App Link : https://www.patreon.com/posts/Trellis-App-Installer-Zip-File-117470976 Our app is super advanced with so many features and supports as low as 6 GB GPUs Also fully supports RTX 5000 GPUs as well TRELLIS is currently the state of the art locally run-able open source image-to-3D very high quality asset generator. I have developed a 1-click installers and super advanced Gradio app for this model with so many amazing features. In this tutorial video I will show you how to step by step use this amazing AI tool and generate the very best very high-quality 3D assets locally. Moreover, you can also use this tool on RunPod and Massed Compute as well if you are GPU poor. \ud83d\udd17Follow below link to download the zip file...", "url": "https://huggingface.co/posts/MonsterMMORPG/718201459901945", "date_published": "2025-05-12T17:20:09.044544"}, {"id": "https://huggingface.co/posts/m-ric/347153743407715", "image": "", "title": "I've made an open version of Google's NotebookLM, and it shows the superiority of the open source tech task! \ud83d\udcaa", "content_text": "I've made an open version of Google's NotebookLM, and it shows the superiority of the open source tech task! \ud83d\udcaa The app's workflow is simple. Given a source PDF or URL, it extracts the content from it, then tasks Meta's Llama 3.3-70B with writing the podcast script, with a good prompt crafted by @ gabrielchua (\"two hosts, with lively discussion, fun notes, insightful question etc.\") Then it hands off the text-to-speech conversion to Kokoro-82M, and there you go, you have two hosts discussion any article. The generation is nearly instant, because: > Llama 3.3 70B is running at 1,000 tokens/seconds with Cerebras inference > The audio is generated in streaming mode by the tiny (yet powerful) Kokoro, generating voices faster than real-time. And the audio generation runs for free on Zero GPUs, hosted by HF on H200s. Overall, open source solutions rival the quality of closed-source solutions at close to no cost! Try it here \ud83d\udc49\ud83d\udc49 m-ric/open-notebooklm See translation", "url": "https://huggingface.co/posts/m-ric/347153743407715", "date_published": "2025-05-12T17:20:09.044977"}, {"id": "https://huggingface.co/posts/as-cle-bert/400981312479742", "image": "", "title": "Let's pipe some \ud835\uddf1\ud835\uddee\ud835\ude01\ud835\uddee \ud835\uddf3\ud835\uddff\ud835\uddfc\ud835\uddfa \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude04\ud835\uddf2\ud835\uddef into our vector database, shall we?\ud83e\udd20", "content_text": "Let's pipe some \ud835\uddf1\ud835\uddee\ud835\ude01\ud835\uddee \ud835\uddf3\ud835\uddff\ud835\uddfc\ud835\uddfa \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude04\ud835\uddf2\ud835\uddef into our vector database, shall we?\ud83e\udd20 With \ud835\udc22\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d-\ud835\udc1a\ud835\udc27\ud835\udc32\ud835\udc2d\ud835\udc21\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2f\ud835\udfcf.\ud835\udfd1.\ud835\udfce ( https://github.com/AstraBert/ingest-anything ) you can now scrape content simply starting from URLs, extract the text from it, chunk it and put it into your favorite LlamaIndex-compatible database!\ud83d\udd78\ufe0f You can do it thanks to \ud835\uddf0\ud835\uddff\ud835\uddee\ud835\ude04\ud835\uddf9\ud835\uddf2\ud835\uddf2 by Apify, an open-source crawling library for python and javascript that handles all the data flow from the web: ingest-anything then combines it with \ud835\uddd5\ud835\uddf2\ud835\uddee\ud835\ude02\ud835\ude01\ud835\uddf6\ud835\uddf3\ud835\ude02\ud835\uddf9\ud835\udde6\ud835\uddfc\ud835\ude02\ud835\uddfd, \ud835\udde3\ud835\uddf1\ud835\uddf3\ud835\udddc\ud835\ude01\ud835\uddd7\ud835\uddfc\ud835\ude04\ud835\uddfb and \ud835\udde3\ud835\ude06\ud835\udde0\ud835\ude02\ud835\udde3\ud835\uddf1\ud835\uddf3 to scrape HTML files, convert them to PDF and extract the text - hassle-free!\ud83d\ude38 Check the attached code snippet if you're curious of knowing how to get started\ud83c\udfac PS: Don't tell anybody, but this release also has another gem... It supports OpenAI models for agentic chunking, following the new releases of Chonkie\ud83e\udd9b\u2728 If you don't want to miss out on the new features, leave us a little star on GitHub \u27a1\ufe0f https://github.com/AstraBert/ingest-anything And join our discord community!...", "url": "https://huggingface.co/posts/as-cle-bert/400981312479742", "date_published": "2025-05-12T17:20:09.045414"}, {"id": "https://huggingface.co/posts/Jaward/144425660093937", "image": "", "title": "finally, a course that makes diffusion math much easier to grasp, well done \ud83d\udc4d", "content_text": "finally, a course that makes diffusion math much easier to grasp, well done \ud83d\udc4d https://diffusion.csail.mit.edu/ See translation", "url": "https://huggingface.co/posts/Jaward/144425660093937", "date_published": "2025-05-12T17:20:09.045622"}, {"id": "https://huggingface.co/posts/VirtualOasis/965866013655862", "image": "", "title": "Automatic Multi-Modal Research Agent", "content_text": "Automatic Multi-Modal Research Agent I am thinking of building an Automatic Research Agent that can boost creativity! Input: Topics or data sources Processing: Automated deep research Output: multimodal results (such as reports, videos, audio, diagrams) & multi-platform publishing. There is a three-stage process In the initial Stage, output for text-based content in markdown format allows for user review before transformation into various other formats, such as PDF or HTML. The second stage transforms the output into other modalities, like audio, video, diagrams, and translations into different languages. The final stage focuses on publishing multi-modal content across multiple platforms like X, GitHub, Hugging Face, YouTube, and podcasts, etc. See translation", "url": "https://huggingface.co/posts/VirtualOasis/965866013655862", "date_published": "2025-05-12T17:20:09.045942"}, {"id": "https://huggingface.co/posts/hesamation/756119536681094", "image": "", "title": "this book actually exists for free, \u201cthe little book of deep learning\u201d. best to refresh your mind about DL basics:", "content_text": "this book actually exists for free, \u201cthe little book of deep learning\u201d. best to refresh your mind about DL basics: > foundations of machine learning > how models train > common layers (dropout, pooling\u2026) > basic intro to LLMs actually optimized for mobile. Book: https://fleuret.org/public/lbdl.pdf See translation", "url": "https://huggingface.co/posts/hesamation/756119536681094", "date_published": "2025-05-12T17:20:09.046202"}]}