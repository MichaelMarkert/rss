{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/MonsterMMORPG/210519935872315", "image": "", "title": "Wan 2.2 Complete Training Tutorial - Text to Image, Text to Video, Image to Video, Windows & Cloud :", "content_text": "Wan 2.2 Complete Training Tutorial - Text to Image, Text to Video, Image to Video, Windows & Cloud : https://youtu.be/ocEkhAsPOs4 Wan 2.2 training is now so easy. I have done over 64 different unique Wan 2.2 trainings to prepare the very best working training configurations for you. The configurations are fully working locally with as low as 6 GB GPUs. So you will be able to train your awesome Wan 2.2 image or video generation LoRAs on your Windows computer with easiness. Moreover, I have shown how to train on cloud platforms RunPod and Massed Compute so even if you have no GPU or you want faster training, you can train on cloud for very cheap prices fully privately. Full step by step tutorial : https://youtu.be/ocEkhAsPOs4 \u23f1\ufe0f Video Chapters: 0:00 Introduction to Wan 2.2 Training & Capabilities 0:56 Installing & Updating Musubi Tuner Locally 2:20 Explanation of Optimized Presets & Research Logic 4:00 Differences Between T2I, T2V, and I2V Configs 5:36 Extracting Files & Running...", "url": "https://huggingface.co/posts/MonsterMMORPG/210519935872315", "date_published": "2025-12-24T09:29:05.055075"}, {"id": "https://huggingface.co/posts/sergiopaniego/741361727784035", "image": "", "title": "The Christmas holidays are here! \ud83c\udf84", "content_text": "The Christmas holidays are here! \ud83c\udf84 Thinking about learning something new in AI? @ huggingface offers 12 FREE courses covering all the relevant topics, for every level of experience. A great challenge for the holidays (and worth saving for later \ud83d\ude44) Let\u2019s explore them! \ud83e\udde0 \ud835\udddf\ud835\udddf\ud835\udde0 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: large language models with HF tools https://huggingface.co/learn/llm-course \ud83e\udd16 \ud835\uddd4\ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: build and deploy AI agents https://huggingface.co/learn/agents-course \ud83c\udfa8 \ud835\uddd7\ud835\uddf6\ud835\uddf3\ud835\uddf3\ud835\ude02\ud835\ude00\ud835\uddf6\ud835\uddfc\ud835\uddfb \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: diffusion models with \ud83e\udd17 Diffusers https://huggingface.co/learn/diffusion-course \ud83d\udd0a \ud835\uddd4\ud835\ude02\ud835\uddf1\ud835\uddf6\ud835\uddfc \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: transformers for audio tasks https://huggingface.co/learn/audio-course \ud83c\udfae \ud835\uddd7\ud835\uddf2\ud835\uddf2\ud835\uddfd \ud835\udde5\ud835\udddf \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: deep reinforcement learning https://huggingface.co/learn/deep-rl-course \ud83d\udc41\ufe0f \ud835\uddd6\ud835\uddfc\ud835\uddfa\ud835\uddfa\ud835\ude02\ud835\uddfb\ud835\uddf6\ud835\ude01\ud835\ude06 \ud835\uddd6\ud835\uddfc\ud835\uddfa\ud835\uddfd\ud835\ude02\ud835\ude01\ud835\uddf2\ud835\uddff \ud835\udde9\ud835\uddf6\ud835\ude00\ud835\uddf6\ud835\uddfc\ud835\uddfb \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: modern computer vision with HF https://huggingface.co/learn/computer-vision-course \ud83e\uddbe \ud835\udde5\ud835\uddfc\ud835\uddef\ud835\uddfc\ud835\ude01\ud835\uddf6\ud835\uddf0\ud835\ude00 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2 (\ud835\udddf\ud835\uddf2\ud835\udde5\ud835\uddfc\ud835\uddef\ud835\uddfc\ud835\ude01): learning-based robotics https://huggingface.co/learn/robotics-course \ud83e\udde9 \ud835\udde0\ud835\uddd6\ud835\udde3 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: Model Context Protocol explained...", "url": "https://huggingface.co/posts/sergiopaniego/741361727784035", "date_published": "2025-12-24T09:29:05.055628"}, {"id": "https://huggingface.co/posts/Jiaqi-hkust/177996283057314", "image": "", "title": "We have open-sourced Robust-R1 (AAAI 2026 Oral), a new paradigm in the field of anti-degradation and robustness enhancement for multimodal large models.", "content_text": "We have open-sourced Robust-R1 (AAAI 2026 Oral), a new paradigm in the field of anti-degradation and robustness enhancement for multimodal large models. Multimodal Large Language Models struggle to maintain reliable performance under extreme real-world visual degradations, which impede their practical robustness. Existing robust MLLMs predominantly rely on implicit training/adaptation that focuses solely on visual encoder generalization, suffering from limited interpretability and isolated optimization. To overcome these limitations, we propose Robust-R1, a novel framework that explicitly models visual degradations through structured reasoning chains. Our approach integrates: (i) supervised fine-tuning for degradation-aware reasoning foundations, (ii) reward-driven alignment for accurately perceiving degradation parameters, and (iii) dynamic reasoning depth scaling adapted to degradation intensity. To facilitate this approach, we introduce a specialized 11K dataset featuring...", "url": "https://huggingface.co/posts/Jiaqi-hkust/177996283057314", "date_published": "2025-12-24T09:29:05.056122"}, {"id": "https://huggingface.co/posts/dhruv3006/288574780413766", "image": "", "title": "Editor-Neutral, Tool-Neutral API Artifacts", "content_text": "Editor-Neutral, Tool-Neutral API Artifacts One thing we hear from developers : API docs and files often get stuck inside specific editors or tools. That friction slows teams down especially when people use different setups. At Voiden, we believe your API artifacts should work anywhere your team does. Our files open seamlessly in VS Code, GitHub, custom Electron clients, and more, without being locked into a specific workspace or tool. Key benefits: -Portability across editors, repos, platforms, and team setups -No proprietary workspace: the repo is the workspace -Easy integration with CI pipelines, linters, and future tools -Future-proof your API workflows with open and flexible artifacts Voiden empowers devs and teams collaborate and stay agile as tools and platforms evolve. Check out whats different about Voiden here: https://voiden.md/features See translation", "url": "https://huggingface.co/posts/dhruv3006/288574780413766", "date_published": "2025-12-24T09:29:05.056457"}, {"id": "https://huggingface.co/posts/telcom/422373414213997", "image": "", "title": "arXiv CS endorsement", "content_text": "arXiv CS endorsement It's Javad, my Google Scholar Profile: https://scholar.google.com/citations?user=bja6GwoAAAAJ&hl=en I would like to share my articles with you on Hugging Face, I'm asking for endorsement* in Computer Science arxiv.org. If you would like to endorse me, please visit the following URL: https://arxiv.org/auth/endorse?x=NVUAPL If that URL does not work for you, please visit http://arxiv.org/auth/endorse.php and enter the following six-digit alphanumeric string: Endorsement Code: NVUAPL Thanks you in advance. Javad Taghia * Who is qualified to endorse? To endorse another user to submit to the cs.AI (Artificial Intelligence) subject class, an arXiv submitter must have submitted 3 papers to any of cs.AI, cs.AR, cs.CC, cs.CE, cs.CG, cs.CL, cs.CR, cs.CV, cs.CY, cs.DB, cs.DC, cs.DL, cs.DM, cs.DS, cs.ET, cs.FL, cs.GL, cs.GR, cs.GT, cs.HC, cs.IR, cs.IT, cs.LG, cs.LO, cs.MA, cs.MM, cs.MS, cs.NA, cs.NE, cs.NI, cs.OH, cs.OS, cs.PF, cs.PL, cs.RO, cs.SC, cs.SD, cs.SE, cs.SI or...", "url": "https://huggingface.co/posts/telcom/422373414213997", "date_published": "2025-12-24T09:29:05.056824"}, {"id": "https://huggingface.co/posts/davidmezzetti/102092244732124", "image": "", "title": "\ud83e\uddec\u2695\ufe0f\ud83d\udd2c Encoding the World's Medical Knowledge into 970K! We're excited to release this new series of vector embeddings models for medical literature based on our recent BERT Hash work.", "content_text": "\ud83e\uddec\u2695\ufe0f\ud83d\udd2c Encoding the World's Medical Knowledge into 970K! We're excited to release this new series of vector embeddings models for medical literature based on our recent BERT Hash work. And you read it right, we're talking 970,000 parameters for a surprisingly strong performing model. Enjoy! https://huggingface.co/blog/neuml/biomedbert-hash-nano See translation", "url": "https://huggingface.co/posts/davidmezzetti/102092244732124", "date_published": "2025-12-24T09:29:05.057089"}, {"id": "https://huggingface.co/posts/Parveshiiii/283996096084237", "image": "", "title": "Hey everyone!", "content_text": "Hey everyone! We\u2019re excited to introduce our new Telegram group: https://t.me/XenArcAI This space is built for **model builders, tech enthusiasts, and developers** who want to learn, share, and grow together. Whether you\u2019re just starting out or already deep into AI/ML, you\u2019ll find a supportive community ready to help with knowledge, ideas, and collaboration. \ud83d\udca1 Join us to: - Connect with fellow developers and AI enthusiasts - Share your projects, insights, and questions - Learn from others and contribute to a growing knowledge base \ud83d\udc49 If you\u2019re interested, hop in and be part of the conversation: https://t.me/XenArcAI See translation", "url": "https://huggingface.co/posts/Parveshiiii/283996096084237", "date_published": "2025-12-24T09:29:05.057426"}, {"id": "https://huggingface.co/posts/MikeDoes/649372647638290", "image": "", "title": "How do you protect your prompts without breaking them? You need a smart sanitizer. A new system called Pr\u03f5\u03f5mpt shows how.", "content_text": "How do you protect your prompts without breaking them? You need a smart sanitizer. A new system called Pr\u03f5\u03f5mpt shows how. The first, critical step in their solution is a high-performance Named Entity Recognition (NER) model to find the sensitive data. We're proud to see that these researchers, Amrita Roy Chowdhury, David Glukhov, Divyam Anshumaan, Prasad Chalasani, Nicolas Papernot, Somesh Jha, and Mihir Bellare from the University of Michigan, University of Toronto, University of Wisconsin-Madison, University of California, San Diego - Rady School of Management and Langroid Incorporated fine-tuned their NER model on 10 high-risk categories from the AI4Privacy dataset. This is a perfect win-win. Our open-source data helps provide the foundation for the critical detection engine, which in turn enables the community to build and test better solutions like Pr\u03f5\u03f5mpt's innovative use of encryption and Differential Privacy. \ud83d\udd17 Check out their paper for a deep dive into a formally private,...", "url": "https://huggingface.co/posts/MikeDoes/649372647638290", "date_published": "2025-12-24T09:29:05.057963"}, {"id": "https://huggingface.co/posts/John1604/712509372180068", "image": "", "title": "\u6211\u5373\u5c06\u8fbe\u5230\u516c\u5171\u5b58\u50a8\u7a7a\u95f4\u4e0a\u9650\u3002\u6211\u53d1\u73b0\u6211\u7684\u4ed3\u5e93 John1604/Kimi-K2-Thinking-q6K-gguf \u6ca1\u6709\u83b7\u5f97\u8db3\u591f\u7684\u4e0b\u8f7d\u91cf\uff0c\u51e0\u4e4e\u5360\u7528\u4e86 1T \u5b58\u50a8\u7a7a\u95f4\u3002\u5c3d\u7ba1\u6211\u559c\u7231 Kimi K2 \u7684\u601d\u8003\u65b9\u5f0f\uff0c\u4f46\u53ef\u80fd\u4e0d\u5f97\u4e0d\u5220\u9664\u8fd9\u4e2a\u6a21\u578b\u3002\u56e0\u4e3a\u5b83\u662f\u4e00\u4e2a\u771f\u6b63\u7684\u5f00\u6e90 1T LLM\uff0c\u4e0e\u4efb\u4f55\u524d\u6cbf\u7684 LLM \u6a21\u578b\u76f8\u5ab2\u7f8e\u3002\u5728 AI \u7ade\u4e89\u4e2d\uff0c\u7f8e\u56fd\u6709\u56db\u5bb6\u516c\u53f8\u62e5\u67091T+\u6a21\u578b\uff1axAI,  OpenAI, \u8c37\u6b4c\u548cAnthropologie\u3002\u4e2d\u56fd\u4e5f\u6709\u56db\u5bb6\u516c\u53f8\u62e5\u67091T+\u6a21\u578b\uff1a\u963f\u91cc\u5df4\u5df4, Kimi, DeepSeek\u548cGLM\u3002\u76ee\u524d\u53cc\u65b9\u52bf\u5747\u529b\u654c\u3002", "content_text": "\u6211\u5373\u5c06\u8fbe\u5230\u516c\u5171\u5b58\u50a8\u7a7a\u95f4\u4e0a\u9650\u3002\u6211\u53d1\u73b0\u6211\u7684\u4ed3\u5e93 John1604/Kimi-K2-Thinking-q6K-gguf \u6ca1\u6709\u83b7\u5f97\u8db3\u591f\u7684\u4e0b\u8f7d\u91cf\uff0c\u51e0\u4e4e\u5360\u7528\u4e86 1T \u5b58\u50a8\u7a7a\u95f4\u3002\u5c3d\u7ba1\u6211\u559c\u7231 Kimi K2 \u7684\u601d\u8003\u65b9\u5f0f\uff0c\u4f46\u53ef\u80fd\u4e0d\u5f97\u4e0d\u5220\u9664\u8fd9\u4e2a\u6a21\u578b\u3002\u56e0\u4e3a\u5b83\u662f\u4e00\u4e2a\u771f\u6b63\u7684\u5f00\u6e90 1T LLM\uff0c\u4e0e\u4efb\u4f55\u524d\u6cbf\u7684 LLM \u6a21\u578b\u76f8\u5ab2\u7f8e\u3002\u5728 AI \u7ade\u4e89\u4e2d\uff0c\u7f8e\u56fd\u6709\u56db\u5bb6\u516c\u53f8\u62e5\u67091T+\u6a21\u578b\uff1axAI, OpenAI, \u8c37\u6b4c\u548cAnthropologie\u3002\u4e2d\u56fd\u4e5f\u6709\u56db\u5bb6\u516c\u53f8\u62e5\u67091T+\u6a21\u578b\uff1a\u963f\u91cc\u5df4\u5df4, Kimi, DeepSeek\u548cGLM\u3002\u76ee\u524d\u53cc\u65b9\u52bf\u5747\u529b\u654c\u3002 I'm about to reach my public storage limit. I've discovered that my repository John1604/Kimi-K2-Thinking-q6K-gguf isn't getting enough downloads and is nearly consuming 1TB of storage. While I love Kimi K2's way of thinking, I have to delete this model because it's a true open-source 1TB LLM, comparable to any cutting-edge LLM model. In the AI \u200b\u200brace, four US companies have 1TB+ models: xAI, OpenAI, Google, and Anthropic. China also has four companies with 1TB+ models: Alibaba, Kimi, DeepSeek, and GLM. Currently, the two sides are evenly matched. Only American team and Chinese team have LLM with 1T+ parameters. Let's cheer for them to reach AGI in next 5 to 10 years. Maybe a 64T chinese model will do it -- Human and cat brain...", "url": "https://huggingface.co/posts/John1604/712509372180068", "date_published": "2025-12-24T09:29:05.058409"}, {"id": "https://huggingface.co/posts/ronantakizawa/356197451153671", "image": "", "title": "Thank you", "content_text": "Thank you @ clem (Co-Founder & CEO of Hugging Face) for sharing my dataset on X / Twitter! ronantakizawa/github-top-developers #github #dataset See translation", "url": "https://huggingface.co/posts/ronantakizawa/356197451153671", "date_published": "2025-12-24T09:29:05.058617"}]}