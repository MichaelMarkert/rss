{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/hesamation/792197182072762", "image": "", "title": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns.", "content_text": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns. the table of contents looks like everything you need to know about agents + code: > advanced prompt techniques > multi-agent patterns > tool use and MCP > you name it read it here: https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0#heading=h.pxcur8v2qagu you can also pre-order on Amazon (published by Springer) and the royalties goes to Save the Children: https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/ See translation", "url": "https://huggingface.co/posts/hesamation/792197182072762", "date_published": "2025-09-07T13:23:10.677592"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/823785587931139", "image": "", "title": "Shout out to the winners of the \"Synthetic2Real Object Detection Challenge\" Duality AI hosted earlier this year. Out of the 1000+ participants in our challenges, these users stood out above the rest.", "content_text": "Shout out to the winners of the \"Synthetic2Real Object Detection Challenge\" Duality AI hosted earlier this year. Out of the 1000+ participants in our challenges, these users stood out above the rest. \ud83e\udd47 1st place: Kaggle user \"richardtroy\" \ud83e\udd48 2nd place: @ sergio-sanz-rodriguez \ud83e\udd49 3rd place: @ Nadiaaaaaaa View the entire leaderboard at - https://tinyurl.com/38ebvcwf Join our current Grocery Items: Multi-Class Object Detection Synthetic2Real Kaggle competition here: https://tinyurl.com/y224rttu And be on the lookout for anther competition in the next couple weeks with a brand new domain! hint: \u2708\ufe0f See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/823785587931139", "date_published": "2025-09-07T13:23:10.677978"}, {"id": "https://huggingface.co/posts/burtenshaw/554434209344305", "image": "", "title": "The open source AI community is just made of people who are passionate and care about their work. So we thought it would be cool to share our favourite icons of the community with a fun award.", "content_text": "The open source AI community is just made of people who are passionate and care about their work. So we thought it would be cool to share our favourite icons of the community with a fun award. Winners get free Hugging Face Pro Subscriptions, Merchandise, or compute credits for the hub. \ud83d\udd17 Follow and nominate here: community-spotlight This is a new initiative to recognise and celebrate the incredible work being done by community members. It's all about inspiring more collaboration and innovation in the world of machine learning and AI. They're highlighting contributors in four key areas: - model creators: building and sharing innovative and state-of-the-art models. - educators: sharing knowledge through posts, articles, demos, and events. - tool builders: creating the libraries, frameworks, and applications that we all use. - community champions: supporting and mentoring others in forums. Know someone who deserves recognition? Nominate them by opening a post in the Hugging Face...", "url": "https://huggingface.co/posts/burtenshaw/554434209344305", "date_published": "2025-09-07T13:23:10.678415"}, {"id": "https://huggingface.co/posts/prithivMLmods/508433106733374", "image": "", "title": "Dropped the HeadshotX : a super-realistic headshot adapter for", "content_text": "Dropped the HeadshotX : a super-realistic headshot adapter for Qwen/Qwen-Image , an image generation model by Qwen. It is an advanced LoRA adaptation of the Qwen-Image model and an upgraded version of prithivMLmods/Qwen-Image-Studio-Realism , offering more precise portrait rendering with a strong focus on realism. The model was trained on diverse face types from across the world, labeled with florence2-en and caption-optimized using prithivMLmods/DeepCaption-VLA-7B . 11(types) \u00d7 5 different face types: Asian, Hispanic, Caucasian, Latina, Middle Eastern, etc. \u2b9e Model\ud83e\udd17: prithivMLmods/Qwen-Image-HeadshotX \u2b9e The Previous Adapter (LoRA): prithivMLmods/Qwen-Image-Studio-Realism \u2b9e Collection: prithivMLmods/qwen-image-exp-lora-68a978fe11400bc3165b0c4d . . . To know more about it, visit the app page or the respective model page!! See translation", "url": "https://huggingface.co/posts/prithivMLmods/508433106733374", "date_published": "2025-09-07T13:23:10.678828"}, {"id": "https://huggingface.co/posts/prithivMLmods/101885688055842", "image": "", "title": "Comparing: DeepCaption-VLA-7B, built on Qwen2.5-VL-7B-Instruct, is tailored for image captioning and vision-language attribution, focusing on precise, descriptive captions of visual properties, object attributes, and scene details. In contrast, Qwen2.5-VL-7B-Abliterated-Caption-it is fine-tuned for abliterated captioning, generating highly detailed descriptions across diverse visual categories.", "content_text": "Comparing: DeepCaption-VLA-7B, built on Qwen2.5-VL-7B-Instruct, is tailored for image captioning and vision-language attribution, focusing on precise, descriptive captions of visual properties, object attributes, and scene details. In contrast, Qwen2.5-VL-7B-Abliterated-Caption-it is fine-tuned for abliterated captioning, generating highly detailed descriptions across diverse visual categories. Models\ud83e\udd17 \u2726 DeepCaption-VLA-7B : prithivMLmods/DeepCaption-VLA-7B \u2726 Qwen2.5-VL-7B-Abliterated-Caption-it : prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it Spaces\u26f5 \u279c VisionScope-R2 : prithivMLmods/VisionScope-R2 \u279c Qwen2.5-VL-Outpost : prithivMLmods/Qwen2.5-VL-Outpost Collection\ud83d\uddde\ufe0f DeepCaption attr. : prithivMLmods/deepcaption-attr-68b041172ebcb867e45c556a VL Abliterated-Caption : prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 Multimodal VLMs - Until July'25 : prithivMLmods/multimodal-vlms-until-july25-688312e6b840e1e156f13027 Multimodal VLMs - Aug'25 : prithivMLmods/multimodal-...", "url": "https://huggingface.co/posts/prithivMLmods/101885688055842", "date_published": "2025-09-07T13:23:10.679365"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/548344764221698", "image": "", "title": "Qwen Image LoRA trainings Stage 1 results and pre-made configs published - As low as training with 6 GB GPUs - Stage 2 research will hopefully improve quality even more - Images generated with 8-steps lightning LoRA + SECourses Musubi Tuner trained LoRA in 8 steps + 2x Latent Upscale", "content_text": "Qwen Image LoRA trainings Stage 1 results and pre-made configs published - As low as training with 6 GB GPUs - Stage 2 research will hopefully improve quality even more - Images generated with 8-steps lightning LoRA + SECourses Musubi Tuner trained LoRA in 8 steps + 2x Latent Upscale 1-click to install SECourses Musubi Tuner app and pre-made training configs shared here : https://www.patreon.com/posts/137551634 Hopefully a full video tutorial will be made after Stage 2 R&D trainings completed Example training made on the hardest training which is training a person and it works really good. Therefore, it shall work even much better on style training, item training, product training, character training and such Stage 1 took more than 35 unique R&D Qwen LoRA training 1-Click installer currently fully supporting Windows, RunPod (Linux & Cloud) and Massed Compute (Linux & recommend Cloud) training for literally every GPU like RTX 3000, 4000, 5000 series or H100, B200, L40, etc 28 images...", "url": "https://huggingface.co/posts/MonsterMMORPG/548344764221698", "date_published": "2025-09-07T13:23:10.679889"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/213039111279918", "image": "", "title": "SUPIR is Still Unchallanged Image Upscaler \u2014 Supports GPUs starting from RTX 1000 series to RTX 5000 series", "content_text": "SUPIR is Still Unchallanged Image Upscaler \u2014 Supports GPUs starting from RTX 1000 series to RTX 5000 series App Download Link You can download SUPIR app from here : https://www.patreon.com/posts/99176057 CHECK BELOW SCREENSHOTS It has 1-click installers for Windows (only Python 3.10.11 and Git should be sufficient), RunPod (official Pytorch 2.2.0 template) and Massed Compute template Creator > SECourses App Info SUPIR: Scaling Up to Excellence: Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild 1 click installer scripts. SUPIR Sampler and Text CFG Comparison : https://imgsli.com/MjU2ODQz/2/1 Gemini 2.5 Pro prompt to get image description for free : describe this image for sdxl. write single line prompt to regenerate it exactly same. make the prompt extremely detailed https://aistudio.google.com/prompts/new_chat Use Default preset for highest loyalty and Replicate preset for adding more details Human upscale from 1024x1024 to 3072x3072 (3x upscale and total 9x...", "url": "https://huggingface.co/posts/MonsterMMORPG/213039111279918", "date_published": "2025-09-07T13:23:10.680507"}, {"id": "https://huggingface.co/posts/dhruv3006/362032292361583", "image": "", "title": "Cua: Best State-of-the-Art Computer-Use Agent", "content_text": "Cua: Best State-of-the-Art Computer-Use Agent Build a SOTA Computer-Use Agent using Cua ( https://github.com/trycua/cua ), the open-source infrastructure and agent framework for controlling real desktop and browser environments. Submissions are evaluated in HUD\u2019s OSWorld-Verified benchmarking environment. The top-scoring team earns a secured interview with a Y Combinator partner for the next batch. Prizes: Guaranteed YC partner interview Feature on the Cua blog + social channels Swag pack for each team member Eligibility: To be considered for judging and prizes, sign up at https://www.trycua.com/hackathon See translation", "url": "https://huggingface.co/posts/dhruv3006/362032292361583", "date_published": "2025-09-07T13:23:10.680874"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/728023706250605", "image": "", "title": "GenTube: Make Stunning AI Art in 2 seconds - New Free Image Generation Platform Review & Tutorial", "content_text": "GenTube: Make Stunning AI Art in 2 seconds - New Free Image Generation Platform Review & Tutorial Tutorial and review link : https://youtu.be/9qPNjIOdpnc GenTube is a platform that you can generate AI images lightning fast. Literally some images generated like in 2 seconds. Currently it is 100% free to use. I don't know how long it will last but you can use it as long as it lasts. This video is raw and honest review and also full tutorial of GenTube. The link of GenTube service : https://www.gentube.app/?_cid=SECourses25 1851 Labs is the crew behind GenTube. Founded by Mo Musbah (AI startup acquired by Microsoft) and Josh Kuntz (scaled Wish to 100M+ MAUs). See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/728023706250605", "date_published": "2025-09-07T13:23:10.681193"}, {"id": "https://huggingface.co/posts/anakin87/373269745519376", "image": "", "title": "Your Language Model needs better (open) environments to learn \ud83c\udf00", "content_text": "Your Language Model needs better (open) environments to learn \ud83c\udf00 \ud83d\udcdd https://huggingface.co/blog/anakin87/environments-hub RL environments help LLMs practice, reason, and improve. I explored the Environments Hub and wrote a walkthrough showing how to train and evaluate models using these open environments. 1\ufe0f\u20e3 \ud835\uddea\ud835\uddf5\ud835\ude06 \ud835\udde5\ud835\udddf \ud835\uddfa\ud835\uddee\ud835\ude01\ud835\ude01\ud835\uddf2\ud835\uddff\ud835\ude00 \ud835\uddf3\ud835\uddfc\ud835\uddff \ud835\udddf\ud835\udddf\ud835\udde0\ud835\ude00 DeepSeek-R1 made clear that Reinforcement Learning can be used to incentivize reasoning in LLMs. In GRPO, the model generates multiple answers and learns to prefer the better ones from rewards. 2\ufe0f\u20e3 \ud835\uddea\ud835\uddf5\ud835\uddee\ud835\ude01 \ud835\uddf2\ud835\uddfb\ud835\ude03\ud835\uddf6\ud835\uddff\ud835\uddfc\ud835\uddfb\ud835\uddfa\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00 \ud835\uddee\ud835\uddff\ud835\uddf2 In classic RL, the environment is the world where the Agent lives, interacts, and get rewards to learn. We can also think of them as software packages, containing data, harness and scoring rules - for the model to learn and be evaluated. Nowadays, the Agent is not just the LLM. It can use tools, from a weather API to a terminal. This makes environments for training and evaluation more complex and critical. 3\ufe0f\u20e3 \ud835\udc13\ud835\udc21\ud835\udc1e \ud835\udc28\ud835\udc29\ud835\udc1e\ud835\udc27 \ud835\udc1c\ud835\udc21\ud835\udc1a\ud835\udc25\ud835\udc25\ud835\udc1e\ud835\udc27\ud835\udc20\ud835\udc1e Big labs...", "url": "https://huggingface.co/posts/anakin87/373269745519376", "date_published": "2025-09-07T13:23:10.681809"}]}