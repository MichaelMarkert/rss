{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/merve/183549115190705", "image": "", "title": "A real-time object detector much faster and accurate than YOLO with Apache 2.0 license just landed to Hugging Face transformers \ud83d\udd25", "content_text": "A real-time object detector much faster and accurate than YOLO with Apache 2.0 license just landed to Hugging Face transformers \ud83d\udd25 D-FINE is the sota real-time object detector that runs on T4 (free Colab) \ud83e\udd29 > Collection with all checkpoints and demo ustc-community/d-fine-68109b427cbe6ee36b4e7352 Notebooks: > Tracking https://github.com/qubvel/transformers-notebooks/blob/main/notebooks/DFine_tracking.ipynb > Inference https://github.com/qubvel/transformers-notebooks/blob/main/notebooks/DFine_inference.ipynb > Fine-tuning https://github.com/qubvel/transformers-notebooks/blob/main/notebooks/DFine_finetune_on_a_custom_dataset.ipynb h/t @ vladislavbro @ qubvel-hf @ ariG23498 and the authors of the paper \ud83c\udfa9 Regular object detectors attempt to predict bounding boxes in (x, y, w, h) pixel perfect coordinates, which is very rigid and hard to solve \ud83e\udd72\u2639\ufe0f D-FINE formulates object detection as a distribution for bounding box coordinates, refines them iteratively, and it's more accurate \ud83e\udd29 Another...", "url": "https://huggingface.co/posts/merve/183549115190705", "date_published": "2025-05-06T17:20:19.084828"}, {"id": "https://huggingface.co/posts/openfree/174131256400578", "image": "", "title": "\ud83d\udd25 Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities \ud83d\ude80", "content_text": "\ud83d\udd25 Creating a qwen3-30b-a3b / qwen3-235b-a22b Chatbot with Deep Research Capabilities \ud83d\ude80 openfree/qwen3-30b-a3b-research openfree/qwen3-235b-a22b-research Hello AI researchers! \ud83d\udc4b Today I'm introducing a powerful chatbot implementation with real-time web search capabilities. \u2728 Key Features \ud83e\udde0 Chatbot based on qwen3-30b-a3b and llama4-maverick models \ud83d\udd0d LLM-based optimal keyword extraction \ud83c\udf10 Real-time web search using SerpHouse API \ud83d\udcac Streaming responses for natural conversation experience \ud83d\udee0\ufe0f Technology Stack Gradio: Implementation of intuitive web interface Fireworks.ai API: Access to high-performance LLM models SerpHouse API: Collection of real-time search results \ud83c\udf1f Application Areas Question answering systems requiring up-to-date information Providing current information beyond training data Delivering reliable information with accurate sources Add real-time search capabilities to your AI applications with this project! \ud83c\udf89 Leave your questions or suggestions in the comments! Let's...", "url": "https://huggingface.co/posts/openfree/174131256400578", "date_published": "2025-05-06T17:20:19.085306"}, {"id": "https://huggingface.co/posts/Kseniase/864305548620639", "image": "", "title": "10 new Chain-of-Thoughts (CoT) methods", "content_text": "10 new Chain-of-Thoughts (CoT) methods CoT has long been one of the hottest techniques in AI thanks to its effectiveness and compelling core idea: encouraging models to solve complex problems through explicit intermediate reasoning steps. But usually researchers modify original CoT approach, finding tips that further improve LLMs' reasoning. That's what we're going to talk about today. Here's a list of 10 latest enhanced CoT approaches: 1. Chain-of-Defensive-Thought -> Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption (2504.20769) Provides a few structured, defensive reasoning exemplars to improve the robustness of LLMs 2. Hybrid-CoT -> AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization (2504.21659) Proposes using Adaptive Hybrid Reasoning Model (AdaR1) that combines Long- and Short-CoT, and applying bi-level preference training to select effective reasoning styles 3. Semantic-level...", "url": "https://huggingface.co/posts/Kseniase/864305548620639", "date_published": "2025-05-06T17:20:19.086041"}, {"id": "https://huggingface.co/posts/BramVanroy/471518743184430", "image": "", "title": "\ud83d\udce2\ud83d\udcbe Introducing the Common Crawl Creative Commons Corpus (C5)!", "content_text": "\ud83d\udce2\ud83d\udcbe Introducing the Common Crawl Creative Commons Corpus (C5)! C5 is a large-scale effort to heavily filter web-crawled data, as collected by the non-profit Common Crawl, to only documents that are Creative Commons-licensed such as cc-by-4.0 or public domain cc0. At this stage 150 billion tokens have been collected. --- \ud83d\udcc4 data: BramVanroy/CommonCrawl-CreativeCommons \ud83e\uddf0 software: https://github.com/BramVanroy/CommonCrawl-CreativeCommons --- </> To build C5, HTML pages are scrutinized and all links (if any) to CC licenses are collected, both in regular hyperlinks as well as in metadata. Additional data fields are included such as \"was the license found in the head ?\" or \"if multiple licenses were found, do they contradict each other?\", which makes further filtering a breeze. \ud83c\udf10 In this first version of C5, 8 languages are included (Afrikaans, German, English, French, Frysian, Italian, Dutch and Spanish). The language set was limited for two reasons: computational and storage limitations,...", "url": "https://huggingface.co/posts/BramVanroy/471518743184430", "date_published": "2025-05-06T17:20:19.086684"}, {"id": "https://huggingface.co/posts/ginipick/917789522887291", "image": "", "title": "\ud83d\udd2e Mistral Perflexity AI - Local LLM Space with Web Search Capabilities \ud83c\udf10", "content_text": "\ud83d\udd2e Mistral Perflexity AI - Local LLM Space with Web Search Capabilities \ud83c\udf10 Hello AI enthusiasts! Today I'm excited to introduce my special Hugging Face space! \ud83d\ude80 ginigen/Mistral-Perflexity \u2728 Key Features Powerful Model: Using Private-BitSix-Mistral-Small-3.1-24B-Instruct-2503, optimized through 6-bit quantization to run smoothly on local 4090 GPUs! \ud83d\udcaa Web Search Integration: Leveraging the Brave Search API to provide real-time web search results for user queries! \ud83d\udd0d Customizable Responses: Shape AI personality and response format through system messages \u2699\ufe0f Multilingual Support: Perfect handling of both English and Korean! \ud83c\uddfa\ud83c\uddf8\ud83c\uddf0\ud83c\uddf7 \ud83d\udee0\ufe0f Technical Highlights GGUF Format: Optimized quantized model with excellent memory efficiency Flash Attention: Applied optimization technology for faster inference speeds 8K Context Window: Capable of handling lengthy conversations and complex queries Streaming Responses: Watch text being generated in real-time \ud83d\udca1 Use Cases Complex Q&A requiring real-time...", "url": "https://huggingface.co/posts/ginipick/917789522887291", "date_published": "2025-05-06T17:20:19.087255"}, {"id": "https://huggingface.co/posts/samihalawa/966135943196710", "image": "", "title": "HELLO GUYS \ud83d\ude80 Just released my first MCP: VUDA \u2013 Visual UI Debug Agent", "content_text": "HELLO GUYS \ud83d\ude80 Just released my first MCP: VUDA \u2013 Visual UI Debug Agent Ever been stuck debugging buttons that don\u2019t work? Broken flows? Inconsistent UI behavior? VUDA sees it, clicks it, fixes it. An automated visual debug agent that inspects, validates, and repairs your UI \u2014 like magic \ud83e\udde0\u2728 Better that any other playwright / puppeteer. \ud83d\udd27 Install now via Smithery: npx -y @ smithery /cli@latest install @ samihalawa /visual-ui-debug-agent-mcp --client cursor \u2e3b Want a shorter alt for social media too? See translation", "url": "https://huggingface.co/posts/samihalawa/966135943196710", "date_published": "2025-05-06T17:20:19.087570"}, {"id": "https://huggingface.co/posts/nyuuzyou/896622962900908", "image": "", "title": "\ud83d\uddbc\ufe0f PublicDomainFiles.com Collection -", "content_text": "\ud83d\uddbc\ufe0f PublicDomainFiles.com Collection - nyuuzyou/publicdomainfiles Collection of 206,204 Public Domain multimedia files featuring: - Comprehensive metadata: title, description, creator name, keywords, original page URL, and more. - Contains various media types including images, clip art, artwork, fonts, videos, and TV shows. - All content explicitly released into the public domain under the CC0 license. - Organized in a single train split with 206,204 entries. See translation", "url": "https://huggingface.co/posts/nyuuzyou/896622962900908", "date_published": "2025-05-06T17:20:19.087898"}, {"id": "https://huggingface.co/posts/ZennyKenny/253232746889795", "image": "", "title": "When I heard the Reasoning Dataset Competition deadline was extended to 9 May, I knew I had time to get in one more entry. \ud83d\udd25\ud83d\udd25\ud83d\udd25", "content_text": "When I heard the Reasoning Dataset Competition deadline was extended to 9 May, I knew I had time to get in one more entry. \ud83d\udd25\ud83d\udd25\ud83d\udd25 With the rise of Vibe Coding, and the potential risks that are introduced by humans letting LLMs build their apps for them, lots of people are (rightfully) concerned about the safety of the code that is hitting prod. In response to that, I'm happy to present my final submission to the Reasoning Dataset Competition and attempt to start benchmarking the ability of LLMs to identify unsafe and / or exploitable code by way of the CoSa (Code Safety) benchmark: ZennyKenny/cosa-benchmark-dataset Currently a curated set of 200 examples, calibrated on OpenAI's standard issue models (GPT-4.1, o4 mini, and GPT-3.5 Turbo) as \"baseline performance\" (70% decile). Check it out and drop a \u2764\ufe0f if you think it could be useful or hit the Community section with suggestions / critiques. See translation", "url": "https://huggingface.co/posts/ZennyKenny/253232746889795", "date_published": "2025-05-06T17:20:19.088320"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/846082369642024", "image": "", "title": "Just published a tutorial that shows how to properly install ComfyUI, SwarmUI, use installed ComfyUI as a backend in SwarmUI with absolutely maximum best performance such as out of the box Sage Attention, Flash Attention, RTX 5000 Series support and more. Also how to upscale images with max quality", "content_text": "Just published a tutorial that shows how to properly install ComfyUI, SwarmUI, use installed ComfyUI as a backend in SwarmUI with absolutely maximum best performance such as out of the box Sage Attention, Flash Attention, RTX 5000 Series support and more. Also how to upscale images with max quality Tutorial Link https://youtu.be/fTzlQ0tjxj0 Tutorial Information If you want to generate the very best AI videos and images on your Windows computer locally this is the tutorial that you were looking for. Literally 1-click to install most powerful and advanced generative AI interface SwarmUI (with Flash Attention, Sage Attention, Triton, DeepSpeed, xFormers, RTX 5000 series perfect compatibility) and download the very best AI image and video generation models with ultra advanced model downloader Gradio app. SwarmUI utilizes the famous and most powerful, advanced, performant and optimized ComfyUI as a backend. So SwarmUI is the ultimate generative AI tool at the moment with vast amount of...", "url": "https://huggingface.co/posts/MonsterMMORPG/846082369642024", "date_published": "2025-05-06T17:20:19.088953"}, {"id": "https://huggingface.co/posts/ZennyKenny/478282156261822", "image": "", "title": "After hearing the news that Marc Andreessen thinks that the only job that is safe from AI replacement is venture capital:", "content_text": "After hearing the news that Marc Andreessen thinks that the only job that is safe from AI replacement is venture capital: https://gizmodo.com/marc-andreessen-says-one-job-is-mostly-safe-from-ai-venture-capitalist-2000596506 \ud83e\udde0\ud83e\udde0\ud83e\udde0 The Reasoned Capital synthetic dataset suddenly feels much more topical: ZennyKenny/synthetic_vc_financial_decisions_reasoning_dataset \ud83d\udd25\ud83d\udd25\ud83d\udd25 Really looking forward to potentially expanding this architecture and seeing how algorithmic clever investment truly is! \ud83d\udcb0\ud83d\udcb0\ud83d\udcb0 See translation", "url": "https://huggingface.co/posts/ZennyKenny/478282156261822", "date_published": "2025-05-06T17:20:19.089248"}]}