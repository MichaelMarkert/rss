{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mike-ravkine/305096078349013", "image": "", "title": "There is no anxiety quite like powering up 2KW of basement compute after rewiring it all. Small bit of trouble with the horizontal 3090 because I misread my motherboard manual, but otherwise so far so good.. Next we see if I've built up enough cooling to hit my target TDP on those 3-slot nvlinked cards especially.  The 4-slot bridges are much easier to work with but their prices went bananas and I couldn't acquire a second, so gotta get a little creative with intakes.", "content_text": "There is no anxiety quite like powering up 2KW of basement compute after rewiring it all. Small bit of trouble with the horizontal 3090 because I misread my motherboard manual, but otherwise so far so good.. Next we see if I've built up enough cooling to hit my target TDP on those 3-slot nvlinked cards especially. The 4-slot bridges are much easier to work with but their prices went bananas and I couldn't acquire a second, so gotta get a little creative with intakes. See translation", "url": "https://huggingface.co/posts/mike-ravkine/305096078349013", "date_published": "2025-11-08T17:18:06.700526"}, {"id": "https://huggingface.co/posts/AdinaY/911192969719025", "image": "", "title": "Kimi K2 Thinking is now live on the hub \ud83d\udd25", "content_text": "Kimi K2 Thinking is now live on the hub \ud83d\udd25 moonshotai/Kimi-K2-Thinking \u2728 1T MoE for deep reasoning & tool use \u2728 Native INT4 quantization = 2\u00d7 faster inference \u2728 256K context window \u2728 Modified MIT license See translation", "url": "https://huggingface.co/posts/AdinaY/911192969719025", "date_published": "2025-11-08T17:18:06.700789"}, {"id": "https://huggingface.co/posts/evalstate/266178055669254", "image": "", "title": "Hugging Face MCP Server v0.2.40", "content_text": "Hugging Face MCP Server v0.2.40 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Improved progressive disclosure and descriptions for Jobs tool. See translation", "url": "https://huggingface.co/posts/evalstate/266178055669254", "date_published": "2025-11-08T17:18:06.701005"}, {"id": "https://huggingface.co/posts/branikita/935466322450846", "image": "", "title": "FEETECH STS3250 Stall Torque and Repeatability Tests", "content_text": "FEETECH STS3250 Stall Torque and Repeatability Tests We recently tested the FEETECH STS3250 servo, comparing actual performance with the official specifications. While the datasheet lists a stall torque of 50 kg\u00b7cm at 12 V, our real-world measurements showed: - 25 kg\u00b7cm sustained torque after protection activation - Up to 48 kg\u00b7cm peak torque for a split second Although the built-in protection limits continuous stall torque, the servo demonstrated excellent stability and control precision. Precision and Repeatability: - Repeatability tolerance: \u00b10.02 mm at the end of a 95 mm arm - Smooth motion response with PID control and 12-bit (4096-step) magnetic encoder - Reliable performance for high-accuracy robotics and automation applications #Feetech #STS3250 #ServoTest #Robotics #Engineering #PrecisionControl #HardwareReview See translation", "url": "https://huggingface.co/posts/branikita/935466322450846", "date_published": "2025-11-08T17:18:06.701430"}, {"id": "https://huggingface.co/posts/narugo1992/829929897247800", "image": "", "title": "Org Rate Limits = Free DDoS Invitation? \ud83e\udd21", "content_text": "Org Rate Limits = Free DDoS Invitation? \ud83e\udd21 One serious question: Is there any way to actually ban clowns abusing this system? Right now all it takes is one bored script kiddie with a grudge (or too much caffeine) to lawnmower an entire org's API endpoints into the stone age. They get to bathe in 429s while we're sitting here like \ud83e\udd21 \"Gee I wonder whose IP is carpet-bombing us today!\" The kicker? Zero accountability. Zero fingerprints. Just vibes\u2122 and chaos. It\u2019s basically a public invitation to hold entire communities hostage while wearing pajamas. \"Come for the open-source collaboration, stay for the unhinged DDoS pi\u00f1ata party!\" \ud83c\udf89 Fix when? See translation", "url": "https://huggingface.co/posts/narugo1992/829929897247800", "date_published": "2025-11-08T17:18:06.701781"}, {"id": "https://huggingface.co/posts/wang12390/587232658251993", "image": "", "title": "\ud83e\udde0 What Is SpeedPaint?", "content_text": "\ud83e\udde0 What Is SpeedPaint? SpeedPaint is an AI Speed Painting software that simulates how an artist paints \u2014 step by step, layer by layer \u2014 but at machine speed. Instead of generating a finished image instantly, it paints in motion, giving users a live-brush experience. Miragic-AI/Miragic-Speed-Painting https://miragic.ai/products/speed-painting See translation", "url": "https://huggingface.co/posts/wang12390/587232658251993", "date_published": "2025-11-08T17:18:06.702059"}, {"id": "https://huggingface.co/posts/branikita/234092651364485", "image": "", "title": "Load test conducted on the Feetech STS3250 servo motor.", "content_text": "Load test conducted on the Feetech STS3250 servo motor. With a 2 kg load on a 100 mm arm, the motor operated near its limit. At higher acceleration settings, lifting performance decreased noticeably. The temperature increased from 40 \u00b0C to 70 \u00b0C within 8 minutes. The test highlights the torque and thermal constraints under sustained load conditions. #Robotics #Engineering #ServoMotor #Testing #Feetech #Automation #Mechatronics #Hardware See translation", "url": "https://huggingface.co/posts/branikita/234092651364485", "date_published": "2025-11-08T17:18:06.702337"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/482948371636786", "image": "", "title": "Qwen Image Models Training - 0 to Hero Level Tutorial - LoRA & Fine Tuning - Base & Edit Model -", "content_text": "Qwen Image Models Training - 0 to Hero Level Tutorial - LoRA & Fine Tuning - Base & Edit Model - https://youtu.be/DPX3eBTuO_Y This is a full comprehensive step-by-step tutorial for how to train Qwen Image models. This tutorial covers how to do LoRA training and full Fine-Tuning / DreamBooth training on Qwen Image models. It covers both the Qwen Image base model and the Qwen Image Edit Plus 2509 model. This tutorial is the product of 21 days of full R&D, costing over $800 in cloud services to find the best configurations for training. Furthermore, we have developed an amazing, ultra-easy-to-use Gradio app to use the legendary Kohya Musubi Tuner trainer with ease. You will be able to train locally on your Windows computer with GPUs with as little as 6 GB of VRAM for both LoRA and Fine-Tuning. Furthermore, I have shown how to train a character (person), a product (perfume) and a style (GTA5 artworks). Tutorial Link : https://youtu.be/DPX3eBTuO_Y See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/482948371636786", "date_published": "2025-11-08T17:18:06.702694"}, {"id": "https://huggingface.co/posts/atasoglu/710262131050494", "image": "", "title": "Introducing ToolsGen \ud83d\udee0\ufe0f", "content_text": "Introducing ToolsGen \ud83d\udee0\ufe0f I built a tool to solve a problem I kept running into: creating quality datasets for training LLMs to use tools. ToolsGen takes your JSON tool definitions and automatically generates realistic user requests, corresponding tool calls, and evaluates them using an LLM-as-a-judge pipeline. It outputs datasets ready to use with Hugging Face. What makes it useful: - Generates realistic user requests + tool calls from JSON definitions - LLM-as-a-judge quality scoring with multi-dimensional rubrics - Multiple sampling strategies (random, parameter-aware, semantic) - OpenAI-compatible API support - Outputs JSONL with train/val splits Still early days (API isn't stable yet), but it's already helping me generate tool-calling datasets much faster. Check it out: https://github.com/atasoglu/toolsgen Happy to hear feedback or ideas! See translation", "url": "https://huggingface.co/posts/atasoglu/710262131050494", "date_published": "2025-11-08T17:18:06.703102"}, {"id": "https://huggingface.co/posts/danielhanchen/603265034116639", "image": "", "title": "You can now run Kimi K2 Thinking locally with our Dynamic 1-bit GGUFs:", "content_text": "You can now run Kimi K2 Thinking locally with our Dynamic 1-bit GGUFs: unsloth/Kimi-K2-Thinking-GGUF We shrank the 1T model to 245GB (-62%) & retained ~85% of accuracy on Aider Polyglot. Run on >247GB RAM for fast inference. We also collaborated with the Moonshot AI Kimi team on a system prompt fix! \ud83e\udd70 Guide + fix details: https://docs.unsloth.ai/models/kimi-k2-thinking-how-to-run-locally See translation", "url": "https://huggingface.co/posts/danielhanchen/603265034116639", "date_published": "2025-11-08T17:18:06.703386"}]}