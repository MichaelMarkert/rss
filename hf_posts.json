{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/etemiz/710778843328598", "image": "", "title": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.", "content_text": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really \"free\": they are costing you your freedom if you know what i mean. See translation", "url": "https://huggingface.co/posts/etemiz/710778843328598", "date_published": "2025-08-17T17:20:10.079252"}, {"id": "https://huggingface.co/posts/ovi054/657358125503535", "image": "", "title": "Image-to-Prompt\u26a1", "content_text": "Image-to-Prompt\u26a1 ovi054/image-to-prompt Extract text prompt from image. And you can reuse the prompt to generate similar images! Useful for prompt engineering, studying image-to-text alignment, making training datasets, or recreating similar outputs. Powered by: Gradio, Florence 2 \ud83d\udc49 Try it now: ovi054/image-to-prompt See translation", "url": "https://huggingface.co/posts/ovi054/657358125503535", "date_published": "2025-08-17T17:20:10.079557"}, {"id": "https://huggingface.co/posts/fdaudens/770107969696647", "image": "", "title": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:", "content_text": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines & specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup \u2014 just open-weight GPT-OSS models via Hugging Face If you\u2019ve been wanting to try agents but weren\u2019t sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation", "url": "https://huggingface.co/posts/fdaudens/770107969696647", "date_published": "2025-08-17T17:20:10.079891"}, {"id": "https://huggingface.co/posts/anakin87/751707976654130", "image": "", "title": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac", "content_text": "Want to quickly try Gemma 3 270m? \ud83d\udc8e\ud83d\udcac I made a simple Space to do that: anakin87/gemma-3-270m-it \u26a1 Fast: Flash Attention, Zero GPU \u2699\ufe0f Configurable See translation", "url": "https://huggingface.co/posts/anakin87/751707976654130", "date_published": "2025-08-17T17:20:10.080111"}, {"id": "https://huggingface.co/posts/prithivMLmods/284574267701705", "image": "", "title": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea", "content_text": "Excited to introduce the Tiny VLMs Lab App for experiencing 15+ multimodal VLMs, ranging from a 250M parameter model to a 4B parameter model, for tasks like OCR, reasoning, small models for single-shot answering, and captioning (abliterated), across a broad range of visual categories including images with complex, sensitive, or nuanced content, while handling varying aspect ratios and resolutions.\ud83e\uddea \ud83e\udd17 Space: prithivMLmods/Tiny-VLMs-Lab \u2726\ufe0e Also introducing prithivMLmods/Qwen2.5-VL-3B-Abliterated-Caption-it , tailored for Abliterated Captioning / Uncensored Image Captioning. This release comes as a lighter alternative to the existing Qwen2.5-VL-7B-Abliterated-Caption-it prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it model, making it usable on mid-range GPUs and even experimental on T4 GPUs. \u2726\ufe0e Collection: prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 \u2726\ufe0e GitHub: https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab . . . To know more about it, visit the app page or the...", "url": "https://huggingface.co/posts/prithivMLmods/284574267701705", "date_published": "2025-08-17T17:20:10.080543"}, {"id": "https://huggingface.co/posts/appvoid/589674942896129", "image": "", "title": "suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source?", "content_text": "suppose someone is working on a reasoning model, which ends up unlocking achievements that lead to agi, should it be open source? keep in mind everybody will have access to it: scientists, governments, terrorists, average people, etc... See translation", "url": "https://huggingface.co/posts/appvoid/589674942896129", "date_published": "2025-08-17T17:20:10.080764"}, {"id": "https://huggingface.co/posts/kanaria007/576453037371058", "image": "", "title": "\u2705 New Article: *Memory as Structured Time*", "content_text": "\u2705 New Article: *Memory as Structured Time* Title: \ud83e\udde0 History: Memory Loops as Civilization Structure \ud83d\udd17 https://huggingface.co/blog/kanaria007/memory-loops-as-civilization-structure --- Summary: Memory is often treated as *storage and retrieval*. Structured Intelligence reframes it as *time\u2011shaping architecture*: * *Loops that preserve context and continuity* * *Rollback paths that enable reflection and correction* * *Patterns that turn experience into adaptive structure* > Memory isn\u2019t static \u2014 > *it\u2019s how intelligence edits time.* --- Why It Matters: \u2022 Reveals *how memory enables learning, identity, and adaptation* \u2022 Supports *AI that can reflect, revise, and self\u2011align* \u2022 Connects *personal cognition and collective history* as structural processes --- What\u2019s Inside: \u2022 Memory as *recursive structural loop* \u2022 *Failure and recovery* as part of adaptive recall \u2022 How *history and record\u2011keeping mirror cognitive memory* \u2022 Implications for *resilient AI and social knowledge systems* --- \ud83d\udcd6...", "url": "https://huggingface.co/posts/kanaria007/576453037371058", "date_published": "2025-08-17T17:20:10.081295"}, {"id": "https://huggingface.co/posts/asigalov61/289707289100732", "image": "", "title": "\ud83d\udd25Check out new SOTA Orpheus Auto-Continuations Generator\ud83d\udd25", "content_text": "\ud83d\udd25Check out new SOTA Orpheus Auto-Continuations Generator\ud83d\udd25 asigalov61/Orpheus-Music-Transformer Now you can generate good music with Orpheus without supervision!!! @ Timzoid @ John6666 @ alvanalrakib See translation", "url": "https://huggingface.co/posts/asigalov61/289707289100732", "date_published": "2025-08-17T17:20:10.081551"}, {"id": "https://huggingface.co/posts/openfree/904316268987326", "image": "", "title": "\ud83e\uddec DNA Diffusion Suite: AI-Powered Revolution in Life Science Research", "content_text": "\ud83e\uddec DNA Diffusion Suite: AI-Powered Revolution in Life Science Research \ud83d\ude80 Transformative Innovation Through AI Technology DNA Diffusion Suite is a next-generation platform that leverages cutting-edge Diffusion models to generate biologically meaningful DNA sequences. By reducing sequence design time from weeks to mere seconds, we're revolutionizing research productivity and accelerating scientific discovery. VIDraft/DNA-Diffusion \ud83d\udca1 Real-World Benefits of AI Technology \ud83c\udfaf Research Acceleration Instant Hypothesis Testing: Pre-validate experimental designs with AI-generated sequence variants Cost Reduction: Test hundreds of sequences virtually before expensive synthesis Time Efficiency: 1000x faster sequence generation compared to manual design \ud83e\udde0 Intelligent Sequence Optimization Cell-Type Specific Learning: AI trained on real ChIP-seq data from K562, GM12878, and HepG2 cells Context-Aware Generation: Fine-tune biological context with precision Guidance Scale control Automated Pattern...", "url": "https://huggingface.co/posts/openfree/904316268987326", "date_published": "2025-08-17T17:20:10.082136"}, {"id": "https://huggingface.co/posts/ginipick/955296677233221", "image": "", "title": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728", "content_text": "\u2728 HairPick | Preview Your Perfect Hair Transformation in 360\u00b0 \u2728 \ud83c\udf8a Free Trial for Hugging Face Launch! Hurry! \u23f0 Hello! Introducing an innovative AI service that helps you choose the perfect hairstyle without any regrets before visiting the salon! \ud83c\udfaf Try It Now ginigen/Hair-Pick \ud83d\udd04 What Makes HairPick Special? 360\u00b0 Complete Preview! Other hair simulators only show the front view? \ud83d\ude11 HairPick is different! \u2705 Front + 4 random angles = Total 5 multi-angle images generated \u2705 Perfect check from side profile \ud83d\udc64 diagonal \ud83d\udcd0 back view \ud83d\udc65! \u2705 100+ trendy hairstyle library \ud83d\udc87\u200d\u2640\ufe0f \ud83d\udca1 Highly Recommended For: \ud83c\udfaf \"I really don't want to fail this time!\" \u2192 Check side volume and back lines thoroughly \ud83c\udfaf \"It's hard to explain exactly to my stylist\" \u2192 Perfect communication with 360\u00b0 result images! \ud83c\udfaf \"I have a profile photo/photoshoot coming up\" \u2192 Preview your best look from every angle \ud83d\ude80 Super Simple Usage (Just 1 Minute!) 1\ufe0f\u20e3 One Selfie \ud83d\udcf8 Take a front-facing photo in bright light (show your forehead and face...", "url": "https://huggingface.co/posts/ginipick/955296677233221", "date_published": "2025-08-17T17:20:10.082792"}]}