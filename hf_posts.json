{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/963278821580490", "image": "", "title": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25", "content_text": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25 Has 1M context window & best in class performance for SWE-Bench, reasoning & chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF \ud83d\udc9a Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation", "url": "https://huggingface.co/posts/danielhanchen/963278821580490", "date_published": "2025-12-17T05:28:06.163647"}, {"id": "https://huggingface.co/posts/DawnC/393405474084583", "image": "", "title": "Intelligent Inpainting for Precise Creative Control \ud83c\udfa8\u2728", "content_text": "Intelligent Inpainting for Precise Creative Control \ud83c\udfa8\u2728 Transform your images with AI-powered precision! SceneWeaver delivers professional-quality image composition with intelligent background replacement and advanced object manipulation. What's New in This Update? \ud83d\udd8c\ufe0f Object Replacement \u2014 Select and transform any element in your scene with natural language prompts while maintaining perfect visual consistency with surrounding content \ud83d\uddd1\ufe0f Object Removal \u2014 Intelligently remove unwanted objects with context-aware generation that preserves natural lighting, shadows, and scene coherence \ud83c\udfaf Context-Aware Processing \u2014 Advanced inpainting technology ensures seamless integration across all regenerated regions Core Capabilities \u26a1 One-click transformation with smart subject detection, 24 curated professional backgrounds, custom scene generation through text prompts, and studio-quality results powered by BiRefNet, Stable Diffusion XL, and ControlNet Inpainting. Current Infrastructure & Future...", "url": "https://huggingface.co/posts/DawnC/393405474084583", "date_published": "2025-12-17T05:28:06.164312"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/439099944779481", "image": "", "title": "New Preview Model:", "content_text": "New Preview Model: unmodeled-tyler/vanta-research-loux-preview VANTA Research is excited to announce a small lab preview of our new 675B fine tune, Loux-Large. Loux is an AI model with a sophisticated, rebellious edge designed to assist and collaborate with engineers, builders, and people working on technical projects. If you enjoy working with Loux and would like full access, let us know by liking the space or opening a discussion in the community! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/439099944779481", "date_published": "2025-12-17T05:28:06.164610"}, {"id": "https://huggingface.co/posts/Kseniase/300455492795256", "image": "", "title": "6 Comprehensive Resources on AI Coding", "content_text": "6 Comprehensive Resources on AI Coding AI coding is moving fast, and it\u2019s getting harder to tell what actually works. Agents, workflows, context management and many other aspects are reshaping how software gets built. We\u2019ve collected a set of resources to help you understand how AI coding is evolving today and what building strategies work best: 1. AI Agentic Programming: A Survey of Techniques, Challenges, and Opportunities (2508.11126) Provides a clear taxonomy, compares agent architectures, and exposes practical gaps in tools, benchmarks, and reliability that AI coding agents now struggle with 2. Does AI-Assisted Coding Deliver? A Difference-in-Differences Study of Cursor's Impact on Software Projects (2511.04427) This survey from Carnegie Mellon University shows causal evidence that LLM agent assistants deliver short-term productivity gains but have lasting quality costs that can slow development over time 3. A Survey of Vibe Coding with Large Language Models (2510.12399) Turns...", "url": "https://huggingface.co/posts/Kseniase/300455492795256", "date_published": "2025-12-17T05:28:06.165332"}, {"id": "https://huggingface.co/posts/Reubencf/239576255947718", "image": "", "title": "Great News !", "content_text": "Great News ! Reubencf/Nano_Banana_Editor Now supports black-forest-labs/FLUX.1-Kontext-dev and Qwen/Qwen-Image-Edit-2509 Just log in with Huggingface and try it out See translation", "url": "https://huggingface.co/posts/Reubencf/239576255947718", "date_published": "2025-12-17T05:28:06.165564"}, {"id": "https://huggingface.co/posts/prithivMLmods/223082724733311", "image": "", "title": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea", "content_text": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea \u25cf Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC \u25cf Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \u25cf Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo \u25cf Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- \u25cf FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 \u25cf FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC \u25cf Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC \u25cf Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast \u25cf Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...", "url": "https://huggingface.co/posts/prithivMLmods/223082724733311", "date_published": "2025-12-17T05:28:06.166041"}, {"id": "https://huggingface.co/posts/AdinaY/236108821864145", "image": "", "title": "Finch \ud83d\udcb0 an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance & accounting work.", "content_text": "Finch \ud83d\udcb0 an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance & accounting work. FinWorkBench/Finch \u2728 Built from real enterprise data (Enron + financial institutions), not synthetic tasks \u2728 Tests end-to-end finance workflows \u2728 Multimodal & cross-file reasoning \u2728 Expert annotated (700+ hours) and genuinely challenging hard See translation", "url": "https://huggingface.co/posts/AdinaY/236108821864145", "date_published": "2025-12-17T05:28:06.166320"}, {"id": "https://huggingface.co/posts/MikeDoes/696146647062201", "image": "", "title": "Making LLMs fast with KV-cache sharing is great. A new paper reports it's also a huge privacy risk.", "content_text": "Making LLMs fast with KV-cache sharing is great. A new paper reports it's also a huge privacy risk. That's why we're excited to see the \"SafeKV\" paper from researchers at the University of Connecticut, Peking University, and others. Their solution-oriented framework selectively shares non-sensitive data while isolating PII. To validate the \"Safe\" part of their system, they needed a robust, multilingual privacy benchmark. We're proud that the Ai4Privacy pii-masking dataset was used for this critical evaluation related to privacy. This is a perfect win-win. Our open-source data enables researchers to build and validate more effective security solutions for core AI infrastructure. Their work, in turn, helps make the entire LLM ecosystem safer, showing that performance and privacy don't have to be mutually exclusive. Kudos to Kexin Chu, Zecheng Lin, Dawei Xiang, \u6c88\u5b50\u65ed, Jianchang Su, cheng chu, Yiwei Yang, Wenhui Zhang, Wenfei Wu, and Wei Zhang on this beautiful work. \ud83d\udd17 Check out their...", "url": "https://huggingface.co/posts/MikeDoes/696146647062201", "date_published": "2025-12-17T05:28:06.166802"}, {"id": "https://huggingface.co/posts/nicolay-r/350400879019559", "image": "", "title": "\ud83d\udce2 For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios.", "content_text": "\ud83d\udce2 For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios. \ud83c\udf1f bulk-chain: https://github.com/nicolay-r/bulk-chain \ud83d\udd11 This features the no-string framework for quierrying LLMs in various modes: sync, async and with optional support for output streaming. \ud83d\udce6\ufe0f In the latest 1.2.0 release, the updates on outlining API parameters for inference mode. \ud83c\udf1f Integration into web: https://github.com/nicolay-r/bulk-chain-web-integration See translation", "url": "https://huggingface.co/posts/nicolay-r/350400879019559", "date_published": "2025-12-17T05:28:06.167175"}, {"id": "https://huggingface.co/posts/daqc/540565360726745", "image": "", "title": "Check out your 2025 Hugging Face Wrapped, a small experimental recap", "content_text": "Check out your 2025 Hugging Face Wrapped, a small experimental recap hf-wrapped/2025 See translation", "url": "https://huggingface.co/posts/daqc/540565360726745", "date_published": "2025-12-17T05:28:06.167369"}]}