{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/MonsterMMORPG/783922297746182", "image": "", "title": "Qwen Image Edit Full Tutorial: 26 Different Demo Cases, Prompts & Images, Pwns FLUX Kontext Dev", "content_text": "Qwen Image Edit Full Tutorial: 26 Different Demo Cases, Prompts & Images, Pwns FLUX Kontext Dev Tutorial Link https://youtu.be/gLCMhbsICEQ Extra Info I tested newly arrived Qwen-Image-Edit-Lightning-8steps-V1.0 (arrived after tutorial recorded) and definitely our existing preset which uses Qwen-Image-Lightning-8steps-V1.1 is better than it, so this tutorial and presets are still 100% best quality and up-to-date Info Qwen Image Edit just has been published and since then I have been experimenting to prepare you this amazing tutorial. I have literally shown 26 unique cases and provided demo images and prompts. After watching this tutorial your image editing skills will move to next level i promise you that. Also this tutorial will give you a lot of ideas. See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/783922297746182", "date_published": "2025-08-26T17:20:20.025591"}, {"id": "https://huggingface.co/posts/merve/292180054306518", "image": "", "title": "first vision language model built off", "content_text": "first vision language model built off openai/gpt-oss-20b just dropped! \ud83d\udd25 InternVL3.5 comes with 32 models \ud83e\udd2f pre-trained, fine-tuned, aligned in various sizes OpenGVLab/internvl35-68ac87bd52ebe953485927fb comes with gpt-oss or Qwen3 for LLM part \u2935\ufe0f See translation", "url": "https://huggingface.co/posts/merve/292180054306518", "date_published": "2025-08-26T17:20:20.025876"}, {"id": "https://huggingface.co/posts/openfree/336669979956450", "image": "", "title": "\ud83e\udd16 Global AI News Stream - 100% Unmanned AI News Automation Platform", "content_text": "\ud83e\udd16 Global AI News Stream - 100% Unmanned AI News Automation Platform \ud83d\ude80 Fully Automated News Generation with Just One Keyword! Link: openfree/News-AI \ud83c\udfaf Incredibly Simple: Just Enter a Keyword or URL! \u2728 One Input, Complete Automation! \u2728 Simply enter one keyword or one URL, and the system springs into action! \ud83d\ude80 From web crawling to AI analysis, article writing, image generation, and auto-publishing - everything happens automatically. Examples: \ud83d\udcac Type \"GPT-5\" \u2192 Instant GPT-5 news article generation! \ud83d\udd17 Paste \"https://openai.com/blog/...\" \u2192 Auto-extracts keywords from URL and creates related articles! \ud83c\udfaf Enter \"Tesla Bot\" \u2192 Latest Tesla Bot developments instantly generated! \ud83d\udc8e Key Features - One Input, Everything Done! \ud83d\udd0d Smart Keyword/URL Processing Just type a keyword or paste any website URL! The system automatically extracts core keywords and gathers all relevant information to generate complete news articles. For URLs, it intelligently parses keywords from domains and paths. \ud83d\udd77\ufe0f Instant...", "url": "https://huggingface.co/posts/openfree/336669979956450", "date_published": "2025-08-26T17:20:20.026499"}, {"id": "https://huggingface.co/posts/kanaria007/706135056688184", "image": "", "title": "\u2705 New Article: *Relationships as Structured Reciprocity*", "content_text": "\u2705 New Article: *Relationships as Structured Reciprocity* Title: \ud83e\udd1d Relationships: Ethics as Cross-Construct Jump Series \ud83d\udd17 https://huggingface.co/blog/kanaria007/structured-relationships --- Summary: Relationships are often framed as *emotion and chance*. Structured Intelligence reframes them as *reciprocal cognitive architectures*: * Trust and love as *reinforced feedback loops* * Conflict as *constraint misalignment and jump failure* * Growth as *loop stabilization through reflection and repair* > Human connection isn\u2019t mystery \u2014 > *it\u2019s structure that learns to align across minds.* --- Why It Matters: \u2022 Reveals *how trust, betrayal, and repair follow structural patterns* \u2022 Bridges *psychology, sociology, and cognitive modeling* \u2022 Enables *AI that supports human connection without mimicry* --- What\u2019s Inside: \u2022 Relationships as *multi\u2011agent jump and memory loops* \u2022 *Attachment and reciprocity* as structural alignment \u2022 *Conflict resolution* as rollback and loop repair \u2022 Implications...", "url": "https://huggingface.co/posts/kanaria007/706135056688184", "date_published": "2025-08-26T17:20:20.027051"}, {"id": "https://huggingface.co/posts/prithivMLmods/835910169748717", "image": "", "title": "OpenGVLab's InternVL3_5-2B-MPO [Mixed Preference Optimization (MPO)] is a compact vision-language model in the InternVL3.5 series. You can now experience it in the Tiny VLMs Lab, an app featuring 15+ multimodal VLMs ranging from 250M to 4B parameters. These models support tasks such as OCR, reasoning, single-shot answering with small models, and captioning (including ablated variants), across a broad range of visual categories. They are also capable of handling images with complex, sensitive, or nuanced content, while adapting to varying aspect ratios and resolutions.", "content_text": "OpenGVLab's InternVL3_5-2B-MPO [Mixed Preference Optimization (MPO)] is a compact vision-language model in the InternVL3.5 series. You can now experience it in the Tiny VLMs Lab, an app featuring 15+ multimodal VLMs ranging from 250M to 4B parameters. These models support tasks such as OCR, reasoning, single-shot answering with small models, and captioning (including ablated variants), across a broad range of visual categories. They are also capable of handling images with complex, sensitive, or nuanced content, while adapting to varying aspect ratios and resolutions. \u2728 Space/App : prithivMLmods/Tiny-VLMs-Lab \ud83e\uded9 Model : OpenGVLab/InternVL3_5-2B-MPO \u2197\ufe0f Collection: OpenGVLab/internvl35-68ac87bd52ebe953485927fb \ud83d\uddde\ufe0f Paper : https://arxiv.org/pdf/2508.18265 \u2197\ufe0f Multimodal Space Collection : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 To learn more, visit the relevant spaces, collections, and model cards. See translation", "url": "https://huggingface.co/posts/prithivMLmods/835910169748717", "date_published": "2025-08-26T17:20:20.027450"}, {"id": "https://huggingface.co/posts/codelion/968650774475150", "image": "", "title": "I recently added a recipe in ellora to improve reasoning capabilities to Gemma-3-1B using self-supervised learning. Model now shows step-by-step thinking in <think> tags before answering.", "content_text": "I recently added a recipe in ellora to improve reasoning capabilities to Gemma-3-1B using self-supervised learning. Model now shows step-by-step thinking in <think> tags before answering. Logic puzzle accuracy: 61% \u2192 84%. 3 hours training on single GPU. \ud83e\udde0 Used GRPO where model generates multiple responses and learns to prefer better reasoning. Works surprisingly well for making smaller models more transparent. \ud83d\udd17 Colab: https://colab.research.google.com/github/codelion/ellora/blob/main/Ellora_Recipe_2_Reasoning_LoRA_with_Self-Rewarding_GRPO.ipynb \ud83e\udd17 Model: codelion/gemma-3-1b-it-reasoning-grpo-lora \ud83d\udcbb Code: https://github.com/codelion/ellora See translation", "url": "https://huggingface.co/posts/codelion/968650774475150", "date_published": "2025-08-26T17:20:20.027770"}, {"id": "https://huggingface.co/posts/openfree/464899901167090", "image": "", "title": "\ud83d\udd12 Ansim Blur: Privacy-First Face Blurring for the AI Era", "content_text": "\ud83d\udd12 Ansim Blur: Privacy-First Face Blurring for the AI Era \ud83d\udea8 The Privacy Crisis is Now Smart CCTVs \ud83d\udcf9, delivery robots \ud83e\udd16, and autonomous vehicles \ud83d\ude97 are everywhere. Your face is being captured, transmitted, and stored without your knowledge or consent. openfree/Face-blurring The privacy threat is real: 24/7 surveillance cameras recording your every move Companies harvesting facial biometric data at scale Your face becoming a commodity without your permission \ud83d\udca1 The Solution: Ansim Blur Real-time face anonymization powered by YOLOv8 \ud83c\udfaf \u2705 Process images, videos, and live streams \u2705 Automatic GPU/CPU detection for universal deployment \u2705 Choose between Gaussian blur or mosaic pixelation \u2705 Fine-tune detection sensitivity for your needs \u2705 Preserve audio tracks in video processing \ud83d\udee1\ufe0f Real-World Applications Enterprise Use Cases Privacy compliance for robotics and drone footage CCTV feed anonymization for regulatory requirements Customer data protection in retail analytics Personal Protection...", "url": "https://huggingface.co/posts/openfree/464899901167090", "date_published": "2025-08-26T17:20:20.028368"}, {"id": "https://huggingface.co/posts/daqc/944546045325401", "image": "", "title": "Just applied for HF Community Grant for \u201cHugging Research\u201d \u2014  a lightweight CodeAgent\u2011based research assistant built on Hugging Face\u2019s Open Deep Research project for the Hugging Face Hub (models, datasets, Spaces, users, collections, papers). It gathers links via dedicated tools and organizes them for easy review.", "content_text": "Just applied for HF Community Grant for \u201cHugging Research\u201d \u2014 a lightweight CodeAgent\u2011based research assistant built on Hugging Face\u2019s Open Deep Research project for the Hugging Face Hub (models, datasets, Spaces, users, collections, papers). It gathers links via dedicated tools and organizes them for easy review. As this is for the community, comments and suggestions are appreciated: daqc/hugging-research#1 See translation", "url": "https://huggingface.co/posts/daqc/944546045325401", "date_published": "2025-08-26T17:20:20.028645"}, {"id": "https://huggingface.co/posts/AdinaY/473496396970919", "image": "", "title": "MiniCPM-V 4.5 \ud83d\ude80 New MLLM for image, multi-image & video understanding, running even on your phone, released by OpenBMB", "content_text": "MiniCPM-V 4.5 \ud83d\ude80 New MLLM for image, multi-image & video understanding, running even on your phone, released by OpenBMB openbmb/MiniCPM-V-4_5 \u2728 SOTA vision language capability \u2728 96\u00d7 video token compression > high-FPS & long video reasoning \u2728 Switchable fast vs deep thinking modes \u2728 Strong OCR, document parsing, supports 30+ languages See translation", "url": "https://huggingface.co/posts/AdinaY/473496396970919", "date_published": "2025-08-26T17:20:20.028925"}, {"id": "https://huggingface.co/posts/jeffboudier/150612686071818", "image": "", "title": "Quick 30s demo of the new Hub > Azure AI integration to deploy HF models in your own Azure account. Now with Py and CLI!", "content_text": "Quick 30s demo of the new Hub > Azure AI integration to deploy HF models in your own Azure account. Now with Py and CLI! GG @ alvarobartt @ kramp @ pagezyhf See translation", "url": "https://huggingface.co/posts/jeffboudier/150612686071818", "date_published": "2025-08-26T17:20:20.029137"}]}