{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ronantakizawa/356197451153671", "image": "", "title": "Thank you", "content_text": "Thank you @ clem (Co-Founder & CEO of Hugging Face) for sharing my dataset on X / Twitter! ronantakizawa/github-top-developers #github #dataset See translation", "url": "https://huggingface.co/posts/ronantakizawa/356197451153671", "date_published": "2025-12-26T05:27:26.299256"}, {"id": "https://huggingface.co/posts/danielhanchen/419718257011904", "image": "", "title": "You can now run GLM-4.7, the new 355B parameter SOTA model on your local device (128GB RAM).\u2728", "content_text": "You can now run GLM-4.7, the new 355B parameter SOTA model on your local device (128GB RAM).\u2728 The model achieves SOTA performance on coding, agentic and chat benchmarks. GGUF: unsloth/GLM-4.7-GGUF Guide: https://docs.unsloth.ai/models/glm-4.7 See translation", "url": "https://huggingface.co/posts/danielhanchen/419718257011904", "date_published": "2025-12-26T05:27:26.299522"}, {"id": "https://huggingface.co/posts/dhruv3006/662739287947138", "image": "", "title": "OpenAPI specs are a great way to describe APIs in a clear, standard format. They provide a full overview of endpoints, methods, parameters etc. which makes working with APIs easier and more consistent.", "content_text": "OpenAPI specs are a great way to describe APIs in a clear, standard format. They provide a full overview of endpoints, methods, parameters etc. which makes working with APIs easier and more consistent. Voiden lets you turn your OpenAPI spec into organized, ready-to-use API request files. Just import your OpenAPI file, and you can immediately browse your endpoints, grouped by tags, and start testing without any manual setup. The generated requests come pre-configured but fully editable, so you can customize them as you want. If you want to get started with your existing APIs or try out new ones, this can save you quite some time. Read the docs here : https://docs.voiden.md/docs/getting-started-section/getting-started/openapi-imports/ See translation", "url": "https://huggingface.co/posts/dhruv3006/662739287947138", "date_published": "2025-12-26T05:27:26.299867"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/548414281502732", "image": "", "title": "Qwen Image Edit 2511 Free and Open Source Crushes Qwen Image Edit 2509 and Challenges Nano Banana Pro :", "content_text": "Qwen Image Edit 2511 Free and Open Source Crushes Qwen Image Edit 2509 and Challenges Nano Banana Pro : https://www.youtube.com/watch?v=YfuQuOk2sB0 Full tutorial link > https://www.youtube.com/watch?v=YfuQuOk2sB0 Full HF article here : https://huggingface.co/blog/MonsterMMORPG/qwen-image-edit-2511-free-and-open-source-crushes Qwen Image Edit 2511 model just published and it is literally competing against Nano Banana Pro at image editing tasks. With native whopping 2560x2560 pixels image output capability and with only 12 steps it is next level. With our installers and specially made Quant FP8 Scaled model, you can run this amazing beast even as low as 6 GB GPUs. In this tutorial, I have compared Qwen Image Edit 2511 with previous successor model Qwen Image 2509 with 12 different unique and hard prompts and cases. Everything is step by step explained and provided. Here check some comparison images See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/548414281502732", "date_published": "2025-12-26T05:27:26.300212"}, {"id": "https://huggingface.co/posts/dhruv3006/122199389172183", "image": "", "title": "Hey folks \ud83d\udc4b", "content_text": "Hey folks \ud83d\udc4b We\u2019re experimenting with a new response panel layout and would love your feedback.We\u2019re testing a more focused experience: - Only one response section open at a time (instead of multiple) - The response body now takes up most of the vertical space, making it easier to read and inspect The goal is simple: reduce clutter and keep the response as the main focus. That said, we know many developers are comfortable with the classic layout (Postman / Bruno-style), where multiple sections can stay open at once.What would you prefer? - A new, focused single-section layout - The classic multi-section layout - A toggle that lets you choose between both? Download Voiden here :https://voiden.md/download See translation", "url": "https://huggingface.co/posts/dhruv3006/122199389172183", "date_published": "2025-12-26T05:27:26.300582"}, {"id": "https://huggingface.co/posts/inoculatemedia/435094377049574", "image": "", "title": "I\u2019m opening the waitlist for what I believe to be the most advanced multimodal bridge for A/V professionals. Txt2img, img2video, editing, export to ProRes, apply Luts, Pexels and TouchDesigner integrations,  music and voice gen, multichannel mixing.", "content_text": "I\u2019m opening the waitlist for what I believe to be the most advanced multimodal bridge for A/V professionals. Txt2img, img2video, editing, export to ProRes, apply Luts, Pexels and TouchDesigner integrations, music and voice gen, multichannel mixing. Announcing: Lilikoi by Haawke AI Teaser video made entirely with Lilikoi: https://youtu.be/-O7DH7vFkYg?si=q2t5t6WjQCk2Cp0w Https://Lilikoi.haawke.com Technical brief: https://haawke.com/technical_brief.html See translation", "url": "https://huggingface.co/posts/inoculatemedia/435094377049574", "date_published": "2025-12-26T05:27:26.300887"}, {"id": "https://huggingface.co/posts/sergiopaniego/741361727784035", "image": "", "title": "The Christmas holidays are here! \ud83c\udf84", "content_text": "The Christmas holidays are here! \ud83c\udf84 Thinking about learning something new in AI? @ huggingface offers 12 FREE courses covering all the relevant topics, for every level of experience. A great challenge for the holidays (and worth saving for later \ud83d\ude44) Let\u2019s explore them! \ud83e\udde0 \ud835\udddf\ud835\udddf\ud835\udde0 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: large language models with HF tools https://huggingface.co/learn/llm-course \ud83e\udd16 \ud835\uddd4\ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: build and deploy AI agents https://huggingface.co/learn/agents-course \ud83c\udfa8 \ud835\uddd7\ud835\uddf6\ud835\uddf3\ud835\uddf3\ud835\ude02\ud835\ude00\ud835\uddf6\ud835\uddfc\ud835\uddfb \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: diffusion models with \ud83e\udd17 Diffusers https://huggingface.co/learn/diffusion-course \ud83d\udd0a \ud835\uddd4\ud835\ude02\ud835\uddf1\ud835\uddf6\ud835\uddfc \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: transformers for audio tasks https://huggingface.co/learn/audio-course \ud83c\udfae \ud835\uddd7\ud835\uddf2\ud835\uddf2\ud835\uddfd \ud835\udde5\ud835\udddf \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: deep reinforcement learning https://huggingface.co/learn/deep-rl-course \ud83d\udc41\ufe0f \ud835\uddd6\ud835\uddfc\ud835\uddfa\ud835\uddfa\ud835\ude02\ud835\uddfb\ud835\uddf6\ud835\ude01\ud835\ude06 \ud835\uddd6\ud835\uddfc\ud835\uddfa\ud835\uddfd\ud835\ude02\ud835\ude01\ud835\uddf2\ud835\uddff \ud835\udde9\ud835\uddf6\ud835\ude00\ud835\uddf6\ud835\uddfc\ud835\uddfb \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: modern computer vision with HF https://huggingface.co/learn/computer-vision-course \ud83e\uddbe \ud835\udde5\ud835\uddfc\ud835\uddef\ud835\uddfc\ud835\ude01\ud835\uddf6\ud835\uddf0\ud835\ude00 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2 (\ud835\udddf\ud835\uddf2\ud835\udde5\ud835\uddfc\ud835\uddef\ud835\uddfc\ud835\ude01): learning-based robotics https://huggingface.co/learn/robotics-course \ud83e\udde9 \ud835\udde0\ud835\uddd6\ud835\udde3 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: Model Context Protocol explained...", "url": "https://huggingface.co/posts/sergiopaniego/741361727784035", "date_published": "2025-12-26T05:27:26.301416"}, {"id": "https://huggingface.co/posts/nicolay-r/476967281276279", "image": "", "title": "Time-Effective LLM Querying in Information Retrieval Tasks", "content_text": "Time-Effective LLM Querying in Information Retrieval Tasks \ud83c\udfa4 Last week at Research Colloquium in Technische Universit\u00e4t Chemnitz, we presented a framework for time-effective data handling with prompting schemas. The video of the talk is now available \ud83d\udc47\ufe0f \ud83c\udfac\ufe0f Video: https://youtu.be/pa8jGOhHViI \ud83c\udf1f Framework (bulk-chain): https://github.com/nicolay-r/bulk-chain \ud83d\udd11 bulk-chain solves the following problems: \u2705 Effective handling CoT schema with big amount of prompts and parameters they are based on (batching policies) \u2705 Easy-to-apply for data-iterators (datasets handling) See translation", "url": "https://huggingface.co/posts/nicolay-r/476967281276279", "date_published": "2025-12-26T05:27:26.301753"}, {"id": "https://huggingface.co/posts/legolasyiu/800837423086765", "image": "", "title": "We release open-weight early experimental Codeforce metatune-gpt20b, fine tuned version of OpenAI's gpt-oss-20b model, this is one of the first public release recursive self improving AI.", "content_text": "We release open-weight early experimental Codeforce metatune-gpt20b, fine tuned version of OpenAI's gpt-oss-20b model, this is one of the first public release recursive self improving AI. EpistemeAI/Codeforce-metatune-gpt20b See translation", "url": "https://huggingface.co/posts/legolasyiu/800837423086765", "date_published": "2025-12-26T05:27:26.301971"}, {"id": "https://huggingface.co/posts/Javedalam/903512733694185", "image": "", "title": "Testing LFM2-2.6B-Exp on Differential Equations", "content_text": "Testing LFM2-2.6B-Exp on Differential Equations I recently tested LFM2-2.6B-Exp, an experimental language model developed by Liquid AI, to see how well it handles differential equations in a practical, step-by-step setting. LFM2-2.6B-Exp is notable for how it was trained: it is an RL-first experimental checkpoint, built without supervised fine-tuning warm-up or distillation. Reinforcement learning was applied sequentially, starting with instruction following and later expanding to knowledge and math. This makes it a particularly interesting model to evaluate beyond benchmark scores. In hands-on testing, the model performed surprisingly well for its size on standard undergraduate-level differential equations\u2014first-order ODEs, second-order linear equations with constant coefficients, and nonhomogeneous problems using undetermined coefficients. It followed instructions closely and produced clear, structured solution steps. However, the model showed limitations on more subtle methods,...", "url": "https://huggingface.co/posts/Javedalam/903512733694185", "date_published": "2025-12-26T05:27:26.302569"}]}