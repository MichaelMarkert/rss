{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/156941968722021", "image": "", "title": "We collaborated with Hugging Face to enable you to train MoE models 12\u00d7 faster with 35% less VRAM via our new Triton kernels (no accuracy loss). \ud83e\udd17", "content_text": "We collaborated with Hugging Face to enable you to train MoE models 12\u00d7 faster with 35% less VRAM via our new Triton kernels (no accuracy loss). \ud83e\udd17 Train gpt-oss locally on 12.8GB VRAM with our free notebooks: https://unsloth.ai/docs/new/faster-moe See translation", "url": "https://huggingface.co/posts/danielhanchen/156941968722021", "date_published": "2026-02-12T06:06:24.411319"}, {"id": "https://huggingface.co/posts/imnotkitty/153097834236594", "image": "", "title": "Made this with ByteDance's Seedance 2.0", "content_text": "Made this with ByteDance's Seedance 2.0 It's crazyyyyyy\ud83d\udd25\ud83d\udd25\ud83d\udd25 See translation", "url": "https://huggingface.co/posts/imnotkitty/153097834236594", "date_published": "2026-02-12T06:06:24.411556"}, {"id": "https://huggingface.co/posts/paasthaamz/730113013208944", "image": "", "title": "test", "content_text": "test", "url": "https://huggingface.co/posts/paasthaamz/730113013208944", "date_published": "2026-02-12T06:06:24.411739"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/552992030098244", "image": "", "title": "SeedVR2 and FlashVSR+ Studio Level Image and Video Upscaler Pro Released", "content_text": "SeedVR2 and FlashVSR+ Studio Level Image and Video Upscaler Pro Released Tutorial video : https://www.youtube.com/watch?v=bPWsg8DREiM \ud83d\udcc2 Resources & Links: \ud83d\udcbb SECourses Ultimate Video and Image Upscaler Pro Download Link : [ https://www.patreon.com/posts/Upscaler-Studio-Pro-150202809 ] \ud83d\ude86 Requirements Tutorial : https://youtu.be/DrhUHnYfwC0 \ud83d\udee0\ufe0f Requirements Written Post : [ https://www.patreon.com/posts/Windows-AI-Requirements-Setup-Guide-111553210 ] \ud83d\udc4b SECourses Discord Channel for 7/24 Support: [ https://bit.ly/SECoursesDiscord ] It has been long waited to have a studio level video and image upscaler app. Today we have publishing the version 1.0 of SECourses Ultimate Video and Image Upscaler Pro. It is supporting SeedVR2, FlashVSR+, Gan based upscalers, RIFE frame interpolation, full queue system, full batch folder processing, scene / chunked based processing and many more. It is fully working on every cloud and consumer GPUs like RTX 2000, 3000, 4000, 5000 series and H100, H200, B200,...", "url": "https://huggingface.co/posts/MonsterMMORPG/552992030098244", "date_published": "2026-02-12T06:06:24.412233"}, {"id": "https://huggingface.co/posts/MikeDoes/800845216560901", "image": "", "title": "Can you teach a giant like Google's Gemini to protect user privacy? A new step-by-step guide shows that the answer is a resounding \"yes.\"", "content_text": "Can you teach a giant like Google's Gemini to protect user privacy? A new step-by-step guide shows that the answer is a resounding \"yes.\" While powerful, large language models aren't specialized for privacy tasks. This tutorial by Analytics Vidhya walks through how to fine-tune Gemini into a dedicated tool for PII anonymization. To teach the model this critical skill, the author needed a robust dataset with thousands of clear 'before' and 'after' examples. We're thrilled they chose the Ai4Privacy pii-masking-200k dataset for this task. Our data provided the high-quality, paired examples of masked and unmasked text necessary to effectively train Gemini to identify and hide sensitive information accurately. This is a perfect example of how the community can use open-source data to add a crucial layer of safety to the world's most powerful models. Great work! \ud83d\udd17 Check out the full tutorial here: https://www.analyticsvidhya.com/blog/2024/03/guide-to-fine-tuning-gemini-for-masking-pii-...", "url": "https://huggingface.co/posts/MikeDoes/800845216560901", "date_published": "2026-02-12T06:06:24.412748"}, {"id": "https://huggingface.co/posts/umarbutler/642764051817350", "image": "", "title": "What happens when you annotate, extract, and disambiguate every entity mentioned in the longest U.S. Supreme Court decision in history? What if you then linked those entities to each other and visualized it as a network?", "content_text": "What happens when you annotate, extract, and disambiguate every entity mentioned in the longest U.S. Supreme Court decision in history? What if you then linked those entities to each other and visualized it as a network? This is the result of enriching all 241 pages and 111,267 words of Dred Scott v. Sandford (1857) with Kanon 2 Enricher in less than ten seconds at the cost of 47 cents. Dred Scott v. Sandford is the longest U.S. Supreme Court decision by far, and has variously been called \"the worst Supreme Court decision ever\" and \"the Court's greatest self-inflicted wound\" due to its denial of the rights of African Americans. Thanks to Kanon 2 Enricher, we now also know that the case contains 950 numbered paragraphs, 6 footnotes, 178 people mentioned 1,340 times, 99 locations mentioned 1,294 times, and 298 external documents referenced 940 times. For an American case, there are a decent number of references to British precedents (27 to be exact), including the Magna Carta (\u00b6 928)....", "url": "https://huggingface.co/posts/umarbutler/642764051817350", "date_published": "2026-02-12T06:06:24.413333"}, {"id": "https://huggingface.co/posts/frumu/690979114080288", "image": "", "title": "I\u2019m looking for Mac/Windows/Linux testers and contributors for Tandem, an open-source, local-first AI desktop workspace.", "content_text": "I\u2019m looking for Mac/Windows/Linux testers and contributors for Tandem, an open-source, local-first AI desktop workspace. Runs on your machine (works great with local LLMs like Ollama / LM Studio) Built with Tauri + a sidecar runtime, so it\u2019s a single install Focused on making agent workflows usable for non-developers (approvals + undo) If you\u2019re willing to test installs (especially macOS) or poke at bugs, I\u2019d really appreciate it. Repo: https://github.com/frumu-ai/tandem See translation", "url": "https://huggingface.co/posts/frumu/690979114080288", "date_published": "2026-02-12T06:06:24.413653"}, {"id": "https://huggingface.co/posts/AdinaY/533197427744906", "image": "", "title": "Ming-flash-omni 2.0 \ud83d\ude80 New open omni-MLLM released by Ant Group", "content_text": "Ming-flash-omni 2.0 \ud83d\ude80 New open omni-MLLM released by Ant Group inclusionAI/Ming-flash-omni-2.0 \u2728 MIT license \u2728 MoE - 100B/6B active \u2728 Zero-shot voice cloning + controllable audio \u2728 Fine-grained visual knowledge grounding See translation", "url": "https://huggingface.co/posts/AdinaY/533197427744906", "date_published": "2026-02-12T06:06:24.413901"}, {"id": "https://huggingface.co/posts/alexnasa/577067311800070", "image": "", "title": "Now with extra functionality at the same LTX-2 HF Space, you can now add also your last frame along side your first frame to guide the generated videos by choosing our frame interpolation mode...", "content_text": "Now with extra functionality at the same LTX-2 HF Space, you can now add also your last frame along side your first frame to guide the generated videos by choosing our frame interpolation mode... Try it out: alexnasa/ltx-2-TURBO See translation", "url": "https://huggingface.co/posts/alexnasa/577067311800070", "date_published": "2026-02-12T06:06:24.414116"}, {"id": "https://huggingface.co/posts/MikeDoes/444764433252763", "image": "", "title": "You don't need a massive research lab to build a privacy-preserving AI tool thanks to open datasets. With the right ingredients, anyone can.", "content_text": "You don't need a massive research lab to build a privacy-preserving AI tool thanks to open datasets. With the right ingredients, anyone can. A fantastic new guide shows how the democratization of AI is helping to advance safety. It walks through how to use Google's new fine-tuning API to turn Gemini into a powerful tool for PII anonymization. This project was powered by two key components: An accessible platform from Google. High-quality, open-source training data. We are honored that the author chose the Ai4Privacy pii-masking-200k dataset to provide the crucial data foundation. Our dataset delivered the volume and structure needed to successfully teach a state-of-the-art model how to perform a critical privacy function. This is the future we're working towards: powerful platforms combined with open, safety-focused data to create tools that benefit everyone. Kudos to the author for showcasing what's possible! \ud83d\udd17 Read the full step-by-step guide:...", "url": "https://huggingface.co/posts/MikeDoes/444764433252763", "date_published": "2026-02-12T06:06:24.414604"}]}