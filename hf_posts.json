{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/codelion/602031524113549", "image": "", "title": "Introducing Dhara-70M: A diffusion language model that achieves 3.8x higher throughput than autoregressive models!", "content_text": "Introducing Dhara-70M: A diffusion language model that achieves 3.8x higher throughput than autoregressive models! Key findings from our research on optimal architectures for small language models: \u2192 Depth beats width: 32 layers outperforms 12 layers at the same parameter count \u2192 Best-in-class factuality: 47.5% on TruthfulQA \u2192 10x training efficiency using WSD (Warmup-Stable-Decay) conversion \u2192 Canon layers add only 0.13% parameters but improve reasoning We trained on 1B tokens using the optimal 50-30-20 dataset mix (PDFs + filtered web + educational content), then converted to diffusion with just 100M additional tokens. Blog: https://huggingface.co/blog/codelion/optimal-model-architecture Model: codelion/dhara-70m See translation", "url": "https://huggingface.co/posts/codelion/602031524113549", "date_published": "2025-12-27T13:31:49.348924"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/548414281502732", "image": "", "title": "Qwen Image Edit 2511 Free and Open Source Crushes Qwen Image Edit 2509 and Challenges Nano Banana Pro :", "content_text": "Qwen Image Edit 2511 Free and Open Source Crushes Qwen Image Edit 2509 and Challenges Nano Banana Pro : https://www.youtube.com/watch?v=YfuQuOk2sB0 Full tutorial link > https://www.youtube.com/watch?v=YfuQuOk2sB0 Full HF article here : https://huggingface.co/blog/MonsterMMORPG/qwen-image-edit-2511-free-and-open-source-crushes Qwen Image Edit 2511 model just published and it is literally competing against Nano Banana Pro at image editing tasks. With native whopping 2560x2560 pixels image output capability and with only 12 steps it is next level. With our installers and specially made Quant FP8 Scaled model, you can run this amazing beast even as low as 6 GB GPUs. In this tutorial, I have compared Qwen Image Edit 2511 with previous successor model Qwen Image 2509 with 12 different unique and hard prompts and cases. Everything is step by step explained and provided. Here check some comparison images See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/548414281502732", "date_published": "2025-12-27T13:31:49.349286"}, {"id": "https://huggingface.co/posts/ronantakizawa/356197451153671", "image": "", "title": "Thank you", "content_text": "Thank you @ clem (Co-Founder & CEO of Hugging Face) for sharing my dataset on X / Twitter! ronantakizawa/github-top-developers #github #dataset See translation", "url": "https://huggingface.co/posts/ronantakizawa/356197451153671", "date_published": "2025-12-27T13:31:49.349521"}, {"id": "https://huggingface.co/posts/dhruv3006/122199389172183", "image": "", "title": "Hey folks \ud83d\udc4b", "content_text": "Hey folks \ud83d\udc4b We\u2019re experimenting with a new response panel layout and would love your feedback.We\u2019re testing a more focused experience: - Only one response section open at a time (instead of multiple) - The response body now takes up most of the vertical space, making it easier to read and inspect The goal is simple: reduce clutter and keep the response as the main focus. That said, we know many developers are comfortable with the classic layout (Postman / Bruno-style), where multiple sections can stay open at once.What would you prefer? - A new, focused single-section layout - The classic multi-section layout - A toggle that lets you choose between both? Download Voiden here :https://voiden.md/download See translation", "url": "https://huggingface.co/posts/dhruv3006/122199389172183", "date_published": "2025-12-27T13:31:49.349891"}, {"id": "https://huggingface.co/posts/MikeDoes/284489022074040", "image": "", "title": "What if an AI agent could be tricked into stealing your data, just by reading a tool's description? A new paper reports it's possible.", "content_text": "What if an AI agent could be tricked into stealing your data, just by reading a tool's description? A new paper reports it's possible. The \"Attractive Metadata Attack\" paper details this stealthy new threat. To measure the real-world impact of their attack, the researchers needed a source of sensitive data for the agent to leak. We're proud that the AI4Privacy corpus was used to create the synthetic user profiles containing standardized PII for their experiments. This is a perfect win-win. Our open-source data helped researchers Kanghua Mo, \u9f99\u6631\u4e1e, Zhihao Li from Guangzhou University and The Hong Kong Polytechnic University to not just demonstrate a new attack, but also quantify its potential for harm. This data-driven evidence is what pushes the community to build better, execution-level defenses for AI agents. \ud83d\udd17 Check out their paper to see how easily an agent's trust in tool metadata could be exploited: https://arxiv.org/pdf/2508.02110 #OpenSource #DataPrivacy #LLM #Anonymization...", "url": "https://huggingface.co/posts/MikeDoes/284489022074040", "date_published": "2025-12-27T13:31:49.350349"}, {"id": "https://huggingface.co/posts/inoculatemedia/435094377049574", "image": "", "title": "I\u2019m opening the waitlist for what I believe to be the most advanced multimodal bridge for A/V professionals. Txt2img, img2video, editing, export to ProRes, apply Luts, Pexels and TouchDesigner integrations,  music and voice gen, multichannel mixing.", "content_text": "I\u2019m opening the waitlist for what I believe to be the most advanced multimodal bridge for A/V professionals. Txt2img, img2video, editing, export to ProRes, apply Luts, Pexels and TouchDesigner integrations, music and voice gen, multichannel mixing. Announcing: Lilikoi by Haawke AI Teaser video made entirely with Lilikoi: https://youtu.be/-O7DH7vFkYg?si=q2t5t6WjQCk2Cp0w Https://Lilikoi.haawke.com Technical brief: https://haawke.com/technical_brief.html See translation", "url": "https://huggingface.co/posts/inoculatemedia/435094377049574", "date_published": "2025-12-27T13:31:49.350654"}, {"id": "https://huggingface.co/posts/kanaria007/731781965803753", "image": "", "title": "\u2705 New Article: *Hardware Paths for Structured Intelligence* (Draft v0.1)", "content_text": "\u2705 New Article: *Hardware Paths for Structured Intelligence* (Draft v0.1) Title: \ud83e\udde9 From CPUs to SI-GSPU: Hardware Paths for Structured Intelligence \ud83d\udd17 https://huggingface.co/blog/kanaria007/hardware-paths-for-si --- Summary: Most \u201cAI hardware\u201d is built for dense matrix math. But real-world intelligence systems bottleneck elsewhere: **semantic parsing, structured memory, governance checks, auditability, and evaluation loops** \u2014 the parts that turn models into safe, resilient systems. This article maps the gap clearly, and sketches how a future **SI-GSPU class accelerator** fits: not \u201ca better GPU,\u201d but a co-processor for **semantics + governance runtime**. > GPUs carry the models. > S I-GSPU carries the rules that decide when models are allowed to act. --- Why It Matters: \u2022 Explains *why* \u201cmore GPU\u201d doesn\u2019t fix governance-heavy AI stacks \u2022 Identifies what to accelerate: semantic transforms, memory ops, coverage/metrics, effect ledgers \u2022 Shows how to build **SI-GSPU-ready** systems...", "url": "https://huggingface.co/posts/kanaria007/731781965803753", "date_published": "2025-12-27T13:31:49.351257"}, {"id": "https://huggingface.co/posts/danielhanchen/419718257011904", "image": "", "title": "You can now run GLM-4.7, the new 355B parameter SOTA model on your local device (128GB RAM).\u2728", "content_text": "You can now run GLM-4.7, the new 355B parameter SOTA model on your local device (128GB RAM).\u2728 The model achieves SOTA performance on coding, agentic and chat benchmarks. GGUF: unsloth/GLM-4.7-GGUF Guide: https://docs.unsloth.ai/models/glm-4.7 See translation", "url": "https://huggingface.co/posts/danielhanchen/419718257011904", "date_published": "2025-12-27T13:31:49.351518"}, {"id": "https://huggingface.co/posts/Parveshiiii/283996096084237", "image": "", "title": "Hey everyone!", "content_text": "Hey everyone! We\u2019re excited to introduce our new Telegram group: https://t.me/XenArcAI This space is built for **model builders, tech enthusiasts, and developers** who want to learn, share, and grow together. Whether you\u2019re just starting out or already deep into AI/ML, you\u2019ll find a supportive community ready to help with knowledge, ideas, and collaboration. \ud83d\udca1 Join us to: - Connect with fellow developers and AI enthusiasts - Share your projects, insights, and questions - Learn from others and contribute to a growing knowledge base \ud83d\udc49 If you\u2019re interested, hop in and be part of the conversation: https://t.me/XenArcAI See translation", "url": "https://huggingface.co/posts/Parveshiiii/283996096084237", "date_published": "2025-12-27T13:31:49.351855"}, {"id": "https://huggingface.co/posts/kanaria007/140378798774766", "image": "", "title": "\u2705 New Article: *Pattern-Learning-Bridge (PLB)*", "content_text": "\u2705 New Article: *Pattern-Learning-Bridge (PLB)* Title: \ud83e\udde9 Pattern-Learning-Bridge: How SI-Core Actually Learns From Its Own Failures \ud83d\udd17 https://huggingface.co/blog/kanaria007/learns-from-its-own-failures --- Summary: Most stacks \u201clearn\u201d by fine-tuning weights and redeploying \u2014 powerful, but opaque. SI-Core already produces *structured evidence* (jump logs, ethics traces, effect ledgers, goal vectors, rollback traces), so learning can be *structural* instead: *Upgrade policies, compensators, SIL code, and goal structures \u2014 using runtime evidence.* > Learning isn\u2019t a model tweak. > *It\u2019s upgrading the structures that shape behavior.* --- Why It Matters: \u2022 Makes improvement *localized and explainable* (what changed, where, and why) \u2022 Keeps \u201cself-improvement\u201d *governable* (versioned deltas + review + CI/CD) \u2022 Turns incidents/metric drift into *actionable patches*, not postmortem PDFs \u2022 Scales to real ops: ethics policies, rollback plans, semantic compression, goal estimators --- What\u2019s...", "url": "https://huggingface.co/posts/kanaria007/140378798774766", "date_published": "2025-12-27T13:31:49.352381"}]}