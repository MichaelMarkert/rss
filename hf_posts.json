{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/merterbak/235850739835485", "image": "", "title": "Qwen 3 can launch very soon. \ud83d\udc40", "content_text": "Qwen 3 can launch very soon. \ud83d\udc40 https://github.com/ggml-org/llama.cpp/pull/12828 See translation", "url": "https://huggingface.co/posts/merterbak/235850739835485", "date_published": "2025-04-10T17:19:40.170329"}, {"id": "https://huggingface.co/posts/hesamation/789492772324435", "image": "", "title": "Google published a 69-page whitepaper on Prompt Engineering and its best practices, a must-read if you are using LLMs in production:", "content_text": "Google published a 69-page whitepaper on Prompt Engineering and its best practices, a must-read if you are using LLMs in production: > zero-shot, one-shot, few-shot > system prompting > chain-of-thought (CoT) > ReAct LINK: https://www.kaggle.com/whitepaper-prompt-engineering > code prompting > best practices See translation", "url": "https://huggingface.co/posts/hesamation/789492772324435", "date_published": "2025-04-10T17:19:40.170620"}, {"id": "https://huggingface.co/posts/fdaudens/513864434208106", "image": "", "title": "\ud83c\udfa8 Designers, meet OmniSVG! This new model helps you create professional vector graphics from text/images, generate editable SVGs from icons to detailed characters, convert rasters to vectors, maintain style consistency with references, and integrate into your workflow.", "content_text": "\ud83c\udfa8 Designers, meet OmniSVG! This new model helps you create professional vector graphics from text/images, generate editable SVGs from icons to detailed characters, convert rasters to vectors, maintain style consistency with references, and integrate into your workflow. @ OmniSVG See translation", "url": "https://huggingface.co/posts/fdaudens/513864434208106", "date_published": "2025-04-10T17:19:40.170919"}, {"id": "https://huggingface.co/posts/jasoncorkill/726469711226418", "image": "", "title": "\ud83d\udd25 Yesterday was a fire day!", "content_text": "\ud83d\udd25 Yesterday was a fire day! We dropped two brand-new datasets capturing Human Preferences for text-to-video and text-to-image generations powered by our own crowdsourcing tool! Whether you're working on model evaluation, alignment, or fine-tuning, this is for you. 1. Text-to-Video Dataset (Pika 2.2 model): Rapidata/text-2-video-human-preferences-pika2.2 2. Text-to-Image Dataset (Reve-AI Halfmoon): Rapidata/Reve-AI-Halfmoon_t2i_human_preference Let\u2019s train AI on AI-generated content with humans in the loop. Let\u2019s make generative models that actually get us. See translation", "url": "https://huggingface.co/posts/jasoncorkill/726469711226418", "date_published": "2025-04-10T17:19:40.171268"}, {"id": "https://huggingface.co/posts/danielhanchen/859959880164586", "image": "", "title": "You can now run Llama 4 on your own local device! \ud83e\udd99", "content_text": "You can now run Llama 4 on your own local device! \ud83e\udd99 Run our Dynamic 1.78-bit and 2.71-bit Llama 4 GGUFs: unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF You can run them on llama.cpp and other inference engines. See our guide here: https://docs.unsloth.ai/basics/tutorial-how-to-run-and-fine-tune-llama-4 See translation", "url": "https://huggingface.co/posts/danielhanchen/859959880164586", "date_published": "2025-04-10T17:19:40.171546"}, {"id": "https://huggingface.co/posts/ajibawa-2023/282296415348325", "image": "", "title": "Hi All,  I recently released two Audio datasets  which are generated using my earlier released dataset:", "content_text": "Hi All, I recently released two Audio datasets which are generated using my earlier released dataset: ajibawa-2023/Children-Stories-Collection First Audio Dataset:https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection-Large has 5600++ stories in .mp3 format. Second Audio Dataset:https://huggingface.co/datasets/ajibawa-2023/Audio-Children-Stories-Collection has 600 stories in .mp3 format. See translation", "url": "https://huggingface.co/posts/ajibawa-2023/282296415348325", "date_published": "2025-04-10T17:19:40.171823"}, {"id": "https://huggingface.co/posts/fcakyon/248454580146320", "image": "", "title": "\ud83c\udf89 GitHub selected the ultralytics computer vision project, known for its YOLOv8/YOLO11 real-time SOTA computer vision models, as one of the top 5 open-source projects for first-time contributors in 2024!", "content_text": "\ud83c\udf89 GitHub selected the ultralytics computer vision project, known for its YOLOv8/YOLO11 real-time SOTA computer vision models, as one of the top 5 open-source projects for first-time contributors in 2024! Link to the project: https://github.com/ultralytics/ultralytics Link to the full GitHub 2024 recap report: https://github.blog/news-insights/octoverse/octoverse-2024/ See translation", "url": "https://huggingface.co/posts/fcakyon/248454580146320", "date_published": "2025-04-10T17:19:40.172112"}, {"id": "https://huggingface.co/posts/Steven10429/887336506731659", "image": "", "title": "I got rejected from llama4.", "content_text": "I got rejected from llama4. So that means I can use quantinized model without following their TOS. Interesting. See translation", "url": "https://huggingface.co/posts/Steven10429/887336506731659", "date_published": "2025-04-10T17:19:40.172334"}, {"id": "https://huggingface.co/posts/jsulz/855747629260036", "image": "", "title": "What does it mean when models share the same bytes?", "content_text": "What does it mean when models share the same bytes? We've investigated some quants and have seen that a considerable portion of quantizations of the same model share the same bytes and can be deduplicated to save considerable upload time for quantizers on the Hub. This space where we crack open a repo from @ bartowski shows we can get significant dedupe xet-team/quantization-dedup You can get a sense of why by reading this write-up: https://github.com/bartowski1182/llm-knowledge/blob/main/quantization/quantization.md But what about finetuned models? Since going into production the xet-team has migrated hundreds of repositories on the Hub to our storage layer, including classic \"pre-Hub\" open-source models like FacebookAI/xlm-roberta-large (XLM-R) from FacebookAI XLM-R, introduced in 2019, set new benchmarks for multilingual NLP by learning shared representations across 100 languages. It was then fine-tuned on English, Spanish, Dutch, and German, generating language-specific...", "url": "https://huggingface.co/posts/jsulz/855747629260036", "date_published": "2025-04-10T17:19:40.172808"}, {"id": "https://huggingface.co/posts/csabakecskemeti/971611835182279", "image": "", "title": "Why the  'how many r's in strawberry' prompt \"breaks\" llama4? :D", "content_text": "Why the 'how many r's in strawberry' prompt \"breaks\" llama4? :D Quants DevQuasar/meta-llama.Llama-4-Scout-17B-16E-Instruct-GGUF See translation", "url": "https://huggingface.co/posts/csabakecskemeti/971611835182279", "date_published": "2025-04-10T17:19:40.173030"}]}