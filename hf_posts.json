{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Jaward/445538723467397", "image": "", "title": "Awesome intro to LLM course \"Language Modeling from Scratch\" by stanford. love the aesthetics behind the lecture notes, notes-in-code genius idea\ud83d\udc4d", "content_text": "Awesome intro to LLM course \"Language Modeling from Scratch\" by stanford. love the aesthetics behind the lecture notes, notes-in-code genius idea\ud83d\udc4d Course site: https://stanford-cs336.github.io/spring2025/ Repo: https://github.com/stanford-cs336/spring2025-lectures Videos: https://www.youtube.com/playlist?list=PLoROMvodv4rOY23Y0BoGoBGgQ1zmU_MT_ See translation", "url": "https://huggingface.co/posts/Jaward/445538723467397", "date_published": "2025-06-25T13:37:35.646856"}, {"id": "https://huggingface.co/posts/bartowski/460622149989234", "image": "", "title": "Was going to post this on /r/LocalLLaMa, but apparently it's without moderation at this time :')", "content_text": "Was going to post this on /r/LocalLLaMa, but apparently it's without moderation at this time :') bartowski/mistralai_Mistral-Small-3.2-24B-Instruct-2506-GGUF Was able to use previous mistral chat templates, some hints from Qwen templates, and Claude to piece together a seemingly working chat template, tested it with llama.cpp server and got perfect results, though lmstudio still seems to be struggling for some reason (don't know how to specify a jinja file there) Outlined the details of the script and results in my llama.cpp PR to add the jinja template: https://github.com/ggml-org/llama.cpp/pull/14349 Start server with a command like this: ./llama-server -m /models/mistralai_Mistral-Small -3 .2 -24 B-Instruct -2506 -Q4_K_M.gguf --jinja --chat-template-file /models/Mistral-Small -3 .2 -24 B-Instruct -2506 .jinja and it should be perfect! Hoping it'll work for ALL tools if lmstudio gets an update or something, not just llama.cpp, but very happy to see it works flawlessly in llama.cpp...", "url": "https://huggingface.co/posts/bartowski/460622149989234", "date_published": "2025-06-25T13:37:35.647284"}, {"id": "https://huggingface.co/posts/merve/128480916969769", "image": "", "title": "Release picks of the past week is here!  Find more models, datasets, Spaces here", "content_text": "Release picks of the past week is here! Find more models, datasets, Spaces here merve/june-20-releases-68594824d1f4dfa61aee3433 \ud83d\uddbc\ufe0f VLMs/OCR > moonshotai/Kimi-VL-A3B-Thinking-2506 is a powerful reasoning vision LM, 3B active params, smarter with less tokens, supports long documents, videos \ud83d\udc4f (OS) > nanonets/Nanonets-OCR-s is 3.75B params OCR model based on Qwen2.5VL-3B-Instruct (OS) \ud83d\udcac LLMs > moonshotai/Kimi-Dev-72B is a strong coding model based on Qwen2.5-72B (OS) > Mistral released mistralai/Mistral-Small-3.2-24B-Instruct-2506 , an update to their former model with better function calling & instruction following (OS) \ud83d\udde3\ufe0f Audio > Google released google/magenta-realtime , real time music generation & audio synthesis (cc-by-4) > kyutai released new speech-to-text models that come in 1B & 2B ( kyutai/stt-1b-en_fr , stt-2b-en_fr) with 0.5s and 2.5s delay 3D > Tencent released tencent/Hunyuan3D-2.1 an image-to-3D model (see below) See translation", "url": "https://huggingface.co/posts/merve/128480916969769", "date_published": "2025-06-25T13:37:35.647736"}, {"id": "https://huggingface.co/posts/Abhaykoul/997219525730173", "image": "", "title": "\ud83d\ude80 Try Dhanishtha 2.0 \u2013 The Intermediate Thinking Model", "content_text": "\ud83d\ude80 Try Dhanishtha 2.0 \u2013 The Intermediate Thinking Model Meet Dhanishtha 2.0, the world's first LLM designed to _think like a philosopher, respond like a poet, and reflect like a human_ \u2014 all in real time. Unlike traditional models that follow a single-pass think \u2192 answer pattern, Dhanishtha can think, rethink, self-evaluate, and refine mid-response using multi-phase cognitive structures like <think> and <ser> blocks. \u26a1\ufe0f Highlights: - Token-Efficient \u2014 Uses up to 79% fewer tokens than DeepSeek R1 on questions - Emotionally Aware Reasoning \u2014 Thinks and reflects in real-time, no fluff --- \ud83d\udcbb Try It Now with the SDK from HelpingAI import HAI # pip install HelpingAI ==1.1.1 from rich import print hai = HAI( api_key = \"hl-***********************\" ) response = hai.chat.completions.create( model = \"Dhanishtha-2.0-preview\" , messages=[{ \"role\" : \"user\" , \"content\" : \"What is the value of \u222b0\u221e\ud835\udc653/\ud835\udc65\u22121\ud835\udc51\ud835\udc65 ?\" }], stream = True , hide_think = False # Hide or show models thinking ) for chunk in...", "url": "https://huggingface.co/posts/Abhaykoul/997219525730173", "date_published": "2025-06-25T13:37:35.648295"}, {"id": "https://huggingface.co/posts/yeonseok-zeticai/727857049396772", "image": "", "title": "Hi everyone,", "content_text": "Hi everyone, I\u2019ve been running small language models (SLLMs) directly on smartphones \u2014 completely offline, with no cloud backend or server API calls. I wanted to share: 1. \u26a1 Tokens/sec performance across several SLLMs 2. \ud83e\udd16 Observations on hardware utilization (where the workload actually runs) 3. \ud83d\udccf Trade-offs between model size, latency, and feasibility for mobile apps There are reports for below models - QWEN3 0.6B - NVIDIA/Nemotron QWEN 1.5B - SimpleScaling S1 - TinyLlama - Unsloth tuned Llama 3.2 1B - Naver HyperClova 0.5B \ud83d\udcdcComparable Benchmark reports (no cloud, all on-device): I\u2019d really value your thoughts on: - Creative ideas to further optimize inference under these hardware constraints - Other compact LLMs worth testing on-device - Experiences you\u2019ve had trying to deploy LLMs at the edge If there\u2019s interest, I\u2019m happy to share more details on the test setup, hardware specs, or the tooling we used for these comparisons. Thanks for taking a look, and you can build your own...", "url": "https://huggingface.co/posts/yeonseok-zeticai/727857049396772", "date_published": "2025-06-25T13:37:35.648759"}, {"id": "https://huggingface.co/posts/pagezyhf/610118153924016", "image": "", "title": "Hackathons in Paris on July 5th and 6th!", "content_text": "Hackathons in Paris on July 5th and 6th! Hugging Face just wrapped 4 months of deep work with AMD to push kernel-level optimization on their MI300X GPUs. Now, it's time to share everything we learned. Join us in Paris at STATION F for a hands-on weekend of workshops and a hackathon focused on making open-source LLMs faster and more efficient on AMD. Prizes, amazing host speakers, ... if you want more details, navigate to https://lu.ma/fmvdjmur ! See translation", "url": "https://huggingface.co/posts/pagezyhf/610118153924016", "date_published": "2025-06-25T13:37:35.649038"}, {"id": "https://huggingface.co/posts/BFFree/190836494252067", "image": "", "title": "Working on some chess set concepts. I went towards minimal sculpted shapes then returned to some traditionalism.", "content_text": "Working on some chess set concepts. I went towards minimal sculpted shapes then returned to some traditionalism. See translation", "url": "https://huggingface.co/posts/BFFree/190836494252067", "date_published": "2025-06-25T13:37:35.649232"}, {"id": "https://huggingface.co/posts/yeonseok-zeticai/882369268235109", "image": "", "title": "\ud83d\udcab Next-Level On-Device AI Showdown", "content_text": "\ud83d\udcab Next-Level On-Device AI Showdown \ud83e\udebd See It to Believe It, How QWEN4b works at On-device environment without expensive GPU Cloud server? We\u2019ve crafted a side-by-side demo video showcasing both Jan-Nano and QWEN 4B in action\u2014no more wondering which model reigns supreme. Click play, compare their speeds, accuracy, and memory footprints, and decide which one fits your needs best! \ud83d\udc4b Why You Can\u2019t Miss This We are actively creating runnable sLLM environments for On-device AI. You can just build On-device AI apps within few hours. Including Jan-Nano, QWEN4b, there are several sLLM models ready to be used on your AI application!. \ud83e\udd11 Please feel free to use, because it is free to use!. Ready to Compare? Watch now, draw your own conclusions, and let us know which model you\u2019d deploy in your next edge-AI project! \ud83c\udf0d\ud83d\udca1 #OnDeviceAI #EdgeAI #AIShowdown #MLOptimization #DemoVideo #AIComparison See translation", "url": "https://huggingface.co/posts/yeonseok-zeticai/882369268235109", "date_published": "2025-06-25T13:37:35.649652"}, {"id": "https://huggingface.co/posts/cgeorgiaw/508678634223532", "image": "", "title": "Huge new bio datasets just dropped!!!", "content_text": "Huge new bio datasets just dropped!!! Check out them out @ ginkgo-datapoints Read the blog for more info: https://huggingface.co/blog/cgeorgiaw/gdp See translation", "url": "https://huggingface.co/posts/cgeorgiaw/508678634223532", "date_published": "2025-06-25T13:37:35.649860"}, {"id": "https://huggingface.co/posts/ghostai1/349800616277230", "image": "", "title": "# The future trends of Explainable AI in 2024", "content_text": "# The future trends of Explainable AI in 2024 The world of artificial intelligence (AI) is constantly evolving, with new advancements and applications emerging every day. One trend that has captured the attention of many is Explainable AI. As the name suggests, this revolutionary technology aims to provide a clear, understandable explanation for the decisions and actions taken by AI systems. In the future, Explainable AI is expected to become even more sophisticated, with advanced algorithms and techniques being developed to better interpret and analyze the vast amounts of data generated by AI systems. This will not only make AI systems more reliable and trustworthy, but it will also help to demystify the world of AI, making it more accessible to a wider audience. As the demand for AI solutions grows, the need for Explainable AI will become increasingly important. Businesses, governments, and individuals will require clear, concise explanations for the AI systems they are using,...", "url": "https://huggingface.co/posts/ghostai1/349800616277230", "date_published": "2025-06-25T13:37:35.650309"}]}