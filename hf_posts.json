{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/579968620456275", "image": "", "title": "You can now fine-tune embedding models in our free Unsloth notebook! \ud83e\udd17", "content_text": "You can now fine-tune embedding models in our free Unsloth notebook! \ud83e\udd17 Fine-tuning embedding models improves retrieval & RAG by aligning vectors to your domain-specific notion of similarity, improving search, clustering, and recommendations on your data. \u2b50 Blog + Notebooks: https://unsloth.ai/docs/new/embedding-finetuning Unsloth trains embedding models 1.8-3.3x faster with 20% less VRAM, 2x longer context & no accuracy loss vs. FA2 setups. We'd like to thank Hugging Face and Unsloth contributor: electroglyph for making this possible! See translation", "url": "https://huggingface.co/posts/danielhanchen/579968620456275", "date_published": "2026-01-23T05:32:59.215276"}, {"id": "https://huggingface.co/posts/hassenhamdi/338157395556750", "image": "", "title": "Google published the paper. I shipped the code. \ud83d\ude80", "content_text": "Google published the paper. I shipped the code. \ud83d\ude80 DeepMind just released PACEvolve (Progress-Aware Consistent Evolution), a massive overhaul of the AlphaEvolve framework. It solves the critical issues of \"Context Pollution\" and \"Mode Collapse\" that have historically crippled evolutionary coding agents. But there was no public implementation. So I built one. Introducing OpenPACEvolve: A fully open-source, production-grade implementation of the PACEvolve framework. \ud83d\udee0 I engineered this framework solo, but I wasn't working alone. I orchestrated a custom coding agents powered by Claude Opus 4.5 as Engineer and Gemini Pro 3 Preview ensuring fiedelity and quallty. By leveraging these SOTA models, I was able to translate complex theoretical research into functional, modular Python architecture in record time. This is what the future of AI engineering looks like: Human architectural oversight + AI velocity. \ud83e\udde0 What OpenPACEvolve Solves: Unlike standard agents that get \"stuck\" in loops, this...", "url": "https://huggingface.co/posts/hassenhamdi/338157395556750", "date_published": "2026-01-23T05:32:59.215920"}, {"id": "https://huggingface.co/posts/branikita/663180639810394", "image": "", "title": "Our engineer Alan from", "content_text": "Our engineer Alan from https://robonine.com/ (Educational Robotics) integrated Feetech STS3250 and STS3215 servo motors into the prototype and completed the first test run of a 6-DOF semi-SCARA manipulator. During motion, the structure demonstrates high stiffness with no visible backlash or mechanical play. The kinematic chain remains stable throughout the test trajectory, confirming the rigidity of the mechanical design and joint assembly. The next stage includes full assembly with all actuators operating in backlash compensation mode, followed by quantitative measurement of positioning accuracy and repeatability. See translation", "url": "https://huggingface.co/posts/branikita/663180639810394", "date_published": "2026-01-23T05:32:59.216237"}, {"id": "https://huggingface.co/posts/mitkox/833172754531021", "image": "", "title": "GLM-4.7-Flash is fast, good and cheap.", "content_text": "GLM-4.7-Flash is fast, good and cheap. 3,074 tokens/sec peak at 200k tokens context window on my desktop PC. Works with Claude Code and opencode for hours. No errors, drop-in replacement of the Anthropic cloud AI. MIT licensed, open weights, free for commercial use and modifications. Supports speculative decoding using MTP, which is highly effective in mitigating latency. Great for on device AI coding as AWQ 4bit at 18.5 GB. Hybrid inference on a single consumer GPU + CPU RAM. See translation", "url": "https://huggingface.co/posts/mitkox/833172754531021", "date_published": "2026-01-23T05:32:59.216526"}, {"id": "https://huggingface.co/posts/projectlosangeles/732365874551092", "image": "", "title": "Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI!", "content_text": "Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI! projectlosangeles/Orpheus-Karaoke See translation", "url": "https://huggingface.co/posts/projectlosangeles/732365874551092", "date_published": "2026-01-23T05:32:59.216724"}, {"id": "https://huggingface.co/posts/Reubencf/519964840142107", "image": "", "title": "Now Live: The", "content_text": "Now Live: The Reubencf/Nano_Banana_Editor now includes 10 free requests/day! \ud83c\udf4c I'm personally sponsoring these credits to help make open AI accessible to all. (Note: Limits are subject to change based on funding). Enjoy ! See translation", "url": "https://huggingface.co/posts/Reubencf/519964840142107", "date_published": "2026-01-23T05:32:59.216961"}, {"id": "https://huggingface.co/posts/mahimairaja/981245341655161", "image": "", "title": "Lacking vllm support  for Transformers v5, frustrating only me?", "content_text": "Lacking vllm support for Transformers v5, frustrating only me? See translation", "url": "https://huggingface.co/posts/mahimairaja/981245341655161", "date_published": "2026-01-23T05:32:59.217142"}, {"id": "https://huggingface.co/posts/efecelik/696705775855438", "image": "", "title": "\ud83c\udfae Introducing: Paper Popularity Game", "content_text": "\ud83c\udfae Introducing: Paper Popularity Game Think you know which AI papers go viral? Test your instincts! I built a little game where you try to guess the popularity of AI research papers from the Hugging Face Daily Papers feed. How it works: You'll see two papers side by side\u2014read the titles, check the abstracts, and pick which one you think got more upvotes from the HF community. It's a great way to discover trending AI research while having fun. Tests your intuition about what the ML community finds interesting. Try it out: efecelik/paper-popularity-game Would love to hear your high scores and feedback! See translation", "url": "https://huggingface.co/posts/efecelik/696705775855438", "date_published": "2026-01-23T05:32:59.217500"}, {"id": "https://huggingface.co/posts/nyuuzyou/331224318760046", "image": "", "title": "\ud83c\udfdb\ufe0f Google Code Archive Dataset -", "content_text": "\ud83c\udfdb\ufe0f Google Code Archive Dataset - nyuuzyou/google-code-archive Expanding beyond the modern code series, this release presents a massive historical snapshot from the Google Code Archive. This dataset captures the open-source landscape from 2006 to 2016, offering a unique time capsule of software development patterns during the era before GitHub's dominance. Key Stats: - 65,825,565 files from 488,618 repositories - 47 GB compressed Parquet storage - 454 programming languages (Heavily featuring Java, PHP, and C++) - Extensive quality filtering (excluding vendor code and build artifacts) - Rich historical metadata: original repo names, file paths, and era-specific licenses This is one of those releases that I'm most interested in getting feedback on. Would you like to see more old code datasets? See translation", "url": "https://huggingface.co/posts/nyuuzyou/331224318760046", "date_published": "2026-01-23T05:32:59.217882"}, {"id": "https://huggingface.co/posts/AdinaY/119145219843817", "image": "", "title": "DeepSeek R1 dropped one year ago \ud83d\udc33 and a lot has changed.", "content_text": "DeepSeek R1 dropped one year ago \ud83d\udc33 and a lot has changed. With @ irenesolaiman , we\u2019re launching a blog series about how that moment reshaped AI + open source in 2025, starting with strategic shifts and the explosion of new open models in China! https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment See translation", "url": "https://huggingface.co/posts/AdinaY/119145219843817", "date_published": "2026-01-23T05:32:59.218135"}]}