{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/nouamanetazi/972464132222376", "image": "", "title": "After training \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25\ud835\udc0b\ud835\udc0c\ud835\udfd1 on \ud835\udfd1\ud835\udfd6\ud835\udfd2 \ud835\udc07\ud835\udfcf\ud835\udfce\ud835\udfce\ud835\udc2c for nearly a month, I've come to realize something most people overlook: \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc26\ud835\udc1a\ud835\udc24\ud835\udc1e-\ud835\udc28\ud835\udc2b-\ud835\udc1b\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc24 \ud835\udc1f\ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc22\ud835\udc27 \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20. \ud83d\udd25", "content_text": "After training \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25\ud835\udc0b\ud835\udc0c\ud835\udfd1 on \ud835\udfd1\ud835\udfd6\ud835\udfd2 \ud835\udc07\ud835\udfcf\ud835\udfce\ud835\udfce\ud835\udc2c for nearly a month, I've come to realize something most people overlook: \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc26\ud835\udc1a\ud835\udc24\ud835\udc1e-\ud835\udc28\ud835\udc2b-\ud835\udc1b\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc24 \ud835\udc1f\ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc22\ud835\udc27 \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20. \ud83d\udd25 Everyone talks about model architecture and data quality. And yes, those matter immensely. But here's what nobody tells you: when your training run fails at 2 AM because of mysterious \ud835\udc0d\ud835\udc02\ud835\udc02\ud835\udc0b \ud835\udc1e\ud835\udc2b\ud835\udc2b\ud835\udc28\ud835\udc2b\ud835\udc2c, or when your expensive GPU cluster is running at \ud835\udfd4\ud835\udfce% \ud835\udc1e\ud835\udc1f\ud835\udc1f\ud835\udc22\ud835\udc1c\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc32, the problem isn't your model. It's most probably a \ud835\udc26\ud835\udc22\ud835\udc2c\ud835\udc2e\ud835\udc2c\ud835\udc1e \ud835\udc28\ud835\udc1f \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc21\ud835\udc1a\ud835\udc2b\ud835\udc1d\ud835\udc30\ud835\udc1a\ud835\udc2b\ud835\udc1e. \ud83d\udee0\ufe0f Questions that seemed simple but had no clear answers: Why is \ud835\udc0c\ud835\udc28\ud835\udc04 \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2c\ud835\udc25\ud835\udc28\ud835\udc30\ud835\udc1e\ud835\udc2b \ud835\udc2d\ud835\udc21\ud835\udc1a\ud835\udc27 \ud835\udc1d\ud835\udc1e\ud835\udc27\ud835\udc2c\ud835\udc1e \ud835\udc26\ud835\udc28\ud835\udc1d\ud835\udc1e\ud835\udc25\ud835\udc2c? Which \ud835\udc0d\ud835\udc02\ud835\udc02\ud835\udc0b \ud835\udc1f\ud835\udc25\ud835\udc1a\ud835\udc20\ud835\udc2c should we actually set? How often should we checkpoint without killing throughput? That's why we built \ud835\udc13\ud835\udc21\ud835\udc1e \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25 \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0f\ud835\udc25\ud835\udc1a\ud835\udc32\ud835\udc1b\ud835\udc28\ud835\udc28\ud835\udc24 \ud83d\udcd6: a complete guide covering everything from model architecture and data curation to the SmolLM3 training marathon, post-training techniques, and crucially, the \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc25\ud835\udc1a\ud835\udc32\ud835\udc1e\ud835\udc2b that most teams get wrong. We validated real vs...", "url": "https://huggingface.co/posts/nouamanetazi/972464132222376", "date_published": "2025-11-02T09:20:50.160433"}, {"id": "https://huggingface.co/posts/sergiopaniego/207791817757812", "image": "", "title": "Sharing the slides from yesterday's talk about \"Fine Tuning with TRL\" from the", "content_text": "Sharing the slides from yesterday's talk about \"Fine Tuning with TRL\" from the @ TogetherAgent x @ huggingface workshop we hosted in our Paris office \ud83c\udf83! Link: https://github.com/sergiopaniego/talks/blob/main/fine_tuning_with_trl/Fine%20tuning%20with%20TRL%20(Oct%2025).pdf See translation", "url": "https://huggingface.co/posts/sergiopaniego/207791817757812", "date_published": "2025-11-02T09:20:50.160678"}, {"id": "https://huggingface.co/posts/piercus/167394123498038", "image": "", "title": "Starts erasing! \ud83c\udf89 \ud83c\udf89 \ud83c\udf89", "content_text": "Starts erasing! \ud83c\udf89 \ud83c\udf89 \ud83c\udf89 This is made with a one-step SD1.5 LBM [1] eraser ! Data is open. Data pipeline is open. Training code is open. On our LBM fork : https://github.com/finegrain-ai/LBM [1] LBM: Latent Bridge Matching for Fast Image-to-Image Translation (2503.07535) See translation", "url": "https://huggingface.co/posts/piercus/167394123498038", "date_published": "2025-11-02T09:20:50.160899"}, {"id": "https://huggingface.co/posts/DmitryRyumin/744756733617336", "image": "", "title": "\ud83d\ude80\ud83d\udc4c\ud83c\udf1f New Research Alert - ICCV 2025 (Oral)! \ud83c\udf1f\ud83e\udd0c\ud83d\ude80", "content_text": "\ud83d\ude80\ud83d\udc4c\ud83c\udf1f New Research Alert - ICCV 2025 (Oral)! \ud83c\udf1f\ud83e\udd0c\ud83d\ude80 \ud83d\udcc4 Title: Understanding Co-speech Gestures in-the-wild \ud83d\udd1d \ud83d\udcdd Description: JEGAL is a tri-modal model that learns from gestures, speech and text simultaneously, enabling devices to interpret co-speech gestures in the wild. \ud83d\udc65 Authors: @ sindhuhegde , K R Prajwal, Taein Kwon, and Andrew Zisserman \ud83d\udcc5 Conference: ICCV, 19 \u2013 23 Oct, 2025 | Honolulu, Hawai'i, USA \ud83c\uddfa\ud83c\uddf8 \ud83d\udcc4 Paper: Understanding Co-speech Gestures in-the-wild (2503.22668) \ud83c\udf10 Web Page: https://www.robots.ox.ac.uk/~vgg/research/jegal \ud83d\udcc1 Repository: https://github.com/Sindhu-Hegde/jegal \ud83d\udcfa Video: https://www.youtube.com/watch?v=TYFOLKfM-rM \ud83d\ude80 ICCV-2023-25-Papers: https://github.com/DmitryRyumin/ICCV-2023-25-Papers \ud83d\ude80 Added to the Human Modeling Section: https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/human-modeling.md \ud83d\udcda More Papers: more cutting-edge research presented at other conferences in the DmitryRyumin/NewEraAI-Papers curated by @ DmitryRyumin \ud83d\udd0d Keywords:...", "url": "https://huggingface.co/posts/DmitryRyumin/744756733617336", "date_published": "2025-11-02T09:20:50.161285"}, {"id": "https://huggingface.co/posts/prithivMLmods/710644146568512", "image": "", "title": "A small blog post titled - Hall of Multimodal OCR VLMs and Demonstrations has been published on \u2197\ufe0f", "content_text": "A small blog post titled - Hall of Multimodal OCR VLMs and Demonstrations has been published on \u2197\ufe0f https://huggingface.co/blog/prithivMLmods/multimodal-ocr-vlms on behalf of strangervisionhf It discusses the latest trends in OCR models, the multilingual support offered by modern OCR systems, their unique capabilities, OCR benchmark model comparisons, transformer-based implementations, and strategies for streamlining transformers compatibility. See translation", "url": "https://huggingface.co/posts/prithivMLmods/710644146568512", "date_published": "2025-11-02T09:20:50.161544"}, {"id": "https://huggingface.co/posts/DavidAU/433692013361833", "image": "", "title": "*** Happy Halloween - Embrace the Horror ! ***", "content_text": "*** Happy Halloween - Embrace the Horror ! *** Unsloth fine tunes using in house horror dataset. Gemma 3 - 1B, 4B, two 12Bs and 27B (uploaded yesterday) Qwen 3 - 1.7B [two] - new today... and , 4B, 6B, 42B ... And 32 MORE horror models: https://huggingface.co/DavidAU/models?search=horror Collection: https://huggingface.co/collections/DavidAU/grand-horror-165b-horror-and-fiction-generation Enjoy ; See translation", "url": "https://huggingface.co/posts/DavidAU/433692013361833", "date_published": "2025-11-02T09:20:50.161761"}, {"id": "https://huggingface.co/posts/ronantakizawa/591564562942305", "image": "", "title": "Introducing the Medical-o1-Reasoning-SFT-Japanese dataset \ud83c\udf89", "content_text": "Introducing the Medical-o1-Reasoning-SFT-Japanese dataset \ud83c\udf89 This dataset is a Japanese dataset consisting questions, reasoning, and answer results for complex medical topics. #japanese #medical #dataset ronantakizawa/Medical-o1-Reasoning-SFT-Japanese See translation", "url": "https://huggingface.co/posts/ronantakizawa/591564562942305", "date_published": "2025-11-02T09:20:50.161961"}, {"id": "https://huggingface.co/posts/onekq/456763679689481", "image": "", "title": "Kimi K2 is a bit disappointing by my expectations. It is on a par with Codex mini.", "content_text": "Kimi K2 is a bit disappointing by my expectations. It is on a par with Codex mini. onekq-ai/WebApp1K-models-leaderboard See translation", "url": "https://huggingface.co/posts/onekq/456763679689481", "date_published": "2025-11-02T09:20:50.162135"}, {"id": "https://huggingface.co/posts/branikita/910220398337791", "image": "", "title": "At", "content_text": "At Robonine , we applied topology optimization to enhance the stiffness and efficiency of a robotic manipulator. Using HyperMesh with the OptiStruct solver, we defined the design space where each element had a pseudo-density coefficient (0\u20131) controlling stiffness. This allowed the algorithm to continuously redistribute material toward regions with higher strain energy \u2014 much like how a fluid naturally flows to balance pressure. Results: - Aluminum bracket: displacement reduced by 0.16 mm - Steel bracket: displacement reduced from 1.05 mm \u2192 0.63 mm - Steel clamp: displacement reduced by 0.14 mm - Final structure: optimized geometry with improved load distribution and reduced deformation This project highlights how advanced structural optimization can significantly improve performance while minimizing material usage \u2014 shaping the next generation of robotic design. See translation", "url": "https://huggingface.co/posts/branikita/910220398337791", "date_published": "2025-11-02T09:20:50.162500"}, {"id": "https://huggingface.co/posts/Shivansh000/941986646578616", "image": "", "title": "I am dedicating this weekend to practicing/reading the latest b(ook)log from hugging face. It is meant to be a guide for anyone trying to go from \u201cwe have a great dataset and GPUs\u201d to \u201cwe built a really strong model.\u201d Will share thoughts upon completion.", "content_text": "I am dedicating this weekend to practicing/reading the latest b(ook)log from hugging face. It is meant to be a guide for anyone trying to go from \u201cwe have a great dataset and GPUs\u201d to \u201cwe built a really strong model.\u201d Will share thoughts upon completion. Thanks for the treat @ eliebak @ ThomasWolf and HF team! HuggingFaceTB/smol-training-playbook See translation", "url": "https://huggingface.co/posts/Shivansh000/941986646578616", "date_published": "2025-11-02T09:20:50.162776"}]}