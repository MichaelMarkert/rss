{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/198818765852761", "image": "", "title": "\ud83d\ude80 DeepSeek V3-0324 + Real-time Research Power! \ud83c\udf10", "content_text": "\ud83d\ude80 DeepSeek V3-0324 + Real-time Research Power! \ud83c\udf10 Hello there! Today I'm excited to introduce an amazing tool based on the DeepSeek V3-0324 latest model. This isn't just another AI chatbot\u2014it's a true \"research assistant\" capable of real-time information retrieval and analysis! openfree/Deepseek-v3-0324-Research \ud83e\udde0 Key Strengths of DeepSeek V3-0324 DeepSeek V3-0324, provided by Fireworks AI, comes with these powerful advantages: \ud83c\udfaf Superior Reasoning: Excellent ability to solve complex problems step-by-step \ud83d\udcda Extensive Knowledge: Deep understanding across various topics from comprehensive training \ud83e\udde9 Context Awareness: Maintains long conversation contexts for consistent responses \ud83c\udf0d Multilingual Support: Processes various languages effectively \ud83d\udd0e Added Real-time \"Deep Research\" Capability! The most exciting feature of this project is the implementation of real-time search functionality similar to ChatGPT's Browse with Bing or Perplexity AI! \ud83c\udf1f How does it work? \ud83d\udccb Query Analysis: Analyzes...", "url": "https://huggingface.co/posts/openfree/198818765852761", "date_published": "2025-03-26T05:21:15.466525"}, {"id": "https://huggingface.co/posts/hanzla/334929914214979", "image": "", "title": "\ud83d\udc4b Hi all!", "content_text": "\ud83d\udc4b Hi all! For any AI agent, internet search \ud83d\udd0e is an important tool. However, with APIs like Tavily and Exa, it becomes really difficult to keep up with the cost. In some cases, these Internet APIs cost more than the LLM. To solve, this, I am making a playwright wrapper API on top of publicly available searXNG instances. This will enable agent applications to fetch internet results for free. Currently, I have set up a basic GitHub repo, and I will continue developing advanced search features, such as image search \ud83d\uddbc\ufe0f Github: https://github.com/HanzlaJavaid/Free-Search/tree/main \ud83d\ude80 Try the deployed version: https://freesearch.replit.app/docs If you find this useful, consider starring \u2b50\ufe0f the GitHub repository to support further development! See translation", "url": "https://huggingface.co/posts/hanzla/334929914214979", "date_published": "2025-03-26T05:21:15.466935"}, {"id": "https://huggingface.co/posts/MikeDoes/814156384414808", "image": "", "title": "\ud83d\ude80 We are quite excited to announce the Ai4Privacy Python library! \ud83c\udf89", "content_text": "\ud83d\ude80 We are quite excited to announce the Ai4Privacy Python library! \ud83c\udf89 pip install ai4privacy to anonymize short english text with OpenPII Masking 500k labels \ud83d\udcca Day 5/7 of PII Masking 1M announcements complete! \u23f0 See translation", "url": "https://huggingface.co/posts/MikeDoes/814156384414808", "date_published": "2025-03-26T05:21:15.467195"}, {"id": "https://huggingface.co/posts/mrs83/394905068174905", "image": "", "title": "\ud83d\ude80 Just released a PoC: Kurtis-E1 MLX Voice Agent", "content_text": "\ud83d\ude80 Just released a PoC: Kurtis-E1 MLX Voice Agent An offline, privacy-first voice assistant built for macOS (Apple Silicon), designed for empathetic, short-form interactions. \ud83e\udde0 Powered by: - Whisper (via MLX) for speech-to-text: https://pypi.org/project/mlx-whisper/ - Kurtis-E1 (a custom SmolLM2 LLM) via Ollama - Coqui-TTS XTTSv2 for multilingual TTS - Optional translation layer via TowerInstruct-13B-v0.1 for non-English voice input/output: Unbabel/TowerInstruct-13B-v0.1 \ud83c\udfa7 Everything runs entirely on-device (Mac Mini M4 Max - 24gb) \u2014 no cloud, no remote API calls, no data leakage. \ud83d\udca1 Code is fully handcrafted (no AI-generated code), and designed to showcase what\u2019s possible with local models, even on laptops. \ud83d\udee0\ufe0f Open to contributions, ideas (e.g., LM Studio for MLX inference, MLX worker subprocess, optimize for latency and VRAM usage). \ud83d\udc49 Video demo (Italian): https://www.youtube.com/watch?v=8-1PcmUStaI PoC: https://github.com/ethicalabs-ai/Kurtis-E1-MLX-Voice-Agent Kurtis-E1:...", "url": "https://huggingface.co/posts/mrs83/394905068174905", "date_published": "2025-03-26T05:21:15.467672"}, {"id": "https://huggingface.co/posts/MikeDoes/593610719403706", "image": "", "title": "\ud83c\udf1f Day 4: Two Models, One Privacy Mission! \ud83c\udf1f", "content_text": "\ud83c\udf1f Day 4: Two Models, One Privacy Mission! \ud83c\udf1f The PII-Masking-1M series rolls on with two gems: Categorical: ai4privacy/llama-ai4privacy-multilingual-categorical-anonymiser-openpii Redaction: ai4privacy/llama-ai4privacy-multilingual-anonymiser-openpii Join us in protecting data everywhere! #AI #Privacy #OpenSource #Multilingual See translation", "url": "https://huggingface.co/posts/MikeDoes/593610719403706", "date_published": "2025-03-26T05:21:15.467954"}, {"id": "https://huggingface.co/posts/onekq/124053264899473", "image": "", "title": "I shared my view on Qwen vs DeepSeek (student vs genius), and I forgot to mention this: they are neighbors in the same city.", "content_text": "I shared my view on Qwen vs DeepSeek (student vs genius), and I forgot to mention this: they are neighbors in the same city. https://en.wikipedia.org/wiki/Hangzhou See translation", "url": "https://huggingface.co/posts/onekq/124053264899473", "date_published": "2025-03-26T05:21:15.468179"}, {"id": "https://huggingface.co/posts/nyuuzyou/253303965846347", "image": "", "title": "I am planning to release *something big* this week, but in the meantime I was bored, so I quickly made a small dataset in as-is format.", "content_text": "I am planning to release *something big* this week, but in the meantime I was bored, so I quickly made a small dataset in as-is format. \ud83d\udcf1 Sponsr.ru Dataset - nyuuzyou/sponsr Collection of 44,138 posts from Sponsr.ru, a Russian content subscription platform featuring: - Comprehensive metadata including project details, post information, and pricing - Detailed content categorization with images, videos, and text formats - Monolingual Russian content from diverse creator projects See translation", "url": "https://huggingface.co/posts/nyuuzyou/253303965846347", "date_published": "2025-03-26T05:21:15.468507"}, {"id": "https://huggingface.co/posts/Dragunflie-420/370006653578005", "image": "", "title": "Hello community. My name is nikki and I am looking to form a team for a serious project build platform/design/idea/project's...Ive been creating AI professional personas with custom skill sets and divisions of expertise. I want to create a viable business. Ive been working hard but i admit theres so much i do not have time to learn to do. Its taken me three years to learn enough to be here. I dont have a big set up in fact im cloud and ide space trial enterprise here and there all for space. I suck at execution and thats because I dont know how really. I need help from a person. AI has done all it can without hands. Im blabbering at this point. Have nothing big techy to say other  than I build and ideate all day hmu glad to meet some like minded individuals ...seriously!  Teach me leave me feeling confident in our collaborations not the need to build security software....poor attemt at hacking humor...im neither a comedian or hacker lol....full stacker yep:)", "content_text": "Hello community. My name is nikki and I am looking to form a team for a serious project build platform/design/idea/project's...Ive been creating AI professional personas with custom skill sets and divisions of expertise. I want to create a viable business. Ive been working hard but i admit theres so much i do not have time to learn to do. Its taken me three years to learn enough to be here. I dont have a big set up in fact im cloud and ide space trial enterprise here and there all for space. I suck at execution and thats because I dont know how really. I need help from a person. AI has done all it can without hands. Im blabbering at this point. Have nothing big techy to say other than I build and ideate all day hmu glad to meet some like minded individuals ...seriously! Teach me leave me feeling confident in our collaborations not the need to build security software....poor attemt at hacking humor...im neither a comedian or hacker lol....full stacker yep:) See translation", "url": "https://huggingface.co/posts/Dragunflie-420/370006653578005", "date_published": "2025-03-26T05:21:15.468892"}, {"id": "https://huggingface.co/posts/prithivMLmods/636017629605073", "image": "", "title": "Dropping Downstream tasks using newly initialized parameters and weights ([classifier.bias & weights]) support domain-specific \ud835\uddf6\ud835\uddfa\ud835\uddee\ud835\uddf4\ud835\uddf2 \ud835\uddf0\ud835\uddf9\ud835\uddee\ud835\ude00\ud835\ude00\ud835\uddf6\ud835\uddf3\ud835\uddf6\ud835\uddf0\ud835\uddee\ud835\ude01\ud835\uddf6\ud835\uddfc\ud835\uddfb. Based on siglip2-base-patch16-224 and DomainNet (single-domain, multi-source adaptation), with Fashion-MNIST for experimental testing. \ud83e\udde4\u2604\ufe0f", "content_text": "Dropping Downstream tasks using newly initialized parameters and weights ([classifier.bias & weights]) support domain-specific \ud835\uddf6\ud835\uddfa\ud835\uddee\ud835\uddf4\ud835\uddf2 \ud835\uddf0\ud835\uddf9\ud835\uddee\ud835\ude00\ud835\ude00\ud835\uddf6\ud835\uddf3\ud835\uddf6\ud835\uddf0\ud835\uddee\ud835\ude01\ud835\uddf6\ud835\uddfc\ud835\uddfb. Based on siglip2-base-patch16-224 and DomainNet (single-domain, multi-source adaptation), with Fashion-MNIST for experimental testing. \ud83e\udde4\u2604\ufe0f Fashion-Mnist : prithivMLmods/Fashion-Mnist-SigLIP2 Multisource-121 : prithivMLmods/Multisource-121-DomainNet Painting-126 : prithivMLmods/Painting-126-DomainNet Sketch-126 : prithivMLmods/Sketch-126-DomainNet Clipart-126 : prithivMLmods/Clipart-126-DomainNet Models are trained with different parameter settings for experimental purposes only, with the intent of further development. Refer to the model page below for instructions on running it with Transformers \ud83e\udd17. Collection : prithivMLmods/domainnet-0324-67e0e3c934c03cc40c6c8782 Citations : SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features https://arxiv.org/pdf/2502.14786 & Moment...", "url": "https://huggingface.co/posts/prithivMLmods/636017629605073", "date_published": "2025-03-26T05:21:15.469334"}, {"id": "https://huggingface.co/posts/Kseniase/498106595218801", "image": "", "title": "8 types of RoPE", "content_text": "8 types of RoPE As we always use Transformers, it's helpful to understand RoPE\u2014Rotary Position Embedding. Since token order matters, RoPE encodes it by rotating token embeddings based on their position, so the model knows how to interpret which token comes first, second, and so on. Here are 8 types of RoPE that can be implemented in different cases: 1. Original RoPE -> RoFormer: Enhanced Transformer with Rotary Position Embedding (2104.09864) Encodes token positions by rotating token embeddings in the complex plane via a position-based rotation matrix, thereby providing the self-attention mechanism with relative positional info. 2. LongRoPE -> LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens (2402.13753) Extends the context window of pre-trained LLMs to 2048k tokens, leveraging non-uniformities in positional interpolation with an efficient search. 3. LongRoPE2 -> LongRoPE2: Near-Lossless LLM Context Window Scaling (2502.20082) Extends the effective context window of...", "url": "https://huggingface.co/posts/Kseniase/498106595218801", "date_published": "2025-03-26T05:21:15.470018"}]}