{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/burtenshaw/189514834246661", "image": "", "title": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts:", "content_text": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts: 1\ufe0f\u20e3 New Supervised Fine-tuning unit in the NLP Course https://huggingface.co/learn/nlp-course/en/chapter11/1 2\ufe0f\u20e3New Finetuning for agents bonus module in the Agents Course https://huggingface.co/learn/agents-course/bonus-unit1/introduction Fine-tuning will squeeze everything out of your model for how you\u2019re using it, more than any prompt. See translation", "url": "https://huggingface.co/posts/burtenshaw/189514834246661", "date_published": "2025-02-20T17:17:24.492981"}, {"id": "https://huggingface.co/posts/fdaudens/121352437859372", "image": "", "title": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses.", "content_text": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses. Check it out: perplexity-ai/r1-1776 Blog post: https://perplexity.ai/hub/blog/open-sourcing-r1-1776 See translation", "url": "https://huggingface.co/posts/fdaudens/121352437859372", "date_published": "2025-02-20T17:17:24.493289"}, {"id": "https://huggingface.co/posts/AdinaY/709023807759284", "image": "", "title": "\ud83d\ude80 StepFun\u9636\u8dc3\u661f\u8fb0 is making BIG open moves!", "content_text": "\ud83d\ude80 StepFun\u9636\u8dc3\u661f\u8fb0 is making BIG open moves! Last year, their GOT-OCR 2.0 took the community by storm \ud83d\udd25but many didn\u2019t know they were also building some amazing models. Now, they\u2019ve just dropped something huge on the hub! \ud83d\udcfa Step-Video-T2V: a 30B bilingual open video model that generates 204 frames (8-10s) at 540P resolution with high information density & consistency. stepfun-ai/stepvideo-t2v \ud83d\udd0a Step-Audio-TTS-3B : a TTS trained with the LLM-Chat paradigm on a large synthetic dataset, capable of generating RAP & Humming stepfun-ai/step-audio-67b33accf45735bb21131b0b See translation", "url": "https://huggingface.co/posts/AdinaY/709023807759284", "date_published": "2025-02-20T17:17:24.493643"}, {"id": "https://huggingface.co/posts/prithivMLmods/874083632338295", "image": "", "title": "Dino: The Minimalist Multipurpose Chat System \ud83c\udf20", "content_text": "Dino: The Minimalist Multipurpose Chat System \ud83c\udf20 Agent-Dino : prithivMLmods/Agent-Dino By default, it performs the following tasks: {Text-to-Text Generation}, {Image-Text-Text Generation} @image : Generates an image using Stable Diffusion xL. @3d : Generates a 3D mesh. @web : Web search agents. @rAgent : Initiates a reasoning chain using Llama mode for coding explanations. @tts1-\u2640 , @tts2-\u2642 : Voice generation (Female and Male voices). @yolo : Object Detection See translation", "url": "https://huggingface.co/posts/prithivMLmods/874083632338295", "date_published": "2025-02-20T17:17:24.493973"}, {"id": "https://huggingface.co/posts/merve/467807900895850", "image": "", "title": "Google just released PaliGemma 2 Mix: new versatile instruction vision language models \ud83d\udd25", "content_text": "Google just released PaliGemma 2 Mix: new versatile instruction vision language models \ud83d\udd25 > Three new models: 3B, 10B, 28B with res 224, 448 \ud83d\udc99 > Can do vision language tasks with open-ended prompts, understand documents, and segment or detect anything \ud83e\udd2f Read more https://huggingface.co/blog/paligemma2mix Try the demo google/paligemma2-10b-mix All models are here google/paligemma-2-mix-67ac6a251aaf3ee73679dcc4 See translation", "url": "https://huggingface.co/posts/merve/467807900895850", "date_published": "2025-02-20T17:17:24.494287"}, {"id": "https://huggingface.co/posts/smirki/311150694603392", "image": "", "title": "UIGEN for Tailwind v4 is coming soon!", "content_text": "UIGEN for Tailwind v4 is coming soon! See translation", "url": "https://huggingface.co/posts/smirki/311150694603392", "date_published": "2025-02-20T17:17:24.494495"}, {"id": "https://huggingface.co/posts/m-ric/436586297766836", "image": "", "title": "Less is More for Reasoning (LIMO): a 32B model fine-tuned with 817 examples can beat o1-preview on math reasoning! \ud83e\udd2f", "content_text": "Less is More for Reasoning (LIMO): a 32B model fine-tuned with 817 examples can beat o1-preview on math reasoning! \ud83e\udd2f Do we really need o1's huge RL procedure to see reasoning emerge? It seems not. Researchers from Shanghai Jiaotong University just demonstrated that carefully selected examples can boost math performance in large language models using SFT \u2014no huge datasets or RL procedures needed. Their procedure allows Qwen2.5-32B-Instruct to jump from 6.5% to 57% on AIME and from 59% to 95% on MATH, while using only 1% of the data in previous approaches. \u26a1 The Less-is-More Reasoning Hypothesis: \u2023 Minimal but precise examples that showcase optimal reasoning patterns matter more than sheer quantity \u2023 Pre-training knowledge plus sufficient computational resources at inference levels up math skills \u27a1\ufe0f Core techniques: \u2023 High-quality reasoning chains with self-verification steps \u2023 817 handpicked problems that encourage deeper reasoning \u2023 Enough inference-time computation to allow...", "url": "https://huggingface.co/posts/m-ric/436586297766836", "date_published": "2025-02-20T17:17:24.495026"}, {"id": "https://huggingface.co/posts/merterbak/134010141714846", "image": "", "title": "\ud83d\udd25 Meet Muse: that can generate a game environment based on visuals or players\u2019 controller actions. It was developed by Microsoft Research in collaboration with Ninja Theory (Hellblade developer). It\u2019s built on something called the World and Human Action Model (WHAM-1.6B model). They trained on 7 years of Bleeding Edge gameplay and it can generate 2 minute long 3D game sequences with consistent physics and character behaviors all from just a second of input. They\u2019ve gone and open-sourced it too. Open weights, the WHAM Demonstrator, and sample data on Azure AI Foundry for anyone to play with. Hope so soon on Hugging Face \ud83e\udd17.", "content_text": "\ud83d\udd25 Meet Muse: that can generate a game environment based on visuals or players\u2019 controller actions. It was developed by Microsoft Research in collaboration with Ninja Theory (Hellblade developer). It\u2019s built on something called the World and Human Action Model (WHAM-1.6B model). They trained on 7 years of Bleeding Edge gameplay and it can generate 2 minute long 3D game sequences with consistent physics and character behaviors all from just a second of input. They\u2019ve gone and open-sourced it too. Open weights, the WHAM Demonstrator, and sample data on Azure AI Foundry for anyone to play with. Hope so soon on Hugging Face \ud83e\udd17. \ud83d\udcc4 Paper: https://www.nature.com/articles/s41586-025-08600-3 Blog Post: https://www.microsoft.com/en-us/research/blog/introducing-muse-our-first-generative-ai-model-designed-for-gameplay-ideation/ See translation", "url": "https://huggingface.co/posts/merterbak/134010141714846", "date_published": "2025-02-20T17:17:24.495448"}, {"id": "https://huggingface.co/posts/dreamerdeo/426313569382827", "image": "", "title": "\ud83d\ude80 Excited to share our technical report on the Southeast Asian multilingual model Sailor2 and its latest updates!", "content_text": "\ud83d\ude80 Excited to share our technical report on the Southeast Asian multilingual model Sailor2 and its latest updates! Our 49-page report details Sailor2's development journey, including multilingual data cleaning, small model data mixture simulations, multi-stage continual pre-training, multi-stage post-training, and multi-cultural multi-lingual evaluations. Sailor2 aims to streamline the multilingual model pre-training process efficiently for the community. \ud83e\udded We highlight Sailor2's impressive performance in low-resource language translation scenarios and its cultural understanding advantages in Southeast Asia, promoting practical applications for regional languages. Model updates include: \ud83d\udca1 More precise outputs: Reduced redundancy in model outputs through refined post-training data and optimization techniques. \ud83c\udf08 Handling longer texts: Expanded to handle up to 128K context length in Southeast Asian languages through long-text training. \u26a1\ufe0f Faster inference: Achieved 2.5x faster inference...", "url": "https://huggingface.co/posts/dreamerdeo/426313569382827", "date_published": "2025-02-20T17:17:24.495985"}, {"id": "https://huggingface.co/posts/AdinaY/586092411565297", "image": "", "title": "The latest paper of DeepSeek is now available on the Daily Papers page \ud83d\ude80", "content_text": "The latest paper of DeepSeek is now available on the Daily Papers page \ud83d\ude80 You can reach out to the authors directly on this page\ud83d\udc47 Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention (2502.11089) See translation", "url": "https://huggingface.co/posts/AdinaY/586092411565297", "date_published": "2025-02-20T17:17:24.496235"}]}