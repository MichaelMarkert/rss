{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/OzTianlu/866420978580038", "image": "", "title": "O(1) inference is the foundational design of Spartacus-1B-Instruct \ud83d\udee1\ufe0f !", "content_text": "O(1) inference is the foundational design of Spartacus-1B-Instruct \ud83d\udee1\ufe0f ! NoesisLab/Spartacus-1B-Instruct We have successfully replaced the KV-cache bottleneck inherent in Softmax Attention with Causal Monoid State Compression. By defining the causal history as a monoid recurrence, , the entire prefix is lossily compressed into a fixed-size state matrix per head. The technical core of this architecture relies on the associativity of the monoid operator: Training: parallel prefix scan using Triton-accelerated JIT kernels to compute all prefix states simultaneously. Inference: True sequential updates. Memory and time complexity per token are decoupled from sequence length. Explicit Causality: We discard RoPE and attention masks. Causality is a first-class citizen, explicitly modeled through learned, content-dependent decay gates. Current zero-shot benchmarks demonstrate that Spartacus-1B-Instruct (1.3B) is already outperforming established sub-quadratic models like Mamba-1.4B and...", "url": "https://huggingface.co/posts/OzTianlu/866420978580038", "date_published": "2026-02-20T05:57:11.883348"}, {"id": "https://huggingface.co/posts/qgallouedec/326351655871382", "image": "", "title": "@CohereLabs", "content_text": "@ CohereLabs just released \ud83c\udf3f Tiny Aya: a fully open-source 3B parameter model that speaks 70+ languages \ud83c\udf0d! But there\u2019s a catch: Tiny Aya is just a language model. It doesn\u2019t support tool calling, the key capability that turns frontier models into powerful *agents*. So the real question is: How hard is it to turn Tiny Aya into an agent? Turns out\u2026 it\u2019s simple, thanks to Hugging Face TRL. We\u2019re sharing a hands-on example showing how to train Tiny Aya to turn it into a tool-calling agent using TRL, unlocking what could become the first *massively multilingual open agent*. Small model. Global reach. Agent capabilities. \ud83d\udc49 https://github.com/huggingface/trl/blob/main/examples/notebooks/sft_tool_calling.ipynb See translation", "url": "https://huggingface.co/posts/qgallouedec/326351655871382", "date_published": "2026-02-20T05:57:11.883773"}, {"id": "https://huggingface.co/posts/ajibawa-2023/551299945389829", "image": "", "title": "JavaScript-Code-Large", "content_text": "JavaScript-Code-Large ajibawa-2023/JavaScript-Code-Large JavaScript-Code-Large is a large-scale corpus of JavaScript source code comprising around 5 million JavaScript files. The dataset is designed to support research in large language model (LLM) pretraining, code intelligence, software engineering automation, and program analysis for the JavaScript ecosystem. By providing a high-volume, language-specific corpus, JavaScript-Code-Large enables systematic experimentation in JavaScript-focused model training, domain adaptation, and downstream code understanding tasks. JavaScript-Code-Large addresses the need for a dedicated JavaScript-only dataset at substantial scale, enabling focused research across frontend, backend, and full-stack JavaScript environments. . See translation", "url": "https://huggingface.co/posts/ajibawa-2023/551299945389829", "date_published": "2026-02-20T05:57:11.884122"}, {"id": "https://huggingface.co/posts/sergiopaniego/682471247625526", "image": "", "title": "Tiny Aya \ud83c\udf3f just dropped from", "content_text": "Tiny Aya \ud83c\udf3f just dropped from @ CohereLabs , a really powerful multilingual small model! To celebrate, we cooked up fresh resources to train it for tool calling \ud83d\udd27 > Free Google Colab guide: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/sft_tool_calling.ipynb > Standalone training script: https://github.com/huggingface/trl/blob/main/examples/scripts/sft_tiny_aya_tool_calling.py See translation", "url": "https://huggingface.co/posts/sergiopaniego/682471247625526", "date_published": "2026-02-20T05:57:11.884417"}, {"id": "https://huggingface.co/posts/branikita/621296339305286", "image": "", "title": "We stress-test the FEETECH STS3215: real backlash (0.87\u00b0 measured vs spec), repeatability, speed accuracy, stall torque above rating, and thermal overload behavior under continuous load. Practical implications for robot arms and grippers.", "content_text": "We stress-test the FEETECH STS3215: real backlash (0.87\u00b0 measured vs spec), repeatability, speed accuracy, stall torque above rating, and thermal overload behavior under continuous load. Practical implications for robot arms and grippers. Full video: https://www.youtube.com/watch?v=UN5_fZVSWcw See translation", "url": "https://huggingface.co/posts/branikita/621296339305286", "date_published": "2026-02-20T05:57:11.884670"}, {"id": "https://huggingface.co/posts/AbstractPhil/673262980484014", "image": "", "title": "The Rosetta Stone geometric vocabulary and the ramping up capacity.", "content_text": "The Rosetta Stone geometric vocabulary and the ramping up capacity. What makes this particular invariant special, is the existence within all structures I've tested so far. I had Claude write up the direct article based on what we built together, but I've tested it on many substructures. This is flawed, and I have a series of answers to making it more accurate. First a reconstruction from the ground up. This means each shape is specifically built upward from the substructure to the point of inductive deviance. This will be less quick at first and then build speed as I optimize like the last system did. The \"saddle\" problem; the system detected saddles because there wasn't enough deviance in the shapes to attenuate to more cardinality and more aligned substructures. The blobs were around 30-40% of the overall patches, which interpolated into the others produced a fair approximation. It MOST DEFINITELY did see those shapes in their voxel complexity. This is real....", "url": "https://huggingface.co/posts/AbstractPhil/673262980484014", "date_published": "2026-02-20T05:57:11.885217"}, {"id": "https://huggingface.co/posts/DavidAU/658014279530502", "image": "", "title": "Gemma 3 (1b, 4b, 12b and 27b) - Uncensored full Reasoning/Thinking models fine tuned using top distill datasets.", "content_text": "Gemma 3 (1b, 4b, 12b and 27b) - Uncensored full Reasoning/Thinking models fine tuned using top distill datasets. 20 Gemma 3 models 1B, 4B, 12B and 27B with full reasoning using GLM 4.7 Flash, GPT, Claude and Gemini datasets and more fully fine tuned using Unsloth. Most models are Heretic'ed (uncensored) first, and tuned second. This vastly improves the model. Models are also bench marked and in almost all cases exceed org model metrics - and in some cases by a lot. Enjoy the freedom and more powerful THINKING/REASONING and UNCENSORED Gemma 3s ! https://huggingface.co/collections/DavidAU/gemma-3-reasoning-thinking-models-incl-uncensored See translation", "url": "https://huggingface.co/posts/DavidAU/658014279530502", "date_published": "2026-02-20T05:57:11.885577"}, {"id": "https://huggingface.co/posts/ZennyKenny/419291286474435", "image": "", "title": "\ud83d\udc49  Like everyone else, I've been blown away by the possibilities unlocked by OpenClaw (I've got an agent running locally and in a Railway pod that's always alive so I can automate as I ride the metro).", "content_text": "\ud83d\udc49 Like everyone else, I've been blown away by the possibilities unlocked by OpenClaw (I've got an agent running locally and in a Railway pod that's always alive so I can automate as I ride the metro). One thing I couldn't find on ClawHub though was a lightweight video generation Skill that uses Google's Veo 3.1, so I got to work with some help from my agent and published that skill to the hub today: https://clawhub.ai/kghamilton89/veo-video-generator \ud83d\ude0e Now your agent can generate SOTA audio/video as you fervently message it from Telegram Messenger demanding minor adjustments. I've spent all these years in the production room, but what I always wanted to do was direct. Feels good man. See translation", "url": "https://huggingface.co/posts/ZennyKenny/419291286474435", "date_published": "2026-02-20T05:57:11.886147"}, {"id": "https://huggingface.co/posts/Tonic/772171916121212", "image": "", "title": "\ud83d\ude4b\ud83c\udffb\u200d\u2642\ufe0fhello my lovelies ,", "content_text": "\ud83d\ude4b\ud83c\udffb\u200d\u2642\ufe0fhello my lovelies , it is with great pleasure i present to you my working one-click deploy 16GB ram completely free huggingface spaces deployment. repo : Tonic/hugging-claw (use git clone to inspect) literally the one-click link : Tonic/hugging-claw you can also run it locally and see for yourself : docker run -it -p 7860:7860 --platform=linux/amd64 \\ -e HF_TOKEN=\"YOUR_VALUE_HERE\" \\ -e OPENCLAW_GATEWAY_TRUSTED_PROXIES=\"YOUR_VALUE_HERE\" \\ -e OPENCLAW_GATEWAY_PASSWORD=\"YOUR_VALUE_HERE\" \\ -e OPENCLAW_CONTROL_UI_ALLOWED_ORIGINS=\"YOUR_VALUE_HERE\" \\ registry.hf.space/tonic-hugging-claw:latest just a few quite minor details i'll take care of but i wanted to share here first See translation", "url": "https://huggingface.co/posts/Tonic/772171916121212", "date_published": "2026-02-20T05:57:11.886525"}, {"id": "https://huggingface.co/posts/danielhanchen/198614576061440", "image": "", "title": "You can now run Qwen3.5 locally! \ud83d\udc9c", "content_text": "You can now run Qwen3.5 locally! \ud83d\udc9c Qwen3.5-397B-A17B is an open MoE vision reasoning LLM for agentic coding & chat. It performs on par with Gemini 3 Pro, Claude Opus 4.5 & GPT-5.2. GGUF: unsloth/Qwen3.5-397B-A17B-GGUF Run Dynamic 3-bit on a 192GB Mac for 20 tokens/s. Guide: https://unsloth.ai/docs/models/qwen3.5 See translation", "url": "https://huggingface.co/posts/danielhanchen/198614576061440", "date_published": "2026-02-20T05:57:11.886789"}]}