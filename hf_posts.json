{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/DawnC/125675008571857", "image": "", "title": "VividFlow: AI Image-to-Video Generation \ud83c\udfac\u2728", "content_text": "VividFlow: AI Image-to-Video Generation \ud83c\udfac\u2728 Bring your images to life with cinematic motion! VividFlow transforms any static image\u2014portraits, artwork, products, or landscapes, into dynamic videos with professional animation quality. The system supports both curated motion templates and custom natural language prompts, giving you complete creative freedom to describe camera movements, subject actions, and atmospheric effects in your own words. What's Inside? \ud83c\udfad Smart Motion Templates \u2014 8 curated categories from fashion cinematography to wildlife animations, each with tested prompts that prevent common artifacts like phantom hands in portraits \u26a1 Optimized Engine \u2014 Powered by Wan2.2-I2V-A14B with Lightning LoRA distillation and FP8 quantization for memory-efficient inference \ud83c\udfaf Full Creative Control \u2014 Seed-based reproducibility for consistent results, adjustable duration from half a second to five seconds, optional AI prompt expansion with Qwen2.5 for enhanced descriptions, and real-time...", "url": "https://huggingface.co/posts/DawnC/125675008571857", "date_published": "2025-12-31T13:35:36.329177"}, {"id": "https://huggingface.co/posts/sergiopaniego/214735266647009", "image": "", "title": "This super detailed tutorial by", "content_text": "This super detailed tutorial by @ Paulescu is pure gold \ud83e\ude99 \"Fine-tuning a Small Language Model for browser control with GRPO and OpenEnv\" LFM2-350M ( @ LiquidAI ) + BrowserGym (OpenEnv) + GRPO (TRL) for learning browser control \ud83e\udd1d https://paulabartabajo.substack.com/p/fine-tuning-lfm2-350m-for-browser See translation", "url": "https://huggingface.co/posts/sergiopaniego/214735266647009", "date_published": "2025-12-31T13:35:36.329429"}, {"id": "https://huggingface.co/posts/MohamedRashad/872380380430431", "image": "", "title": "I have update my", "content_text": "I have update my https://huggingface.co/collections/MohamedRashad/arabic-speech-datasets with new datasets, making the full audio data more than 3000 hours of good arabic speech. Feel Free to use it in your new innovations, And happy new year! See translation", "url": "https://huggingface.co/posts/MohamedRashad/872380380430431", "date_published": "2025-12-31T13:35:36.329640"}, {"id": "https://huggingface.co/posts/prithivMLmods/527859222205581", "image": "", "title": "Update: TRELLIS.2 (Text to 3D, Image to 3D) Gradio with Rerun Embedded demo with improved visualization of the 3D model previewer is now available on Hugging Face. Generate assets and view them in the 3D viewer, powered and streamlined with Microsoft\u2019s TRELLIS.2 and Tongyi-MAI\u2019s Z-Image-Turbo models.", "content_text": "Update: TRELLIS.2 (Text to 3D, Image to 3D) Gradio with Rerun Embedded demo with improved visualization of the 3D model previewer is now available on Hugging Face. Generate assets and view them in the 3D viewer, powered and streamlined with Microsoft\u2019s TRELLIS.2 and Tongyi-MAI\u2019s Z-Image-Turbo models. \ud83e\udd17 TRELLIS.2 (Demo): prithivMLmods/TRELLIS.2-Text-to-3D \ud83d\udd79\ufe0f GitHub: https://github.com/PRITHIVSAKTHIUR/TRELLIS.2-Text-to-3D-RERUN \ud83d\udd79\ufe0f Collection: https://huggingface.co/collections/prithivMLmods/multimodal-implementations To know more about it, visit the app page or the respective model page! See translation", "url": "https://huggingface.co/posts/prithivMLmods/527859222205581", "date_published": "2025-12-31T13:35:36.329919"}, {"id": "https://huggingface.co/posts/dhruv3006/142145591956765", "image": "", "title": "Git is powerful, but it\u2019s also one of the biggest sources of developer mistakes.", "content_text": "Git is powerful, but it\u2019s also one of the biggest sources of developer mistakes. What is Git GUI, and how does it help here ? Git GUI makes version control visual, predictable, and easier to reason about especially when things go wrong. That\u2019s exactly why we built Git GUI in Voiden. Instead of relying on memorized commands, Voiden lets you see what Git is doing before it does it. What Voiden\u2019s Git GUI helps developers do \u2022 View exact file and line-level changes before committing \u2022 Stage only intended changes (no accidental commits) \u2022 Clearly distinguish staged vs unstaged files \u2022 Inspect visual diffs with full context \u2022 Understand branches, commit history, and repo state instantly When Git behavior is hidden, errors increase. Voiden\u2019s Git GUI doesn\u2019t abstract Git away, it explains Git. Whether you\u2019re new to Git or an experienced developer who prefers clarity, this is Git you can reason about. Version control should feel safe, not stressful. What Git pain points slow you down today?...", "url": "https://huggingface.co/posts/dhruv3006/142145591956765", "date_published": "2025-12-31T13:35:36.330318"}, {"id": "https://huggingface.co/posts/Reubencf/502627640855049", "image": "", "title": "As 2025 is ending i would like to thank everyone for trying out", "content_text": "As 2025 is ending i would like to thank everyone for trying out Reubencf/Nano_Banana_Editor looking forward to build and release more in the future for the open source community See translation", "url": "https://huggingface.co/posts/Reubencf/502627640855049", "date_published": "2025-12-31T13:35:36.330515"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/729956870553821", "image": "", "title": "How to Use SwarmUI Presets & Workflows in ComfyUI + Custom Model Paths Setup for ComfyUI & SwarmUI :", "content_text": "How to Use SwarmUI Presets & Workflows in ComfyUI + Custom Model Paths Setup for ComfyUI & SwarmUI : https://www.youtube.com/watch?v=EqFilBM3i7s Full tutorial link > https://www.youtube.com/watch?v=EqFilBM3i7s Info Generating workflow inside SwarmUI and using in ComfyUI is literally 1-click. In this tutorial I will show you how to use our 40+ amazing generative AI presets made for SwarmUI in ComfyUI with most easy way. You will be able to get very best outcomes of all AI models such as SDXL, FLUX, Z Image Turbo, Wan 2.1, Wan 2.2, FLUX 2, Qwen Image, Qwen Image Edit, FLUX Kontext, Image Outpainting, Image Inpainting and many more. Moreover, I will show how to use custom model paths in ComfyUI and SwarmUI to unify your models in same folder and avoid model duplication and save massive amount of disk space. See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/729956870553821", "date_published": "2025-12-31T13:35:36.330798"}, {"id": "https://huggingface.co/posts/eaddario/324771984862709", "image": "", "title": "Experimental global target bits\u2011per\u2011weight quantization of allenai/Olmo-3-7B-Instruct and allenai/Olmo-3-7B-Think", "content_text": "Experimental global target bits\u2011per\u2011weight quantization of allenai/Olmo-3-7B-Instruct and allenai/Olmo-3-7B-Think Unlike standard llama.cpp quantizations that rely on fixed type heuristics (e.g., Q4_K_M), the Target BPW approach optimizes per-tensor precision where it matters the most, and produces high quality models that meet a precise global file size target. Key Advantages: - VRAM Maximization: Can generate high quality models sized exactly to fit hardware constraints (e.g., fitting the model into exactly 24GB VRAM). - Data-Driven Precision: Quantization mix is determined by actual weight error sensitivity rather than hardcoded rules, often yielding better PPL/KLD size trade-offs. Full benchmarks (PPL, KLD, ARC, MMLU, etc.) and methodology in the models' cards eaddario/Olmo-3-7B-Instruct-GGUF eaddario/Olmo-3-7B-Think-GGUF See translation", "url": "https://huggingface.co/posts/eaddario/324771984862709", "date_published": "2025-12-31T13:35:36.331125"}, {"id": "https://huggingface.co/posts/kanaria007/622562072144954", "image": "", "title": "\u2705 New Article: *Deep-Space SI-Core \u2014 Autonomy Across Light-Hours*", "content_text": "\u2705 New Article: *Deep-Space SI-Core \u2014 Autonomy Across Light-Hours* Title: \ud83d\ude80 Deep-Space SI-Core: Autonomy Across Light-Hours - How an onboard SI-Core evolves safely while Earth is hours away \ud83d\udd17 https://huggingface.co/blog/kanaria007/deep-space-si-core --- Summary: Most autonomy stories quietly assume \u201csomeone can intervene in minutes.\u201d Deep space breaks that assumption. With 2\u20136 hours round-trip latency and intermittent links, an onboard SI-Core must act as a *local sovereign*\u2014while remaining *globally accountable* to Earth. This note sketches how mission continuity survives when nobody is listening: DTN-style semantic bundles, local vs. global rollback, bounded self-improvement, and auditability that still works after contact windows return. > Autonomy isn\u2019t a divorce from governance\u2014 > it\u2019s a measured loan of authority, under a constitution, with evidence. --- Why It Matters: \u2022 Makes \u201cautonomous\u201d mean *operational*, not rhetorical, under light-hour delays \u2022 Clarifies how rollback...", "url": "https://huggingface.co/posts/kanaria007/622562072144954", "date_published": "2025-12-31T13:35:36.331658"}, {"id": "https://huggingface.co/posts/dhruv3006/954892005568912", "image": "", "title": "Runtime variables let you capture data from one API request and reuse it in the next. With Voiden, it\u2019s just plain YAML, no extra setup or scripts.", "content_text": "Runtime variables let you capture data from one API request and reuse it in the next. With Voiden, it\u2019s just plain YAML, no extra setup or scripts. Learn how to chain requests here: https://docs.voiden.md/docs/core-features-section/variables/runtime-variables Visit voiden here : https://voiden.md See translation", "url": "https://huggingface.co/posts/dhruv3006/954892005568912", "date_published": "2025-12-31T13:35:36.331874"}]}