{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/141662077994282", "image": "", "title": "\ud83d\ude80 FLUX Workflow Canvas", "content_text": "\ud83d\ude80 FLUX Workflow Canvas Welcome to Workflow Canvas, your ultimate AI-driven platform for crafting stunning design concepts and intricate workflow diagrams that empower your business! \ud83e\udd16\u2728 ginigen/Workflow-Canvas Features Product Design \ud83d\udee0\ufe0f Transform your ideas into reality with sleek, industrial product designs that blend modern aesthetics with advanced technology. Mindmap \ud83e\udde0 Generate vibrant, educational mind maps that outline your strategies and processes in a clear, visually engaging layout. Mockup \ud83d\udcf1 Quickly prototype intuitive app interfaces and web designs using clean, hand-drawn wireframes that capture your vision. Infographic \ud83d\udcca Build polished, data-rich infographics that communicate complex corporate metrics and trends with style and clarity. Diagram \ud83d\udcc8 Illustrate comprehensive, end-to-end business workflows\u2014from market analysis to implementation\u2014with detailed and organized diagrams. Flowchart \ud83d\udd04 Design easy-to-follow, hand-drawn style flowcharts that map out your operational...", "url": "https://huggingface.co/posts/ginipick/141662077994282", "date_published": "2025-02-18T13:25:49.508068"}, {"id": "https://huggingface.co/posts/prithivMLmods/804280933500371", "image": "", "title": "The last week of Impression Craft Arts and sketches from strangerzonehf\ud83c\udfa8\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa8", "content_text": "The last week of Impression Craft Arts and sketches from strangerzonehf\ud83c\udfa8\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa8 - Collection : strangerzonehf/Flux-Ultimate-LoRA-Collection Adapters: + Ld-Art : strangerzonehf/Ld-Art + Animeopix-Flux : strangerzonehf/Animeopix-Flux + Flux-Super-Paint-LoRA : strangerzonehf/Flux-Super-Paint-LoRA + CinematicShot-Pics-Flux : strangerzonehf/cinematicShot-Pics-Flux + Oil-Wall-Art-Flux : strangerzonehf/Oil-Wall-Art-Flux + Pixelo-Flux : strangerzonehf/Pixelo-Flux + Abstract-Shattered : strangerzonehf/Abstract-Shattered + Neon-Impressionism-Flux : strangerzonehf/Neon-Impressionism-Flux + NewG-Art : strangerzonehf/NewG-Art \ud83e\udea7Demo : prithivMLmods/FLUX-LoRA-DLC \ud83e\udd17Page : https://huggingface.co/strangerzonehf See translation", "url": "https://huggingface.co/posts/prithivMLmods/804280933500371", "date_published": "2025-02-18T13:25:49.508485"}, {"id": "https://huggingface.co/posts/Reality123b/533143502736808", "image": "", "title": "I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait", "content_text": "I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait See translation", "url": "https://huggingface.co/posts/Reality123b/533143502736808", "date_published": "2025-02-18T13:25:49.508738"}, {"id": "https://huggingface.co/posts/Jaward/905904518817417", "image": "", "title": "Finally here it is: a faster, custom, scalable GRPO trainer for smaller models with < 500M params, can train on 8gb ram cpu,  also supports gpu for sanity sake (includes support for vllm + flash attention). Using smolLM2-135M/360M-instructs as ref & base models. Experience your own \u201caha\u201d moment \ud83d\udc33 on 8gb ram.", "content_text": "Finally here it is: a faster, custom, scalable GRPO trainer for smaller models with < 500M params, can train on 8gb ram cpu, also supports gpu for sanity sake (includes support for vllm + flash attention). Using smolLM2-135M/360M-instructs as ref & base models. Experience your own \u201caha\u201d moment \ud83d\udc33 on 8gb ram. Code: https://github.com/Jaykef/ai-algorithms/blob/main/smollm2_360M_135M_grpo_gsm8k.ipynb See translation", "url": "https://huggingface.co/posts/Jaward/905904518817417", "date_published": "2025-02-18T13:25:49.509034"}, {"id": "https://huggingface.co/posts/ginipick/539440985640088", "image": "", "title": "Gini's AI Spaces: Everything You Need for Visual Content Creation!", "content_text": "Gini's AI Spaces: Everything You Need for Visual Content Creation! Hello! \u2728 Let me introduce Gini\u2019s 5 AI Spaces that effortlessly generate various styles of visual content. Each Space leverages Diffusers and Gradio, so you can create stunning images in just a few clicks! 1) Flowchart Features: Hand-drawn style flowcharts for workflows or business processes Use Cases: Software release pipelines, data pipelines, corporate workflows Benefits: Clear stage-by-stage structure, simple icon usage ginigen/Flowchart 2) Infographic Features: Visually appealing infographics that communicate data or statistics Use Cases: Global energy charts, startup growth metrics, health tips and more Benefits: Eye-catching icons and layouts, perfect for storytelling at a glance ginigen/Infographic 3) Mockup Features: Sketch-style wireframes or UX mockups for apps/websites Use Cases: Mobile login flows, dashboards, e-commerce site layouts Benefits: Rapid prototyping of early design ideas, perfect for...", "url": "https://huggingface.co/posts/ginipick/539440985640088", "date_published": "2025-02-18T13:25:49.509664"}, {"id": "https://huggingface.co/posts/tianchez/384417618281589", "image": "", "title": "Introducing VLM-R1!", "content_text": "Introducing VLM-R1! GRPO has helped DeepSeek R1 to learn reasoning. Can it also help VLMs perform stronger for general computer vision tasks? The answer is YES and it generalizes better than SFT. We trained Qwen 2.5 VL 3B on RefCOCO (a visual grounding task) and eval on RefCOCO Val and RefGTA (an OOD task). https://github.com/om-ai-lab/VLM-R1 See translation", "url": "https://huggingface.co/posts/tianchez/384417618281589", "date_published": "2025-02-18T13:25:49.509934"}, {"id": "https://huggingface.co/posts/clem/679572962523651", "image": "", "title": "We crossed 1B+ tokens routed to inference providers partners on HF, that we released just a few days ago.", "content_text": "We crossed 1B+ tokens routed to inference providers partners on HF, that we released just a few days ago. Just getting started of course but early users seem to like it & always happy to be able to partner with cool startups in the ecosystem. Have you been using any integration and how can we make it better? https://huggingface.co/blog/inference-providers See translation", "url": "https://huggingface.co/posts/clem/679572962523651", "date_published": "2025-02-18T13:25:49.510210"}, {"id": "https://huggingface.co/posts/schuler/523097349867184", "image": "", "title": "\ud83d\udd2e GPT-3 implemented in pure Free Pascal!", "content_text": "\ud83d\udd2e GPT-3 implemented in pure Free Pascal! https://github.com/joaopauloschuler/gpt-3-for-pascal This implementation follows the GPT-3 Small architecture from the landmark paper \"Language Models are Few-Shot Learners\": \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Input Layer \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Token & Positional \u2502 \u2502 Embedding \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 12x Transformer \u2502 \u2502 Blocks \u2502 \u2502 - 12 heads \u2502 \u2502 - 768 hidden dims \u2502 \u2502 - 3072 intermediate \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Output Layer \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Clean Pascal Implementation for CntLayer := 1 to {Layers=} 12 do begin Result .AddTransformerBlockCAI( {Heads=} 12 , {intermediate dimensions=} 4 * 768 , {NoForward=} true , {HasNorm=} true , false ) ; end ; See translation", "url": "https://huggingface.co/posts/schuler/523097349867184", "date_published": "2025-02-18T13:25:49.510613"}, {"id": "https://huggingface.co/posts/louisbrulenaudet/828105702758595", "image": "", "title": "I am pleased to introduce my first project built upon Hugging Face\u2019s smolagents framework, integrated with Alpaca for financial market analysis automation \ud83e\udd99\ud83e\udd17", "content_text": "I am pleased to introduce my first project built upon Hugging Face\u2019s smolagents framework, integrated with Alpaca for financial market analysis automation \ud83e\udd99\ud83e\udd17 The project implements technical indicators such as the Relative Strength Index (RSI) and Bollinger Bands to provide momentum and volatility analysis. Market data is retrieved through the Alpaca API, enabling access to historical price information across various timeframes. AI-powered insights are generated using Hugging Face\u2019s inference API, facilitating the analysis of market trends through natural language processing with DuckDuckGo search integration for real-time sentiment analysis based on financial news \ud83e\udd86 Link to the GitHub project: https://github.com/louisbrulenaudet/agentic-market-tool See translation", "url": "https://huggingface.co/posts/louisbrulenaudet/828105702758595", "date_published": "2025-02-18T13:25:49.510989"}, {"id": "https://huggingface.co/posts/Kseniase/134685305854108", "image": "", "title": "8 New Applications of Test-Time Scaling", "content_text": "8 New Applications of Test-Time Scaling We've noticed a huge interest in test-time scaling (TTS), so we decided to explore this concept further. Test-time compute (TTC) refers to the amount of computational power used by an AI model when generating a response. Many researchers are now focused on scaling TTC, as it enables slow, deep \"thinking\" and step-by-step reasoning, which improves overall models' performance. Here are 8 fresh studies on test-time scaling: 1. Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach (2502.05171) Introduces an LM that scales TTC by reasoning in latent space instead of generating more tokens with no special training. Here, a recurrent block to processes information iteratively. 2. Generating Symbolic World Models via Test-time Scaling of Large Language Models (2502.04728) Shows how TTS is applied to enhance model's Planning Domain Definition Language (PDDL) reasoning capabilities, which can be used to generate a symbolic world...", "url": "https://huggingface.co/posts/Kseniase/134685305854108", "date_published": "2025-02-18T13:25:49.511583"}]}