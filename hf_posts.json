{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/wcy1122/435759509322871", "image": "", "title": "\ud83d\ude80 Introducing MGM-Omni, an omni-chatbot capable of processing text, image, video, and speech inputs, and can generate both text and speech responses.", "content_text": "\ud83d\ude80 Introducing MGM-Omni, an omni-chatbot capable of processing text, image, video, and speech inputs, and can generate both text and speech responses. \ud83d\udc42 MGM-Omni support hour-level audio understanding. \ud83d\udde3\ufe0f MGM-Omni support 10-minute speech generation and voice cloning. For more details, please check: \ud83d\udcdd Blog: https://mgm-omni.notion.site/MGM-Omni-An-Open-source-Omni-Chatbot-2395728e0b0180149ac9f24683fc9907 \ud83c\udf1f Code: https://github.com/dvlab-research/MGM-Omni \ud83e\udd16 Model: wcy1122/mgm-omni-6896075e97317a88825032e1 \ud83c\udfae Demo: wcy1122/MGM-Omni See translation", "url": "https://huggingface.co/posts/wcy1122/435759509322871", "date_published": "2025-08-22T13:31:58.021032"}, {"id": "https://huggingface.co/posts/AdinaY/251517572573964", "image": "", "title": "\u2728 DeepSeek V3.1 just dropped on the hub.", "content_text": "\u2728 DeepSeek V3.1 just dropped on the hub. deepseek-ai/DeepSeek-V3.1-Base See translation", "url": "https://huggingface.co/posts/AdinaY/251517572573964", "date_published": "2025-08-22T13:31:58.021319"}, {"id": "https://huggingface.co/posts/ccocks-deca/499605656909204", "image": "", "title": "12 hours ago:", "content_text": "12 hours ago: Something big* coming * big = biggest in the world Annnnnd... here it is! deca-ai/3-alpha-ultra \u2014the largest AI model in the world by deca-ai , clocking in at a whopping 4.6T parameters. Apologies for the delay, but we\u2019re stoked to finally drop this, even in its alpha stage. Before you dive in, here are a few things to keep in mind: 1. **No commercial use yet**: We're still working on Deca 2.5 (Proprietary), and releasing Deca 3 for commercial use right now would impact that. Once Deca 3.5 hits in early '26, we\u2019ll be opening it up with a more permissive license. 2. **Built on existing models**: Deca 3 isn\u2019t a ground-up creation\u2014it\u2019s a huge step forward, building on what\u2019s already out there. 3. **It\u2019s experimental**: As much as we\u2019re hyped about its scale, it\u2019s still in testing. 4. **DynaMoE architecture**: Run a (very) small part of the model with 64GB of RAM/VRAM (when quantized - quants coming soon), or the whole thing with 1TB. It\u2019s that scalable. 5. **Not widely...", "url": "https://huggingface.co/posts/ccocks-deca/499605656909204", "date_published": "2025-08-22T13:31:58.021870"}, {"id": "https://huggingface.co/posts/ProCreations/419010322512677", "image": "", "title": "why did 36 people unfollow me \ud83d\ude2d", "content_text": "why did 36 people unfollow me \ud83d\ude2d we are back in the hundreds. if you become my 500th follower and have proof I'll give you 5 dollars worth of openrouter credits as an API key See translation", "url": "https://huggingface.co/posts/ProCreations/419010322512677", "date_published": "2025-08-22T13:31:58.022109"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/826512832075444", "image": "", "title": "Wan 2.2, FLUX, FLUX Krea & Qwen Image Just got Upgraded: Ultimate Tutorial for Open Source SOTA Image & Video Gen Models - With easy to use SwarmUI with ComfyUI Backend :", "content_text": "Wan 2.2, FLUX, FLUX Krea & Qwen Image Just got Upgraded: Ultimate Tutorial for Open Source SOTA Image & Video Gen Models - With easy to use SwarmUI with ComfyUI Backend : https://youtu.be/3BFDcO2Ysu4 Tutorial Video : https://youtu.be/3BFDcO2Ysu4 Wan 2.2, Qwen Image, FLUX, FLUX Krea, all these models are the SOTA open-source models and in this master tutorial I will show you how to use these models in the easiest, most performant, and most accurate way. After doing almost one week of research, I have determined the very best presets and prepared this tutorial. With literally one click you will be able to install, download models, set presets, and use these amazing models. Wan 2.2 is currently the king of video generation models and now it is super fast with lightx2v Wan2.2-Lightning LoRAs. Moreover, Qwen Image is now ultra-fast with the recently released 8-step LoRA with almost no quality loss. Furthermore, I have updated FLUX and FLUX Krea presets to improve image generation...", "url": "https://huggingface.co/posts/MonsterMMORPG/826512832075444", "date_published": "2025-08-22T13:31:58.022521"}, {"id": "https://huggingface.co/posts/AdinaY/149610366794720", "image": "", "title": "Seed-OSS \ud83d\udd25 The latest open LLM from Bytedance Seed team", "content_text": "Seed-OSS \ud83d\udd25 The latest open LLM from Bytedance Seed team ByteDance-Seed/seed-oss-68a609f4201e788db05b5dcd \u2728 36B - Base & Instruct \u2728 Apache 2.0 \u2728 Native 512K long context \u2728 Strong reasoning & agentic intelligence \u2728 2 Base versions: with & without synthetic data See translation", "url": "https://huggingface.co/posts/AdinaY/149610366794720", "date_published": "2025-08-22T13:31:58.022765"}, {"id": "https://huggingface.co/posts/pagezyhf/949187233847606", "image": "", "title": "We've improved the Deploy button on Hugging Face model pages for Microsoft Azure", "content_text": "We've improved the Deploy button on Hugging Face model pages for Microsoft Azure 1/ no more long waits before seeing model support status 2/ ready-to-use CLI and Python snippets 3/ redirection to Azure AI Foundry rather than Azure ML \u270b if you see any bugs or have feedback, open an issue on our repo: https://github.com/huggingface/Microsoft-Azure See translation", "url": "https://huggingface.co/posts/pagezyhf/949187233847606", "date_published": "2025-08-22T13:31:58.023034"}, {"id": "https://huggingface.co/posts/seawolf2357/250380945868372", "image": "", "title": "\ud83c\udfa8 Open Nano-Banana: Revolution in Ultra-Fast AI Image Editing!", "content_text": "\ud83c\udfa8 Open Nano-Banana: Revolution in Ultra-Fast AI Image Editing! \ud83d\ude80 Introduction **Open Nano-Banana** is an innovative image editing tool based on the Qwen-Image-Edit model. Experience amazing quality image editing in just 8 steps! Heartsync/Nano-Banana \u2728 Core Features \u26a1 Lightning-Fast Editing * **8-Step Generation**: Ultra-fast processing with Qwen-Image-Lightning LoRA * **Real-time Editing**: 10x faster than conventional methods * **GPU Optimization**: Maximized memory efficiency with xformers \ud83e\udd16 AI Prompt Enhancement * **Automatic Prompt Improvement**: Intelligent rewriting with Cerebras' Qwen3-235B model * **Multilingual Support**: Auto-detection for Korean/Chinese/English * **Context Understanding**: Sophisticated command generation aligned with image context \ud83c\udfaf Versatile Editing Functions \u2705 Add/Delete/Replace objects \u2705 Text editing and style transformation \u2705 Person editing (expressions, hairstyles) \u2705 Vintage restoration and style conversion \u2705 Background replacement and enhancement...", "url": "https://huggingface.co/posts/seawolf2357/250380945868372", "date_published": "2025-08-22T13:31:58.023622"}, {"id": "https://huggingface.co/posts/ZacMasa5000/133834634332701", "image": "", "title": "New Hugging Face Dataset is LIVE \ud83e\udd17", "content_text": "New Hugging Face Dataset is LIVE \ud83e\udd17 In this dataset, you\u2019ll find 20,000+ rows of the top trending posts on X over the past several weeks. \ud83d\udd25Topics Include: \ud83d\udd39Bitcoin \ud83d\udd39GPT-5 \ud83d\udd39Grok \ud83d\udd39Cursor \ud83d\udd39AI, Agents + Prompts \ud83d\udd39Chainlink $LINK \ud83d\udcc2Download dataset! Easily, plug it into your AI agents, LLMs or apps. MasaFoundation/X_Twitter_Trending_Topics_August2025 You can start query fresh data in our app and request API key here: https://bit.ly/4mrqbO2 See translation", "url": "https://huggingface.co/posts/ZacMasa5000/133834634332701", "date_published": "2025-08-22T13:31:58.023916"}, {"id": "https://huggingface.co/posts/kanaria007/560902944774008", "image": "", "title": "\u2705 New Article: *Time as Structured Recursion*", "content_text": "\u2705 New Article: *Time as Structured Recursion* Title: \u23f3 Time: Recursive Loop Indexing and Future as Jump Prediction \ud83d\udd17 https://huggingface.co/blog/kanaria007/structured-time --- Summary: Time is often imagined as *a linear flow*. Structured Intelligence reframes it as *recursive architecture*: * Past as *active memory loops* * Present as *indexed structural state* * Future as *bounded jump space and anticipatory frame* > Time isn\u2019t a river \u2014 > *it\u2019s the looped structure that makes thought possible.* --- Why It Matters: \u2022 Explains how *memory, prediction, and decision* rely on time as structure \u2022 Bridges *philosophy of time and cognitive architecture* \u2022 Enables *AI systems to handle temporal reasoning and rollback* --- What\u2019s Inside: \u2022 Time as *loop, index, and jump space* \u2022 *Cognitive experience of temporality* as structural phenomenon \u2022 *Rollback and anticipation* in decision architecture \u2022 Implications for *AI temporal reasoning and self\u2011alignment* --- \ud83d\udcd6 Article 23 of the Structured...", "url": "https://huggingface.co/posts/kanaria007/560902944774008", "date_published": "2025-08-22T13:31:58.024454"}]}