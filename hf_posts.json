{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/539440985640088", "image": "", "title": "Gini's AI Spaces: Everything You Need for Visual Content Creation!", "content_text": "Gini's AI Spaces: Everything You Need for Visual Content Creation! Hello! \u2728 Let me introduce Gini\u2019s 5 AI Spaces that effortlessly generate various styles of visual content. Each Space leverages Diffusers and Gradio, so you can create stunning images in just a few clicks! 1) Flowchart Features: Hand-drawn style flowcharts for workflows or business processes Use Cases: Software release pipelines, data pipelines, corporate workflows Benefits: Clear stage-by-stage structure, simple icon usage ginigen/Flowchart 2) Infographic Features: Visually appealing infographics that communicate data or statistics Use Cases: Global energy charts, startup growth metrics, health tips and more Benefits: Eye-catching icons and layouts, perfect for storytelling at a glance ginigen/Infographic 3) Mockup Features: Sketch-style wireframes or UX mockups for apps/websites Use Cases: Mobile login flows, dashboards, e-commerce site layouts Benefits: Rapid prototyping of early design ideas, perfect for...", "url": "https://huggingface.co/posts/ginipick/539440985640088", "date_published": "2025-02-17T13:27:38.002270"}, {"id": "https://huggingface.co/posts/tianchez/384417618281589", "image": "", "title": "Introducing VLM-R1!", "content_text": "Introducing VLM-R1! GRPO has helped DeepSeek R1 to learn reasoning. Can it also help VLMs perform stronger for general computer vision tasks? The answer is YES and it generalizes better than SFT. We trained Qwen 2.5 VL 3B on RefCOCO (a visual grounding task) and eval on RefCOCO Val and RefGTA (an OOD task). https://github.com/om-ai-lab/VLM-R1 See translation", "url": "https://huggingface.co/posts/tianchez/384417618281589", "date_published": "2025-02-17T13:27:38.002561"}, {"id": "https://huggingface.co/posts/prithivMLmods/804280933500371", "image": "", "title": "The last week of Impression Craft Arts and sketches from strangerzonehf\ud83c\udfa8\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa8", "content_text": "The last week of Impression Craft Arts and sketches from strangerzonehf\ud83c\udfa8\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa8 - Collection : strangerzonehf/Flux-Ultimate-LoRA-Collection Adapters: + Ld-Art : strangerzonehf/Ld-Art + Animeopix-Flux : strangerzonehf/Animeopix-Flux + Flux-Super-Paint-LoRA : strangerzonehf/Flux-Super-Paint-LoRA + CinematicShot-Pics-Flux : strangerzonehf/cinematicShot-Pics-Flux + Oil-Wall-Art-Flux : strangerzonehf/Oil-Wall-Art-Flux + Pixelo-Flux : strangerzonehf/Pixelo-Flux + Abstract-Shattered : strangerzonehf/Abstract-Shattered + Neon-Impressionism-Flux : strangerzonehf/Neon-Impressionism-Flux + NewG-Art : strangerzonehf/NewG-Art \ud83e\udea7Demo : prithivMLmods/FLUX-LoRA-DLC \ud83e\udd17Page : https://huggingface.co/strangerzonehf See translation", "url": "https://huggingface.co/posts/prithivMLmods/804280933500371", "date_published": "2025-02-17T13:27:38.002934"}, {"id": "https://huggingface.co/posts/Reality123b/533143502736808", "image": "", "title": "I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait", "content_text": "I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? (edit: it takes 1000s for one task forgive me as i dont have some kind of huge server for that) edit2: this is not a clickbait See translation", "url": "https://huggingface.co/posts/Reality123b/533143502736808", "date_published": "2025-02-17T13:27:38.003184"}, {"id": "https://huggingface.co/posts/schuler/523097349867184", "image": "", "title": "\ud83d\udd2e GPT-3 implemented in pure Free Pascal!", "content_text": "\ud83d\udd2e GPT-3 implemented in pure Free Pascal! https://github.com/joaopauloschuler/gpt-3-for-pascal This implementation follows the GPT-3 Small architecture from the landmark paper \"Language Models are Few-Shot Learners\": \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Input Layer \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Token & Positional \u2502 \u2502 Embedding \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 12x Transformer \u2502 \u2502 Blocks \u2502 \u2502 - 12 heads \u2502 \u2502 - 768 hidden dims \u2502 \u2502 - 3072 intermediate \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 Output Layer \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Clean Pascal Implementation for CntLayer := 1 to {Layers=} 12 do begin Result .AddTransformerBlockCAI( {Heads=} 12 , {intermediate dimensions=} 4 * 768 , {NoForward=} true , {HasNorm=} true , false ) ; end ; See translation", "url": "https://huggingface.co/posts/schuler/523097349867184", "date_published": "2025-02-17T13:27:38.003598"}, {"id": "https://huggingface.co/posts/Kseniase/134685305854108", "image": "", "title": "8 New Applications of Test-Time Scaling", "content_text": "8 New Applications of Test-Time Scaling We've noticed a huge interest in test-time scaling (TTS), so we decided to explore this concept further. Test-time compute (TTC) refers to the amount of computational power used by an AI model when generating a response. Many researchers are now focused on scaling TTC, as it enables slow, deep \"thinking\" and step-by-step reasoning, which improves overall models' performance. Here are 8 fresh studies on test-time scaling: 1. Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach (2502.05171) Introduces an LM that scales TTC by reasoning in latent space instead of generating more tokens with no special training. Here, a recurrent block to processes information iteratively. 2. Generating Symbolic World Models via Test-time Scaling of Large Language Models (2502.04728) Shows how TTS is applied to enhance model's Planning Domain Definition Language (PDDL) reasoning capabilities, which can be used to generate a symbolic world...", "url": "https://huggingface.co/posts/Kseniase/134685305854108", "date_published": "2025-02-17T13:27:38.004173"}, {"id": "https://huggingface.co/posts/benhaotang/322538825901593", "image": "", "title": "Try out my updated implementation of forked OpenDeepResearcher(link below) as an OpenAI compatible endpoint, but with full control, can be deployed completely free with Gemini api or completely locally with ollama, or pay-as-you-go in BYOK format, the AI agents will think dynamically based on the difficulties of given research, compatible with any OpenAI compatible configurable clients(Msty, Chatbox, even vscode AI Toolkit playground).", "content_text": "Try out my updated implementation of forked OpenDeepResearcher(link below) as an OpenAI compatible endpoint, but with full control, can be deployed completely free with Gemini api or completely locally with ollama, or pay-as-you-go in BYOK format, the AI agents will think dynamically based on the difficulties of given research, compatible with any OpenAI compatible configurable clients(Msty, Chatbox, even vscode AI Toolkit playground). If you don't want to pay OpenAI $200 to use or want to take control of your deep research, check out here: \ud83d\udc49 https://github.com/benhaotang/OpenDeepResearcher-via-searxng **Personal take** Based on my testing against Perplexity's and Gemini's implementation with some Physics domain questions, mine is comparable and very competent at finding even the most rare articles or methods. Also a funny benchmark of mine to test all these searching models, is to trouble shot a WSL2 hanging issue I experienced last year, with prompt: > wsl2 in windows hangs in...", "url": "https://huggingface.co/posts/benhaotang/322538825901593", "date_published": "2025-02-17T13:27:38.004817"}, {"id": "https://huggingface.co/posts/louisbrulenaudet/828105702758595", "image": "", "title": "I am pleased to introduce my first project built upon Hugging Face\u2019s smolagents framework, integrated with Alpaca for financial market analysis automation \ud83e\udd99\ud83e\udd17", "content_text": "I am pleased to introduce my first project built upon Hugging Face\u2019s smolagents framework, integrated with Alpaca for financial market analysis automation \ud83e\udd99\ud83e\udd17 The project implements technical indicators such as the Relative Strength Index (RSI) and Bollinger Bands to provide momentum and volatility analysis. Market data is retrieved through the Alpaca API, enabling access to historical price information across various timeframes. AI-powered insights are generated using Hugging Face\u2019s inference API, facilitating the analysis of market trends through natural language processing with DuckDuckGo search integration for real-time sentiment analysis based on financial news \ud83e\udd86 Link to the GitHub project: https://github.com/louisbrulenaudet/agentic-market-tool See translation", "url": "https://huggingface.co/posts/louisbrulenaudet/828105702758595", "date_published": "2025-02-17T13:27:38.005192"}, {"id": "https://huggingface.co/posts/nroggendorff/464265972064174", "image": "", "title": "hello, dev mode explorers!", "content_text": "hello, dev mode explorers! See translation", "url": "https://huggingface.co/posts/nroggendorff/464265972064174", "date_published": "2025-02-17T13:27:38.005413"}, {"id": "https://huggingface.co/posts/fffiloni/806803691807876", "image": "", "title": "I was thinking i need to step up my game on training Flux LoRas models, time to have some fun ! \u2600\ufe0f", "content_text": "I was thinking i need to step up my game on training Flux LoRas models, time to have some fun ! \u2600\ufe0f Expect a new drop per week on aesthetics that catched my attention, here are 3 of them that worked really well ! fffiloni/cute-comic-800 fffiloni/carbo-800 fffiloni/oniric-750 See translation", "url": "https://huggingface.co/posts/fffiloni/806803691807876", "date_published": "2025-02-17T13:27:38.005677"}]}