{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/807578740801859", "image": "", "title": "\ud83c\udfef Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! \u2728", "content_text": "\ud83c\udfef Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! \u2728 Hello AI enthusiasts! \ud83d\ude4b\u200d\u2640\ufe0f Today I'm introducing a truly magical project: Open Ghibli Studio \ud83c\udfa8 ginigen/FLUX-Open-Ghibli-Studio \ud83c\udf1f What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! \ud83c\udfde\ufe0f\u2728 \ud83d\udd27 How Does It Work? \ud83d\udcf8 Upload your photo \ud83e\udd16 Florence-2 AI analyzes the image and generates a description \u270f\ufe0f \"Ghibli style\" is added to the description \ud83c\udfad Magic transformation happens using the FLUX.1 model and Ghibli LoRA! \u2699\ufe0f Customization Options Want more control? Adjust these in the advanced settings: \ud83c\udfb2 Set a seed (for reproducible results) \ud83d\udccf Adjust image dimensions \ud83d\udd0d Guidance scale (prompt adherence) \ud83d\udd04 Number of generation steps \ud83d\udcab Ghibli style intensity \ud83d\ude80 Try It Now! Click the \"Transform to Ghibli Style\" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? \ud83c\udf08 \ud83c\udf3f Note: For best results,...", "url": "https://huggingface.co/posts/ginipick/807578740801859", "date_published": "2025-04-04T05:22:28.043142"}, {"id": "https://huggingface.co/posts/seawolf2357/883323339740165", "image": "", "title": "\ud83c\udfa8 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition \ud83c\udf0f\u2728", "content_text": "\ud83c\udfa8 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition \ud83c\udf0f\u2728 Hello creators! Today I'm introducing a special image generator that combines the beautiful aesthetics of Studio Ghibli with multilingual text integration! \ud83d\ude0d seawolf2357/Ghibli-Multilingual-Text-rendering \u2728 Key Features Ghibli-Style Image Generation - High-quality animation-style images based on FLUX.1 Multilingual Text Rendering - Support for Korean, Japanese, English, and all languages! \ud83c\uddf0\ud83c\uddf7\ud83c\uddef\ud83c\uddf5\ud83c\uddec\ud83c\udde7 Automatic Image Editing with Simple Prompts - Just input your desired text and you're done! Two Stylistic Variations Provided - Get two different results from a single prompt Full Hugging Face Spaces Support - Deploy and share instantly! \ud83d\ude80 How Does It Work? Enter a prompt describing your desired image (e.g., \"a cat sitting by the window\") Input the text you want to add (any language works!) Select the text position, size, and color Two different versions are automatically generated! \ud83d\udcaf...", "url": "https://huggingface.co/posts/seawolf2357/883323339740165", "date_published": "2025-04-04T05:22:28.043803"}, {"id": "https://huggingface.co/posts/openfree/925352420925810", "image": "", "title": "\ud83d\udd25 'Open Meme Studio': Your Creative Meme Factory \ud83c\udfad\u2728", "content_text": "\ud83d\udd25 'Open Meme Studio': Your Creative Meme Factory \ud83c\udfad\u2728 Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. \ud83d\ude80 VIDraft/Open-Meme-Studio \ud83c\udfaf Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! \ud83d\udee0\ufe0f Features You'll Love \ud83d\udcf8 Transform and reinterpret existing meme templates \ud83c\udfad Freely change expressions and poses \ud83d\udc53 Add props (sunglasses, hats, etc.) \ud83c\udfde\ufe0f Change backgrounds and composite characters \ud83c\udfa8 Apply various artistic styles \ud83d\udcaa Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...", "url": "https://huggingface.co/posts/openfree/925352420925810", "date_published": "2025-04-04T05:22:28.044471"}, {"id": "https://huggingface.co/posts/jasoncorkill/394806250895359", "image": "", "title": "\ud83d\ude80 Rapidata: Setting the Standard for Model Evaluation", "content_text": "\ud83d\ude80 Rapidata: Setting the Standard for Model Evaluation Rapidata is proud to announce our first independent appearance in academic research, featured in the Lumina-Image 2.0 paper. This marks the beginning of our journey to become the standard for testing text-to-image and generative models. Our expertise in large-scale human annotations allows researchers to refine their models with accurate, real-world feedback. As we continue to establish ourselves as a key player in model evaluation, we\u2019re here to support researchers with high-quality annotations at scale. Reach out to info@rapidata.ai to see how we can help. Lumina-Image 2.0: A Unified and Efficient Image Generative Framework (2503.21758) See translation", "url": "https://huggingface.co/posts/jasoncorkill/394806250895359", "date_published": "2025-04-04T05:22:28.044852"}, {"id": "https://huggingface.co/posts/AdinaY/602638381866736", "image": "", "title": "Dolphin \ud83d\udc2c an open ASR model released by DataOceanAI, one of the biggest AI data provider in China \ud83d\udd25", "content_text": "Dolphin \ud83d\udc2c an open ASR model released by DataOceanAI, one of the biggest AI data provider in China \ud83d\udd25 \u2728 Supports 40 Eastern languages & 22 Chinese dialects \u2728 Apache2.0 \u2728 With 21.2M hours of data (7.4M open data) Model: DataoceanAI/dolphin-base DataoceanAI/dolphin-small Paper: Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages (2503.20212) See translation", "url": "https://huggingface.co/posts/AdinaY/602638381866736", "date_published": "2025-04-04T05:22:28.045175"}, {"id": "https://huggingface.co/posts/abidlabs/192598522318521", "image": "", "title": "JOURNEY TO 1 MILLION DEVELOPERS", "content_text": "JOURNEY TO 1 MILLION DEVELOPERS 5 years ago, we launched Gradio as a simple Python library to let researchers at Stanford easily demo computer vision models with a web interface. Today, Gradio is used by >1 million developers each month to build and share AI web apps. This includes some of the most popular open-source projects of all time, like Automatic1111, Fooocus, Oobabooga\u2019s Text WebUI, Dall-E Mini, and LLaMA-Factory. How did we get here? How did Gradio keep growing in the very crowded field of open-source Python libraries? I get this question a lot from folks who are building their own open-source libraries. This post distills some of the lessons that I have learned over the past few years: 1. Invest in good primitives, not high-level abstractions 2. Embed virality directly into your library 3. Focus on a (growing) niche 4. Your only roadmap should be rapid iteration 5. Maximize ways users can consume your library's outputs 1. Invest in good primitives, not high-level...", "url": "https://huggingface.co/posts/abidlabs/192598522318521", "date_published": "2025-04-04T05:22:28.045701"}, {"id": "https://huggingface.co/posts/fdaudens/934723096237481", "image": "", "title": "Did we just drop personalized AI evaluation?! This tool auto-generates custom benchmarks on your docs to test which models are the best.", "content_text": "Did we just drop personalized AI evaluation?! This tool auto-generates custom benchmarks on your docs to test which models are the best. Most benchmarks test general capabilities, but what matters is how models handle your data and tasks. YourBench helps answer critical questions like: - Do you really need a hundreds-of-billions-parameter model sledgehammer to crack a nut? - Could a smaller, fine-tuned model work better? - How well do different models understand your domain? Some cool features: \ud83d\udcda Generates custom benchmarks from your own documents (PDFs, Word, HTML) \ud83c\udfaf Tests models on real tasks, not just general capabilities \ud83d\udd04 Supports multiple models for different pipeline stages \ud83e\udde0 Generate both single-hop and multi-hop questions \ud83d\udd0d Evaluate top models and deploy leaderboards instantly \ud83d\udcb0 Full cost analysis to optimize for your budget \ud83d\udee0\ufe0f Fully configurable via a single YAML file 26 SOTA models tested for question generation. Interesting finding: Qwen2.5 32B leads in question...", "url": "https://huggingface.co/posts/fdaudens/934723096237481", "date_published": "2025-04-04T05:22:28.046201"}, {"id": "https://huggingface.co/posts/John6666/145133458851083", "image": "", "title": "I used up my Zero GPU Quota yesterday (about 12 hours ago). At the time, I got a message saying \u201cRetry at 13:45 (approx.)\u201d, but now it's just changed to \u201cRetry at 03:22\u201d.", "content_text": "I used up my Zero GPU Quota yesterday (about 12 hours ago). At the time, I got a message saying \u201cRetry at 13:45 (approx.)\u201d, but now it's just changed to \u201cRetry at 03:22\u201d. Anyway, everyone, let's be careful not to use up our Quota... Related: https://huggingface.co/posts/Keltezaa/754755723533287#67e6ed5e3394f1ed9ca41dbd See translation", "url": "https://huggingface.co/posts/John6666/145133458851083", "date_published": "2025-04-04T05:22:28.046481"}, {"id": "https://huggingface.co/posts/onekq/914618105461192", "image": "", "title": "Adding MLX version of OneSQL 7B for MacBook (Apple Silicon) users", "content_text": "Adding MLX version of OneSQL 7B for MacBook (Apple Silicon) users onekq-ai/OneSQL-v0.1-Qwen-7B-MLX-4bit This model has the best accuracy among all quantized versions (AWX, GGUF etc.), which I am very happy about. I tested this model on my MacBook Air with M1 processor and 8GB of RAM, which is the lower bound of Apple Silicon, also the earliest and still the most popular. On average it took 16 seconds to generate a SQL query, and one minute in the worst case. If you own a newer MacBook with M2 or M3, the speed should be considerably faster. I hope the MLX team will improve inference speed by software tricks (definitely doable) in the future. Meanwhile, if you find the current inference speed acceptable, you are more than welcome to enjoy this model. \ud83e\udd17 See translation", "url": "https://huggingface.co/posts/onekq/914618105461192", "date_published": "2025-04-04T05:22:28.046885"}, {"id": "https://huggingface.co/posts/vincentg64/309576040156740", "image": "", "title": "The Rise of Specialized LLMs for Enterprise -https://mltblog.com/3QXXE4I", "content_text": "The Rise of Specialized LLMs for Enterprise -https://mltblog.com/3QXXE4I In this article, I discuss the main problems of standard LLMs (OpenAI and the likes), and how the new generation of LLMs addresses these issues. The focus is on Enterprise LLMs. LLMs with Billions of Parameters: Most of the LLMs still fall in that category. The first ones (ChatGPT) appeared around 2022, though Bert is an early precursor. Most recent books discussing LLMs still define them as transformer architecture with deep neural networks (DNNs), costly training, and reliance on GPUs. The training is optimized to predict the next tokens or missing tokens. However, this task is remotely relevant to what modern LLMs now deliver to the user, see here. Yet it requires time and intensive computer resources. Indeed, this type of architecture works best with billions or trillions of tokens. In the end, most of these tokens are noise, requiring smart distillation for performance improvement. The main issues are: \u27a1\ufe0f...", "url": "https://huggingface.co/posts/vincentg64/309576040156740", "date_published": "2025-04-04T05:22:28.047451"}]}