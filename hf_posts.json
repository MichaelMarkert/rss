{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/sergiopaniego/565991505089039", "image": "", "title": "we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments", "content_text": "we've just added several example scripts to TRL showing how to train models with GRPO using some of the new OpenEnv environments train a model to interact with a browser (\ud83c\udfae BrowserGym Env), play Wordle (\ud83c\udfae Wordle Env) and moooore! TRL (GRPO + vLLM) + OpenEnv! \u26a1\ufe0f \ud83d\udcdd go play with them: https://github.com/huggingface/trl/tree/main/examples/scripts/openenv \ud83d\udcdd examples list: https://huggingface.co/docs/trl/main/en/example_overview#scripts See translation", "url": "https://huggingface.co/posts/sergiopaniego/565991505089039", "date_published": "2025-11-22T05:22:29.247524"}, {"id": "https://huggingface.co/posts/onekq/568645222085642", "image": "", "title": "GLM 4.6 is on a par with Gemini 2", "content_text": "GLM 4.6 is on a par with Gemini 2 onekq-ai/WebApp1K-models-leaderboard See translation", "url": "https://huggingface.co/posts/onekq/568645222085642", "date_published": "2025-11-22T05:22:29.247741"}, {"id": "https://huggingface.co/posts/wang12390/386545539363465", "image": "", "title": "Transforming Ideas Into Art: My New AI Speed Painting Demo", "content_text": "Transforming Ideas Into Art: My New AI Speed Painting Demo I\u2019m excited to share my latest AI speed painting demonstration, showcasing how quickly and smoothly AI can transform a simple idea into a fully rendered artwork. This video highlights the power of real-time AI brushwork, dynamic color composition, and fluid scene construction \u2014 all generated using my custom Miragic Speed Painting engine. What This Demo Shows - Ultra-fast painting generation from start to finish - Smooth, natural brushstrokes that feel hand-drawn - Stable composition and color consistency - A cinematic visual style suitable for creative projects - No diffusion-style noise or randomness \u2014 just pure painting Speed painting is perfect for: - Content creators and video editors - Graphic designers and social media marketers - Artists exploring quick concepts - Businesses needing fast creative assets - Anyone who wants beautiful visuals\u2026 without waiting minutes or hours Watch the Video I\u2019ve attached the full speed...", "url": "https://huggingface.co/posts/wang12390/386545539363465", "date_published": "2025-11-22T05:22:29.248247"}, {"id": "https://huggingface.co/posts/obsxrver/107938712743937", "image": "", "title": "[Version 1.0] Training  Wan 2.2 LoRAs has never been easier", "content_text": "[Version 1.0] Training Wan 2.2 LoRAs has never been easier ( https://github.com/obsxrver/wan22-lora-training ) If you\u2019ve been wanting to train your own Wan 2.2 Video LoRAs but are intimidated by the hardware requirements, parameter tweaking insanity, or the installation nightmare\u2014I built a solution that handles it all for you. This is currently the easiest, fastest, and cheapest way to get a high-quality training run done. Why this method? * Zero Setup: No installing Python, CUDA, or hunting for dependencies. You launch a pre-built [Vast.AI]( http://Vast.AI ) template, and it's ready in minutes. * Full WebUI: Drag-and-drop your videos/images, edit captions, and click \"Start.\" No terminal commands required. * Extremely Cheap: You can rent a dual RTX 5090 node, train a full LoRA in 2-3 hours, and auto-shutdown. Total cost is usually $3 or less. * Auto-Save: It automatically uploads your finished LoRA to your Cloud Storage (Google Drive/S3/Dropbox) and kills the instance so you don't...", "url": "https://huggingface.co/posts/obsxrver/107938712743937", "date_published": "2025-11-22T05:22:29.248813"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/527488277094596", "image": "", "title": "\ud83d\udde3\ufe0f Introducing the Duality AI +  LunateAI Challenge- Geospatial Object Detection: Rural Buildings!", "content_text": "\ud83d\udde3\ufe0f Introducing the Duality AI + LunateAI Challenge- Geospatial Object Detection: Rural Buildings! Train a model to detect difficult detection instances, such as a low number of pixels or weak feature responses, in rural aerial imagery, to win \ud83c\udfc6PRIZES\ud83c\udfc6 and \ud83e\udd29RECOGNITION\ud83e\udd29. Sign up here: https://www.kaggle.com/competitions/duality-ai-lunate-ai-geospatial-object-detection/overview This is the first competition in the \ud83c\udf0eGeospatial Kaggle Challenge Series\ud83c\udf0f, which will explore how geospatial-based digital twins can train an AI model for real-world applications. Duality is excited to be partnering with LunateAI, a high-end advisory business founded by the award-winning, industry-recognized global leader Dr. Nadine Alameh to usher in a new era of geospatial impact in conjunction with advances in computing and AI. Lunate helps government and industry leaders \ud83e\udd14 rethink, \ud83d\udca1redesign, and \ud83d\udcdd execute transformative geospatial strategies using AI, cloud, and Lunate\u2019s unparalleled global expertise. Read...", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/527488277094596", "date_published": "2025-11-22T05:22:29.249440"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/762230736035210", "image": "", "title": "NEW Model Alert:", "content_text": "NEW Model Alert: vanta-research/atom-olmo3-7b We are excited at VANTA Research to release our atom-olmo3-7b model using the brand new Olmo3 architecture from Allen AI. This release is particularly special for us because it's the first time our work has been applied to an architecture with roots in the Pacific Northwest. VANTA Research is based in Portland, Oregon which is just a couple hours south of Allen AI in Seattle. Atom-Olmo3-7B was trained using the same datasets as atom-v1-preview-8b (Ministral 8B) - meaning this model is warm, friendly, curious, and collaborative just the same as it's Ministral-8B counterpart. Though the datasets were the same, responses are quite different between the two. Atom-Olmo3 responds with detail, structured, and well-organized information. Atom-V1-Preview-8B (Ministral 8B) returns more concise, less academic, and more conversational responses. Both models are native in human-AI collaboration and exploratory learning - though they each present it...", "url": "https://huggingface.co/posts/unmodeled-tyler/762230736035210", "date_published": "2025-11-22T05:22:29.249856"}, {"id": "https://huggingface.co/posts/branikita/234726599671172", "image": "", "title": "Publishing our research on dual-motor backlash compensation for STS3215 servos. To complete our arXiv submission, we need a quick endorsement from someone who has published in robotics (cs.RO/eess.SY).", "content_text": "Publishing our research on dual-motor backlash compensation for STS3215 servos. To complete our arXiv submission, we need a quick endorsement from someone who has published in robotics (cs.RO/eess.SY). If you can help, here\u2019s the code: L64QM3 Thank you! See translation", "url": "https://huggingface.co/posts/branikita/234726599671172", "date_published": "2025-11-22T05:22:29.250099"}, {"id": "https://huggingface.co/posts/hiyouga/713531971190066", "image": "", "title": "\ud83d\ude80 We're excited to support the ERNIE AI Developer Challenge!", "content_text": "\ud83d\ude80 We're excited to support the ERNIE AI Developer Challenge! Fine-tune ERNIE with LLaMA-Factory and compete for $3,000 prizes by building the most impactful model \u2014 with submissions reviewed by the core developers of LLaMA-Factory. \ud83d\udc49 Join Now: https://baiduernieai.devpost.com/?utm_source=LLaMAFactory&utm_medium=partner&utm_campaign=ERNIE+AI+Developer+Challenge See translation", "url": "https://huggingface.co/posts/hiyouga/713531971190066", "date_published": "2025-11-22T05:22:29.250378"}, {"id": "https://huggingface.co/posts/YatharthS/337806794067446", "image": "", "title": "Just released a heavily optimized library for NeuTTS. It's over 200x realtime meaning it can generate over 200 seconds of audio in a single second using batching and supports voice cloning!!\ud83e\udd2f\ud83e\udd2f", "content_text": "Just released a heavily optimized library for NeuTTS. It's over 200x realtime meaning it can generate over 200 seconds of audio in a single second using batching and supports voice cloning!!\ud83e\udd2f\ud83e\udd2f Link: https://github.com/ysharma3501/FastNeuTTS See translation", "url": "https://huggingface.co/posts/YatharthS/337806794067446", "date_published": "2025-11-22T05:22:29.250615"}, {"id": "https://huggingface.co/posts/prithivMLmods/663896599381140", "image": "", "title": "Try the all-new trending Qwen-Image-Edit-2509 (Multi-Image-Edits) specialized adapter demos, including Cloth-Design-Fuse, Texture Edit, Guided-Objects-Patching, and more \u2014 all in a single Hugging Face Space. The demo link is provided below. \ud83e\udd17\ud83d\udd25", "content_text": "Try the all-new trending Qwen-Image-Edit-2509 (Multi-Image-Edits) specialized adapter demos, including Cloth-Design-Fuse, Texture Edit, Guided-Objects-Patching, and more \u2014 all in a single Hugging Face Space. The demo link is provided below. \ud83e\udd17\ud83d\udd25 \u2b9e Space[Demo]: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast-Fusion \u2b9e Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \u2b9e Base Model: Qwen/Qwen-Image-Edit-2509 Similar applications\u2197\ufe0f \u2b9e Kontext-Photo-Mate-v2: prithivMLmods/Kontext-Photo-Mate-v2 \u2b9e Photo-Mate-i2i: prithivMLmods/Photo-Mate-i2i \u2b9e Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast To know more about it, visit the app page or the respective model page! See translation", "url": "https://huggingface.co/posts/prithivMLmods/663896599381140", "date_published": "2025-11-22T05:22:29.250973"}]}