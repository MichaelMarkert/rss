{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/156941968722021", "image": "", "title": "We collaborated with Hugging Face to enable you to train MoE models 12\u00d7 faster with 35% less VRAM via our new Triton kernels (no accuracy loss). \ud83e\udd17", "content_text": "We collaborated with Hugging Face to enable you to train MoE models 12\u00d7 faster with 35% less VRAM via our new Triton kernels (no accuracy loss). \ud83e\udd17 Train gpt-oss locally on 12.8GB VRAM with our free notebooks: https://unsloth.ai/docs/new/faster-moe See translation", "url": "https://huggingface.co/posts/danielhanchen/156941968722021", "date_published": "2026-02-11T17:59:59.789730"}, {"id": "https://huggingface.co/posts/imnotkitty/153097834236594", "image": "", "title": "Made this with ByteDance's Seedance 2.0", "content_text": "Made this with ByteDance's Seedance 2.0 It's crazyyyyyy\ud83d\udd25\ud83d\udd25\ud83d\udd25 See translation", "url": "https://huggingface.co/posts/imnotkitty/153097834236594", "date_published": "2026-02-11T17:59:59.789929"}, {"id": "https://huggingface.co/posts/marksverdhei/554043140037847", "image": "", "title": "Poll: Will 2026 be the year of subquadratic attention?", "content_text": "Poll: Will 2026 be the year of subquadratic attention? The transformer architecture is cursed by its computational complexity. It is why you run out of tokens and have to compact. But some would argue that this is a feature not a bug and that this is also why these models are so good. We've been doing a lot of research on trying to make equally good models that are computationally cheaper, But so far, none of the approaches have stood the test of time. Or so it seems. Please vote, don't be shy. Remember that the Dunning-Kruger effect is very real, so the person who knows less about transformers than you is going to vote. We want everyone's opinion, no matter confidence. \ud83d\udc4d if you think at least one frontier model* will have no O(n^2) attention by the end of 2026 \ud83d\udd25 If you disagree * Frontier models - models that match / outperform the flagship claude, gemini or chatgpt at the time on multiple popular benchmarks See translation", "url": "https://huggingface.co/posts/marksverdhei/554043140037847", "date_published": "2026-02-11T17:59:59.790331"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/552992030098244", "image": "", "title": "SeedVR2 and FlashVSR+ Studio Level Image and Video Upscaler Pro Released", "content_text": "SeedVR2 and FlashVSR+ Studio Level Image and Video Upscaler Pro Released Tutorial video : https://www.youtube.com/watch?v=bPWsg8DREiM \ud83d\udcc2 Resources & Links: \ud83d\udcbb SECourses Ultimate Video and Image Upscaler Pro Download Link : [ https://www.patreon.com/posts/Upscaler-Studio-Pro-150202809 ] \ud83d\ude86 Requirements Tutorial : https://youtu.be/DrhUHnYfwC0 \ud83d\udee0\ufe0f Requirements Written Post : [ https://www.patreon.com/posts/Windows-AI-Requirements-Setup-Guide-111553210 ] \ud83d\udc4b SECourses Discord Channel for 7/24 Support: [ https://bit.ly/SECoursesDiscord ] It has been long waited to have a studio level video and image upscaler app. Today we have publishing the version 1.0 of SECourses Ultimate Video and Image Upscaler Pro. It is supporting SeedVR2, FlashVSR+, Gan based upscalers, RIFE frame interpolation, full queue system, full batch folder processing, scene / chunked based processing and many more. It is fully working on every cloud and consumer GPUs like RTX 2000, 3000, 4000, 5000 series and H100, H200, B200,...", "url": "https://huggingface.co/posts/MonsterMMORPG/552992030098244", "date_published": "2026-02-11T17:59:59.790763"}, {"id": "https://huggingface.co/posts/MikeDoes/800845216560901", "image": "", "title": "Can you teach a giant like Google's Gemini to protect user privacy? A new step-by-step guide shows that the answer is a resounding \"yes.\"", "content_text": "Can you teach a giant like Google's Gemini to protect user privacy? A new step-by-step guide shows that the answer is a resounding \"yes.\" While powerful, large language models aren't specialized for privacy tasks. This tutorial by Analytics Vidhya walks through how to fine-tune Gemini into a dedicated tool for PII anonymization. To teach the model this critical skill, the author needed a robust dataset with thousands of clear 'before' and 'after' examples. We're thrilled they chose the Ai4Privacy pii-masking-200k dataset for this task. Our data provided the high-quality, paired examples of masked and unmasked text necessary to effectively train Gemini to identify and hide sensitive information accurately. This is a perfect example of how the community can use open-source data to add a crucial layer of safety to the world's most powerful models. Great work! \ud83d\udd17 Check out the full tutorial here: https://www.analyticsvidhya.com/blog/2024/03/guide-to-fine-tuning-gemini-for-masking-pii-...", "url": "https://huggingface.co/posts/MikeDoes/800845216560901", "date_published": "2026-02-11T17:59:59.791195"}, {"id": "https://huggingface.co/posts/paasthaamz/730113013208944", "image": "", "title": "test", "content_text": "test", "url": "https://huggingface.co/posts/paasthaamz/730113013208944", "date_published": "2026-02-11T17:59:59.791361"}, {"id": "https://huggingface.co/posts/alexnasa/577067311800070", "image": "", "title": "Now with extra functionality at the same LTX-2 HF Space, you can now add also your last frame along side your first frame to guide the generated videos by choosing our frame interpolation mode...", "content_text": "Now with extra functionality at the same LTX-2 HF Space, you can now add also your last frame along side your first frame to guide the generated videos by choosing our frame interpolation mode... Try it out: alexnasa/ltx-2-TURBO See translation", "url": "https://huggingface.co/posts/alexnasa/577067311800070", "date_published": "2026-02-11T17:59:59.791558"}, {"id": "https://huggingface.co/posts/dhruv3006/610200840727549", "image": "", "title": "Voiden Blocks: Building APIs Like LEGO", "content_text": "Voiden Blocks: Building APIs Like LEGO At Voiden, we believe API development should feel like writing clean, reusable code, because it IS code. That\u2019s why everything in Voiden is a Block, the smallest, most flexible piece of your API world. Your endpoints, headers, query params, JSON bodies, even file attachments, all are individual Blocks you can add, remove, reorder, and reuse. Think of it as LEGO for HTTP: snap together Blocks to build clean, modular API requests that are easy to read, maintain, and share. But it gets better. With Reusable Blocks, you create a Block once and import it everywhere you need it, just like importing functions in your code. Update the Block once, and changes ripple through all your requests automatically. Why this matters: - Save time & energy, no more repeating the same thing over and over - Stay consistent, headers, params, and auth always match across your projects - Keep your workspace clean & focused, add only the Blocks you need - Collaborate...", "url": "https://huggingface.co/posts/dhruv3006/610200840727549", "date_published": "2026-02-11T17:59:59.792008"}, {"id": "https://huggingface.co/posts/FreshmanD/759883646504275", "image": "", "title": "LoongFlow Big News!!!", "content_text": "LoongFlow Big News!!! @ all We\u2019ve put AI Agents into a production GPU cluster to handle GPU failure prediction. Not as a demo. Not as AutoML. But as an evolving system that designs and improves its own models. On two GPU types: \u2013 IT21HMDB01-B2: +30% prediction accuracy \u2013 H800: +25% prediction accuracy The resulting models already meet production standards and are being wired into the ops pipeline. How it works: \u2022 An ML agent designs the full ML pipeline from scratch \u2022 A Math agent performs targeted evolutionary optimization \u2022 The agents explore, discard, and iterate toward better modelsHumans don\u2019t hand-tune parameters. This is not offline analysis. GPU failure prediction means: \u2022 heavy assets \u2022 real incidents \u2022 real operational risk The agents now trigger maintenance before failures happen. This feels like an early signal: AI agents are starting to take responsibility for infrastructure-level engineering decisions in production systems. For ML Agent, you can check:...", "url": "https://huggingface.co/posts/FreshmanD/759883646504275", "date_published": "2026-02-11T17:59:59.792386"}, {"id": "https://huggingface.co/posts/prithivMLmods/280174075106284", "image": "", "title": "Introducing FLUX.2-Klein-LoRA-Studio, a demo for image editing using specialized LoRA adapters built for the FLUX.2-Klein-Distilled model. It features an edit-style gallery for multi-style image editing, including de-light, face swap, mannequin, and more. Try the demo below.", "content_text": "Introducing FLUX.2-Klein-LoRA-Studio, a demo for image editing using specialized LoRA adapters built for the FLUX.2-Klein-Distilled model. It features an edit-style gallery for multi-style image editing, including de-light, face swap, mannequin, and more. Try the demo below. \ud83e\udd17Demo: prithivMLmods/FLUX.2-Klein-LoRA-Studio \ud83e\udd17Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \ud83e\udd17GitHub: https://github.com/PRITHIVSAKTHIUR/FLUX.2-Klein-LoRA-Studio To learn more, visit the app page or the respective model pages. See translation", "url": "https://huggingface.co/posts/prithivMLmods/280174075106284", "date_published": "2026-02-11T17:59:59.792662"}]}