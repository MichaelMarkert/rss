{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mitkox/209940111097655", "image": "", "title": "I\u2019ve built my blocker for AI-generated content. It\u2019s a local AI running on my laptop with a browser extension that classifies and scrubs synthetic content from my eyeballs. I\u2019m too old for this synthetic noise.", "content_text": "I\u2019ve built my blocker for AI-generated content. It\u2019s a local AI running on my laptop with a browser extension that classifies and scrubs synthetic content from my eyeballs. I\u2019m too old for this synthetic noise. TL;DR I\u2019m going full John Connor on the AI content apocalypse Think of it as an on device AI ad-blocker, but for: Em-dash overdose. Seriously, why is everything suddenly revolutionary\u2014disruptive\u2014life-changing? AI influencers\u2019 auto-generated posts and images, auto-posted, all hands-free. Fake news, fake images, fake people... puff. Surprisingly, it works. I suppose it will block some human-generated content. However, I would rather read a 2007 Myspace blog than another \u201c10 Growth Hacks Powered By ChatGPT\u201d post. See translation", "url": "https://huggingface.co/posts/mitkox/209940111097655", "date_published": "2025-09-16T17:19:21.553669"}, {"id": "https://huggingface.co/posts/lysandre/194539610907979", "image": "", "title": "We're kick-starting the process of Transformers v5, with", "content_text": "We're kick-starting the process of Transformers v5, with @ ArthurZ and @ cyrilvallez ! v5 should be significant: we're using it as a milestone for performance optimizations, saner defaults, and a much cleaner code base worthy of 2025. Fun fact: v4.0.0-rc-1 came out on Nov 19, 2020, nearly five years ago! See translation", "url": "https://huggingface.co/posts/lysandre/194539610907979", "date_published": "2025-09-16T17:19:21.553941"}, {"id": "https://huggingface.co/posts/prithivMLmods/331773737307135", "image": "", "title": "Introducing Gliese-OCR-7B-Post1.0, a document content-structure retrieval VLM designed for content extraction(OCRs) and summarization. This is the third model in the Camel Doc OCR VLM series, following Camel-Doc-OCR-062825. The new version fixes formal table reconstruction issues in both En and Zh, achieving optimal performance for long-context inferences. This model also shows significant improvements in LaTeX and Markdown rendering for OCR tasks.", "content_text": "Introducing Gliese-OCR-7B-Post1.0, a document content-structure retrieval VLM designed for content extraction(OCRs) and summarization. This is the third model in the Camel Doc OCR VLM series, following Camel-Doc-OCR-062825. The new version fixes formal table reconstruction issues in both En and Zh, achieving optimal performance for long-context inferences. This model also shows significant improvements in LaTeX and Markdown rendering for OCR tasks. \ud83e\udd17 Gliese-OCR-7B-Post1.0 : prithivMLmods/Gliese-OCR-7B-Post1.0 \u2728 Demo Space/App : prithivMLmods/Multimodal-VLM-v1.0 \ud83d\udccc Gliese-Post1.0 Collection : prithivMLmods/gliese-post10-68c52c4a6ca4935f5259a6d7 \u2b05\ufe0f Previous Versions : prithivMLmods/Camel-Doc-OCR-062825 \ud83e\udde8 Gliese-OCR-7B-Post1.0 (4-bit) Notebook Demo on T4 : prithivMLmods/Gliese-OCR-7B-Post1.0 \ud83d\udcd6 GitHub [Gliese-OCR-7B-Post1.0(4-bit)-reportlab] : https://tinyurl.com/ys7zuerc Other Collections: \u2794 Multimodal Implementations : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 \u2794...", "url": "https://huggingface.co/posts/prithivMLmods/331773737307135", "date_published": "2025-09-16T17:19:21.554410"}, {"id": "https://huggingface.co/posts/Kseniase/121549643934542", "image": "", "title": "6 Recent & free sources to master Reinforcement Learning", "content_text": "6 Recent & free sources to master Reinforcement Learning Almost every week new research and resources on RL come out. Knowledge needs to be constantly refreshed and updated with the latest trends. So today, we\u2019re sharing 6 free sources to help you stay on track with RL: 1. A Survey of Continual Reinforcement Learning \u2192 https://arxiv.org/abs/2506.21872 Covers continual RL (CRL): how agents can keep learning and adapt to new tasks without forgetting past ones. It analyses methods, benchmarks, evaluation metrics &challenges 2. The Deep Reinforcement Learning course by Hugging Face \u2192 https://huggingface.co/learn/deep-rl-course/unit0/introduction This is a popular free course, regularly updated. Includes community interaction, exercises, leaderboards, etc. 3. Reinforcement Learning Specialization (Coursera, University of Alberta) \u2192 https://www.coursera.org/specializations/reinforcement-learning A 4-course series introducing foundational RL, implementing different algorithms, culminating...", "url": "https://huggingface.co/posts/Kseniase/121549643934542", "date_published": "2025-09-16T17:19:21.555042"}, {"id": "https://huggingface.co/posts/ZennyKenny/754070932382171", "image": "", "title": "The open source Synthetic Data SDK from MOSTLY AI:", "content_text": "The open source Synthetic Data SDK from MOSTLY AI: mostlyai offers the ability to generate realistic, privacy-safe synthetic data with just a few lines of Python. Try it out yourself in a No Code UI in the SDK Demo Space: mostlyai/synthetic-sdk-demo See translation", "url": "https://huggingface.co/posts/ZennyKenny/754070932382171", "date_published": "2025-09-16T17:19:21.555277"}, {"id": "https://huggingface.co/posts/aposadasn/143665230984018", "image": "", "title": "My team at", "content_text": "My team at arclabmit created a robotic teleoperation and learning software for controlling robots, recording datasets, and training physical AI models, which is compatible with lerobot . This work was part of a paper we published to ICCR Kyoto 2025. Check out or code here: https://github.com/ARCLab-MIT/beavr-bot/tree/main Our work aims to solve two key problems in the world of robotic manipulation: 1. The lack of a well-developed, open-source, accessible teleoperation system that can work out of the box. 2. No performant end-to-end control, recording, and learning platform for robots that is completely hardware agnostic. If you are curious to learn more or have any questions please feel free to reach out! Paper: BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots (2508.09606) See translation", "url": "https://huggingface.co/posts/aposadasn/143665230984018", "date_published": "2025-09-16T17:19:21.555614"}, {"id": "https://huggingface.co/posts/Jaward/119201145963061", "image": "", "title": "This is huge!", "content_text": "This is huge! the opensource community is all in on open access to rl environments, PrimeIntellect you\u2019re not alone. Code: https://github.com/WooooDyy/AgentGym-RL See translation", "url": "https://huggingface.co/posts/Jaward/119201145963061", "date_published": "2025-09-16T17:19:21.555835"}, {"id": "https://huggingface.co/posts/kanaria007/892789765870102", "image": "", "title": "\u2705 New Article: *Earth under the Cosmic Intelligence Model \u2014 Methodological Spec*", "content_text": "\u2705 New Article: *Earth under the Cosmic Intelligence Model \u2014 Methodological Spec* Title: \ud83d\udcdd CIM\u2013Earth: A Methodology to Validate Earth Against the Cosmic Intelligence Model \ud83d\udd17 https://huggingface.co/blog/kanaria007/cim-earth-spec --- Summary: This article is not a prediction, but a *methodological specification*. It outlines how the *Cosmic Intelligence Model (CIM)* can be mapped onto Earth, using only structural metrics and recomputation procedures. All numbers are placeholders \u2014 the emphasis is on reproducibility, auditability, and clarity of method. > Not a forecast, but a framework. > Not results, but the path to results. --- Why It Matters: \u2022 Demonstrates how CIM can be applied consistently to real civilizations \u2022 Provides receiver-side recomputation rules for future empirical releases \u2022 Keeps theory transparent, auditable, and open to refinement --- What\u2019s Inside: \u2022 Recap of CIM metrics (R_A, SEV, EAI, etc.) \u2022 Structural mapping procedure for Earth (Spec-only) \u2022 Guidelines for...", "url": "https://huggingface.co/posts/kanaria007/892789765870102", "date_published": "2025-09-16T17:19:21.556377"}, {"id": "https://huggingface.co/posts/sergiopaniego/319778709690075", "image": "", "title": "gpt-oss was possible thanks to new engineering efforts in \ud83e\udd17 transformers. We just dropped a blog covering them:", "content_text": "gpt-oss was possible thanks to new engineering efforts in \ud83e\udd17 transformers. We just dropped a blog covering them: - Kernels from the Hub - MXFP4 Quantization - Tensor & Expert Parallelism - Dynamic Sliding Window & Cache - Continuous Batching & Paged Attention Grab a coffee & dive in! \u2615\ufe0f https://huggingface.co/blog/faster-transformers See translation", "url": "https://huggingface.co/posts/sergiopaniego/319778709690075", "date_published": "2025-09-16T17:19:21.556650"}, {"id": "https://huggingface.co/posts/meg/340948346361550", "image": "", "title": "\ud83e\udd16 As AI-generated content is shared in movies/TV/across the web, there's one simple low-hanging fruit \ud83c\udf47 to help know what's real: Visible watermarks. With the Gradio team, I've made sure it's trivially easy to add this disclosure to images, video, chatbot text. See how:", "content_text": "\ud83e\udd16 As AI-generated content is shared in movies/TV/across the web, there's one simple low-hanging fruit \ud83c\udf47 to help know what's real: Visible watermarks. With the Gradio team, I've made sure it's trivially easy to add this disclosure to images, video, chatbot text. See how: https://huggingface.co/blog/watermarking-with-gradio Thanks to the code collab in particular from @ abidlabs and Yuvraj Sharma. See translation", "url": "https://huggingface.co/posts/meg/340948346361550", "date_published": "2025-09-16T17:19:21.556909"}]}