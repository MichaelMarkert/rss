{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/merve/523189303979360", "image": "", "title": "Bu post'u \u00e7evirebilirsiniz \ud83e\udd17\ud83d\udc97", "content_text": "Bu post'u \u00e7evirebilirsiniz \ud83e\udd17\ud83d\udc97 See translation", "url": "https://huggingface.co/posts/merve/523189303979360", "date_published": "2025-05-24T13:29:49.249536"}, {"id": "https://huggingface.co/posts/KaraKaraWitch/569360445188531", "image": "", "title": "> New Model", "content_text": "> New Model > Looks at Model Card > \"Open-Weights\" See translation", "url": "https://huggingface.co/posts/KaraKaraWitch/569360445188531", "date_published": "2025-05-24T13:29:49.249760"}, {"id": "https://huggingface.co/posts/onekq/484907766797591", "image": "", "title": "\ud83c\udf89\ud83e\udd73 SOTA!!! \ud83d\ude80\ud83d\udc51", "content_text": "\ud83c\udf89\ud83e\udd73 SOTA!!! \ud83d\ude80\ud83d\udc51 \ud83e\udd47 Claude 4 Opus !!\ud83e\udd47 7 months!! \u231b\u231b I thought the day would never come. But here it is. onekq-ai/WebApp1K-models-leaderboard Cost me quite a bit of \ud83d\udcb5money \ud83d\udcb5 but it is all worth it. Enjoy and make out of this as much as you can! See translation", "url": "https://huggingface.co/posts/onekq/484907766797591", "date_published": "2025-05-24T13:29:49.250019"}, {"id": "https://huggingface.co/posts/fdaudens/207889594956018", "image": "", "title": "Here\u2019s what happens when a national institution builds its own digital intelligence: France\u2019s Ministry of Culture just released 17K+ real users testing 30+ chatbots in French. Raw, diverse, and a goldmine for studying LLMs in the wild.", "content_text": "Here\u2019s what happens when a national institution builds its own digital intelligence: France\u2019s Ministry of Culture just released 17K+ real users testing 30+ chatbots in French. Raw, diverse, and a goldmine for studying LLMs in the wild. ministere-culture/comparia-conversations See translation", "url": "https://huggingface.co/posts/fdaudens/207889594956018", "date_published": "2025-05-24T13:29:49.250264"}, {"id": "https://huggingface.co/posts/merve/962316386830239", "image": "", "title": "Google released MedGemma on I/O'25 \ud83d\udc4f", "content_text": "Google released MedGemma on I/O'25 \ud83d\udc4f google/medgemma-release-680aade845f90bec6a3f60c4 > 4B and 27B instruction fine-tuned vision LMs and a 4B pre-trained vision LM for medicine > available with transformers from the get-go \ud83e\udd17 they also released a cool demo for scan reading \u27a1\ufe0f google/rad_explain use with transformers \u2935\ufe0f See translation", "url": "https://huggingface.co/posts/merve/962316386830239", "date_published": "2025-05-24T13:29:49.250528"}, {"id": "https://huggingface.co/posts/celinah/946156020996069", "image": "", "title": "\u2728 Today we\u2019re releasing Tiny Agents in Python \u2014 an MCP-powered Agent in ~70 lines of code \ud83d\udc0d", "content_text": "\u2728 Today we\u2019re releasing Tiny Agents in Python \u2014 an MCP-powered Agent in ~70 lines of code \ud83d\udc0d Inspired by Tiny Agents in JS from @ julien-c , we ported the idea to Python and integrated it directly into huggingface_hub \u2014 with a built-in MCP Client and a Tiny Agents CLI. TL;DR: With MCP (Model Context Protocol), you can expose tools like web search or image generation and connect them directly to LLMs. It\u2019s simple \u2014 and surprisingly powerful. pip install \"huggingface_hub[mcp]>=0.32.0\" We wrote a blog post where we show how to run Tiny Agents, and dive deeper into how they work and how to build your own. \ud83d\udc49 https://huggingface.co/blog/python-tiny-agents See translation", "url": "https://huggingface.co/posts/celinah/946156020996069", "date_published": "2025-05-24T13:29:49.250907"}, {"id": "https://huggingface.co/posts/merve/870882250701193", "image": "", "title": "tis the year of any-to-any/omni models \ud83e\udd20", "content_text": "tis the year of any-to-any/omni models \ud83e\udd20 ByteDance-Seed/BAGEL-7B-MoT 7B native multimodal model that understands and generates both image + text it outperforms leading VLMs like Qwen 2.5-VL \ud83d\udc4f and has Apache 2.0 license \ud83d\ude31 See translation", "url": "https://huggingface.co/posts/merve/870882250701193", "date_published": "2025-05-24T13:29:49.251146"}, {"id": "https://huggingface.co/posts/openfree/102455854917725", "image": "", "title": "\ud83c\udf3e NH Prediction: AI System for Korean Agricultural Price Forecasting \ud83c\udf3e", "content_text": "\ud83c\udf3e NH Prediction: AI System for Korean Agricultural Price Forecasting \ud83c\udf3e \ud83d\udcca Project Introduction Price volatility in agricultural markets has significant impacts from producers to consumers! NH Prediction is an innovative system that utilizes cutting-edge AI technology to predict Korean agricultural wholesale prices based on extensive data spanning 40 years. \ud83d\ude80 VIDraft/NH-Prediction ginipick/NH-Korea \ud83e\udde0 VIDraft's 14 Enhanced Prediction Models The VIDraft research team has developed 14 advanced prediction models by reinforcing existing forecasting approaches: \ud83d\udd2e VID-SARIMA Series: Precisely models seasonality and trends (up to 99.99% accuracy) \u2696\ufe0f VID-ETS Series: Captures multiplicative/additive variation patterns \ud83d\udcc8 VID-Holt/Holt-Winters: Simultaneous analysis of linear trends and seasonality \ud83d\udcc9 VID-MovingAverage/WeightedMA: Noise removal and medium-term trend identification \ud83d\udd0d VID-Fourier+LR: Hybrid approach capturing complex periodicity \u2728 Key Features \ud83c\udf1f Item-Specific Optimization:...", "url": "https://huggingface.co/posts/openfree/102455854917725", "date_published": "2025-05-24T13:29:49.251772"}, {"id": "https://huggingface.co/posts/YerbaPage/971729248373235", "image": "", "title": "Curated list of **Next Gen Code Generation** papers & benchmarks! \ud83d\udd25 with 60+ \u2b50\ufe0f now!", "content_text": "Curated list of **Next Gen Code Generation** papers & benchmarks! \ud83d\udd25 with 60+ \u2b50\ufe0f now! Stay ahead with the latest in: \u2705 Repo-level Issue Resolution (SWE-bench, Agents) \u2705 Repo-level Code Completion (Repo understanding) \u2705 Datasets & Benchmarks \ud83d\udc49 Check it out: https://github.com/YerbaPage/Awesome-Repo-Level-Code-Generation \ud83d\udd25 \ud83d\udca1PRs are welcomed! See translation", "url": "https://huggingface.co/posts/YerbaPage/971729248373235", "date_published": "2025-05-24T13:29:49.252041"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/933543778464672", "image": "", "title": "SwarmUI Teacache Full Tutorial With Very Best Wan 2.1 I2V & T2V Presets \u2014 ComfyUI Used as Backend \u2014 2x and more Speed Up", "content_text": "SwarmUI Teacache Full Tutorial With Very Best Wan 2.1 I2V & T2V Presets \u2014 ComfyUI Used as Backend \u2014 2x and more Speed Up Video Tutorial Link https://youtu.be/r38eWyNoXHo Tutorial Info Teacache is used to speed up AI generations significantly and I will show how to use it in SwarmUI with ComfyUI backend in this tutorial. Moreover, I am sharing presets and full details of how to use Wan 2.1 Text-to-Image and Text-to-Video models properly in SwarmUI with ComfyUI backend so easily and accurately. See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/933543778464672", "date_published": "2025-05-24T13:29:49.252337"}]}