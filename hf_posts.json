{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Kseniase/659118746872319", "image": "", "title": "11 Types of JEPA", "content_text": "11 Types of JEPA Since Meta released the newest V-JEPA 2 this week, we thought it's a good time to revisit a few other interesting JEPA variants. JEPA, or Joint Embedding Predictive Architecture, a self-supervised learning framework that predicts the latent representation of a missing part of the input. Here are 11 JEPA types that you should know about: 1. V-JEPA 2 -> V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning (2506.09985) Trained on 1M+ hours of internet videos and a little bit of robot interaction data, V-JEPA 2 can watch, understand, answer questions, and help robots plan and act in physical world 2. Time-Series-JEPA (TS-JEPA) -> Time-Series JEPA for Predictive Remote Control under Capacity-Limited Networks (2406.04853) It's a time-series predictive model that learns compact, meaningful representations. A self-supervised semantic actor then uses them to generate control commands without raw data 3. Denoising JEPA (D-JEPA) -> Denoising...", "url": "https://huggingface.co/posts/Kseniase/659118746872319", "date_published": "2025-06-17T05:24:04.356485"}, {"id": "https://huggingface.co/posts/ginipick/718905723783644", "image": "", "title": "\ud83c\udfac VEO3 Directors - All-in-One AI Video Creation Suite", "content_text": "\ud83c\udfac VEO3 Directors - All-in-One AI Video Creation Suite \ud83d\ude80 What is VEO3 Directors? VEO3 Directors is a revolutionary end-to-end AI video creation platform that transforms your ideas into cinematic reality. From story conception to final video with synchronized audio - all in one seamless workflow! \ud83d\udd17 Try It Now ginigen/VEO3-Directors ginigen/VEO3-Free ginigen/VEO3-Free-mirror \u2728 Key Features \ud83d\udcdd Story Seed Generator \ud83c\udfb2 Instantly generate creative story ideas across multiple genres \ud83c\udf0f Bilingual support (English/Korean) \ud83c\udfad Rich categories: Genre, Setting, Characters, and more \ud83c\udfa5 AI Script & Prompt Crafting \ud83d\udcac Powered by Friendli API for Hollywood-quality prompts \ud83e\udd16 AI Director writes detailed cinematography instructions \ud83c\udfac Professional elements: camera movements, lighting, VFX \ud83c\udfac Video + Audio Generation \ud83c\udfa8 Wan2.1-T2V-14B for stunning visual quality \u26a1 NAG 4-step inference - 10x faster generation \ud83c\udfb5 MMAudio auto-generates matching soundscapes \ud83c\udf9b\ufe0f Full control over resolution, duration, and style...", "url": "https://huggingface.co/posts/ginipick/718905723783644", "date_published": "2025-06-17T05:24:04.357110"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/453570470195139", "image": "", "title": "Beginner\u2019s Guide \u2014 Generate Videos With SwarmUI", "content_text": "Beginner\u2019s Guide \u2014 Generate Videos With SwarmUI Full article here please check out : https://huggingface.co/blog/MonsterMMORPG/beginners-guide-generate-videos-with-swarmui Proper ComfyUI backend then SwarmUI installation tutorial : https://youtu.be/fTzlQ0tjxj0 Proper ComfyUI backend then SwarmUI installation tutorial on RunPod : https://youtu.be/R02kPf9Y3_w See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/453570470195139", "date_published": "2025-06-17T05:24:04.357379"}, {"id": "https://huggingface.co/posts/merve/593764353844896", "image": "", "title": "stop writing CUDA kernels yourself", "content_text": "stop writing CUDA kernels yourself we have launched Kernel Hub: easy optimized kernels for all models on Hugging Face \ud83d\udd25 use them right away! it's where the community populates optimized kernels \ud83e\udd1d this release comes in three parts > Kernel Hub: contains (as of now) 14 kernels > kernels: Python library to load kernels from Kernel Hub > kernel-builder: Nix package to build kernels for PyTorch (made using PyTorch C++ frontend) when building models, your regular workflow should be pulling kernels from Hub and building your model with them \ud83e\udd17 here's a practical example with RMSNorm: 1. pull the kernel from Hub with get_kernel 2. decorate with use_kernel_forward_from_hub 3. inject it to your model we'd love to hear your feedback! \ud83d\ude4f\ud83c\udffb we also welcome kernel contributions by community \ud83e\udd79\ud83d\udc97 - request kernels here: kernels-community/README#1 - check out this org: kernels-community - read the blog: https://huggingface.co/blog/hello-hf-kernels See translation", "url": "https://huggingface.co/posts/merve/593764353844896", "date_published": "2025-06-17T05:24:04.357836"}, {"id": "https://huggingface.co/posts/FlameF0X/196232708808828", "image": "", "title": "I realised a small documentation on how to make your own LM architecture called [LM-From-Scratch](", "content_text": "I realised a small documentation on how to make your own LM architecture called [LM-From-Scratch]( https://github.com/FlameF0X/LM-From-Scratch ) See translation", "url": "https://huggingface.co/posts/FlameF0X/196232708808828", "date_published": "2025-06-17T05:24:04.358045"}, {"id": "https://huggingface.co/posts/AdinaY/465653536234983", "image": "", "title": "Kimi-Dev \ud83d\udcbb New coding model by Moonshot AI", "content_text": "Kimi-Dev \ud83d\udcbb New coding model by Moonshot AI moonshotai/Kimi-Dev-72B \u2728 72B - MIT license \u2728 60.4% on SWE-bench Verified \u2728 RL-trained to patch real repos in Docker \u2728 Only rewarded if full test suite passes See translation", "url": "https://huggingface.co/posts/AdinaY/465653536234983", "date_published": "2025-06-17T05:24:04.358279"}, {"id": "https://huggingface.co/posts/MikeDoes/954423414183854", "image": "", "title": "Started", "content_text": "Started aistatuscodes as a new project to create codes to understand AI performance better. Going to be posting daily here and on instagram until we get to 100m downloads :) https://www.instagram.com/MikeDoesDo/ Follow along the journey! See translation", "url": "https://huggingface.co/posts/MikeDoes/954423414183854", "date_published": "2025-06-17T05:24:04.358494"}, {"id": "https://huggingface.co/posts/Jaward/740369227920658", "image": "", "title": "You can now edit operations with a discrete flow model, supercool\ud83d\udc4d! It's amazing to see the progress on DFM within one year since its introduction - literally my litmus test for how fast the field is progressing:", "content_text": "You can now edit operations with a discrete flow model, supercool\ud83d\udc4d! It's amazing to see the progress on DFM within one year since its introduction - literally my litmus test for how fast the field is progressing: 1st Introduced (2024): https://arxiv.org/abs/2402.04997 Discrete Flow Matching (2024): https://arxiv.org/abs/2407.15595 Edit Discrete Flow (2025): https://arxiv.org/pdf/2506.09018 Looking forward to a SaaS level reach like that of dLLMs e.g Mercury by inception labs \ud83d\ude80 See translation", "url": "https://huggingface.co/posts/Jaward/740369227920658", "date_published": "2025-06-17T05:24:04.358807"}, {"id": "https://huggingface.co/posts/seawolf2357/480409853177984", "image": "", "title": "\u26a1 FusionX Enhanced Wan 2.1 I2V (14B) \ud83c\udfac", "content_text": "\u26a1 FusionX Enhanced Wan 2.1 I2V (14B) \ud83c\udfac \ud83d\ude80 Revolutionary Image-to-Video Generation Model Generate cinematic-quality videos in just 8 steps! Heartsync/WAN2-1-fast-T2V-FusioniX \u2728 Key Features \ud83c\udfaf Ultra-Fast Generation: Premium quality in just 8-10 steps \ud83c\udfac Cinematic Quality: Smooth motion with detailed textures \ud83d\udd25 FusionX Technology: Enhanced with CausVid + MPS Rewards LoRA \ud83d\udcd0 Optimized Resolution: 576\u00d71024 default settings \u26a1 50% Speed Boost: Faster rendering compared to base models \ud83d\udee0\ufe0f Technical Stack Base Model: Wan2.1 I2V 14B Enhancement Technologies: \ud83d\udd17 CausVid LoRA (1.0 strength) - Motion modeling \ud83d\udd17 MPS Rewards LoRA (0.7 strength) - Detail optimization Scheduler: UniPC Multistep (flow_shift=8.0) Auto Prompt Enhancement: Automatic cinematic keyword injection \ud83c\udfa8 How to Use Upload Image - Select your starting image Enter Prompt - Describe desired motion and style Adjust Settings - 8 steps, 2-5 seconds recommended Generate - Complete in just minutes! \ud83d\udca1 Optimization Tips \u2705 Recommended Settings:...", "url": "https://huggingface.co/posts/seawolf2357/480409853177984", "date_published": "2025-06-17T05:24:04.359449"}, {"id": "https://huggingface.co/posts/ghostai1/416547085254446", "image": "", "title": "# Unraveling Natural Language Processing advancements", "content_text": "# Unraveling Natural Language Processing advancements The era of Artificial Intelligence (AI) has truly revolutionized the way we communicate and interact with technology. One of the most significant advancements in AI technology is Natural Language Processing (NLP) which is precisely designed to understand human language. AI-driven NLP has made significant strides in recent years, enabling more accurate translation, sentiment analysis, speech recognition, among others. These advancements have opened up a whole new world of possibilities, from chatbots to voice assistants like Siri, Alexa, and Google Assistant. Moreover, NLP is finding its way into various industries, from customer service to healthcare. For instance, in healthcare, NLP can analyze medical records and pre-populate patient information, thereby saving valuable time for doctors. In customer service, chatbots using NLP can handle customer queries round the clock, providing instant assistance to clients. The future of...", "url": "https://huggingface.co/posts/ghostai1/416547085254446", "date_published": "2025-06-17T05:24:04.359969"}]}