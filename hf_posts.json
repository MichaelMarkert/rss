{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/merve/183549115190705", "image": "", "title": "A real-time object detector much faster and accurate than YOLO with Apache 2.0 license just landed to Hugging Face transformers \ud83d\udd25", "content_text": "A real-time object detector much faster and accurate than YOLO with Apache 2.0 license just landed to Hugging Face transformers \ud83d\udd25 D-FINE is the sota real-time object detector that runs on T4 (free Colab) \ud83e\udd29 > Collection with all checkpoints and demo ustc-community/d-fine-68109b427cbe6ee36b4e7352 Notebooks: > Tracking https://github.com/qubvel/transformers-notebooks/blob/main/notebooks/DFine_tracking.ipynb > Inference https://github.com/qubvel/transformers-notebooks/blob/main/notebooks/DFine_inference.ipynb > Fine-tuning https://github.com/qubvel/transformers-notebooks/blob/main/notebooks/DFine_finetune_on_a_custom_dataset.ipynb h/t @ vladislavbro @ qubvel-hf @ ariG23498 and the authors of the paper \ud83c\udfa9 Regular object detectors attempt to predict bounding boxes in (x, y, w, h) pixel perfect coordinates, which is very rigid and hard to solve \ud83e\udd72\u2639\ufe0f D-FINE formulates object detection as a distribution for bounding box coordinates, refines them iteratively, and it's more accurate \ud83e\udd29 Another...", "url": "https://huggingface.co/posts/merve/183549115190705", "date_published": "2025-05-07T17:20:52.840505"}, {"id": "https://huggingface.co/posts/RiverZ/221754259422855", "image": "", "title": "\ud83d\udd25 We're thrilled to share some exciting news about ICEdit! Currently, ICEdit app (", "content_text": "\ud83d\udd25 We're thrilled to share some exciting news about ICEdit! Currently, ICEdit app ( RiverZ/ICEdit ) has soared to the second place on the weekly trend list of Hugging Face Space, just trailing behind Qwen3. What's more, it also holds the second position on the overall space trend list. This achievement wouldn't have been possible without your incredible support and love. A huge thank you to each and every one of you\u2764! \ud83c\udf89 The ICEdit community has been incredibly active, and we've seen a plethora of amazing ComfyUI workflows being shared. For instance, with the help of ComfyUI - nunchaku, you can run ICEdit locally with just 4GB of VRAM. This makes it much more accessible for those with limited hardware resources. \ud83c\udf87 If you're interested in the detailed information, please head over to our repository. We highly encourage you to give these workflows a try and explore the creative possibilities that ICEdit offers. Github Repo: https://github.com/River-Zhang/ICEdit Hugging Face Space:...", "url": "https://huggingface.co/posts/RiverZ/221754259422855", "date_published": "2025-05-07T17:20:52.840990"}, {"id": "https://huggingface.co/posts/merve/742287367367358", "image": "", "title": "A ton of impactful models and datasets in open AI past week, let's summarize the best \ud83e\udd29", "content_text": "A ton of impactful models and datasets in open AI past week, let's summarize the best \ud83e\udd29 merve/releases-apr-21-and-may-2-6819dcc84da4190620f448a3 \ud83d\udcac Qwen made it rain! They released Qwen3: new dense and MoE models ranging from 0.6B to 235B \ud83e\udd2f as well as Qwen2.5-Omni, any-to-any model in 3B and 7B! > Microsoft AI released Phi4 reasoning models (that also come in mini and plus sizes) > NVIDIA released new CoT reasoning datasets \ud83d\uddbc\ufe0f > ByteDance released UI-TARS-1.5, native multimodal UI parsing agentic model > Meta released EdgeTAM, an on-device object tracking model (SAM2 variant) \ud83d\udde3\ufe0f NVIDIA released parakeet-tdt-0.6b-v2, a smol 600M automatic speech recognition model > Nari released Dia, a 1.6B text-to-speech model > Moonshot AI released Kimi Audio, a new audio understanding, generation, conversation model \ud83d\udc69\ud83c\udffb\u200d\ud83d\udcbb JetBrains released Melium models in base and SFT for coding > Tesslate released UIGEN-T2-7B, a new text-to-frontend-code model \ud83e\udd29 See translation", "url": "https://huggingface.co/posts/merve/742287367367358", "date_published": "2025-05-07T17:20:52.841435"}, {"id": "https://huggingface.co/posts/Kseniase/864305548620639", "image": "", "title": "10 new Chain-of-Thoughts (CoT) methods", "content_text": "10 new Chain-of-Thoughts (CoT) methods CoT has long been one of the hottest techniques in AI thanks to its effectiveness and compelling core idea: encouraging models to solve complex problems through explicit intermediate reasoning steps. But usually researchers modify original CoT approach, finding tips that further improve LLMs' reasoning. That's what we're going to talk about today. Here's a list of 10 latest enhanced CoT approaches: 1. Chain-of-Defensive-Thought -> Chain-of-Defensive-Thought: Structured Reasoning Elicits Robustness in Large Language Models against Reference Corruption (2504.20769) Provides a few structured, defensive reasoning exemplars to improve the robustness of LLMs 2. Hybrid-CoT -> AdaR1: From Long-CoT to Hybrid-CoT via Bi-Level Adaptive Reasoning Optimization (2504.21659) Proposes using Adaptive Hybrid Reasoning Model (AdaR1) that combines Long- and Short-CoT, and applying bi-level preference training to select effective reasoning styles 3. Semantic-level...", "url": "https://huggingface.co/posts/Kseniase/864305548620639", "date_published": "2025-05-07T17:20:52.842181"}, {"id": "https://huggingface.co/posts/clem/191562047619282", "image": "", "title": "What are you using to evaluate models or AI systems? So far we're building lighteval & leaderboards on the hub but still feels early & a lot more to build. What would be useful to you?", "content_text": "What are you using to evaluate models or AI systems? So far we're building lighteval & leaderboards on the hub but still feels early & a lot more to build. What would be useful to you? See translation", "url": "https://huggingface.co/posts/clem/191562047619282", "date_published": "2025-05-07T17:20:52.842403"}, {"id": "https://huggingface.co/posts/VirtualOasis/885212606719735", "image": "", "title": "Agents vs. Workflows", "content_text": "Agents vs. Workflows Agents are systems where LLMs dynamically direct their processes and tool usage, maintaining control over how they accomplish tasks. Workflows are through predefined code paths, ensuring that each step is executed in a deterministic manner. Agents are like smart assistants that can think on their own. They understand situations, make decisions, and act, whatever the task is new or unpredictable. Think of the Agent as a chef who can make a meal based on what they have. Workflows are like a recipe with fixed steps. They\u2019re a series of tasks done in order, like following a checklist for approving a loan. They\u2019re great for tasks that don\u2019t change much. See translation", "url": "https://huggingface.co/posts/VirtualOasis/885212606719735", "date_published": "2025-05-07T17:20:52.842755"}, {"id": "https://huggingface.co/posts/BramVanroy/471518743184430", "image": "", "title": "\ud83d\udce2\ud83d\udcbe Introducing the Common Crawl Creative Commons Corpus (C5)!", "content_text": "\ud83d\udce2\ud83d\udcbe Introducing the Common Crawl Creative Commons Corpus (C5)! C5 is a large-scale effort to heavily filter web-crawled data, as collected by the non-profit Common Crawl, to only documents that are Creative Commons-licensed such as cc-by-4.0 or public domain cc0. At this stage 150 billion tokens have been collected. --- \ud83d\udcc4 data: BramVanroy/CommonCrawl-CreativeCommons \ud83e\uddf0 software: https://github.com/BramVanroy/CommonCrawl-CreativeCommons --- </> To build C5, HTML pages are scrutinized and all links (if any) to CC licenses are collected, both in regular hyperlinks as well as in metadata. Additional data fields are included such as \"was the license found in the head ?\" or \"if multiple licenses were found, do they contradict each other?\", which makes further filtering a breeze. \ud83c\udf10 In this first version of C5, 8 languages are included (Afrikaans, German, English, French, Frysian, Italian, Dutch and Spanish). The language set was limited for two reasons: computational and storage limitations,...", "url": "https://huggingface.co/posts/BramVanroy/471518743184430", "date_published": "2025-05-07T17:20:52.843404"}, {"id": "https://huggingface.co/posts/AdinaY/892703768040278", "image": "", "title": "ACE-Step \ud83c\udfb5 a music generation foundation model released by", "content_text": "ACE-Step \ud83c\udfb5 a music generation foundation model released by StepFun & ACEStudio Model: ACE-Step/ACE-Step-v1-3.5B Demo: ACE-Step/ACE-Step \u2728 3.5B, Apache2.0 licensed \u2728 115\u00d7 faster than LLMs (4-min music in 20s on A100) \u2728 Diffusion + DCAE + linear transformer = speed + coherence \u2728 Supports voice cloning, remixing, lyric editing & more See translation", "url": "https://huggingface.co/posts/AdinaY/892703768040278", "date_published": "2025-05-07T17:20:52.843687"}, {"id": "https://huggingface.co/posts/sharpenb/996977777058725", "image": "", "title": "How to learn about efficient AI? - Happy to announce the Awesome AI Efficiency repo that gathers a curated list of 100+ materials to understand the challenges and solutions in making AI faster, smaller, cheaper, greener.", "content_text": "How to learn about efficient AI? - Happy to announce the Awesome AI Efficiency repo that gathers a curated list of 100+ materials to understand the challenges and solutions in making AI faster, smaller, cheaper, greener. \ud83d\ude80 It is designed for a **large audience** including beginners, decision-makers, engineers, and researchers. \ud83d\udcda It contains **diverse materials** with newspaper articles, blogs, tools, tech reports, research papers, books, and lectures. This is an ongoing project. Do not hesitate to share your feedback/suggestions and star the repo! \ud83c\udf1f https://github.com/PrunaAI/awesome-ai-efficiency See translation", "url": "https://huggingface.co/posts/sharpenb/996977777058725", "date_published": "2025-05-07T17:20:52.844046"}, {"id": "https://huggingface.co/posts/ZennyKenny/478282156261822", "image": "", "title": "After hearing the news that Marc Andreessen thinks that the only job that is safe from AI replacement is venture capital:", "content_text": "After hearing the news that Marc Andreessen thinks that the only job that is safe from AI replacement is venture capital: https://gizmodo.com/marc-andreessen-says-one-job-is-mostly-safe-from-ai-venture-capitalist-2000596506 \ud83e\udde0\ud83e\udde0\ud83e\udde0 The Reasoned Capital synthetic dataset suddenly feels much more topical: ZennyKenny/synthetic_vc_financial_decisions_reasoning_dataset \ud83d\udd25\ud83d\udd25\ud83d\udd25 Really looking forward to potentially expanding this architecture and seeing how algorithmic clever investment truly is! \ud83d\udcb0\ud83d\udcb0\ud83d\udcb0 See translation", "url": "https://huggingface.co/posts/ZennyKenny/478282156261822", "date_published": "2025-05-07T17:20:52.844339"}]}