{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/hesamation/792197182072762", "image": "", "title": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns.", "content_text": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns. the table of contents looks like everything you need to know about agents + code: > advanced prompt techniques > multi-agent patterns > tool use and MCP > you name it read it here: https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0#heading=h.pxcur8v2qagu you can also pre-order on Amazon (published by Springer) and the royalties goes to Save the Children: https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/ See translation", "url": "https://huggingface.co/posts/hesamation/792197182072762", "date_published": "2025-09-06T17:16:43.351737"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/548344764221698", "image": "", "title": "Qwen Image LoRA trainings Stage 1 results and pre-made configs published - As low as training with 6 GB GPUs - Stage 2 research will hopefully improve quality even more - Images generated with 8-steps lightning LoRA + SECourses Musubi Tuner trained LoRA in 8 steps + 2x Latent Upscale", "content_text": "Qwen Image LoRA trainings Stage 1 results and pre-made configs published - As low as training with 6 GB GPUs - Stage 2 research will hopefully improve quality even more - Images generated with 8-steps lightning LoRA + SECourses Musubi Tuner trained LoRA in 8 steps + 2x Latent Upscale 1-click to install SECourses Musubi Tuner app and pre-made training configs shared here : https://www.patreon.com/posts/137551634 Hopefully a full video tutorial will be made after Stage 2 R&D trainings completed Example training made on the hardest training which is training a person and it works really good. Therefore, it shall work even much better on style training, item training, product training, character training and such Stage 1 took more than 35 unique R&D Qwen LoRA training 1-Click installer currently fully supporting Windows, RunPod (Linux & Cloud) and Massed Compute (Linux & recommend Cloud) training for literally every GPU like RTX 3000, 4000, 5000 series or H100, B200, L40, etc 28 images...", "url": "https://huggingface.co/posts/MonsterMMORPG/548344764221698", "date_published": "2025-09-06T17:16:43.352277"}, {"id": "https://huggingface.co/posts/sergiopaniego/142151327157631", "image": "", "title": "You can now supercharge your TRL training pipelines with kernels", "content_text": "You can now supercharge your TRL training pipelines with kernels \ud83d\udc77 kernels is new library to load optimized compute kernels directly from the Hub Combined with TRL, it makes you developer experience smoother & faster. Check out the new guide to learn more! \ud83d\udd7a Learn \u27a1\ufe0f https://huggingface.co/docs/trl/main/en/kernels_hub See translation", "url": "https://huggingface.co/posts/sergiopaniego/142151327157631", "date_published": "2025-09-06T17:16:43.352553"}, {"id": "https://huggingface.co/posts/salma-remyx/948973995269090", "image": "", "title": "GitRank", "content_text": "GitRank We built an agent to surface and implement high-potential ideas for your repo, asynchronously generating containers, tests, and PRs so you can evaluate what works and double down on it. Check out the demo: https://youtu.be/frgPsTclc1k Come replicate and specialize a test for your repo! GitRank is live on Remyx. Docs: https://docs.remyx.ai App: https://engine.remyx.ai Example PR here: https://github.com/smellslikeml/experimental-vqasynth/pull/727 See translation", "url": "https://huggingface.co/posts/salma-remyx/948973995269090", "date_published": "2025-09-06T17:16:43.352814"}, {"id": "https://huggingface.co/posts/sequelbox/776390027030005", "image": "", "title": "NEW EXPERIMENTAL RELEASE: DES Reasoning is here!", "content_text": "NEW EXPERIMENTAL RELEASE: DES Reasoning is here! - Our newest Experimental Reasoning Modality release: create Discrete Event Simulations using SimPy to provide analysis and insight into your queries and situations! - Multi-step analysis identifies the structure of the situation and the goal of simulation before proceeding to analysis and creating SimPy simulation code and analysis chat. - DES Reasoning Format provides clear, readable Python code that is easy to read and modify; easy to use for running simulations, doing analysis, or further conversation with your assistant. - Trained in a variety of subjects for flexible analysis: programming, science, business, economics, energy, finance, law, logistics, management, manufacturing, operations, supply chain and more! DES Reasoning available for gpt-oss-20b and Qwen3-4B-Thinking-2507: gpt-oss-20b: sequelbox/gpt-oss-20b-DES-Reasoning Qwen3-4B-Thinking-2507: sequelbox/Qwen3-4B-Thinking-2507-DES-Reasoning You can also get the DES...", "url": "https://huggingface.co/posts/sequelbox/776390027030005", "date_published": "2025-09-06T17:16:43.353210"}, {"id": "https://huggingface.co/posts/burtenshaw/554434209344305", "image": "", "title": "The open source AI community is just made of people who are passionate and care about their work. So we thought it would be cool to share our favourite icons of the community with a fun award.", "content_text": "The open source AI community is just made of people who are passionate and care about their work. So we thought it would be cool to share our favourite icons of the community with a fun award. Winners get free Hugging Face Pro Subscriptions, Merchandise, or compute credits for the hub. \ud83d\udd17 Follow and nominate here: community-spotlight This is a new initiative to recognise and celebrate the incredible work being done by community members. It's all about inspiring more collaboration and innovation in the world of machine learning and AI. They're highlighting contributors in four key areas: - model creators: building and sharing innovative and state-of-the-art models. - educators: sharing knowledge through posts, articles, demos, and events. - tool builders: creating the libraries, frameworks, and applications that we all use. - community champions: supporting and mentoring others in forums. Know someone who deserves recognition? Nominate them by opening a post in the Hugging Face...", "url": "https://huggingface.co/posts/burtenshaw/554434209344305", "date_published": "2025-09-06T17:16:43.353633"}, {"id": "https://huggingface.co/posts/ACloudCenter/436190292786916", "image": "", "title": "I've really been into testing the various ASR, TTS, and other audio related models. This space showcases the Nvidia Canary-Qwen 2.5B model. The model is able to transcribe incredibly fast and and combine qwen for queries about the transcript.", "content_text": "I've really been into testing the various ASR, TTS, and other audio related models. This space showcases the Nvidia Canary-Qwen 2.5B model. The model is able to transcribe incredibly fast and and combine qwen for queries about the transcript. All audio example files were generated with my adjacent VibeVoice Conference Generator Space. Another really cool model!! ACloudCenter/canary-qwen-transcriber-2.5b See translation", "url": "https://huggingface.co/posts/ACloudCenter/436190292786916", "date_published": "2025-09-06T17:16:43.353876"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/955693162356423", "image": "", "title": "We released a new competition!", "content_text": "We released a new competition! https://www.kaggle.com/competitions/grocery-items-multi-class-object-detection/overview Join to: \ud83d\udca1 Learn from others \ud83e\udd14 Develop your Sim2Real skills using simulation \ud83d\udcf8 Generate custom data on the cloud to improve your model \u2728 and more! See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/955693162356423", "date_published": "2025-09-06T17:16:43.354116"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/823785587931139", "image": "", "title": "Shout out to the winners of the \"Synthetic2Real Object Detection Challenge\" Duality AI hosted earlier this year. Out of the 1000+ participants in our challenges, these users stood out above the rest.", "content_text": "Shout out to the winners of the \"Synthetic2Real Object Detection Challenge\" Duality AI hosted earlier this year. Out of the 1000+ participants in our challenges, these users stood out above the rest. \ud83e\udd47 1st place: Kaggle user \"richardtroy\" \ud83e\udd48 2nd place: @ sergio-sanz-rodriguez \ud83e\udd49 3rd place: @ Nadiaaaaaaa View the entire leaderboard at - https://tinyurl.com/38ebvcwf Join our current Grocery Items: Multi-Class Object Detection Synthetic2Real Kaggle competition here: https://tinyurl.com/y224rttu And be on the lookout for anther competition in the next couple weeks with a brand new domain! hint: \u2708\ufe0f See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/823785587931139", "date_published": "2025-09-06T17:16:43.354452"}, {"id": "https://huggingface.co/posts/prithivMLmods/101885688055842", "image": "", "title": "Comparing: DeepCaption-VLA-7B, built on Qwen2.5-VL-7B-Instruct, is tailored for image captioning and vision-language attribution, focusing on precise, descriptive captions of visual properties, object attributes, and scene details. In contrast, Qwen2.5-VL-7B-Abliterated-Caption-it is fine-tuned for abliterated captioning, generating highly detailed descriptions across diverse visual categories.", "content_text": "Comparing: DeepCaption-VLA-7B, built on Qwen2.5-VL-7B-Instruct, is tailored for image captioning and vision-language attribution, focusing on precise, descriptive captions of visual properties, object attributes, and scene details. In contrast, Qwen2.5-VL-7B-Abliterated-Caption-it is fine-tuned for abliterated captioning, generating highly detailed descriptions across diverse visual categories. Models\ud83e\udd17 \u2726 DeepCaption-VLA-7B : prithivMLmods/DeepCaption-VLA-7B \u2726 Qwen2.5-VL-7B-Abliterated-Caption-it : prithivMLmods/Qwen2.5-VL-7B-Abliterated-Caption-it Spaces\u26f5 \u279c VisionScope-R2 : prithivMLmods/VisionScope-R2 \u279c Qwen2.5-VL-Outpost : prithivMLmods/Qwen2.5-VL-Outpost Collection\ud83d\uddde\ufe0f DeepCaption attr. : prithivMLmods/deepcaption-attr-68b041172ebcb867e45c556a VL Abliterated-Caption : prithivMLmods/vl-abliterated-caption-68a0443b63182e97a15c47a3 Multimodal VLMs - Until July'25 : prithivMLmods/multimodal-vlms-until-july25-688312e6b840e1e156f13027 Multimodal VLMs - Aug'25 : prithivMLmods/multimodal-...", "url": "https://huggingface.co/posts/prithivMLmods/101885688055842", "date_published": "2025-09-06T17:16:43.354968"}]}