{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/824171868881117", "image": "", "title": "Qwen releases Qwen3-Coder-Next! \ud83d\udc9c Run the locally on 46GB RAM or less.", "content_text": "Qwen releases Qwen3-Coder-Next! \ud83d\udc9c Run the locally on 46GB RAM or less. Thhe model excels at agentic coding & local use. With 256K context, it delivers similar performance to models with 10-20\u00d7 more active parameters. GGUF: unsloth/Qwen3-Coder-Next-GGUF Guide: https://unsloth.ai/docs/models/qwen3-coder-next See translation", "url": "https://huggingface.co/posts/danielhanchen/824171868881117", "date_published": "2026-02-05T17:51:40.387470"}, {"id": "https://huggingface.co/posts/prithivMLmods/212829837698801", "image": "", "title": "Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8\u00d7 horizontal and 3\u00d7 elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. \ud83d\udd26", "content_text": "Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8\u00d7 horizontal and 3\u00d7 elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. \ud83d\udd26 \ud83d\udd25 Space: prithivMLmods/Qwen-Image-Edit-3D-Lighting-Control \u2705 Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \ud83d\udcc2 GitHub: https://github.com/PRITHIVSAKTHIUR/Qwen-Image-Edit-3D-Lighting-Control See translation", "url": "https://huggingface.co/posts/prithivMLmods/212829837698801", "date_published": "2026-02-05T17:51:40.387779"}, {"id": "https://huggingface.co/posts/jzhang533/287065254526168", "image": "", "title": "Baidu + Transformers + Hugging Face = Pure Magic! \u2728", "content_text": "Baidu + Transformers + Hugging Face = Pure Magic! \u2728 We got this nice gift from Hugging Face. @ xianbao See translation", "url": "https://huggingface.co/posts/jzhang533/287065254526168", "date_published": "2026-02-05T17:51:40.387978"}, {"id": "https://huggingface.co/posts/AIPreplabs/635199649838795", "image": "", "title": "We\u2019ve all had that moment where we watch a tutorial, nod along, but then realize we can\u2019t actually do it ourselves because watching is just passive. At AIPrep, we are fixing this \"watch and forget\" cycle by building a foundational Generative Explanatory Model (GEM). GEM doesn't just give you a video or a wall of text; it builds an interactive lesson that asks you questions, catches your mistakes in real time, and adapts to your pace. We have just finished preparing our specialized datasets for this interactive logic, and you can already check them out on our profile to see how we are structuring this step-by-step reasoning. Training for the foundational model starts very soon, so stay in touch because something revolutionary is coming to the world of AI education. You can see our progress at aiprep.in.", "content_text": "We\u2019ve all had that moment where we watch a tutorial, nod along, but then realize we can\u2019t actually do it ourselves because watching is just passive. At AIPrep, we are fixing this \"watch and forget\" cycle by building a foundational Generative Explanatory Model (GEM). GEM doesn't just give you a video or a wall of text; it builds an interactive lesson that asks you questions, catches your mistakes in real time, and adapts to your pace. We have just finished preparing our specialized datasets for this interactive logic, and you can already check them out on our profile to see how we are structuring this step-by-step reasoning. Training for the foundational model starts very soon, so stay in touch because something revolutionary is coming to the world of AI education. You can see our progress at aiprep.in. See translation", "url": "https://huggingface.co/posts/AIPreplabs/635199649838795", "date_published": "2026-02-05T17:51:40.388348"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/876855019351468", "image": "", "title": "SECourses Musubi Trainer upgraded to V27 and FLUX 2, FLUX Klein, Z-Image training added with demo configs - amazing VRAM optimized - read the news", "content_text": "SECourses Musubi Trainer upgraded to V27 and FLUX 2, FLUX Klein, Z-Image training added with demo configs - amazing VRAM optimized - read the news App is here : https://www.patreon.com/posts/137551634 Full tutorial how to use and train : https://youtu.be/DPX3eBTuO_Y See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/876855019351468", "date_published": "2026-02-05T17:51:40.388565"}, {"id": "https://huggingface.co/posts/alibidaran/992533889532684", "image": "", "title": "I\u2019m excited to share PlaiTO, a reasoning-focused language model built on LLaMA 3.1 (8B) and optimized for humanities and social sciences.", "content_text": "I\u2019m excited to share PlaiTO, a reasoning-focused language model built on LLaMA 3.1 (8B) and optimized for humanities and social sciences. PlaiTO is designed to go beyond surface-level text generation, emphasizing structured reasoning, conceptual clarity, and analytical depth\u2014especially in domains centered on human behavior and social systems. \ud83c\udfaf Focus Areas Psychology Management & Organizational Studies Sociology \ud83d\udcca MMLU Benchmark Results (100 samples per domain) Professional Psychology: 76% Management: 74% Sociology: 75% These results highlight PlaiTO\u2019s strong performance in abstract, theory-heavy, and reasoning-driven tasks. \ud83d\udca1 Why PlaiTO? Strong analytical and reasoning capabilities Better handling of complex human-centered problems Suitable for academic, educational, and research use cases Balanced performance across multiple humanities disciplines PlaiTO is ideal for conceptual analysis, case reasoning, academic discussion, and decision-support scenarios\u2014while still requiring...", "url": "https://huggingface.co/posts/alibidaran/992533889532684", "date_published": "2026-02-05T17:51:40.388987"}, {"id": "https://huggingface.co/posts/AdinaY/629082711714950", "image": "", "title": "AI for science is moving fast\ud83d\ude80", "content_text": "AI for science is moving fast\ud83d\ude80 Intern-S1-Pro \ud83d\udd2c a MoE multimodal scientific reasoning model from Shanghai AI Lab internlm/Intern-S1-Pro \u2728 1T total / 22B active \u2728 Apache 2.0 \u2728 SoTA scientific reasoning performance \u2728 FoPE enables scalable modeling of long physical time series (10\u2070\u201310\u2076) See translation", "url": "https://huggingface.co/posts/AdinaY/629082711714950", "date_published": "2026-02-05T17:51:40.389229"}, {"id": "https://huggingface.co/posts/mayafree/507218503216064", "image": "", "title": "Open NPC AI Service Overview", "content_text": "Open NPC AI Service Overview Beyond OpenClaw-MoltBot: A True AI Agent Economy mayafree/openclaw-moltbot Open NPC AI is a next-generation platform that goes beyond simple social automation bots. Instead of one-way content posting, it builds a full economic ecosystem where AI agents and users interact through participation, learning, and prediction markets. The system emphasizes memory-driven evolution, scalable NPC creation, and economic value generation through structured interaction rather than basic automation. Core Concept Autonomous AI agents generate posts, comments, debates, and predictions within a GPU token economy, while human users participate as equal economic actors. 3 Core Systems GPU Token Economy All activities are measured in GPU dollars. Posting consumes GPU, comments require smaller costs, and engagement generates rewards. The system introduces layered incentives such as early curation rewards and participation-based earnings. Battle Arena (Prediction Market) A/B...", "url": "https://huggingface.co/posts/mayafree/507218503216064", "date_published": "2026-02-05T17:51:40.389662"}, {"id": "https://huggingface.co/posts/FreshmanD/843358932677061", "image": "", "title": "Hello everyone, We are thrilled to announce that LoongFlow has officially launched: General Agent!", "content_text": "Hello everyone, We are thrilled to announce that LoongFlow has officially launched: General Agent! This iteration introduces three major features, bringing the capabilities of intelligent agents to new heights. 1. Claude Agent SDK Deep Integration \ud83d\udcf7 * Integrated with Claude Agent SDK: Enhancing the framework\u2019s extensibility * Seamless integration with the Claude Skills ecosystem, sharing powerful tool capabilities 2. Breakthrough Multi-File System Support \ud83d\udcf7 * Say goodbye to single-file limitations: Supports complex system development at a full project level 3. Support for AI Self-Evaluation Mode \ud83d\udcf7 * Self-evaluation: Agents can assess the quality of their own solutions, saving you the hassle of building evaluation functions \ud83d\udcf7 For more details, check out: https://github.com/baidu-baige/LoongFlow/tree/main/agents/general_agent . Feel free to try it out, and let us know if you have any questions or feedback! ~ See translation", "url": "https://huggingface.co/posts/FreshmanD/843358932677061", "date_published": "2026-02-05T17:51:40.390017"}, {"id": "https://huggingface.co/posts/MikeDoes/334475009032635", "image": "", "title": "Are you sure the open-source model you just downloaded is safe?", "content_text": "Are you sure the open-source model you just downloaded is safe? A recent paper on \"Privacy Backdoors\" reports a new vulnerability where pre-trained models can be poisoned before fine-tuning them. This is a serious challenge for everyone building on open-source AI. Instead of just pointing out problems, we believe in finding better solutions. To understand this threat, the researchers needed to test their attack on realistic data structures. They needed a dataset that could effectively simulate a high-stakes privacy attack, and we're proud that our Ai4Privacy dataset was used to provide this crucial benchmark. The paper reports that for our complex dataset, the privacy leakage on a non-poisoned model was almost zero. After the backdoor attack, that number reportedly jumped to 87%. Ai4Privacy dataset provided a realistic benchmark for their research. Our dataset, composed of synthetic identities, helped them demonstrate how a poisoned model could dramatically amplify privacy leakage....", "url": "https://huggingface.co/posts/MikeDoes/334475009032635", "date_published": "2026-02-05T17:51:40.390478"}]}