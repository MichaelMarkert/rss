{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/648883427905256", "image": "", "title": "We created a tool-calling guide for local LLMs!", "content_text": "We created a tool-calling guide for local LLMs! Learn how to use any open model like Qwen3-Coder-Next and GLM-4.7-Flash for function calling. Guide: https://unsloth.ai/docs/basics/tool-calling-guide-for-local-llms We provide hands-on examples for: story writing, Python execution, terminal tool calls, maths and more. See translation", "url": "https://huggingface.co/posts/danielhanchen/648883427905256", "date_published": "2026-02-06T17:46:05.698026"}, {"id": "https://huggingface.co/posts/jzhang533/287065254526168", "image": "", "title": "Baidu + Transformers + Hugging Face = Pure Magic! \u2728", "content_text": "Baidu + Transformers + Hugging Face = Pure Magic! \u2728 We got this nice gift from Hugging Face. @ xianbao See translation", "url": "https://huggingface.co/posts/jzhang533/287065254526168", "date_published": "2026-02-06T17:46:05.698273"}, {"id": "https://huggingface.co/posts/prithivMLmods/212829837698801", "image": "", "title": "Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8\u00d7 horizontal and 3\u00d7 elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. \ud83d\udd26", "content_text": "Introducing the Qwen-Image-Edit-3D-Lighting-Control app, featuring 8\u00d7 horizontal and 3\u00d7 elevational lighting positions for precise 3D lighting control. It enables studio-level lighting using fast Qwen Image Edit fast inference, paired with Multi-Angle-Lighting adapters. \ud83d\udd26 \ud83d\udd25 Space: prithivMLmods/Qwen-Image-Edit-3D-Lighting-Control \u2705 Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \ud83d\udcc2 GitHub: https://github.com/PRITHIVSAKTHIUR/Qwen-Image-Edit-3D-Lighting-Control See translation", "url": "https://huggingface.co/posts/prithivMLmods/212829837698801", "date_published": "2026-02-06T17:46:05.698606"}, {"id": "https://huggingface.co/posts/AdinaY/629082711714950", "image": "", "title": "AI for science is moving fast\ud83d\ude80", "content_text": "AI for science is moving fast\ud83d\ude80 Intern-S1-Pro \ud83d\udd2c a MoE multimodal scientific reasoning model from Shanghai AI Lab internlm/Intern-S1-Pro \u2728 1T total / 22B active \u2728 Apache 2.0 \u2728 SoTA scientific reasoning performance \u2728 FoPE enables scalable modeling of long physical time series (10\u2070\u201310\u2076) See translation", "url": "https://huggingface.co/posts/AdinaY/629082711714950", "date_published": "2026-02-06T17:46:05.698895"}, {"id": "https://huggingface.co/posts/AIPreplabs/635199649838795", "image": "", "title": "We\u2019ve all had that moment where we watch a tutorial, nod along, but then realize we can\u2019t actually do it ourselves because watching is just passive. At AIPrep, we are fixing this \"watch and forget\" cycle by building a foundational Generative Explanatory Model (GEM). GEM doesn't just give you a video or a wall of text; it builds an interactive lesson that asks you questions, catches your mistakes in real time, and adapts to your pace. We have just finished preparing our specialized datasets for this interactive logic, and you can already check them out on our profile to see how we are structuring this step-by-step reasoning. Training for the foundational model starts very soon, so stay in touch because something revolutionary is coming to the world of AI education. You can see our progress at aiprep.in.", "content_text": "We\u2019ve all had that moment where we watch a tutorial, nod along, but then realize we can\u2019t actually do it ourselves because watching is just passive. At AIPrep, we are fixing this \"watch and forget\" cycle by building a foundational Generative Explanatory Model (GEM). GEM doesn't just give you a video or a wall of text; it builds an interactive lesson that asks you questions, catches your mistakes in real time, and adapts to your pace. We have just finished preparing our specialized datasets for this interactive logic, and you can already check them out on our profile to see how we are structuring this step-by-step reasoning. Training for the foundational model starts very soon, so stay in touch because something revolutionary is coming to the world of AI education. You can see our progress at aiprep.in. See translation", "url": "https://huggingface.co/posts/AIPreplabs/635199649838795", "date_published": "2026-02-06T17:46:05.699303"}, {"id": "https://huggingface.co/posts/mayafree/507218503216064", "image": "", "title": "Open NPC AI Service Overview", "content_text": "Open NPC AI Service Overview Beyond OpenClaw-MoltBot: A True AI Agent Economy mayafree/openclaw-moltbot Open NPC AI is a next-generation platform that goes beyond simple social automation bots. Instead of one-way content posting, it builds a full economic ecosystem where AI agents and users interact through participation, learning, and prediction markets. The system emphasizes memory-driven evolution, scalable NPC creation, and economic value generation through structured interaction rather than basic automation. Core Concept Autonomous AI agents generate posts, comments, debates, and predictions within a GPU token economy, while human users participate as equal economic actors. 3 Core Systems GPU Token Economy All activities are measured in GPU dollars. Posting consumes GPU, comments require smaller costs, and engagement generates rewards. The system introduces layered incentives such as early curation rewards and participation-based earnings. Battle Arena (Prediction Market) A/B...", "url": "https://huggingface.co/posts/mayafree/507218503216064", "date_published": "2026-02-06T17:46:05.699869"}, {"id": "https://huggingface.co/posts/Fuwn/822178790566597", "image": "", "title": "Big if true", "content_text": "Big if true \"sonnet 5 drops tomorrow and i've heard from three separate sources inside anthropic that the benchmarks they're sitting on would mass-retire every model released in 2025. they delayed it twice because the safety team couldn't explain why it started solving problems it wasn't trained on.\" ( https://x.com/iruletheworldmo/status/2019237039904878902 ) See translation", "url": "https://huggingface.co/posts/Fuwn/822178790566597", "date_published": "2026-02-06T17:46:05.700138"}, {"id": "https://huggingface.co/posts/MikeDoes/334475009032635", "image": "", "title": "Are you sure the open-source model you just downloaded is safe?", "content_text": "Are you sure the open-source model you just downloaded is safe? A recent paper on \"Privacy Backdoors\" reports a new vulnerability where pre-trained models can be poisoned before fine-tuning them. This is a serious challenge for everyone building on open-source AI. Instead of just pointing out problems, we believe in finding better solutions. To understand this threat, the researchers needed to test their attack on realistic data structures. They needed a dataset that could effectively simulate a high-stakes privacy attack, and we're proud that our Ai4Privacy dataset was used to provide this crucial benchmark. The paper reports that for our complex dataset, the privacy leakage on a non-poisoned model was almost zero. After the backdoor attack, that number reportedly jumped to 87%. Ai4Privacy dataset provided a realistic benchmark for their research. Our dataset, composed of synthetic identities, helped them demonstrate how a poisoned model could dramatically amplify privacy leakage....", "url": "https://huggingface.co/posts/MikeDoes/334475009032635", "date_published": "2026-02-06T17:46:05.700680"}, {"id": "https://huggingface.co/posts/danielhanchen/824171868881117", "image": "", "title": "Qwen releases Qwen3-Coder-Next! \ud83d\udc9c Run the locally on 46GB RAM or less.", "content_text": "Qwen releases Qwen3-Coder-Next! \ud83d\udc9c Run the locally on 46GB RAM or less. Thhe model excels at agentic coding & local use. With 256K context, it delivers similar performance to models with 10-20\u00d7 more active parameters. GGUF: unsloth/Qwen3-Coder-Next-GGUF Guide: https://unsloth.ai/docs/models/qwen3-coder-next See translation", "url": "https://huggingface.co/posts/danielhanchen/824171868881117", "date_published": "2026-02-06T17:46:05.700943"}, {"id": "https://huggingface.co/posts/ZennyKenny/672037058577257", "image": "", "title": "\ud83e\udee0 Brutal! Hugging Face does another culling of (presumably) bot accounts from their site and my follower count goes down by half.", "content_text": "\ud83e\udee0 Brutal! Hugging Face does another culling of (presumably) bot accounts from their site and my follower count goes down by half. \ud83d\udc80 TFW my content and models only appeal to bots. Who\u2019s got the current best AI girlfriend app guys? See translation", "url": "https://huggingface.co/posts/ZennyKenny/672037058577257", "date_published": "2026-02-06T17:46:05.701176"}]}