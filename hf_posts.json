{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mitkox/604222926195865", "image": "", "title": "XBai o4 claims to beat Claude Opus 4 and o3-mini, and they provide verifiable proof. My skepticism circuits overloaded, but my local AI FOMO module screamed louder.", "content_text": "XBai o4 claims to beat Claude Opus 4 and o3-mini, and they provide verifiable proof. My skepticism circuits overloaded, but my local AI FOMO module screamed louder. I've thrown this 33B monoblock LLM onto a single GPU and used Roo Code for some\u2026 let\u2019s call it \u201cvibe testing\u201d. It\u2019s terrifyingly competent. As an architect, it\u2019s the best open-weight model I\u2019ve touched this side of 2025. See translation", "url": "https://huggingface.co/posts/mitkox/604222926195865", "date_published": "2025-08-05T05:33:40.187538"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/425722660691765", "image": "", "title": "Wan 2.2 & FLUX Krea Full Tutorial - Automated Install - Ready Perfect Presets - SwarmUI with ComfyUI - Install Wan 2.2 and FLUX Krea with literally 1-click and use our pre-made most amazing quality presets :", "content_text": "Wan 2.2 & FLUX Krea Full Tutorial - Automated Install - Ready Perfect Presets - SwarmUI with ComfyUI - Install Wan 2.2 and FLUX Krea with literally 1-click and use our pre-made most amazing quality presets : https://youtu.be/8MvvuX4YPeo https://youtu.be/8MvvuX4YPeo Video Chapters 0:00 Introduction: The Ultimate Wan 2.2 Tutorial with Optimized Presets 1:03 Free Prompt Generation Tool & Introducing the New FLUX Krea Dev Model 2:01 How SwarmUI & ComfyUI Enable Video Generation on Low-End Hardware 2:46 Quick Start Guide: Downloading the Latest SwarmUI & ComfyUI Installers 3:10 Step-by-Step: How to Update or Perform a Fresh Installation of ComfyUI 3:51 Step-by-Step: How to Update or Perform a Fresh Installation of SwarmUI 4:18 Essential Setup: Configuring the SwarmUI Backend for ComfyUI 4:53 One-Click Setup: Downloading All Required Wan 2.2 Models Automatically 5:46 Importing the Ultimate SwarmUI Presets Pack for Best Results 6:22 Wan 2.2 Image-to-Video Generation: A Complete Step-by-...", "url": "https://huggingface.co/posts/MonsterMMORPG/425722660691765", "date_published": "2025-08-05T05:33:40.188082"}, {"id": "https://huggingface.co/posts/sergiopaniego/720514750677796", "image": "", "title": "Just included example scripts for aligning models using GSPO (including VLM example) \ud83d\ude46\u200d\u2642\ufe0f\ud83d\ude46\u200d\u2642\ufe0f", "content_text": "Just included example scripts for aligning models using GSPO (including VLM example) \ud83d\ude46\u200d\u2642\ufe0f\ud83d\ude46\u200d\u2642\ufe0f GSPO is the latest RL alignment algo by @Alibaba_Qwen and it's already supported in the latest TRL v0.20 release. Super-easy-to-get-started example scripts below, GO run them!\ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc69\u200d\ud83d\udcbb \ud83e\uddd1\u200d\ud83c\udfa8 Script: https://github.com/huggingface/trl/blob/main/examples/scripts/gspo.py \ud83e\udd84 VLM script: https://github.com/huggingface/trl/blob/main/examples/scripts/gspo_vlm.py \ud83e\udde9 More TRL examples: https://huggingface.co/docs/trl/main/en/example_overview \ud83e\uddd9\u200d\u2642\ufe0f GSPO paper: Group Sequence Policy Optimization (2507.18071) See translation", "url": "https://huggingface.co/posts/sergiopaniego/720514750677796", "date_published": "2025-08-05T05:33:40.188415"}, {"id": "https://huggingface.co/posts/Tonic/788576464887071", "image": "", "title": "\ud83e\udee1 I am the first and only one to like the French Tax Code Dataset", "content_text": "\ud83e\udee1 I am the first and only one to like the French Tax Code Dataset that's it , that's the post find the dataset here : louisbrulenaudet/code-impots follow : @ louisbrulenaudet See translation", "url": "https://huggingface.co/posts/Tonic/788576464887071", "date_published": "2025-08-05T05:33:40.188648"}, {"id": "https://huggingface.co/posts/codelion/145733180850232", "image": "", "title": "Extended the ICM paper to show cross-model capability transfer - used Qwen3's mathematical reasoning to improve Gemma3 without any human supervision.", "content_text": "Extended the ICM paper to show cross-model capability transfer - used Qwen3's mathematical reasoning to improve Gemma3 without any human supervision. Key results: Qwen3-0.6B: 63.2 \u2192 66.0 on MATH-500 (+4%) Gemma3-1B: 41.0 \u2192 45.6 on MATH-500 (+11%) The method extracts coherent reasoning patterns from one model via Internal Coherence Maximization, converts them to DPO training data, and uses that to improve a completely different model architecture. This goes beyond the original ICM paper which only improved models using their own labels. We're showing you can transfer capabilities between any models - imagine extracting capabilities from strong models to improve your local ones. Models available: codelion/Qwen3-0.6B-ICM-DPO codelion/gemma-3-1b-it-ICM-DPO Complete collection with code and datasets: codelion/internal-coherence-maximization-687a1bd1c1f5f1d6f76e9b3b Full methodology and results: https://huggingface.co/blog/codelion/internal-coherence-maximization Planning to extend this...", "url": "https://huggingface.co/posts/codelion/145733180850232", "date_published": "2025-08-05T05:33:40.189111"}, {"id": "https://huggingface.co/posts/Kseniase/651523050744942", "image": "", "title": "12 Powerful World Models", "content_text": "12 Powerful World Models World models are one of the most challenging areas in AI, pushing the boundaries of reasoning, perception, and planning. They're gen AI systems that help models and agents learn internal representations of real-world environments. Today, we invite you to take a look at 12 standout examples: 1. WorldVLA \u2192 WorldVLA: Towards Autoregressive Action World Model (2506.21539) This autoregressive world model integrates action prediction and visual world modeling in a single framework, allowing each to enhance the other. It introduces an attention masking strategy to reduce action prediction errors 2. SimuRA \u2192 https://arxiv.org/abs/2507.23773 A generalized world model that uses a language-based world model to simulate and plan actions before execution, enabling more general and flexible reasoning 3. PAN (Physical, Agentic, and Nested) world models \u2192 Critiques of World Models (2507.05169) Has a hybrid architecture that combines discrete concept-based reasoning (via...", "url": "https://huggingface.co/posts/Kseniase/651523050744942", "date_published": "2025-08-05T05:33:40.189753"}, {"id": "https://huggingface.co/posts/mrs83/268112975581936", "image": "", "title": "Introducing Completionist, an open-source command-line tool that automates synthetic dataset generation.", "content_text": "Introducing Completionist, an open-source command-line tool that automates synthetic dataset generation. It works by iterating over an existing HF dataset and by using a LLM to create completions. - Problem: You need a fast way to create custom datasets for fine-tuning or RAG, but you want the flexibility to use different LLM backends or your own infrastructure. - Solution: Completionist connects with any OpenAI-compatible endpoint, including Ollama and LM Studio, or a Hugging Face inference endpoint. A simple CLI like Completionist gives you the possibility to take full control of your synthetic data generation workflow. \ud83d\udc49 Check out Completionist on GitHub: https://github.com/ethicalabs-ai/completionist Synthetic Dataset Example: ethicalabs/kurtis-mental-health-v2-sft-reasoning See translation", "url": "https://huggingface.co/posts/mrs83/268112975581936", "date_published": "2025-08-05T05:33:40.190145"}, {"id": "https://huggingface.co/posts/Abhaykoul/625756342268823", "image": "", "title": "\ud83d\ude80 Dhanishtha-2.0-preview-0825 Is Here", "content_text": "\ud83d\ude80 Dhanishtha-2.0-preview-0825 Is Here The Intermediate Thinking Model just leveled up again. With sharper reasoning, better tool use, and expanded capabilities, Dhanishtha-2.0-preview-0825 is now live and ready to impress. \ud83e\udde0 What Makes Dhanishtha Special? Unlike typical CoT models that only thinks one time, Dhanishtha thinks iteratively: > Think \u2192 Answer \u2192 Rethink \u2192 Improve \u2192 Rethink again if needed. \ud83d\udd17 Try it now: HelpingAI/Dhanishtha-2.0-preview-0825 \ud83d\udd1e Dhanishtha NSFW Preview For those exploring more expressive and immersive roleplay scenarios, we\u2019re also releasing: HelpingAI/Dhanishtha-nsfw A specialized version tuned for adult-themed interactions and character-driven roleplay. \ud83d\udd17 Explore it here: HelpingAI/Dhanishtha-nsfw \ud83d\udcac You can also try all of these live at chat.helpingai.co See translation", "url": "https://huggingface.co/posts/Abhaykoul/625756342268823", "date_published": "2025-08-05T05:33:40.190533"}, {"id": "https://huggingface.co/posts/mitkox/378542221866585", "image": "", "title": "I run Claude Code with Qwen3 Coder Flash locally on my MacBook Air. It works offline, zero cloud, zero internet, zero EU AI Act anxiety. No limit with all tokens on the house.", "content_text": "I run Claude Code with Qwen3 Coder Flash locally on my MacBook Air. It works offline, zero cloud, zero internet, zero EU AI Act anxiety. No limit with all tokens on the house. It\u2019s not great, not terrible- adequate performance for an on device AI agent chewing through code on a 1.24 kg laptop. I wrote an interpreter to broker peace between Claude Code and my local AI runtime. Make sure you own your AI. AI in the cloud is not aligned with you; it\u2019s aligned with the company that owns it. See translation", "url": "https://huggingface.co/posts/mitkox/378542221866585", "date_published": "2025-08-05T05:33:40.190835"}, {"id": "https://huggingface.co/posts/prithivMLmods/210600524016945", "image": "", "title": "Introducing Camel-Doc-OCR-080125(v2), a document content-structure retrieval VLM designed for content extraction and summarization. This is the second model in the Camel Doc OCR VLM series, following Camel-Doc-OCR-062825(v1). The new version fixes formal table reconstruction issues in both en and zh language, achieving optimal performance for long-context inferences.\ud83e\udd17\ud83d\udc2a", "content_text": "Introducing Camel-Doc-OCR-080125(v2), a document content-structure retrieval VLM designed for content extraction and summarization. This is the second model in the Camel Doc OCR VLM series, following Camel-Doc-OCR-062825(v1). The new version fixes formal table reconstruction issues in both en and zh language, achieving optimal performance for long-context inferences.\ud83e\udd17\ud83d\udc2a \u2937 Camel-Doc-OCR(v2) : prithivMLmods/Camel-Doc-OCR-080125 \u2937 Camel-Doc-OCR(v1) : prithivMLmods/Camel-Doc-OCR-062825 \u2937 Demo : prithivMLmods/core-OCR Multimodal Model Collections and Spaces: \u279d Camel-Doc-OCR : prithivMLmods/camel-doc-ocr-080125-688c0c61c5dba648756f31f8 \u279d Vision-Language (VLr) : prithivMLmods/vision-language-for-reasoning-vlr-6889b3f45917352b5e3a6f7a \u279d Multimodal Spaces : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 \u279d Multimodal VLMs : prithivMLmods/multimodal-vlms-until-july25-688312e6b840e1e156f13027 . . . To know more about it, visit the model card of the respective model. !! See...", "url": "https://huggingface.co/posts/prithivMLmods/210600524016945", "date_published": "2025-08-05T05:33:40.191293"}]}