{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/859959880164586", "image": "", "title": "You can now run Llama 4 on your own local device! \ud83e\udd99", "content_text": "You can now run Llama 4 on your own local device! \ud83e\udd99 Run our Dynamic 1.78-bit and 2.71-bit Llama 4 GGUFs: unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF You can run them on llama.cpp and other inference engines. See our guide here: https://docs.unsloth.ai/basics/tutorial-how-to-run-and-fine-tune-llama-4 See translation", "url": "https://huggingface.co/posts/danielhanchen/859959880164586", "date_published": "2025-04-10T05:22:13.763333"}, {"id": "https://huggingface.co/posts/merterbak/235850739835485", "image": "", "title": "Qwen 3 can launch very soon. \ud83d\udc40", "content_text": "Qwen 3 can launch very soon. \ud83d\udc40 https://github.com/ggml-org/llama.cpp/pull/12828 See translation", "url": "https://huggingface.co/posts/merterbak/235850739835485", "date_published": "2025-04-10T05:22:13.763596"}, {"id": "https://huggingface.co/posts/jasoncorkill/726469711226418", "image": "", "title": "\ud83d\udd25 Yesterday was a fire day!", "content_text": "\ud83d\udd25 Yesterday was a fire day! We dropped two brand-new datasets capturing Human Preferences for text-to-video and text-to-image generations powered by our own crowdsourcing tool! Whether you're working on model evaluation, alignment, or fine-tuning, this is for you. 1. Text-to-Video Dataset (Pika 2.2 model): Rapidata/text-2-video-human-preferences-pika2.2 2. Text-to-Image Dataset (Reve-AI Halfmoon): Rapidata/Reve-AI-Halfmoon_t2i_human_preference Let\u2019s train AI on AI-generated content with humans in the loop. Let\u2019s make generative models that actually get us. See translation", "url": "https://huggingface.co/posts/jasoncorkill/726469711226418", "date_published": "2025-04-10T05:22:13.763947"}, {"id": "https://huggingface.co/posts/fcakyon/248454580146320", "image": "", "title": "\ud83c\udf89 GitHub selected the ultralytics computer vision project, known for its YOLOv8/YOLO11 real-time SOTA computer vision models, as one of the top 5 open-source projects for first-time contributors in 2024!", "content_text": "\ud83c\udf89 GitHub selected the ultralytics computer vision project, known for its YOLOv8/YOLO11 real-time SOTA computer vision models, as one of the top 5 open-source projects for first-time contributors in 2024! Link to the project: https://github.com/ultralytics/ultralytics Link to the full GitHub 2024 recap report: https://github.blog/news-insights/octoverse/octoverse-2024/ See translation", "url": "https://huggingface.co/posts/fcakyon/248454580146320", "date_published": "2025-04-10T05:22:13.764238"}, {"id": "https://huggingface.co/posts/fdaudens/650208950263848", "image": "", "title": "I read the 456-page AI Index report so you don't have to (kidding). The wild part? While AI gets ridiculously more accessible, the power gap is actually widening:", "content_text": "I read the 456-page AI Index report so you don't have to (kidding). The wild part? While AI gets ridiculously more accessible, the power gap is actually widening: 1\ufe0f\u20e3 The democratization of AI capabilities is accelerating rapidly: - The gap between open and closed models is basically closed: difference in benchmarks like MMLU and HumanEval shrunk to just 1.7% in 2024 - The cost to run GPT-3.5-level performance dropped 280x in 2 years - Model size is shrinking while maintaining performance - Phi-3-mini hitting 60%+ MMLU at fraction of parameters of early models like PaLM 2\ufe0f\u20e3 But we're seeing concerning divides deepening: - Geographic: US private investment ($109B) dwarfs everyone else - 12x China's $9.3B - Research concentration: US and China dominate highly-cited papers (50 and 34 respectively in 2023), while next closest is only 7 - Gender: Major gaps in AI skill penetration rates - US shows 2.39 vs 1.71 male/female ratio The tech is getting more accessible but the benefits aren't...", "url": "https://huggingface.co/posts/fdaudens/650208950263848", "date_published": "2025-04-10T05:22:13.764741"}, {"id": "https://huggingface.co/posts/DawnC/553378321840890", "image": "", "title": "New in PawMatchAI\ud83d\udc3e : Turn Your Dog Photos into Art!", "content_text": "New in PawMatchAI\ud83d\udc3e : Turn Your Dog Photos into Art! I\u2019m excited to introduce a brand-new creative feature \u2014 Dog Style Transfer is now live on PawMatchAI! Just upload your dog\u2019s photo and transform it into 5 artistic styles: \ud83c\udf38 Japanese Anime \ud83d\udcda Classic Cartoon \ud83d\uddbc\ufe0f Oil Painting \ud83c\udfa8 Watercolor \ud83c\udf06 Cyberpunk All powered by Stable Diffusion and enhanced with smart prompt tuning to preserve your dog\u2019s unique traits and breed identity , so the artwork stays true to your furry friend. Whether you're creating a custom portrait or just having fun, this feature brings your pet photos to life in completely new ways. And here\u2019s a little secret: although it\u2019s designed with dogs in mind, it actually works on any photo \u2014 cats, plush toys, even humans. Feel free to experiment! Results may not always be perfectly accurate, sometimes your photo might come back looking a little different, or even beyond your imagination. But that\u2019s part of the fun! It\u2019s all about creative surprises and letting the AI do its...", "url": "https://huggingface.co/posts/DawnC/553378321840890", "date_published": "2025-04-10T05:22:13.765239"}, {"id": "https://huggingface.co/posts/jsulz/855747629260036", "image": "", "title": "What does it mean when models share the same bytes?", "content_text": "What does it mean when models share the same bytes? We've investigated some quants and have seen that a considerable portion of quantizations of the same model share the same bytes and can be deduplicated to save considerable upload time for quantizers on the Hub. This space where we crack open a repo from @ bartowski shows we can get significant dedupe xet-team/quantization-dedup You can get a sense of why by reading this write-up: https://github.com/bartowski1182/llm-knowledge/blob/main/quantization/quantization.md But what about finetuned models? Since going into production the xet-team has migrated hundreds of repositories on the Hub to our storage layer, including classic \"pre-Hub\" open-source models like FacebookAI/xlm-roberta-large (XLM-R) from FacebookAI XLM-R, introduced in 2019, set new benchmarks for multilingual NLP by learning shared representations across 100 languages. It was then fine-tuned on English, Spanish, Dutch, and German, generating language-specific...", "url": "https://huggingface.co/posts/jsulz/855747629260036", "date_published": "2025-04-10T05:22:13.765734"}, {"id": "https://huggingface.co/posts/csabakecskemeti/971611835182279", "image": "", "title": "Why the  'how many r's in strawberry' prompt \"breaks\" llama4? :D", "content_text": "Why the 'how many r's in strawberry' prompt \"breaks\" llama4? :D Quants DevQuasar/meta-llama.Llama-4-Scout-17B-16E-Instruct-GGUF See translation", "url": "https://huggingface.co/posts/csabakecskemeti/971611835182279", "date_published": "2025-04-10T05:22:13.765964"}, {"id": "https://huggingface.co/posts/jsulz/541804424324012", "image": "", "title": "The Llama 4 release  -", "content_text": "The Llama 4 release - meta-llama/llama-4-67f0c30d9fe03840bc9d0164 - was a big one for the xet-team with every model backed by the storage infrastructure of the future for the Hub. It's been a wild few days, and especially \ud83e\udd2f to see every tensor file with a Xet logo next to it instead of LFS. The attached graph shows requests per second to our content-addressed store (CAS) right as the release went live. yellow = GETs; dashed line = launch time. You can definitely tell when the community started downloading \ud83d\udc40 h/t to @ rajatarya for the graph, the entire Xet crew to bring us to this point, and special shoutout to Rajat, @ port8080 , @ brianronan , @ seanses , and @ znation who made sure the bytes kept flying all weekend \u26a1\ufe0f See translation", "url": "https://huggingface.co/posts/jsulz/541804424324012", "date_published": "2025-04-10T05:22:13.766361"}, {"id": "https://huggingface.co/posts/BrigitteTousi/559995441481207", "image": "", "title": "AI agents are transforming how we interact with technology, but how sustainable are they? \ud83c\udf0d", "content_text": "AI agents are transforming how we interact with technology, but how sustainable are they? \ud83c\udf0d Design choices \u2014 like model size and structure \u2014 can massively impact energy use and cost. \u26a1\ud83d\udcb0 The key takeaway: smaller, task-specific models can be far more efficient than large, general-purpose ones. \ud83d\udd11 Open-source models offer greater transparency, allowing us to track energy consumption and make more informed decisions on deployment. \ud83c\udf31 Open-source = more efficient, eco-friendly, and accountable AI. Read our latest, led by @ sasha with assists from myself + @ yjernite \ud83e\udd17 https://huggingface.co/blog/sasha/ai-agent-sustainability See translation", "url": "https://huggingface.co/posts/BrigitteTousi/559995441481207", "date_published": "2025-04-10T05:22:13.766756"}]}