{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/682363513025265", "image": "", "title": "Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams \ud83d\udcdd", "content_text": "Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams \ud83d\udcdd openfree/Korean-Exam-Leaderboard ## \ud83d\udcca What is this leaderboard? This leaderboard evaluates the performance of various AI models on 22 Korean civil service and professional qualification exams. All scores are converted to a 100-point scale to show how well different LLMs can solve actual Korean civil service and professional qualification tests! ## \ud83c\udfc6 Current Top Performers - **OpenAI/GPT-o1**: Bar Exam 52.5 points \ud83e\udd47 - **OpenAI/GPT-4.5**: Bar Exam 49.33 points \ud83e\udd48 - **OpenAI/GPT-4o**: Bar Exam 49.11 points \ud83e\udd49 - **deepseek-ai/DeepSeek-R1**: Bar Exam 47.33 points ## \ud83d\udccb Exams Being Evaluated The leaderboard includes various Korean civil service and professional qualification exams: - Korean Bar Exam - Senior Civil Service Grade 5 - Judicial Service Grade 5 - National Assembly Grade 5 - Judicial Scrivener - Police Executive Candidate - And more exams! ## \ud83e\udd16 Models Being Evaluated We are testing a variety of...", "url": "https://huggingface.co/posts/openfree/682363513025265", "date_published": "2025-03-24T17:20:12.272124"}, {"id": "https://huggingface.co/posts/hanzla/334929914214979", "image": "", "title": "\ud83d\udc4b Hi all!", "content_text": "\ud83d\udc4b Hi all! For any AI agent, internet search \ud83d\udd0e is an important tool. However, with APIs like Tavily and Exa, it becomes really difficult to keep up with the cost. In some cases, these Internet APIs cost more than the LLM. To solve, this, I am making a playwright wrapper API on top of publicly available searXNG instances. This will enable agent applications to fetch internet results for free. Currently, I have set up a basic GitHub repo, and I will continue developing advanced search features, such as image search \ud83d\uddbc\ufe0f Github: https://github.com/HanzlaJavaid/Free-Search/tree/main \ud83d\ude80 Try the deployed version: https://freesearch.replit.app/docs If you find this useful, consider starring \u2b50\ufe0f the GitHub repository to support further development! See translation", "url": "https://huggingface.co/posts/hanzla/334929914214979", "date_published": "2025-03-24T17:20:12.272568"}, {"id": "https://huggingface.co/posts/Kseniase/498106595218801", "image": "", "title": "8 types of RoPE", "content_text": "8 types of RoPE As we always use Transformers, it's helpful to understand RoPE\u2014Rotary Position Embedding. Since token order matters, RoPE encodes it by rotating token embeddings based on their position, so the model knows how to interpret which token comes first, second, and so on. Here are 8 types of RoPE that can be implemented in different cases: 1. Original RoPE -> RoFormer: Enhanced Transformer with Rotary Position Embedding (2104.09864) Encodes token positions by rotating token embeddings in the complex plane via a position-based rotation matrix, thereby providing the self-attention mechanism with relative positional info. 2. LongRoPE -> LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens (2402.13753) Extends the context window of pre-trained LLMs to 2048k tokens, leveraging non-uniformities in positional interpolation with an efficient search. 3. LongRoPE2 -> LongRoPE2: Near-Lossless LLM Context Window Scaling (2502.20082) Extends the effective context window of...", "url": "https://huggingface.co/posts/Kseniase/498106595218801", "date_published": "2025-03-24T17:20:12.273259"}, {"id": "https://huggingface.co/posts/onekq/812629409559433", "image": "", "title": "Folks, let's get ready.\ud83e\udd73 We will be busy soon.  \ud83d\ude05\ud83e\udd17https://github.com/huggingface/transformers/pull/36878", "content_text": "Folks, let's get ready.\ud83e\udd73 We will be busy soon. \ud83d\ude05\ud83e\udd17https://github.com/huggingface/transformers/pull/36878 See translation", "url": "https://huggingface.co/posts/onekq/812629409559433", "date_published": "2025-03-24T17:20:12.273500"}, {"id": "https://huggingface.co/posts/merve/746832157330905", "image": "", "title": "So many open releases at Hugging Face past week \ud83e\udd2f recapping all here \u2935\ufe0f", "content_text": "So many open releases at Hugging Face past week \ud83e\udd2f recapping all here \u2935\ufe0f merve/march-21-releases-67dbe10e185f199e656140ae \ud83d\udc40 Multimodal > Mistral AI released a 24B vision LM, both base and instruction FT versions, sota \ud83d\udd25 (OS) > with IBM we released SmolDocling, a sota 256M document parser with Apache 2.0 license (OS) > SpatialLM is a new vision LM that outputs 3D bounding boxes, comes with 0.5B (QwenVL based) and 1B (Llama based) variants > SkyWork released SkyWork-R1V-38B, new vision reasoning model (OS) \ud83d\udcac LLMs > NVIDIA released new Nemotron models in 49B and 8B with their post-training dataset > LG released EXAONE, new reasoning models in 2.4B, 7.8B and 32B > Dataset: Glaive AI released a new reasoning dataset of 22M+ examples > Dataset: NVIDIA released new helpfulness dataset HelpSteer3 > Dataset: OpenManusRL is a new agent dataset based on ReAct framework (OS) > Open-R1 team released OlympicCoder, new competitive coder model in 7B and 32B > Dataset: GeneralThought-430K is a new...", "url": "https://huggingface.co/posts/merve/746832157330905", "date_published": "2025-03-24T17:20:12.274127"}, {"id": "https://huggingface.co/posts/OFT/371302061549874", "image": "", "title": "Today I decided to cancel my PRO subscription for Hugging Face. I had a lot of fun with it but with the current changes to API and allowed limits I think it isn't worth it anymore. So I just turned everything off and cancelled my subscription. It feels like one of these movies scenes where you see an old computerlab and someone putting big white sheets over it and closing the door behind him.  I am not going, I am not gone, but watching through the glass window of the door that I just closed.", "content_text": "Today I decided to cancel my PRO subscription for Hugging Face. I had a lot of fun with it but with the current changes to API and allowed limits I think it isn't worth it anymore. So I just turned everything off and cancelled my subscription. It feels like one of these movies scenes where you see an old computerlab and someone putting big white sheets over it and closing the door behind him. I am not going, I am not gone, but watching through the glass window of the door that I just closed. See translation", "url": "https://huggingface.co/posts/OFT/371302061549874", "date_published": "2025-03-24T17:20:12.274444"}, {"id": "https://huggingface.co/posts/MikeDoes/593610719403706", "image": "", "title": "\ud83c\udf1f Day 4: Two Models, One Privacy Mission! \ud83c\udf1f", "content_text": "\ud83c\udf1f Day 4: Two Models, One Privacy Mission! \ud83c\udf1f The PII-Masking-1M series rolls on with two gems: Categorical: ai4privacy/llama-ai4privacy-multilingual-categorical-anonymiser-openpii Redaction: ai4privacy/llama-ai4privacy-multilingual-anonymiser-openpii Join us in protecting data everywhere! #AI #Privacy #OpenSource #Multilingual See translation", "url": "https://huggingface.co/posts/MikeDoes/593610719403706", "date_published": "2025-03-24T17:20:12.274731"}, {"id": "https://huggingface.co/posts/onekq/124053264899473", "image": "", "title": "I shared my view on Qwen vs DeepSeek (student vs genius), and I forgot to mention this: they are neighbors in the same city.", "content_text": "I shared my view on Qwen vs DeepSeek (student vs genius), and I forgot to mention this: they are neighbors in the same city. https://en.wikipedia.org/wiki/Hangzhou See translation", "url": "https://huggingface.co/posts/onekq/124053264899473", "date_published": "2025-03-24T17:20:12.274969"}, {"id": "https://huggingface.co/posts/Jaward/890536870890791", "image": "", "title": "Implemented a custom multimodal GRPO trainer that scales for Small VLMs, supports cpu and gpu with vllm + flash attention. Using SmolVLM-256M-Instruct reference & reward model, wasn\u2019t trained for long btw, still got some sparks of \u201cthinking\u201d:)", "content_text": "Implemented a custom multimodal GRPO trainer that scales for Small VLMs, supports cpu and gpu with vllm + flash attention. Using SmolVLM-256M-Instruct reference & reward model, wasn\u2019t trained for long btw, still got some sparks of \u201cthinking\u201d:) Code: https://github.com/Jaykef/ai-algorithms/blob/main/grpo_multimodal_reasoner.ipynb See translation", "url": "https://huggingface.co/posts/Jaward/890536870890791", "date_published": "2025-03-24T17:20:12.275260"}, {"id": "https://huggingface.co/posts/csabakecskemeti/287842366376256", "image": "", "title": "I'm collecting llama-bench results for inference with a llama 3.1 8B q4 and q8 reference models on varoius GPUs. The results are average of 5 executions.", "content_text": "I'm collecting llama-bench results for inference with a llama 3.1 8B q4 and q8 reference models on varoius GPUs. The results are average of 5 executions. The system varies (different motherboard and CPU ... but that probably that has little effect on the inference performance). https://devquasar.com/gpu-gguf-inference-comparison/ the exact models user are in the page I'd welcome results from other GPUs is you have access do anything else you've need in the post. Hopefully this is useful information everyone. See translation", "url": "https://huggingface.co/posts/csabakecskemeti/287842366376256", "date_published": "2025-03-24T17:20:12.275555"}]}