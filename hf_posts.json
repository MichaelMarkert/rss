{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/682363513025265", "image": "", "title": "Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams \ud83d\udcdd", "content_text": "Korean Exam Leaderboard: LLMs vs Civil Service and Professional Qualification Exams \ud83d\udcdd openfree/Korean-Exam-Leaderboard ## \ud83d\udcca What is this leaderboard? This leaderboard evaluates the performance of various AI models on 22 Korean civil service and professional qualification exams. All scores are converted to a 100-point scale to show how well different LLMs can solve actual Korean civil service and professional qualification tests! ## \ud83c\udfc6 Current Top Performers - **OpenAI/GPT-o1**: Bar Exam 52.5 points \ud83e\udd47 - **OpenAI/GPT-4.5**: Bar Exam 49.33 points \ud83e\udd48 - **OpenAI/GPT-4o**: Bar Exam 49.11 points \ud83e\udd49 - **deepseek-ai/DeepSeek-R1**: Bar Exam 47.33 points ## \ud83d\udccb Exams Being Evaluated The leaderboard includes various Korean civil service and professional qualification exams: - Korean Bar Exam - Senior Civil Service Grade 5 - Judicial Service Grade 5 - National Assembly Grade 5 - Judicial Scrivener - Police Executive Candidate - And more exams! ## \ud83e\udd16 Models Being Evaluated We are testing a variety of...", "url": "https://huggingface.co/posts/openfree/682363513025265", "date_published": "2025-03-23T17:17:25.797528"}, {"id": "https://huggingface.co/posts/onekq/812629409559433", "image": "", "title": "Folks, let's get ready.\ud83e\udd73 We will be busy soon.  \ud83d\ude05\ud83e\udd17https://github.com/huggingface/transformers/pull/36878", "content_text": "Folks, let's get ready.\ud83e\udd73 We will be busy soon. \ud83d\ude05\ud83e\udd17https://github.com/huggingface/transformers/pull/36878 See translation", "url": "https://huggingface.co/posts/onekq/812629409559433", "date_published": "2025-03-23T17:17:25.797776"}, {"id": "https://huggingface.co/posts/burtenshaw/105046709529701", "image": "", "title": "The Hugging Face Agents Course now includes three major agent frameworks!", "content_text": "The Hugging Face Agents Course now includes three major agent frameworks! \ud83d\udd17 https://huggingface.co/agents-course This includes LlamaIndex, LangChain, and our very own smolagents. We've worked to integrate the three frameworks in distinctive ways so that learners can reflect on when and where to use each. This also means that you can follow the course if you're already familiar with one of these frameworks, and soak up some of the fundamental knowledge in earlier units. Hopefully, this makes the agents course as open to as many people as possible. See translation", "url": "https://huggingface.co/posts/burtenshaw/105046709529701", "date_published": "2025-03-23T17:17:25.798125"}, {"id": "https://huggingface.co/posts/OFT/371302061549874", "image": "", "title": "Today I decided to cancel my PRO subscription for Hugging Face. I had a lot of fun with it but with the current changes to API and allowed limits I think it isn't worth it anymore. So I just turned everything off and cancelled my subscription. It feels like one of these movies scenes where you see an old computerlab and someone putting big white sheets over it and closing the door behind him.  I am not going, I am not gone, but watching through the glass window of the door that I just closed.", "content_text": "Today I decided to cancel my PRO subscription for Hugging Face. I had a lot of fun with it but with the current changes to API and allowed limits I think it isn't worth it anymore. So I just turned everything off and cancelled my subscription. It feels like one of these movies scenes where you see an old computerlab and someone putting big white sheets over it and closing the door behind him. I am not going, I am not gone, but watching through the glass window of the door that I just closed. See translation", "url": "https://huggingface.co/posts/OFT/371302061549874", "date_published": "2025-03-23T17:17:25.798422"}, {"id": "https://huggingface.co/posts/Kseniase/498106595218801", "image": "", "title": "8 types of RoPE", "content_text": "8 types of RoPE As we always use Transformers, it's helpful to understand RoPE\u2014Rotary Position Embedding. Since token order matters, RoPE encodes it by rotating token embeddings based on their position, so the model knows how to interpret which token comes first, second, and so on. Here are 8 types of RoPE that can be implemented in different cases: 1. Original RoPE -> RoFormer: Enhanced Transformer with Rotary Position Embedding (2104.09864) Encodes token positions by rotating token embeddings in the complex plane via a position-based rotation matrix, thereby providing the self-attention mechanism with relative positional info. 2. LongRoPE -> LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens (2402.13753) Extends the context window of pre-trained LLMs to 2048k tokens, leveraging non-uniformities in positional interpolation with an efficient search. 3. LongRoPE2 -> LongRoPE2: Near-Lossless LLM Context Window Scaling (2502.20082) Extends the effective context window of...", "url": "https://huggingface.co/posts/Kseniase/498106595218801", "date_published": "2025-03-23T17:17:25.799096"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/579577092717485", "image": "", "title": "I am doing a workflow research for a company and our Ultimate Image Processing tool is being extremely helpful. You can auto zoom / crop into desired aspect ratio with using prompts (like a shoe) via SAM2 that we have in our batch processing app.", "content_text": "I am doing a workflow research for a company and our Ultimate Image Processing tool is being extremely helpful. You can auto zoom / crop into desired aspect ratio with using prompts (like a shoe) via SAM2 that we have in our batch processing app. Gradio based App link : https://www.patreon.com/posts/120352012 See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/579577092717485", "date_published": "2025-03-23T17:17:25.799359"}, {"id": "https://huggingface.co/posts/stefan-french/995663487518303", "image": "", "title": "Hey \ud83d\udc4b Want to build your own personal timeline algorithm?", "content_text": "Hey \ud83d\udc4b Want to build your own personal timeline algorithm? \u2b50\ufe0f -> https://github.com/mozilla-ai/byota \ud83d\udd25 Try the live demo mozilla-ai/byota \ud83e\uddd0 Read more about it https://huggingface.co/blog/mozilla-ai/build-your-own-timeline-algorithm See translation", "url": "https://huggingface.co/posts/stefan-french/995663487518303", "date_published": "2025-03-23T17:17:25.799620"}, {"id": "https://huggingface.co/posts/clem/968928866217294", "image": "", "title": "Should we assemble affordable open-source robots at Hugging Face for the community. Would you buy them? At what price?", "content_text": "Should we assemble affordable open-source robots at Hugging Face for the community. Would you buy them? At what price? See translation", "url": "https://huggingface.co/posts/clem/968928866217294", "date_published": "2025-03-23T17:17:25.799843"}, {"id": "https://huggingface.co/posts/eaddario/966662987888563", "image": "", "title": "Squeezing Tensor Bits: the quest for smaller LLMs", "content_text": "Squeezing Tensor Bits: the quest for smaller LLMs An area of personal interest is finding ways to optimize the inference performance of LLMs when deployed in resource-constrained environments like commodity hardware, desktops, laptops, mobiles, edge devices, etc. The method that I'm using to produce these experimental versions, for example eaddario/DeepSeek-R1-Distill-Llama-8B-GGUF is explained in https://medium.com/@eaddario/squeezing-tensor-bits-the-quest-for-smaller-llms-86b23bd052ca At a high level it involves using a custom version of the llama-quantize tool to selectively quantize different tensors at different levels. On average a 10% or more reduction with little loss of quality is possible. There\u2019re two PRs to merge these changes back into the core project but until then, the modified version will be available on GitHub https://github.com/EAddario/llama.cpp/tree/quantize Would love to hear if you can achieve smaller sizes at higher quality! See translation", "url": "https://huggingface.co/posts/eaddario/966662987888563", "date_published": "2025-03-23T17:17:25.800281"}, {"id": "https://huggingface.co/posts/csabakecskemeti/458514085783723", "image": "", "title": "Managed to get my hands on a 5090FE, it's beefy", "content_text": "Managed to get my hands on a 5090FE, it's beefy | llama 8B Q8_0 | 7.95 GiB | 8.03 B | CUDA | 99 | pp512 | 12207.44 \u00b1 481.67 | | llama 8B Q8_0 | 7.95 GiB | 8.03 B | CUDA | 99 | tg128 | 143.18 \u00b1 0.18 | Comparison with others GPUs http://devquasar.com/gpu-gguf-inference-comparison/ See translation", "url": "https://huggingface.co/posts/csabakecskemeti/458514085783723", "date_published": "2025-03-23T17:17:25.800556"}]}