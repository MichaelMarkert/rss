{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mlabonne/575026837446793", "image": "", "title": "Liquid just released two 450M and 1.6B param VLMs!", "content_text": "Liquid just released two 450M and 1.6B param VLMs! They're super fast and leverage SigLIP2 NaFlex encoders to handle native resolutions without distortion. It's ideal for on-device deployment in constrained environments like phones. It's available today on Hugging Face, with an inference and a fine-tuning Colab notebooks. LiquidAI/LFM2-VL-450M LiquidAI/LFM2-VL-1.6B See translation", "url": "https://huggingface.co/posts/mlabonne/575026837446793", "date_published": "2025-08-15T09:26:11.739396"}, {"id": "https://huggingface.co/posts/nroggendorff/812423234168314", "image": "", "title": "No, I did not create those bots that just got banned today.", "content_text": "No, I did not create those bots that just got banned today. See translation", "url": "https://huggingface.co/posts/nroggendorff/812423234168314", "date_published": "2025-08-15T09:26:11.739619"}, {"id": "https://huggingface.co/posts/ovi054/459497213356295", "image": "", "title": "Update on", "content_text": "Update on ovi054/Qwen-Image-LORA \u26a1 You can now load a Qwen LoRA in this space as follows: 1. Model ID: flymy-ai/qwen-image-realism-lora 2. Model link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora 3. Specific file link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /blob/m ain/flymy_realism.safetensors 4. Direct download link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /resolve/m ain/flymy_realism.safetensors You can also use an external .safetensors download link (if Hugging Face doesn\u2019t block it). It is useful if a model repository contains multiple weights and you want to load a specific one. \ud83d\udc49 Try it now: ovi054/Qwen-Image-LORA See translation", "url": "https://huggingface.co/posts/ovi054/459497213356295", "date_published": "2025-08-15T09:26:11.739990"}, {"id": "https://huggingface.co/posts/fdaudens/770107969696647", "image": "", "title": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:", "content_text": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines & specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup \u2014 just open-weight GPT-OSS models via Hugging Face If you\u2019ve been wanting to try agents but weren\u2019t sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation", "url": "https://huggingface.co/posts/fdaudens/770107969696647", "date_published": "2025-08-15T09:26:11.740318"}, {"id": "https://huggingface.co/posts/etemiz/710778843328598", "image": "", "title": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.", "content_text": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really \"free\": they are costing you your freedom if you know what i mean. See translation", "url": "https://huggingface.co/posts/etemiz/710778843328598", "date_published": "2025-08-15T09:26:11.740575"}, {"id": "https://huggingface.co/posts/prithivMLmods/730170022133992", "image": "", "title": "Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B & LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU!", "content_text": "Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B & LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU! \u2197 LFM2-VL-1.6B-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-1.6B-LiquidAI/LFM2-VL-1.6B_ReportLab.ipynb \u2197 LFM2-VL-450M-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-450M-LiquidAI/LFM2-VL-450M_ReportLab.ipynb . . . To know more about it, visit the multimodal outpost notebooks !! See translation", "url": "https://huggingface.co/posts/prithivMLmods/730170022133992", "date_published": "2025-08-15T09:26:11.740894"}, {"id": "https://huggingface.co/posts/mrs83/441245217845502", "image": "", "title": "Introducing the Computer Says No Dataset:", "content_text": "Introducing the Computer Says No Dataset: ethicalabs/computer-says-no An LLM can do almost anything, but should it? This dataset provides clear examples of when LLMs should decline requests, such as: - Counting characters (e.g., \"number of 'r's in 'raspberry'\" \u2013 seriously, you\u2019ve got this) - Solving basic equations (like *5.9 = x + 5.11* \u2013 please, show that calculator some love) Inspired by Little Britain's iconic \"Computer Says No\" sketch, we address a critical issue in AI systems today: the waste of using a rocket launcher to swat flies (aka powerful models for trivial tasks). Goals: - Reduce waste by saving compute for tasks that actually need it - Guide users to better tools - Spark discussion about ethical AI This isn\u2019t a training set. It\u2019s a provocation: if we don\u2019t define AI's limits, who will? See translation", "url": "https://huggingface.co/posts/mrs83/441245217845502", "date_published": "2025-08-15T09:26:11.741297"}, {"id": "https://huggingface.co/posts/hba123/107730379524841", "image": "", "title": "We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so:", "content_text": "We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so: Check it out: https://huggingface.co/blog/hba123/ark See translation", "url": "https://huggingface.co/posts/hba123/107730379524841", "date_published": "2025-08-15T09:26:11.741542"}, {"id": "https://huggingface.co/posts/kanaria007/811473012655185", "image": "", "title": "\u2705 New Article: *Media as Cognitive Infrastructure*", "content_text": "\u2705 New Article: *Media as Cognitive Infrastructure* Title: \ud83d\udcf0 Protocolic Media: Structured Intelligence and the Future of Cognitive Environments \ud83d\udd17 https://huggingface.co/blog/kanaria007/protocolic-media --- Summary: Media doesn\u2019t just *deliver content* \u2014 it *shapes how collective thought moves*. Every feed, stream, and algorithm is *a scaffold for attention and reasoning*, determining *what we notice, connect, and forget*. Structured Intelligence reframes media as *cognitive infrastructure*: not passive transmission, but *active architecture for collective reasoning*. > Media isn\u2019t flow \u2014 > *it\u2019s the frame of shared cognition.* --- Why It Matters: \u2022 Modern media amplifies *bias, noise, and cognitive drift* \u2022 Traditional moderation reacts *after harm occurs* \u2022 Structured approaches support: * *Traceable content flows with coherence checks* * *Ethical filtering without black\u2011box censorship* * *Reflective scaffolds that encourage deliberate reasoning* --- What\u2019s Inside: \u2022 Media reframed...", "url": "https://huggingface.co/posts/kanaria007/811473012655185", "date_published": "2025-08-15T09:26:11.742130"}, {"id": "https://huggingface.co/posts/ZennyKenny/202723059163333", "image": "", "title": "It's just a matter of time before all the data leakage and data scraping associated with building, training, and using AI results in some kind of major scandal.", "content_text": "It's just a matter of time before all the data leakage and data scraping associated with building, training, and using AI results in some kind of major scandal. That's why I think this paper by @ spintronic is so important: Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN (2508.06647) Glad to know that there are already researchers looking to mitigate and address this risk before the s**t hits the fan. See translation", "url": "https://huggingface.co/posts/ZennyKenny/202723059163333", "date_published": "2025-08-15T09:26:11.742387"}]}