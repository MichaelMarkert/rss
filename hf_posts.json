{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/bartowski/160920719239523", "image": "", "title": "Access requests enabled for latest GLM models", "content_text": "Access requests enabled for latest GLM models While a fix is being implemented ( https://github.com/ggml-org/llama.cpp/pull/12957 ) I want to leave the models up for visibility and continued discussion, but want to prevent accidental downloads of known broken models (even though there are settings that could fix it at runtime for now) With this goal, I've enabled access requests. I don't really want your data, so I'm sorry that I don't think there's a way around that? But that's what I'm gonna do for now, and I'll remove the gate when a fix is up and verified and I have a chance to re-convert and quantize! Hope you don't mind in the mean time :D See translation", "url": "https://huggingface.co/posts/bartowski/160920719239523", "date_published": "2025-04-17T05:22:20.507473"}, {"id": "https://huggingface.co/posts/openfree/305569626054328", "image": "", "title": "Agentic AI Era: Analyzing MCP vs MCO \ud83d\ude80", "content_text": "Agentic AI Era: Analyzing MCP vs MCO \ud83d\ude80 Hello everyone! With the rapid advancement of AI agent technology, two architectures have come into the spotlight: MCP (Model Context Protocol) and MCO (Model Context Open-json). Today, we\u2019ll introduce the key features and differences of these two approaches. VIDraft/Agentic-AI-CHAT MCP: The Traditional Approach \ud83c\udfdb\ufe0f Centralized Function Registry: All functions are hardcoded into the core system. Static Function Definitions & Tight Coupling: New features require changes to the core application code, limiting scalability. Monolithic Design: Complex deployment and version management can cause a single error to affect the whole system. Code Example: '''py FUNCTION_REGISTRY = { \"existing_function\": existing_function, \"new_function\": new_function # Adding a new function } ''' MCO: A Revolutionary Approach \ud83c\udd95 JSON-based Function Definitions: Function details are stored in external JSON files, enabling dynamic module loading. Loose Coupling &...", "url": "https://huggingface.co/posts/openfree/305569626054328", "date_published": "2025-04-17T05:22:20.508147"}, {"id": "https://huggingface.co/posts/hesamation/690372011092552", "image": "", "title": "this paper has been blowing up", "content_text": "this paper has been blowing up they train an open-source multimodal LLM (InternVL3) that can compete with GPT-4o and Claude 3.5 Sonnet by: > training text and vision on a single stage > a novel V2PE positional encoding > SFT & mixed preference optimization Paper: InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models (2504.10479) > test-time scaling See translation", "url": "https://huggingface.co/posts/hesamation/690372011092552", "date_published": "2025-04-17T05:22:20.508480"}, {"id": "https://huggingface.co/posts/Yehor/373485901957909", "image": "", "title": "Made a workable program that uses IREE runtime using Rust to inference wav2vec2-bert model for Automatic Speech Recognition.", "content_text": "Made a workable program that uses IREE runtime using Rust to inference wav2vec2-bert model for Automatic Speech Recognition. See translation", "url": "https://huggingface.co/posts/Yehor/373485901957909", "date_published": "2025-04-17T05:22:20.508793"}, {"id": "https://huggingface.co/posts/neph1/196685851091384", "image": "", "title": "I know Hunyuan Video is yesterday's jam, but in case you're looking for some cinematic LoRA's (and don't like civitai for some reason), I've uploaded my most popular ones to hf. They are:", "content_text": "I know Hunyuan Video is yesterday's jam, but in case you're looking for some cinematic LoRA's (and don't like civitai for some reason), I've uploaded my most popular ones to hf. They are: 1980s fantasy: neph1/1980s_Fantasy_Movies_Hunyuan_Video_Lora 1950s scifi: neph1/50s_scifi_hunyuan_video_lora 1920s horror: neph1/1920s_horror_hunyuan_video_lora See translation", "url": "https://huggingface.co/posts/neph1/196685851091384", "date_published": "2025-04-17T05:22:20.509057"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/356661920833488", "image": "", "title": "We\u2019re back\u2014with higher stakes, new datasets, and more chances to stand out. Duality AI's Synthetic-to-Real Object Detection Challenge 2 is LIVE!\ud83d\udea6", "content_text": "We\u2019re back\u2014with higher stakes, new datasets, and more chances to stand out. Duality AI's Synthetic-to-Real Object Detection Challenge 2 is LIVE!\ud83d\udea6 \u270d Sign up here: https://lnkd.in/g2avFP_X After the overwhelming response to Challenge 1, we're pushing the boundaries even further in Challenge 2, where your object detection models will be put to the test in the real world after training only on synthetic data. \ud83d\udc49 Join our Synthetic-to-Real Object Detection Challenge 2 on Kaggle! What\u2019s Different This Time? Unlike our first challenge, we\u2019re now diving deep into data manipulation. Competitors can: \ud83d\udd39Access 4 new supplemental datasets via FalconCloud with varying lighting, occlusions, and camera angles. \ud83d\udd39Generate your own synthetic datasets using FalconEditor to simulate edge cases. \ud83d\udd39Mix, match, and build custom training pipelines for maximum mAP@50 performance This challenge isn\u2019t just about using synthetic data\u2014it\u2019s about mastering how to craft the right synthetic data. Ready to test your...", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/356661920833488", "date_published": "2025-04-17T05:22:20.509657"}, {"id": "https://huggingface.co/posts/thomwolf/895902166332251", "image": "", "title": "If you've followed the progress of robotics in the past 18 months, you've likely noticed how robotics is increasingly becoming the next frontier that AI will unlock.", "content_text": "If you've followed the progress of robotics in the past 18 months, you've likely noticed how robotics is increasingly becoming the next frontier that AI will unlock. At Hugging Face\u2014in robotics and across all AI fields\u2014we believe in a future where AI and robots are open-source, transparent, and affordable; community-built and safe; hackable and fun. We've had so much mutual understanding and passion working with the Pollen Robotics team over the past year that we decided to join forces! You can already find our open-source humanoid robot platform Reachy 2 on the Pollen website and the Pollen community and people here on the hub at pollen-robotics We're so excited to build and share more open-source robots with the world in the coming months! See translation", "url": "https://huggingface.co/posts/thomwolf/895902166332251", "date_published": "2025-04-17T05:22:20.510053"}, {"id": "https://huggingface.co/posts/AdinaY/225696597302421", "image": "", "title": "\ud83d\udd25 New reasoning models from the Chinese community, by Skywork \u5929\u5de5-\u6606\u4ed1\u4e07\u7ef4", "content_text": "\ud83d\udd25 New reasoning models from the Chinese community, by Skywork \u5929\u5de5-\u6606\u4ed1\u4e07\u7ef4 Skywork/skywork-or1-67fa1bcb41b436ef2def76b9 \u2728Skywork OR1-Math-7B > Optimized for math reasoning \u2728Skywork-OR1-7B-preview > Excels in math & coding \u2728Skywork-OR1-32B-preview > Matches Deepseek-R1 on math (AIME24/25) and coding (LiveCodeBench) Released under the Apache 2.0 license \ud83e\udd73 Final version coming in 2 weeks! See translation", "url": "https://huggingface.co/posts/AdinaY/225696597302421", "date_published": "2025-04-17T05:22:20.510354"}, {"id": "https://huggingface.co/posts/gavinkhung/300399121852584", "image": "", "title": "Want to see machine learning algorithms training?", "content_text": "Want to see machine learning algorithms training? I made a website: https://gavinkhung.github.io/machine-learning-visualized/ The website implements, visualizes, and mathematically derives machine learning algorithms from first-principles. Feel free to contribute to this open-source resource: https://github.com/gavinkhung/machine-learning-visualized See translation", "url": "https://huggingface.co/posts/gavinkhung/300399121852584", "date_published": "2025-04-17T05:22:20.510602"}, {"id": "https://huggingface.co/posts/luigi12345/402431491640847", "image": "", "title": "BREAKING NEWS! \ud83d\ude80 OpenAI\u2019s GPT-4.1 API Models Are Here \u2013 Built for Developers", "content_text": "BREAKING NEWS! \ud83d\ude80 OpenAI\u2019s GPT-4.1 API Models Are Here \u2013 Built for Developers OpenAI has launched GPT-4.1, GPT-4.1 Mini, and GPT-4.1 Nano\u2014models engineered for real-world coding, instruction following, and long-context tasks. \ufffc \ud83d\udd27 Key Dev Features \u2022 Coding Performance: GPT-4.1 scores 54.6% on SWE-bench Verified, outperforming GPT-4o by 21.4% and GPT-4.5 by 26.6%. It handles diffs more precisely, reduces unnecessary edits, and adheres to formatting constraints. \ufffc \u2022 Long Context: All models support up to 1 million tokens\u20148x more than GPT-4o\u2014enabling full repo analysis and deep document comprehension. \ufffc \u2022 Instruction Following: Improved multi-step reasoning and formatting accuracy, with a 10.5% gain over GPT-4o on MultiChallenge. \ufffc \u2022 Latency & Cost: GPT-4.1 is 40% faster and 80% cheaper per query than GPT-4o. Mini and Nano versions offer even greater speed and affordability. \ufffc \ud83e\udde0 Model Lineup Model Context Window Use Case Cost per 1M Tokens GPT-4.1 1M tokens Production-grade coding &...", "url": "https://huggingface.co/posts/luigi12345/402431491640847", "date_published": "2025-04-17T05:22:20.511164"}]}