{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/cbensimon/565026286160860", "image": "", "title": "\ud83d\ude80 ZeroGPU now supports PyTorch native quantization via", "content_text": "\ud83d\ude80 ZeroGPU now supports PyTorch native quantization via torchao While it hasn\u2019t been battle-tested yet, Int8WeightOnlyConfig is already working flawlessly in our tests. Let us know if you run into any issues \u2014 and we\u2019re excited to see what the community will build! import spaces from diffusers import FluxPipeline from torchao.quantization.quant_api import Int8WeightOnlyConfig, quantize_ pipeline = FluxPipeline.from_pretrained(...).to( 'cuda' ) quantize_(pipeline.transformer, Int8WeightOnlyConfig()) # Or any other component(s) @spaces.GPU def generate ( prompt: str ): return pipeline(prompt).images[ 0 ] See translation", "url": "https://huggingface.co/posts/cbensimon/565026286160860", "date_published": "2025-06-13T09:26:07.963253"}, {"id": "https://huggingface.co/posts/openfree/428786122279500", "image": "", "title": "\ud83e\udd17 I'm leading 'Openfree AI', Korea's most prominent AI open-source community. First and foremost, I'd like to express my deepest gratitude for Hugging Face's continuous support and efforts. \ud83d\udc99", "content_text": "\ud83e\udd17 I'm leading 'Openfree AI', Korea's most prominent AI open-source community. First and foremost, I'd like to express my deepest gratitude for Hugging Face's continuous support and efforts. \ud83d\udc99 Our Openfree AI collaborates with various AI communities across Korea, contributing to knowledge sharing and ecosystem development. \ud83e\udd1d I've been actively promoting the critical importance of Hugging Face as Korea's AI infrastructure backbone, engaging with senior government officials, National Assembly members, university leaders, and media executives to emphasize how Hugging Face represents Korea's AI future at a national policy level. I consider myself a 'voluntary Korean ambassador for Hugging Face'. \ud83c\uddf0\ud83c\uddf7\u2728 Let me share our community's achievements on the Hugging Face platform over the past year: \ud83c\udfaf \ud83d\ude80 Published hundreds of models and spaces \ud83d\udc65 Surpassed 10 million cumulative visitors \ud83d\udcc8 Achieved 1.7 million Monthly Active Users (MAU) \ud83c\udfa8 Generated over 1 million images/videos per month These...", "url": "https://huggingface.co/posts/openfree/428786122279500", "date_published": "2025-06-13T09:26:07.963888"}, {"id": "https://huggingface.co/posts/csabakecskemeti/762115035937109", "image": "", "title": "Has anyone ever backed up a model to a sequential tape drive, or I'm the world first? :D", "content_text": "Has anyone ever backed up a model to a sequential tape drive, or I'm the world first? :D Just played around with my retro PC that has got a tape drive\u2014did it just because I can. See translation", "url": "https://huggingface.co/posts/csabakecskemeti/762115035937109", "date_published": "2025-06-13T09:26:07.964124"}, {"id": "https://huggingface.co/posts/jasoncorkill/871941197791232", "image": "", "title": "Imagine you could have an Image Arena score equivalent at each checkpoint during training. We released the first version of just that:", "content_text": "Imagine you could have an Image Arena score equivalent at each checkpoint during training. We released the first version of just that: Crowd-Eval Add one line of code to your training loop and you will have a new real human loss curve in your W&B dashboard. Thousands of real humans from around the world rating your model in real time at the cost of a few dollars per checkpoint is a game changer. Check it out here: https://github.com/RapidataAI/crowd-eval First 5 people to put it in their loop get 100'000 human responses for free! (ping me) See translation", "url": "https://huggingface.co/posts/jasoncorkill/871941197791232", "date_published": "2025-06-13T09:26:07.964427"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/462704497331407", "image": "", "title": "\ud83d\udde3\ufe0f \ud83d\udce2  New article alert!", "content_text": "\ud83d\udde3\ufe0f \ud83d\udce2 New article alert! \"Integrity Threats in AI: When Data Poisoning Undermines Model Effectiveness\" from Duality AI is now on HuggingFace here: https://huggingface.co/blog/DualityAI-RebekahBogdanoff/integrity-threats-in-ai Significant threats to AI model performance aren\u2019t always loud or obvious. Integrity violations\u2014like subtle data poisoning attacks\u2014can quietly erode your model\u2019s reliability, long before anyone notices. These attacks can be surprisingly effective with minimal changes to the dataset. At Duality, our work in high-stakes sectors like defense has driven us to tackle this threat head-on. In our latest blog from Duality's Director of Infrastructure and Security at Duality, David Strout, we unpack how data poisoning works, why it\u2019s so dangerous, and how organizations can secure their AI pipelines with clear provenance, regular performance auditing, and a trusted synthetic data supply chain. Whether you're building AI models for finance, healthcare, manufacturing, or...", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/462704497331407", "date_published": "2025-06-13T09:26:07.964907"}, {"id": "https://huggingface.co/posts/a-r-r-o-w/231008365980283", "image": "", "title": "Recently, I've been focusing my learning on the following topics:", "content_text": "Recently, I've been focusing my learning on the following topics: - Pytorch internals, specifically the inductor system (roughly ~1 month of experience) - Triton internals (~8 moe) - CUDA (~3 moe) - Understanding fusion patterns in compilers and how to improve them (~1 moe) - Parallelism strategies for large scale inference optimization (~6-7 moe) I thought it would be nice to document it somewhere for no particular reason. Maybe someone will find it useful? It's also because I want to get into the habit of writing, but had no motivation to do so. Maybe writing short informal posts will help build the habit. Since I don't have a personal site, and don't plan to create one in the near future, I think HF posts are best suited for short and informal documentation to share my little discoveries and learnings. If you're interested, strap in! First post in this series will be on basic study of Pytorch's float32 matmuls and their Triton implementation (nothing much, just the tutorial...", "url": "https://huggingface.co/posts/a-r-r-o-w/231008365980283", "date_published": "2025-06-13T09:26:07.965275"}, {"id": "https://huggingface.co/posts/danielhanchen/426556210957370", "image": "", "title": "Mistral releases Magistral, their new reasoning models! \ud83d\udd25", "content_text": "Mistral releases Magistral, their new reasoning models! \ud83d\udd25 GGUFs to run: unsloth/Magistral-Small-2506-GGUF Magistral-Small-2506 excels at mathematics and coding. You can run the 24B model locally with just 32GB RAM by using our Dynamic GGUFs. See translation", "url": "https://huggingface.co/posts/danielhanchen/426556210957370", "date_published": "2025-06-13T09:26:07.965537"}, {"id": "https://huggingface.co/posts/hesamation/842061188959684", "image": "", "title": "this repo is gold! a collection of LLM apps with multi-agents, MCP, RAG and so much more.", "content_text": "this repo is gold! a collection of LLM apps with multi-agents, MCP, RAG and so much more. the best way to learn is by building, and this repo provides the blueprint. Repo: https://github.com/Shubhamsaboo/awesome-llm-apps See translation", "url": "https://huggingface.co/posts/hesamation/842061188959684", "date_published": "2025-06-13T09:26:07.965759"}, {"id": "https://huggingface.co/posts/burtenshaw/642764546410723", "image": "", "title": "Super excited to release Autotrain MCP. This is an MCP server for training AI models, so you can use your AI tools to train your AI models \ud83e\udd2f.", "content_text": "Super excited to release Autotrain MCP. This is an MCP server for training AI models, so you can use your AI tools to train your AI models \ud83e\udd2f. \ud83d\udd17 burtenshaw/autotrain-mcp Use this MCP server with tools like Claude Desktop, Cursor, VSCode, or Continue to do this: - Define an ML problem like Image Classification, LLM fine-tuning, Text Classification, etc. - The AI can retrieve models and datasets from the hub using the hub MCP. - Training happens on a Hugging Face space, so no worries about hardware restraints. - Models are pushed to the hub to be used inference tools like Llama.cpp, vLLM, MLX, etc. - Built on top of the AutoTrain library, so it has full integration with transformers and other libraries. Everything is still under active development, but I\u2019m super excited to hear what people build, and I\u2019m open to contributions! See translation", "url": "https://huggingface.co/posts/burtenshaw/642764546410723", "date_published": "2025-06-13T09:26:07.966159"}, {"id": "https://huggingface.co/posts/Narsil/207015264611430", "image": "", "title": "Me: This function is too slow. Find a faster algorithm.", "content_text": "Me: This function is too slow. Find a faster algorithm. Cursor: Hold my beer. Me: *Slacking off with colleagues* Cursor: Ping. Me: \ud83e\udd2f See translation", "url": "https://huggingface.co/posts/Narsil/207015264611430", "date_published": "2025-06-13T09:26:07.966388"}]}