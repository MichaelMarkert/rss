{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/721764114758575", "image": "", "title": "\ud83d\ude80 AI Blog Generator with Streamlit: The Ultimate Guide!", "content_text": "\ud83d\ude80 AI Blog Generator with Streamlit: The Ultimate Guide! ginigen/blogger Hello there! Today I'm excited to introduce you to a powerful AI blog creation tool called Ginigen Blog. This amazing app automatically generates high-quality blog content using Streamlit and the latest ChatGPT 4.1 API. And the best part? It's completely free to use! \ud83d\udc69\u200d\ud83d\udcbb\u2728 \ud83e\udde0 What Makes Ginigen Blog Special Ginigen Blog is not just a simple text generator! It offers these exceptional features: Multiple Blog Templates: SEO-optimized, tutorials, reviews, and more Web Search Integration: Creates accurate content based on the latest information File Upload Analysis: Automatically analyzes TXT, CSV, and PDF files to incorporate into blogs Automatic Image Generation: Creates images that match your blog topic Various Output Formats: Download in Markdown, HTML, and more Latest GPT-4.1 Model: Cutting-edge AI technology for higher quality blog creation Completely Free Service: Access high-quality content generation without...", "url": "https://huggingface.co/posts/ginipick/721764114758575", "date_published": "2025-04-24T13:32:59.426699"}, {"id": "https://huggingface.co/posts/clem/295367997414146", "image": "", "title": "Energy is a massive constraint for AI but do you even know what energy your chatGPT convos are using?", "content_text": "Energy is a massive constraint for AI but do you even know what energy your chatGPT convos are using? We're trying to change this by releasing ChatUI-energy, the first interface where you see in real-time what energy your AI conversations consume. Great work from @ jdelavande powered by spaces & TGI, available for a dozen of open-source models like Llama, Mistral, Qwen, Gemma and more. jdelavande/chat-ui-energy Should all chat interfaces have this? Just like ingredients have to be shown on products you buy, we need more transparency in AI for users! See translation", "url": "https://huggingface.co/posts/clem/295367997414146", "date_published": "2025-04-24T13:32:59.427038"}, {"id": "https://huggingface.co/posts/luigi12345/382493254979768", "image": "", "title": "SkyReels-V2 INFINITE VIDEO\ud83d\udd25\u267e\ufe0f\ud83c\udfac UNLIMITED duration video generation model  by Skywork.", "content_text": "SkyReels-V2 INFINITE VIDEO\ud83d\udd25\u267e\ufe0f\ud83c\udfac UNLIMITED duration video generation model by Skywork. > \u201cFinally is here. An Open-Source model that achieves what we all have waiting for: Infinite Length Videos.\u2019\u2019\ud83d\ude2e Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought (2504.05599) Model: Skywork/SkyReels-V2-T2V-14B-720P \u2728 1.3B & 14B \u2728 Generates infinite length videos using Diffusion Forcing with diffusion models + autoregressive methods See translation", "url": "https://huggingface.co/posts/luigi12345/382493254979768", "date_published": "2025-04-24T13:32:59.427370"}, {"id": "https://huggingface.co/posts/hannayukhymenko/367157502110648", "image": "", "title": "\ud83d\ude80 We are delighted to announce MamayLM, a new state-of-the-art efficient Ukrainian LLM!", "content_text": "\ud83d\ude80 We are delighted to announce MamayLM, a new state-of-the-art efficient Ukrainian LLM! \ud83d\udcc8 MamayLM surpasses similar-sized models in both English and Ukrainian, while matching or overtaking up to 10x larger models. \ud83d\udcca MamayLM is a 9B model that can run on a single GPU, enabling cost-efficient AI autonomy and adoption across sectors in Ukraine such as education, legal, healthcare, public services and others (e.g., by specializing it to particular use cases). MalayLM is also attractive for organizations wishing to preserve data privacy as it s efficiency allows it to run on a local machine. \ud83e\udde0 MamayLM is trained on high-quality Ukrainian data and understands Ukrainian language, culture, and history. It is built on top of Google\u2019s Gemma 2 9B model, but uses a number of new advances stemming from INSAIT\u2019s experience in creating BgGPT, a Bulgarian LLM we released last year, now adopted nationwide and profiled several times by Google as a worldwide success case. \ud83e\udd1d MamayLM is developed in a...", "url": "https://huggingface.co/posts/hannayukhymenko/367157502110648", "date_published": "2025-04-24T13:32:59.427991"}, {"id": "https://huggingface.co/posts/AdinaY/770723049329200", "image": "", "title": "MAGI-1 \ud83e\ude84 the autoregressive diffusion video model, released by Sand AI", "content_text": "MAGI-1 \ud83e\ude84 the autoregressive diffusion video model, released by Sand AI sand-ai/MAGI-1 \u2728 24B with Apache 2.0 \u2728 Strong temporal consistency \u2728 Benchmark-topping performance See translation", "url": "https://huggingface.co/posts/AdinaY/770723049329200", "date_published": "2025-04-24T13:32:59.428240"}, {"id": "https://huggingface.co/posts/merve/338904780470677", "image": "", "title": "New foundation model on image and video captioning just dropped by NVIDIA AI \ud83d\udd25", "content_text": "New foundation model on image and video captioning just dropped by NVIDIA AI \ud83d\udd25 Describe Anything Model (DAM) is a 3B vision language model to generate detailed captions with localized references \ud83d\ude2e The team released the models, the dataset, a new benchmark and a demo \ud83e\udd29 nvidia/describe-anything-680825bb8f5e41ff0785834c Most of the vision LMs focus on image as a whole, lacking localized references in captions, and not taking in visual prompts (points, boxes, drawings around objects) DAM addresses this on two levels: new vision backbone that takes in focal crops and the image itself, and a large scale dataset \ud83d\udc40 They generate a dataset by extending existing segmentation and referring expression generation datasets like REFCOCO, by passing in the images and classes to VLMs and generating captions. Lastly, they also release a new benchmark again with self-supervision, they use an LLM to evaluate the detailed captions focusing on localization \ud83d\udc4f See translation", "url": "https://huggingface.co/posts/merve/338904780470677", "date_published": "2025-04-24T13:32:59.428695"}, {"id": "https://huggingface.co/posts/Jaward/857345172218118", "image": "", "title": "New reasoning algo just dropped: Adaptive Parallel Reasoning", "content_text": "New reasoning algo just dropped: Adaptive Parallel Reasoning \u201cwe propose Adaptive Parallel Reasoning (APR), a novel reasoning framework that enables language models to orchestrate both serialized and parallel computations end-to-end. APR generalizes existing reasoning methods by enabling adaptive multi-threaded inference using spawn() and join() operations.\u201d Paper: https://arxiv.org/pdf/2504.15466 Code: https://github.com/Parallel-Reasoning/APR See translation", "url": "https://huggingface.co/posts/Jaward/857345172218118", "date_published": "2025-04-24T13:32:59.428997"}, {"id": "https://huggingface.co/posts/clem/713065682470379", "image": "", "title": "Just crossed half a million public apps on Hugging Face. A new public app is created every minute these days \ud83e\udd2f\ud83e\udd2f\ud83e\udd2f", "content_text": "Just crossed half a million public apps on Hugging Face. A new public app is created every minute these days \ud83e\udd2f\ud83e\udd2f\ud83e\udd2f What's your favorite? http://hf.co/spaces See translation", "url": "https://huggingface.co/posts/clem/713065682470379", "date_published": "2025-04-24T13:32:59.429240"}, {"id": "https://huggingface.co/posts/linoyts/495650054643276", "image": "", "title": "We just shipped HiDream Image LoRA fine-tuning to diffusers\ud83e\udde8", "content_text": "We just shipped HiDream Image LoRA fine-tuning to diffusers\ud83e\udde8 HiDream's sota capabilities (and mit license) bring a lot of potential to explore with fine-tunes \ud83d\udd25 - more upgrades and features soon! - code, weights and config example \ud83d\udc47 \ud83e\uddf6Yarn art lora: linoyts/HiDream-yarn-art-LoRA code: https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README_hidream.md See translation", "url": "https://huggingface.co/posts/linoyts/495650054643276", "date_published": "2025-04-24T13:32:59.429549"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/129160122230232", "image": "", "title": "30 seconds hard test on FramePack - [0] a man talking , [5] a man crying , [10] a man smiling , [15] a man frowning , [20] a man sleepy , [25] a man going crazy - i think result is excellent when we consider how hard this test is - Generated with SECourses FramePack App V40", "content_text": "30 seconds hard test on FramePack - [0] a man talking , [5] a man crying , [10] a man smiling , [15] a man frowning , [20] a man sleepy , [25] a man going crazy - i think result is excellent when we consider how hard this test is - Generated with SECourses FramePack App V40 App link and 1-click installers for Windows, RunPod and Massed Compute here : https://www.patreon.com/posts/126855226 I got the prompt using idea from this pull request : https://github.com/lllyasviel/FramePack/pull/218/files Not exactly same implementation but i think pretty accurate when considering that it is a 30 second 30 fps video at 840p resolution See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/129160122230232", "date_published": "2025-04-24T13:32:59.429862"}]}