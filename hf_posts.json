{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/prithivMLmods/223082724733311", "image": "", "title": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea", "content_text": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea \u25cf Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC \u25cf Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \u25cf Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo \u25cf Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- \u25cf FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 \u25cf FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC \u25cf Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC \u25cf Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast \u25cf Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...", "url": "https://huggingface.co/posts/prithivMLmods/223082724733311", "date_published": "2025-12-18T09:32:09.423086"}, {"id": "https://huggingface.co/posts/danielhanchen/963278821580490", "image": "", "title": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25", "content_text": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25 Has 1M context window & best in class performance for SWE-Bench, reasoning & chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF \ud83d\udc9a Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation", "url": "https://huggingface.co/posts/danielhanchen/963278821580490", "date_published": "2025-12-18T09:32:09.423402"}, {"id": "https://huggingface.co/posts/Reubencf/239576255947718", "image": "", "title": "Great News !", "content_text": "Great News ! Reubencf/Nano_Banana_Editor Now supports black-forest-labs/FLUX.1-Kontext-dev and Qwen/Qwen-Image-Edit-2509 Just log in with Huggingface and try it out See translation", "url": "https://huggingface.co/posts/Reubencf/239576255947718", "date_published": "2025-12-18T09:32:09.423636"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/439099944779481", "image": "", "title": "New Preview Model:", "content_text": "New Preview Model: unmodeled-tyler/vanta-research-loux-preview VANTA Research is excited to announce a small lab preview of our new 675B fine tune, Loux-Large. Loux is an AI model with a sophisticated, rebellious edge designed to assist and collaborate with engineers, builders, and people working on technical projects. If you enjoy working with Loux and would like full access, let us know by liking the space or opening a discussion in the community! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/439099944779481", "date_published": "2025-12-18T09:32:09.423922"}, {"id": "https://huggingface.co/posts/YatharthS/190514854652270", "image": "", "title": "\ud83e\udd2f \ud83e\udd2f Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! \ud83e\udd2f \ud83e\udd2f", "content_text": "\ud83e\udd2f \ud83e\udd2f Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! \ud83e\udd2f \ud83e\udd2f Github link: https://github.com/ysharma3501/MiraTTS Model link: https://github.com/ysharma3501/MiraTTS Blog explaining llm tts models: https://huggingface.co/blog/YatharthS/llm-tts-models See translation", "url": "https://huggingface.co/posts/YatharthS/190514854652270", "date_published": "2025-12-18T09:32:09.424193"}, {"id": "https://huggingface.co/posts/AdinaY/236108821864145", "image": "", "title": "Finch \ud83d\udcb0 an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance & accounting work.", "content_text": "Finch \ud83d\udcb0 an enterprise-grade benchmark that measures whether AI agents can truly handle real world finance & accounting work. FinWorkBench/Finch \u2728 Built from real enterprise data (Enron + financial institutions), not synthetic tasks \u2728 Tests end-to-end finance workflows \u2728 Multimodal & cross-file reasoning \u2728 Expert annotated (700+ hours) and genuinely challenging hard See translation", "url": "https://huggingface.co/posts/AdinaY/236108821864145", "date_published": "2025-12-18T09:32:09.424471"}, {"id": "https://huggingface.co/posts/ronantakizawa/412513789590360", "image": "", "title": "Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on.", "content_text": "Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on. #github #developers ronantakizawa/github-top-developers See translation", "url": "https://huggingface.co/posts/ronantakizawa/412513789590360", "date_published": "2025-12-18T09:32:09.424695"}, {"id": "https://huggingface.co/posts/davidberenstein1957/505419805971375", "image": "", "title": "\ud83d\udea8 Phare LLM benchmark V2: Reasoning models don't guarantee better security", "content_text": "\ud83d\udea8 Phare LLM benchmark V2: Reasoning models don't guarantee better security Read the full blog here: https://huggingface.co/blog/davidberenstein1957/phare-llm-benchmark-v2 See translation", "url": "https://huggingface.co/posts/davidberenstein1957/505419805971375", "date_published": "2025-12-18T09:32:09.424911"}, {"id": "https://huggingface.co/posts/DawnC/393405474084583", "image": "", "title": "Intelligent Inpainting for Precise Creative Control \ud83c\udfa8\u2728", "content_text": "Intelligent Inpainting for Precise Creative Control \ud83c\udfa8\u2728 Transform your images with AI-powered precision! SceneWeaver delivers professional-quality image composition with intelligent background replacement and advanced object manipulation. What's New in This Update? \ud83d\udd8c\ufe0f Object Replacement \u2014 Select and transform any element in your scene with natural language prompts while maintaining perfect visual consistency with surrounding content \ud83d\uddd1\ufe0f Object Removal \u2014 Intelligently remove unwanted objects with context-aware generation that preserves natural lighting, shadows, and scene coherence \ud83c\udfaf Context-Aware Processing \u2014 Advanced inpainting technology ensures seamless integration across all regenerated regions Core Capabilities \u26a1 One-click transformation with smart subject detection, 24 curated professional backgrounds, custom scene generation through text prompts, and studio-quality results powered by BiRefNet, Stable Diffusion XL, and ControlNet Inpainting. Current Infrastructure & Future...", "url": "https://huggingface.co/posts/DawnC/393405474084583", "date_published": "2025-12-18T09:32:09.425498"}, {"id": "https://huggingface.co/posts/nicolay-r/350400879019559", "image": "", "title": "\ud83d\udce2 For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios.", "content_text": "\ud83d\udce2 For those who interested in applying LLM for inferring iterators of data with CoT / prompts, this update might be relevant. Deligted to share the new release of the bulk-chain. This is a framework that contributes to efficient AI querying in synthetic data generation scenarios. \ud83c\udf1f bulk-chain: https://github.com/nicolay-r/bulk-chain \ud83d\udd11 This features the no-string framework for quierrying LLMs in various modes: sync, async and with optional support for output streaming. \ud83d\udce6\ufe0f In the latest 1.2.0 release, the updates on outlining API parameters for inference mode. \ud83c\udf1f Integration into web: https://github.com/nicolay-r/bulk-chain-web-integration See translation", "url": "https://huggingface.co/posts/nicolay-r/350400879019559", "date_published": "2025-12-18T09:32:09.425840"}]}