{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/prithivMLmods/844227545389355", "image": "", "title": "The demo of Qwen3-VL-30B-A3B-Instruct, the next-generation and powerful vision-language model in the Qwen series, delivers comprehensive upgrades across the board \u2014 including superior text understanding and generation, deeper visual perception and reasoning, extended context length, enhanced spatial and video dynamics comprehension, and stronger agent interaction capabilities. \ud83e\udd17\ud83d\udd25", "content_text": "The demo of Qwen3-VL-30B-A3B-Instruct, the next-generation and powerful vision-language model in the Qwen series, delivers comprehensive upgrades across the board \u2014 including superior text understanding and generation, deeper visual perception and reasoning, extended context length, enhanced spatial and video dynamics comprehension, and stronger agent interaction capabilities. \ud83e\udd17\ud83d\udd25 \u26a1 Space / App: prithivMLmods/Qwen3-VL-HF-Demo The model\u2019s demo supports a wide range of tasks, including; Image Inference, Video Inference, PDF Inference, Image Captioning (VLA), GIF Inference. \u26a1 Collection: prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 Thanks for granting the blazing-fast Zero GPU access, @ merve \ud83d\ude4f \u26a1 Other Pages > Github: https://github.com/prithivsakthiur/qwen3-vl-hf-demo > Multimodal VLMs July'25 : prithivMLmods/multimodal-vlms-until-july25-688312e6b840e1e156f13027 > VL caption \u2014 < Sep 15 \u201925 : prithivMLmods/vl-caption-sep-15-25-68c7f6d737985c63c13e2391 > Multimodal...", "url": "https://huggingface.co/posts/prithivMLmods/844227545389355", "date_published": "2025-10-13T13:33:21.608888"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/350754844731753", "image": "", "title": "Ovi is Local Version of VEO 3 & SORA 2 - The first-ever public, open-source model that generates both VIDEO and synchronized AUDIO, and you can run it on your own computer on Windows even with a 6GB GPUs - Full Tutorial for Windows, RunPod and Massed Compute - Gradio App >", "content_text": "Ovi is Local Version of VEO 3 & SORA 2 - The first-ever public, open-source model that generates both VIDEO and synchronized AUDIO, and you can run it on your own computer on Windows even with a 6GB GPUs - Full Tutorial for Windows, RunPod and Massed Compute - Gradio App > https://youtu.be/T00VmkMQRPQ Tutorial : https://youtu.be/T00VmkMQRPQ Forget waiting lists and expensive APIs. The era of closed-off, corporate-controlled AI video generation is soon over. This is Ovi : The first-ever public, open-source model that generates both VIDEO and synchronized AUDIO, and you can run it on your own computer\u2014even with a 6GB GPU! This isn't just a demo; it's a full, step-by-step revolution. Tutorial Info In this ultimate A-Z guide, I'll show you EVERYTHING you need to know to install and master this Sora 2 and VEO3 like AI. We'll go from zero to generating incredible talking videos from text or a single image. \ud83d\udd25 In This Tutorial, You Will Learn To: \ud83c\udf93 Master the Ultimate SORA 2 and VEO 3...", "url": "https://huggingface.co/posts/MonsterMMORPG/350754844731753", "date_published": "2025-10-13T13:33:21.609490"}, {"id": "https://huggingface.co/posts/sondhiArm/422203128655094", "image": "", "title": "Arm will be @ PyTorch Conference, Join Us!", "content_text": "Arm will be @ PyTorch Conference, Join Us! Join us on site October 22-23 to see how Arm empowers developers to build and deploy AI applications with ease using PyTorch and ExecuTorch. Learn about the latest AI technologies from Arm and our ecosystem while expanding your professional network alongside like-minded AI engineers. Learn more here: https://huggingface.co/blog/Arm/arm-at-pytorch-conference See translation", "url": "https://huggingface.co/posts/sondhiArm/422203128655094", "date_published": "2025-10-13T13:33:21.609764"}, {"id": "https://huggingface.co/posts/Kseniase/543365627154110", "image": "", "title": "9 Powerful AI Video Generation Tools", "content_text": "9 Powerful AI Video Generation Tools Since Sora 2 is on fire these weeks, reminding us what high-quality video generation should look like, we decided you really need this list of video generation tools \u2013 great alternatives or complements to it. 1. Sora 2 \u2192 https://openai.com/sora/ It needs no introduction, but this OpenAI\u2019s text-to-video model produces short, ultra-realistic clips across styles (cinematic, photorealistic, animated, etc.) with synced audio 2. Google Veo 3 (Gemini Video Generation) \u2192 https://aistudio.google.com/models/veo-3 Part of Gemini AI. Generates 8-second high-fidelity videos from text or images with native sound: background soundtracks and realistic voices with near-perfect lip sync 3. Runway (Gen-4 by Runway ML) \u2192 https://runwayml.com/ Text, image, or video-to-video generation with advanced editing like changing lighting, weather, camera angles or replacing objects. Popular in AI filmmaking 4. Pika Labs \u2192 https://pollo.ai/m/pika-ai Provides creative, often...", "url": "https://huggingface.co/posts/Kseniase/543365627154110", "date_published": "2025-10-13T13:33:21.610305"}, {"id": "https://huggingface.co/posts/YerbaPage/639392890035292", "image": "", "title": "How to compress long code context? \ud83d\udcda", "content_text": "How to compress long code context? \ud83d\udcda Check out our LongCodeZip! Paper just got accepted to ASE 2025. \ud83d\udd25 Code & Demo: https://github.com/YerbaPage/LongCodeZip Paper: LongCodeZip: Compress Long Context for Code Language Models (2510.00446) See translation", "url": "https://huggingface.co/posts/YerbaPage/639392890035292", "date_published": "2025-10-13T13:33:21.610542"}, {"id": "https://huggingface.co/posts/Ethank01/902315574816069", "image": "", "title": "\ud83d\ude80 No invite. No watermark. Just pure AI magic.", "content_text": "\ud83d\ude80 No invite. No watermark. Just pure AI magic. Experience Sora 2 on iMini \u2014 free for members \ud83d\udc49 https://imini.com/ See translation", "url": "https://huggingface.co/posts/Ethank01/902315574816069", "date_published": "2025-10-13T13:33:21.610762"}, {"id": "https://huggingface.co/posts/vincentg64/231735241059410", "image": "", "title": "Benchmarking xLLM and Specialized Language Models: New Approach & Results", "content_text": "Benchmarking xLLM and Specialized Language Models: New Approach & Results https://mltblog.com/4nzaKUb Standard benchmarking techniques using LLM as a judge have strong limitations. First it creates a circular loop and reflects the flaws present in the AI judges. Then, the perceived quality depends on the end user: an enterprise LLM appeals to professionals and business people, while a generic one appeals to laymen. The two have almost opposite criteria to assess the value. Finally, benchmarking metrics currently in use fail to capture many of the unique features of specialized LLMs, such as exhaustivity, or the quality of the relevancy and trustworthiness scores attached to each element in the response. In fact, besides xLLM, very few if any LLMs display such scores to the user. I now discuss these points, as well as the choice of test prompts, and preliminary results about xLLM, compared to others. -- Structured output vs standard response -- A peculiarity of xLLM is that if offers...", "url": "https://huggingface.co/posts/vincentg64/231735241059410", "date_published": "2025-10-13T13:33:21.611371"}, {"id": "https://huggingface.co/posts/m-ric/175050207181959", "image": "", "title": "STOP EVERYTHING NOW - we might finally have a radical architecture improvement over Transformers!!! \ud83d\udea8", "content_text": "STOP EVERYTHING NOW - we might finally have a radical architecture improvement over Transformers!!! \ud83d\udea8 A lone scientist just proposed Tiny Recursive Model (TRM), and it is literally the most impressive model that I've seen this year. \u27a1\ufe0f Tiny Recursive Model is 7M parameters \u27a1\ufe0f On ARC-AGI, it beats flagship models like Gemini-2.5-pro Consider how wild this is: Gemini-2.5-pro must be over 10,000x bigger and had 1,000 as many authors \ud83d\ude02 (Alexia is alone on the paper) What's this sorcery? In short: it's a very tiny Transformers, but it loops over itself at two different frequencies, updating two latent variables: one for the proposed answer and one for the reasoning. @ AlexiaJM started from the paper Hierarchical Reasoning Model, published a few months ago, that already showed breakthrough improvement on AGI for its small size (27M) Hierarchical Reasoning Model had introduced one main feature: \ud83d\udd0e Deep supervision In their model, one part (here one layer) would run at high frequency, and...", "url": "https://huggingface.co/posts/m-ric/175050207181959", "date_published": "2025-10-13T13:33:21.612014"}, {"id": "https://huggingface.co/posts/404Zen/731905286538257", "image": "", "title": "4 must-try AI video models in 2026 \u2014 all in one place on iMini! \ud83c\udfac\u2728", "content_text": "4 must-try AI video models in 2026 \u2014 all in one place on iMini! \ud83c\udfac\u2728 Featuring Sora 2, Veo 3, Wan 2.5, and Seedance 3.0 \u2014 no invite code, no watermark! Try it now \ud83d\udc49 https://imini.com/ See translation", "url": "https://huggingface.co/posts/404Zen/731905286538257", "date_published": "2025-10-13T13:33:21.612246"}, {"id": "https://huggingface.co/posts/Monica997/870861781065582", "image": "", "title": "You think those playful puppies are real? \ud83d\udc36\u2728", "content_text": "You think those playful puppies are real? \ud83d\udc36\u2728 Nope! It\u2019s a video I created using iMini\u2019s newly integrated Sora 2 model \u2014 no invite code, no watermark, just one simple text prompt to generate dynamic videos in seconds! \ud83c\udfac Limited-time offer: members can create without using credits! \ud83d\udc49 Try it now: https://imini.com/ See translation", "url": "https://huggingface.co/posts/Monica997/870861781065582", "date_published": "2025-10-13T13:33:21.612498"}]}