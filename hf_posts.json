{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/917789522887291", "image": "", "title": "\ud83d\udd2e Mistral Perflexity AI - Local LLM Space with Web Search Capabilities \ud83c\udf10", "content_text": "\ud83d\udd2e Mistral Perflexity AI - Local LLM Space with Web Search Capabilities \ud83c\udf10 Hello AI enthusiasts! Today I'm excited to introduce my special Hugging Face space! \ud83d\ude80 ginigen/Mistral-Perflexity \u2728 Key Features Powerful Model: Using Private-BitSix-Mistral-Small-3.1-24B-Instruct-2503, optimized through 6-bit quantization to run smoothly on local 4090 GPUs! \ud83d\udcaa Web Search Integration: Leveraging the Brave Search API to provide real-time web search results for user queries! \ud83d\udd0d Customizable Responses: Shape AI personality and response format through system messages \u2699\ufe0f Multilingual Support: Perfect handling of both English and Korean! \ud83c\uddfa\ud83c\uddf8\ud83c\uddf0\ud83c\uddf7 \ud83d\udee0\ufe0f Technical Highlights GGUF Format: Optimized quantized model with excellent memory efficiency Flash Attention: Applied optimization technology for faster inference speeds 8K Context Window: Capable of handling lengthy conversations and complex queries Streaming Responses: Watch text being generated in real-time \ud83d\udca1 Use Cases Complex Q&A requiring real-time...", "url": "https://huggingface.co/posts/ginipick/917789522887291", "date_published": "2025-05-04T05:22:04.200950"}, {"id": "https://huggingface.co/posts/fdaudens/694548457778636", "image": "", "title": "Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me!", "content_text": "Forget everything you know about transcription models - NVIDIA's parakeet-tdt-0.6b-v2 changed the game for me! Just tested it with Steve Jobs' Stanford speech and was speechless (pun intended). The video isn\u2019t sped up. 3 things that floored me: - Transcription took just 10 seconds for a 15-min file - Got a CSV with perfect timestamps, punctuation & capitalization - Stunning accuracy (correctly captured \"Reed College\" and other specifics) NVIDIA also released a demo where you can click any transcribed segment to play it instantly. The improvement is significant: number 1 on the ASR Leaderboard, 6% error rate (best in class) with complete commercial freedom (cc-by-4.0 license). Time to update those Whisper pipelines! H/t @ Steveeeeeeen for the finding! Model: nvidia/parakeet-tdt-0.6b-v2 Demo: nvidia/parakeet-tdt-0.6b-v2 ASR Leaderboard: hf-audio/open_asr_leaderboard See translation", "url": "https://huggingface.co/posts/fdaudens/694548457778636", "date_published": "2025-05-04T05:22:04.201369"}, {"id": "https://huggingface.co/posts/abidlabs/810486848644944", "image": "", "title": "HOW TO ADD MCP SUPPORT TO ANY \ud83e\udd17 SPACE", "content_text": "HOW TO ADD MCP SUPPORT TO ANY \ud83e\udd17 SPACE Gradio now supports MCP! If you want to convert an existing Space, like this one hexgrad/Kokoro-TTS , so that you can use it with Claude Desktop / Cursor / Cline / TinyAgents / or any LLM that supports MCP, here's all you need to do: 1. Duplicate the Space (in the Settings Tab) 2. Upgrade the Gradio sdk_version to 5.28 (in the README.md ) 3. Set mcp_server=True in launch() 4. (Optionally) add docstrings to the function so that the LLM knows how to use it, like this: def generate ( text, speed= 1 ): \"\"\" Convert text to speech audio. Parameters: text (str): The input text to be converted to speech. speed (float, optional): Playback speed of the generated speech. That's it! Now your LLM will be able to talk to you \ud83e\udd2f See translation", "url": "https://huggingface.co/posts/abidlabs/810486848644944", "date_published": "2025-05-04T05:22:04.201783"}, {"id": "https://huggingface.co/posts/ginipick/692850049335646", "image": "", "title": "\ud83c\udfa8 Renoir Studio: Impressionist Masterpieces Reborn Through AI \u2728", "content_text": "\ud83c\udfa8 Renoir Studio: Impressionist Masterpieces Reborn Through AI \u2728 \ud83c\udf1f Experience Renoir's Magical Brushstrokes with AI! \ud83d\udd17 Try it now: ginigen/flux-lora-renoir \ud83d\udd17 Model page: openfree/pierre-auguste-renoir \ud83d\udd17 Collection: openfree/painting-art-ai-681453484ec15ef5978bbeb1 Hello, AI art enthusiasts! \ud83d\udc96 Today I'm introducing a special model - Pierre-Auguste Renoir Studio. Create your own beautiful artwork in the style of the 19th century French Impressionist master! \ud83d\uddbc\ufe0f \u2728 Why Renoir's Style? Renoir is famous for his luminous colors and soft brushstrokes. His works feature: \ud83c\udf1e Warm sunshine and dancing light \ud83d\udc68\u200d\ud83d\udc69\u200d\ud83d\udc67\u200d\ud83d\udc66 The beauty of everyday life and joyful moments \ud83c\udf38 Vibrant nature and portraits of beautiful women \ud83c\udfad Lively Parisian social gatherings and outdoor scenes \ud83d\udd2c Technical Features This model was developed as a flux-based learning model trained on a curated collection of high-resolution masterpieces from renowned global artists. The LoRA fine-tuning process leveraged exceptional quality open-...", "url": "https://huggingface.co/posts/ginipick/692850049335646", "date_published": "2025-05-04T05:22:04.202384"}, {"id": "https://huggingface.co/posts/as-cle-bert/299436064475061", "image": "", "title": "One of the biggest challenges I've been facing since I started developing [\ud835\udc0f\ud835\udc1d\ud835\udc1f\ud835\udc08\ud835\udc2d\ud835\udc03\ud835\udc28\ud835\udc30\ud835\udc27](", "content_text": "One of the biggest challenges I've been facing since I started developing [\ud835\udc0f\ud835\udc1d\ud835\udc1f\ud835\udc08\ud835\udc2d\ud835\udc03\ud835\udc28\ud835\udc30\ud835\udc27]( https://github.com/AstraBert/PdfItDown ) was handling correctly the conversion of files like Excel sheets and CSVs: table conversion was bad and messy, almost unusable for downstream tasks\ud83e\udee3 That's why today I'm excited to introduce \ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc1d\ud835\udc1e\ud835\udc2b\ud835\udc2c, the new feature of PdfItDown v1.4.0!\ud83c\udf89 With \ud835\ude33\ud835\ude26\ud835\ude22\ud835\ude25\ud835\ude26\ud835\ude33\ud835\ude34, you can choose among three (for now\ud83d\udc40) flavors of text extraction and conversion to PDF: - \ud835\uddd7\ud835\uddfc\ud835\uddf0\ud835\uddf9\ud835\uddf6\ud835\uddfb\ud835\uddf4, which does a fantastic work with presentations, spreadsheets and word documents\ud83e\udd86 - \ud835\udddf\ud835\uddf9\ud835\uddee\ud835\uddfa\ud835\uddee\ud835\udde3\ud835\uddee\ud835\uddff\ud835\ude00\ud835\uddf2 by LlamaIndex, suitable for more complex and articulated documents, with mixture of texts, images and tables\ud83e\udd99 - \ud835\udde0\ud835\uddee\ud835\uddff\ud835\uddf8\ud835\udddc\ud835\ude01\ud835\uddd7\ud835\uddfc\ud835\ude04\ud835\uddfb by Microsoft, not the best at handling highly structured documents, by extremly flexible in terms of input file format (it can even convert XML, JSON and ZIP files!)\u2712\ufe0f You can use this new feature in your python scripts (check the attached code snippet!\ud83d\ude09) and in the command line interface as well!\ud83d\udc0d...", "url": "https://huggingface.co/posts/as-cle-bert/299436064475061", "date_published": "2025-05-04T05:22:04.202844"}, {"id": "https://huggingface.co/posts/lukmanaj/906857593942972", "image": "", "title": "I\u2019m excited to share that I\u2019ve completed the Hugging Face Agents Course and earned my certificate.", "content_text": "I\u2019m excited to share that I\u2019ve completed the Hugging Face Agents Course and earned my certificate. Over the past few months, I explored how to build intelligent, autonomous agents using cutting-edge tools like smolagents, LlamaIndex, and LangGraph. The course covered everything from the fundamentals of agents to advanced topics like fine-tuning for function-calling, observability, evaluation, and even agents in games. Some key content included: 1. Introduction to AI Agents 2. Agentic RAG use cases 3. Multi-framework implementation: smolagents, LlamaIndex, and LangGraph 4. Building, testing, and certifying a complete agent project This was a hands-on, practical experience that deepened my understanding of how to design reliable, tool-using LLM agents. Looking forward to leveraging these skills in real-world applications in healthcare, logistics, and beyond. Many thanks to the Hugging Face team for putting this together. Let\u2019s build safe and useful agents! See translation", "url": "https://huggingface.co/posts/lukmanaj/906857593942972", "date_published": "2025-05-04T05:22:04.203250"}, {"id": "https://huggingface.co/posts/sometimesanotion/274970281216191", "image": "", "title": "The capabilities of the new Qwen 3 models are fascinating, and I am watching that space!", "content_text": "The capabilities of the new Qwen 3 models are fascinating, and I am watching that space! My experience, however, is that context management is vastly more important with them. If you use a client with a typical session log with rolling compression, a Qwen 3 model will start to generate the same messages over and over. I don't think that detracts from them. They're optimized for a more advanced MCP environment. I honestly think the 8B is optimal for home use, given proper RAG/CAG. In typical session chats, Lamarck and Chocolatine are still my daily drives. I worked hard to give Lamarck v0.7 a sprinkling of CoT from both DRT and Deepseek R1. While those models got surpassed on the leaderboards, in practice, I still really enjoy their output. My projects are focusing on application and context management, because that's where the payoff in improved quality is right now. But should there be a mix of finetunes to make just the right mix of - my recipes are standing by. See translation", "url": "https://huggingface.co/posts/sometimesanotion/274970281216191", "date_published": "2025-05-04T05:22:04.203623"}, {"id": "https://huggingface.co/posts/DawnC/822045713383062", "image": "", "title": "VisionScout \u2014 Now with Scene Understanding! \ud83d\ude80", "content_text": "VisionScout \u2014 Now with Scene Understanding! \ud83d\ude80 I'm excited to share a major update to VisionScout, my interactive vision tool that combines powerful object detection with emerging scene understanding capabilities! \ud83d\udc40\ud83d\udd0d What can VisionScout do today? \ud83d\uddbc\ufe0f Upload any image and detect 80 object types using YOLOv8. \ud83d\udd04 Instantly switch between Nano, Medium, and XLarge models depending on speed vs. accuracy needs. \ud83c\udfaf Filter specific classes (people, vehicles, animals, etc.) to focus only on what matters to you. \ud83d\udcca View detailed statistics on detected objects, confidence levels, and spatial distribution. \u2b50\ufe0f NEW: Scene understanding layer now added! - Automatically interprets the scene based on detected objects. - Uses a combination of rule-based reasoning and CLIP-powered semantic validation. - Outputs descriptions, possible activities, and even safety concerns. What\u2019s coming next? \ud83d\udd0e Expanding YOLO\u2019s object categories. \ud83c\udfa5 Adding video processing and multi-frame object tracking. \u26a1 Faster real-time...", "url": "https://huggingface.co/posts/DawnC/822045713383062", "date_published": "2025-05-04T05:22:04.204159"}, {"id": "https://huggingface.co/posts/RiverZ/535015681556179", "image": "", "title": "\ud83d\ude80 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer\uff5e", "content_text": "\ud83d\ude80 Excited to Share Our Latest Work: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer\uff5e \ud83c\udfa8 Daily Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) \ud83d\udd13 Code is now open source! \ud83d\udd25 Huggingface DEMO: RiverZ/ICEdit \ud83c\udf10 Project Website: https://river-zhang.github.io/ICEdit-gh-pages/ \ud83c\udfe0 GitHub Repository: https://github.com/River-Zhang/ICEdit/blob/main/scripts/gradio_demo.py \ud83e\udd17 Huggingface: sanaka87/ICEdit-MoE-LoRA \ud83d\udcc4 arxiv Paper: In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer (2504.20690) \ud83d\udd25 Why it\u2019s cool: - Achieves high-quality, multi-task image editing. - Uses only 1% of the training parameters and 0.1% of the training data compared to existing methods \u2014 extremely efficient - Beats several commercial models on background preservation, ID control, and consistency - Open-...", "url": "https://huggingface.co/posts/RiverZ/535015681556179", "date_published": "2025-05-04T05:22:04.204641"}, {"id": "https://huggingface.co/posts/nyuuzyou/253978208604387", "image": "", "title": "\ud83d\uddbc\ufe0f OpenClipart SVG Dataset -", "content_text": "\ud83d\uddbc\ufe0f OpenClipart SVG Dataset - nyuuzyou/openclipart Collection of 178,604 Public Domain Scalable Vector Graphics (SVG) clipart images featuring: - Comprehensive metadata: title, description, artist name, tags, original page URL, and more. - Contains complete SVG XML content (minified) for direct use or processing. - All images explicitly released into the public domain under the CC0 license. - Organized in a single train split with 178,604 entries. See translation", "url": "https://huggingface.co/posts/nyuuzyou/253978208604387", "date_published": "2025-05-04T05:22:04.204944"}]}