{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ovi054/459497213356295", "image": "", "title": "Update on", "content_text": "Update on ovi054/Qwen-Image-LORA \u26a1 You can now load a Qwen LoRA in this space as follows: 1. Model ID: flymy-ai/qwen-image-realism-lora 2. Model link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora 3. Specific file link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /blob/m ain/flymy_realism.safetensors 4. Direct download link: https://huggingface.co /flymy-ai/ qwen-image-realism-lora /resolve/m ain/flymy_realism.safetensors You can also use an external .safetensors download link (if Hugging Face doesn\u2019t block it). It is useful if a model repository contains multiple weights and you want to load a specific one. \ud83d\udc49 Try it now: ovi054/Qwen-Image-LORA See translation", "url": "https://huggingface.co/posts/ovi054/459497213356295", "date_published": "2025-08-15T17:21:39.970092"}, {"id": "https://huggingface.co/posts/fdaudens/770107969696647", "image": "", "title": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS:", "content_text": "Want to learn to build an AI Agent? I put together a cookbook for creating your own news research agent with OpenAI GPT-OSS: - Searches headlines & specific sites - Pulls full articles when you need depth - Summarizes with clickable sources - Runs in a simple Gradio chat UI - No GPU, no local setup \u2014 just open-weight GPT-OSS models via Hugging Face If you\u2019ve been wanting to try agents but weren\u2019t sure where to start, this is an end-to-end example you can fork, run, and adapt. Full guide + code https://huggingface.co/blog/fdaudens/openai-gpt-oss-agent-inference-providers See translation", "url": "https://huggingface.co/posts/fdaudens/770107969696647", "date_published": "2025-08-15T17:21:39.970463"}, {"id": "https://huggingface.co/posts/nroggendorff/812423234168314", "image": "", "title": "No, I did not create those bots that just got banned today.", "content_text": "No, I did not create those bots that just got banned today. See translation", "url": "https://huggingface.co/posts/nroggendorff/812423234168314", "date_published": "2025-08-15T17:21:39.970663"}, {"id": "https://huggingface.co/posts/etemiz/710778843328598", "image": "", "title": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model.", "content_text": "gpt-oss-120B scored 28 (one of the lowest) on AHA leaderboard. not very human aligned model. these kind of models are not really \"free\": they are costing you your freedom if you know what i mean. See translation", "url": "https://huggingface.co/posts/etemiz/710778843328598", "date_published": "2025-08-15T17:21:39.970883"}, {"id": "https://huggingface.co/posts/mlabonne/575026837446793", "image": "", "title": "Liquid just released two 450M and 1.6B param VLMs!", "content_text": "Liquid just released two 450M and 1.6B param VLMs! They're super fast and leverage SigLIP2 NaFlex encoders to handle native resolutions without distortion. It's ideal for on-device deployment in constrained environments like phones. It's available today on Hugging Face, with an inference and a fine-tuning Colab notebooks. LiquidAI/LFM2-VL-450M LiquidAI/LFM2-VL-1.6B See translation", "url": "https://huggingface.co/posts/mlabonne/575026837446793", "date_published": "2025-08-15T17:21:39.971154"}, {"id": "https://huggingface.co/posts/hba123/107730379524841", "image": "", "title": "We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so:", "content_text": "We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so: Check it out: https://huggingface.co/blog/hba123/ark See translation", "url": "https://huggingface.co/posts/hba123/107730379524841", "date_published": "2025-08-15T17:21:39.971388"}, {"id": "https://huggingface.co/posts/kanaria007/826383234496581", "image": "", "title": "\u2705 New Article: *Acting as Structured Cognition*", "content_text": "\u2705 New Article: *Acting as Structured Cognition* Title: \ud83c\udfad Structural Acting: Cognitive Performance via Jump Protocols \ud83d\udd17 https://huggingface.co/blog/kanaria007/structural-acting --- Summary: Acting is often framed as *losing yourself in a role*. Structured Intelligence reframes performance as *cognitive architecture*: * Jumping across *identity\u2011adjacent frames* * Maintaining *self\u2011coherence* while simulating others * *Modeling judgment structures* instead of emotional fusion > Acting isn\u2019t about disappearing \u2014 > *it\u2019s about showing the structure behind identity.* --- Why It Matters: \u2022 Reduces *psychological strain* by keeping self anchored \u2022 Enables *traceable and reversible performance states* \u2022 Turns acting into a *laboratory for identity, motivation, and simulation* --- What\u2019s Inside: \u2022 Structured approach to *role construction and safe detachment* \u2022 *Recursive rehearsal loops* for adaptive performance \u2022 Insights for *theater, therapy, and human\u2011AI collaboration* \u2022 Comparison of...", "url": "https://huggingface.co/posts/kanaria007/826383234496581", "date_published": "2025-08-15T17:21:39.971939"}, {"id": "https://huggingface.co/posts/jjokah/756442516282804", "image": "", "title": "After responding to this question on my blog about SLMs, I'm beginning to wonder if the term \"Small Language Model\" is already dated.", "content_text": "After responding to this question on my blog about SLMs, I'm beginning to wonder if the term \"Small Language Model\" is already dated. Ref (article): https://huggingface.co/blog/jjokah/small-language-model See translation", "url": "https://huggingface.co/posts/jjokah/756442516282804", "date_published": "2025-08-15T17:21:39.972176"}, {"id": "https://huggingface.co/posts/BramVanroy/381312664935235", "image": "", "title": "Thanks to popular request, I've just added two subsets to the CommonCrawl-Creative Commons Corpus (C5;", "content_text": "Thanks to popular request, I've just added two subsets to the CommonCrawl-Creative Commons Corpus (C5; BramVanroy/CommonCrawl-CreativeCommons ) so that you do not have to do filtering manually - C5f ( BramVanroy/CommonCrawl-CreativeCommons-fine ): only retains high-quality samples that are also present in FineWeb or FineWeb-2; - C5r ( BramVanroy/CommonCrawl-CreativeCommons-recommended ): additional strict filtering that removes samples with license disagreement, non-commercial licenses, and Wikipedia samples. The latter because you should probably get those from a more reliable source that provides better parsed content. It goes without saying that these filters lead to a massive reduction in quantity. Doc and token counts are given on the dataset pages. See translation", "url": "https://huggingface.co/posts/BramVanroy/381312664935235", "date_published": "2025-08-15T17:21:39.972490"}, {"id": "https://huggingface.co/posts/dmoxy/476103184884522", "image": "", "title": "\u2600\ufe0f ApertureDB Summer of Workflows #6 is here!  Ingest from SQL", "content_text": "\u2600\ufe0f ApertureDB Summer of Workflows #6 is here! Ingest from SQL Multimodal data (text, images, videos) stuck in PostgreSQL? Getting it out for AI applications is usually painful \u2014 but now it\u2019s just: connect \u2192 click \u2192 ready for AI. \ud83c\udfac See It In Action: https://youtu.be/Uh3fJc1lkFo ApertureDB Ingest from SQL Workflow: Works with PostgreSQL credentials you already have Ingests directly into ApertureDB for unified multimodal search Powers RAG, retrieval, and agentic AI without glue code \ud83d\udc49 Try It Now!: https://cloud.aperturedata.io/signup ? Read The Docs: https://shorturl.at/jop9b Explore The Code: https://shorturl.at/gwFyJ Get Additional Resources: https://shorturl.at/zNND4 We\u2019re halfway through the series \u2014 6 workflows down, 6 to go! \ud83d\udc47 Let us know what you think in the comments below. We are listening. Team ApertureData See translation", "url": "https://huggingface.co/posts/dmoxy/476103184884522", "date_published": "2025-08-15T17:21:39.972875"}]}