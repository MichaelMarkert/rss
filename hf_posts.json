{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ZennyKenny/720018379255407", "image": "", "title": "\ud83d\udda4  Probably one of my favorite projects that I've worked on so far, introducing \u041d\u043e\u0432\u043e\u044f\u0437 (Novoyaz).", "content_text": "\ud83d\udda4 Probably one of my favorite projects that I've worked on so far, introducing \u041d\u043e\u0432\u043e\u044f\u0437 (Novoyaz). \ud83d\udee0 One of the first acts of the Bolshevik government after the Russian Revolution was the reform and standardization of the Russian language, which at the time had a non-standard and challenging orthography. \ud83d\udcda Upon its reform the government launched a nationwide campaign called \u041b\u0438\u043a\u0431\u0435\u0437 (Likbez), which sought to improve literacy in the country (by the way, it worked, bringing the national literacy rate from <20% in the 1920s to >80% by the 1930s). \u203c While this is a remarkable result that should absolutely be celebrated, it's one that has left behind literally hundreds of thousands if not millions of artifacts using pre-reform Russian orthography. \ud83d\ude13 Researchers and historians are working tirelessly to translate these artifacts to modern Russian so that they may be archived and studied but many have told me that. they are doing this BY HAND (!). \ud83d\udca1 I thought, well this is a perfect use case...", "url": "https://huggingface.co/posts/ZennyKenny/720018379255407", "date_published": "2025-09-30T17:19:55.601108"}, {"id": "https://huggingface.co/posts/giadap/999915316832908", "image": "", "title": "One of the hardest challenges in AI safety is finding the right balance: how do we protect people from harm without undermining their agency? This tension is especially visible in conversational systems, where safeguards can sometimes feel more paternalistic than supportive.", "content_text": "One of the hardest challenges in AI safety is finding the right balance: how do we protect people from harm without undermining their agency? This tension is especially visible in conversational systems, where safeguards can sometimes feel more paternalistic than supportive. In my latest piece for Hugging Face, I argue that open source and community-driven approaches offer a promising (though not exclusive) way forward. \u2728 Transparency can make safety mechanisms into learning opportunities. \u2728 Collaboration with diverse communities makes safeguards more relevant across contexts. \u2728 Iteration in the open lets protections evolve rather than freeze into rigid, one-size-fits-all rules. Of course, this isn\u2019t a silver bullet. Top-down safety measures will still be necessary in some cases. But if we only rely on corporate control, we risk building systems that are safe at the expense of trust and autonomy. Read the blog post here: https://huggingface.co/blog/giadap/preserving-agency See...", "url": "https://huggingface.co/posts/giadap/999915316832908", "date_published": "2025-09-30T17:19:55.601549"}, {"id": "https://huggingface.co/posts/Kseniase/566496725881885", "image": "", "title": "12 Excellent MCP Servers", "content_text": "12 Excellent MCP Servers The family of MCP (Model Context Protocol) servers keeps expanding to bridge agents, models, tools, web, data and apps. Here are 12 useful MCP servers that will help you create convenient agentic ecosystems: 1. Chrome DevTools MCP \u2192 https://github.com/ChromeDevTools/chrome-devtools-mcp Lets your coding agent (Gemini, Claude, Cursor, Copilot) control a live Chrome browser with full DevTools access for automation, debugging, and performance analysis 2. Windows-MCP \u2192 https://github.com/CursorTouch/Windows-MCP Provides interaction between agents and Windows, handling file navigation, app control, UI actions, QA testing 3. MCPControl \u2192 https://github.com/claude-did-this/MCPControl Windows control server for programmatic control of mouse, keyboard, window management, and screen capture 4. MetaMCP \u2192 https://github.com/metatool-ai/metamcp A proxy that aggregates multiple MCP servers into one, with middleware support. Works as a standard MCP server for any client 5....", "url": "https://huggingface.co/posts/Kseniase/566496725881885", "date_published": "2025-09-30T17:19:55.602170"}, {"id": "https://huggingface.co/posts/Parveshiiii/228189451590505", "image": "", "title": "\ud83d\ude80 Big news from XenArcAI!", "content_text": "\ud83d\ude80 Big news from XenArcAI! We\u2019ve just released our new dataset: **Bhagwat\u2011Gita\u2011Infinity** \ud83c\udf38\ud83d\udcd6 \u2728 What\u2019s inside: - Verse\u2011aligned Sanskrit, Hindi, and English - Clean, structured, and ready for ML/AI projects - Perfect for research, education, and open\u2011source exploration \ud83d\udd17 Hugging Face: XenArcAI/Bhagwat-Gita-Infinity Let\u2019s bring timeless wisdom into modern AI together \ud83d\ude4c See translation", "url": "https://huggingface.co/posts/Parveshiiii/228189451590505", "date_published": "2025-09-30T17:19:55.602451"}, {"id": "https://huggingface.co/posts/hba123/508032894003486", "image": "", "title": "Hey, amazing, awesome people of the beautiful internet \ud83d\ude0d\ud83e\udd70", "content_text": "Hey, amazing, awesome people of the beautiful internet \ud83d\ude0d\ud83e\udd70 Distillation has been (from my point of view) a main driving factor for the success of hashtag#LLMs - like distilling the knowledge of an amazing big model (say hashtag#DeepSeekv3, or hashtag#GeminiAI) into yours. Probably, you have done it with minimising a KL divergence, and it somehow worked. Well, not that well, right? 1\ufe0f\u20e3 Your model tends to memorise! 2\ufe0f\u20e3 Your model might get the right answer, but its reasoning might be flawed. To fix those problems, we rethink distillation and process a new approach! A method that is based on constrained RL that comes with nice theoretical guarantees and excellent performance! Check it out: Rethinking Large Language Model Distillation: A Constrained Markov Decision Process Perspective (2509.22921) Let us do distillation right! Please upvote if you find it useful! See translation", "url": "https://huggingface.co/posts/hba123/508032894003486", "date_published": "2025-09-30T17:19:55.602861"}, {"id": "https://huggingface.co/posts/yeonseok-zeticai/773315710052361", "image": "", "title": "\u26a1 ColBERT-ko-v1.0 Complete On-device Study: SOTA Korean Retrieval on Mobile", "content_text": "\u26a1 ColBERT-ko-v1.0 Complete On-device Study: SOTA Korean Retrieval on Mobile Major Release: Comprehensive mobile deployment study of yoonjong's ColBERT-ko-v1.0 with detailed performance benchmarks across 50+ mobile devices! \ud83c\udfaf Model Overview: Architecture: Korean-optimized ColBERT (late interaction) Parameters: 0.1B (compact and efficient) Specialty: Korean document retrieval and semantic search Performance: 1.0 recall@10, 0.966 nDCG@10 on AutoRAGRetrieval Benchmark: Outperforms Jina-ColBERT-v2 on Korean MTEB tasks \ud83d\udcca Mobile Performance Results: Latency Metrics: NPU (Best): 3.17ms average inference GPU: 11.67ms average CPU: 21.36ms average NPU Advantage: 18.46x speedup over CPU Memory Efficiency: Model Size: 567.89 MB (production optimized) Runtime Memory: 170.87 MB peak consumption Load Range: 4-614 MB across device categories FP32 Memory: 642.65 MB (optional high precision) Accuracy Preservation: - FP16 Precision: 53.51 dB maintained - Quantized Mode: 32.77 dB (available for memory...", "url": "https://huggingface.co/posts/yeonseok-zeticai/773315710052361", "date_published": "2025-09-30T17:19:55.603490"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/580682771947064", "image": "", "title": "Now You Can Edit Word Documents and Excel Spreadsheets With Claude AI and Wan Training Has Arrived. Also tell me what you think about voice quality.", "content_text": "Now You Can Edit Word Documents and Excel Spreadsheets With Claude AI and Wan Training Has Arrived. Also tell me what you think about voice quality. https://youtu.be/6cH-6JaBMnM See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/580682771947064", "date_published": "2025-09-30T17:19:55.603716"}, {"id": "https://huggingface.co/posts/AdinaY/592151236664481", "image": "", "title": "Ring-1T-preview \ud83d\udd25 1T thinking model released by Ant Group.", "content_text": "Ring-1T-preview \ud83d\udd25 1T thinking model released by Ant Group. inclusionAI/Ring-1T-preview \u2728 MoE architecture + 20T tokens + RLVR via ASystem \u2728 Strong natural language reasoning (AIME\u201925: 92.6, close to GPT-5) \u2728IMO tests: advanced problem-solving & reasoning See translation", "url": "https://huggingface.co/posts/AdinaY/592151236664481", "date_published": "2025-09-30T17:19:55.603968"}, {"id": "https://huggingface.co/posts/prithivMLmods/278211210315293", "image": "", "title": "Try Banana Zoom an advanced image enhancement web app that lets users select regions of an image for AI-powered upscaling and detail refinement. Using Google\u2019s (nano banana), it analyzes selections, generates context-aware enhancements, and produces high-resolution outputs. Simply drag-and-drop or upload images, make precise or fixed-size selections, and watch improvements in real-time with smooth zoom and pixel-dissolve effects.", "content_text": "Try Banana Zoom an advanced image enhancement web app that lets users select regions of an image for AI-powered upscaling and detail refinement. Using Google\u2019s (nano banana), it analyzes selections, generates context-aware enhancements, and produces high-resolution outputs. Simply drag-and-drop or upload images, make precise or fixed-size selections, and watch improvements in real-time with smooth zoom and pixel-dissolve effects. Space / App: prithivMLmods/Banana-Zoom Collection: prithivMLmods/image-gen-apps-diffusion-lastupdated-09-23-68a2f4c5ef3e5e394eacc20a GitHub: https://github.com/prithivsakthiur/banana-zoom Your API will be automatically destroyed once you refresh the app or exit it, so each user's API will be cycled in this way. See translation", "url": "https://huggingface.co/posts/prithivMLmods/278211210315293", "date_published": "2025-09-30T17:19:55.604318"}, {"id": "https://huggingface.co/posts/grimjim/556474107312531", "image": "", "title": "I've uploaded abliteration code with support for sparsification of the refusal vector. It's poorly documented, but the code should be straightforward.", "content_text": "I've uploaded abliteration code with support for sparsification of the refusal vector. It's poorly documented, but the code should be straightforward. https://github.com/jim-plus/llm-abliteration The code is built atop a fork that enabled abliteration to be performed on models loaded in 4-bit or 8-bit bitsandbytes quantization. TransformerLens is not required, just plain Transformers. For those previously unaware, this opens up abliteration experimentation to more people with local VRAM limitations. Since performing abliteration on a quant involves precision and perplexity loss, it stands to reason that a small amount of magnitude sparsification could filter out some noise and possibly even reduce the damage inflicted on latent space via ablation of the refusal vector. There's a small but real acceleration of ablation of the refusal vector by reducing outer product operations from O(d\u00b2\u00d7n) to O(d\u00d7n), and then by pushing said computation layerwise to GPU. The code is hardcoded for...", "url": "https://huggingface.co/posts/grimjim/556474107312531", "date_published": "2025-09-30T17:19:55.604773"}]}