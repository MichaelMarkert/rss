{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Jofthomas/993866418471203", "image": "", "title": "The new Mistral 3 models are here !", "content_text": "The new Mistral 3 models are here ! Today, we announce Mistral 3, the next generation of Mistral models. Mistral 3 includes three state-of-the-art small, dense models (14B, 8B, and 3B) and Mistral Large 3 \u2013 our most capable model to date \u2013 a sparse mixture-of-experts trained with 41B active and 675B total parameters. All models are released under the Apache 2.0 license. Ministrals : https://huggingface.co/collections/mistralai/ministral-3 Mistral Large 3: https://huggingface.co/collections/mistralai/mistral-large-3 See translation", "url": "https://huggingface.co/posts/Jofthomas/993866418471203", "date_published": "2025-12-03T17:26:27.987727"}, {"id": "https://huggingface.co/posts/sergiopaniego/920736659206393", "image": "", "title": "ICYMI, transformers v5 is out!", "content_text": "ICYMI, transformers v5 is out! Grab a coffee \u2615 and go read the announcement blog https://huggingface.co/blog/transformers-v5 See translation", "url": "https://huggingface.co/posts/sergiopaniego/920736659206393", "date_published": "2025-12-03T17:26:27.987951"}, {"id": "https://huggingface.co/posts/flozi00/166942879954778", "image": "", "title": "We recently discussed how Tensor Parallelism slices matrices to reduce latency within a single node. But what happens when you need to scale beyond that, where the bandwidth drops?", "content_text": "We recently discussed how Tensor Parallelism slices matrices to reduce latency within a single node. But what happens when you need to scale beyond that, where the bandwidth drops? That is where Pipeline Parallelism (PP) takes over. Instead of slicing the operation, PP slices the model depth. It turns your GPU cluster into an assembly line: GPU 0 handles layers 1-12, GPU 1 handles 13-24, and so on. The hardware challenge here isn't the interconnect speed\u2014it is the \"Pipeline Bubble.\" In a naive setup, expensive H100s sit idle for most of the cycle waiting for data to flow through the chain. My latest guide breaks down the scheduling strategies used to minimize this idle silicon time. In this deep dive, we cover: The Hardware Mechanics: Vertical Slicing Unlike TP which requires \"chatty\" All-Reduce operations, PP relies on lightweight Point-to-Point (Send/Recv) communication. This makes it the only viable strategy for crossing node boundaries over Ethernet or InfiniBand. Fighting the...", "url": "https://huggingface.co/posts/flozi00/166942879954778", "date_published": "2025-12-03T17:26:27.988491"}, {"id": "https://huggingface.co/posts/hesamation/869653062191419", "image": "", "title": "this is big... 50 AI researchers from Bytedance, Alibaba, Tencent, and other labs/universities just published a 300-page paper with surprising lessons about coding models and agents (data, pre and post-training, etc).", "content_text": "this is big... 50 AI researchers from Bytedance, Alibaba, Tencent, and other labs/universities just published a 300-page paper with surprising lessons about coding models and agents (data, pre and post-training, etc). key highlights: > small LLMs can beat proprietary giants RL (RLVR specifically) gives small open-source models an edge over big models in reasoning. a 14B model trained with RLVR on high-quality verified problems can match the performance of OpenAI's o3. > models have a hard time learning Python. mixing language models during pre-training is good, but Python behaves different from statically typed languages. languages with similar syntax (Java and C#, or JavaScript and TypeScript) creates high positive synergy. mixing Python heavily into the training of statically typed languages can actually hurt because of Python's dynamic typing. > not all languages are equal (coding scaling laws) the amount of data required to specialize a model on a language drastically depends on...", "url": "https://huggingface.co/posts/hesamation/869653062191419", "date_published": "2025-12-03T17:26:27.988971"}, {"id": "https://huggingface.co/posts/prithivMLmods/649242345044742", "image": "", "title": "Hello everyone,", "content_text": "Hello everyone, The strangerzonehf [HF] Community / Organization Page, which is maintained by me, has reached the Top 10 Developer Pages ranking at 6th place, contributing 3.4% in the calendar cycle from August 2024 to August 2025. It is also the only South Asia / Indian page in the list. I could not be more proud to be doing things for the community. \u2764\ufe0f\ud83e\udd17 Source: https://www.dataprovenance.org/economies-of-open-intelligence.pdf It is a pleasure to be a part of it. Thank you! @ prithivMLmods See translation", "url": "https://huggingface.co/posts/prithivMLmods/649242345044742", "date_published": "2025-12-03T17:26:27.989269"}, {"id": "https://huggingface.co/posts/sergiopaniego/422459569314108", "image": "", "title": "want to use open models easily through an API?", "content_text": "want to use open models easily through an API? Inference Providers might be exactly what you\u2019re looking for sooo here\u2019s a complete beginner-friendly walkthrough \ud83e\uddd0 https://www.youtube.com/watch?v=oxwsizy1Spw See translation", "url": "https://huggingface.co/posts/sergiopaniego/422459569314108", "date_published": "2025-12-03T17:26:27.989477"}, {"id": "https://huggingface.co/posts/ovi054/498416611324104", "image": "", "title": "Introducing Anim Lab AI\u26a1", "content_text": "Introducing Anim Lab AI\u26a1 My submission for the MCP 1st Birthday Hackathon Turn any math concept or logic into a clear video explanation instantly using AI. \ud83d\udc49 Try it now: MCP-1st-Birthday/anim-lab-ai Demo outputs are attached \ud83d\udc47 See translation", "url": "https://huggingface.co/posts/ovi054/498416611324104", "date_published": "2025-12-03T17:26:27.989706"}, {"id": "https://huggingface.co/posts/Kseniase/298526462161147", "image": "", "title": "9 Recent advances in Multi-Agent Systems (all open-source)", "content_text": "9 Recent advances in Multi-Agent Systems (all open-source) The idea to split tasks across multiple agents instead of relying on one universal agent is now seen as one of the most effective ways to build an AI stack. Concepts like \u201cagent swarms\u201d were highlighted at the AI Engineer Code Summit in NYC (Nov 20\u201321) as the winning architecture. And this trend is not only about coding and software. It applies across all AI domains. So here is some recent research that helps keep multi-agent systems (MAS) better and up-to-date: 1. LatentMAS \u2192 Latent Collaboration in Multi-Agent Systems (2511.20639) AI agents share their hidden \"thoughts\" directly in latent space instead of talking through text. This makes collaboration and reasoning way faster and accurate (no extra training needed) 2. Puppeteer \u2192 Multi-Agent Collaboration via Evolving Orchestration (2505.19591) Uses a \u201cpuppeteer\u201d LLM that dynamically decides which agents (\u201cpuppets\u201d) to call and in what order. By learning this orchestration...", "url": "https://huggingface.co/posts/Kseniase/298526462161147", "date_published": "2025-12-03T17:26:27.990293"}, {"id": "https://huggingface.co/posts/rajkumarrawal/715420178191599", "image": "", "title": "September(2025) LLM Safety & Reliability Benchmarks Report By AI Parivartan Research Lab (AIPRL-LIR)", "content_text": "September(2025) LLM Safety & Reliability Benchmarks Report By AI Parivartan Research Lab (AIPRL-LIR) Monthly LLM's Intelligence Reports for AI Decision Makers : Our \"aiprl-llm-intelligence-report\" repo to establishes (AIPRL-LIR) framework for Large Language Model overall evaluation and analysis through systematic monthly intelligence reports. Unlike typical AI research papers or commercial reports. It provides structured insights into AI model performance, benchmarking methodologies, Multi-hosting provider analysis, industry trends ... ( all in one monthly report ) Leading Models & Companies, 23 Benchmarks in 6 Categories, Global Hosting Providers, & Research Highlights Here\u2019s what you\u2019ll find inside this month\u2019s intelligence report:- Leading Models & Companies : 23 Benchmarks in 6 Categories : With a special focus on Safety & Reliability performance across diverse tasks. Global Hosting Providers : Research Highlights : Comparative insights, evaluation methodologies, and industry...", "url": "https://huggingface.co/posts/rajkumarrawal/715420178191599", "date_published": "2025-12-03T17:26:27.990817"}, {"id": "https://huggingface.co/posts/ronantakizawa/980428183016922", "image": "", "title": "Introducing the tiktok-trending-hashtags dataset: a compilation of  1,830 unique trending hashtags on TikTok from 2022 to 2025. This dataset captures viral one-time and seasonal viral moments on TikTok and is perfect for researchers, marketers, and content creators studying viral content patterns on social media.", "content_text": "Introducing the tiktok-trending-hashtags dataset: a compilation of 1,830 unique trending hashtags on TikTok from 2022 to 2025. This dataset captures viral one-time and seasonal viral moments on TikTok and is perfect for researchers, marketers, and content creators studying viral content patterns on social media. ronantakizawa/tiktok-trending-hashtags #tiktok #trends #social-media See translation", "url": "https://huggingface.co/posts/ronantakizawa/980428183016922", "date_published": "2025-12-03T17:26:27.991036"}]}