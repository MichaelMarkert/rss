{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/merve/544378273517703", "image": "", "title": "VLMS 2025 UPDATE \ud83d\udd25", "content_text": "VLMS 2025 UPDATE \ud83d\udd25 We just shipped a blog on everything latest on vision language models, including \ud83e\udd16 GUI agents, agentic VLMs, omni models \ud83d\udcd1 multimodal RAG \u23ef\ufe0f video LMs \ud83e\udd0f\ud83c\udffb smol models ..and more! https://huggingface.co/blog/vlms-2025 See translation", "url": "https://huggingface.co/posts/merve/544378273517703", "date_published": "2025-05-13T17:21:07.757550"}, {"id": "https://huggingface.co/posts/ginipick/766230066345476", "image": "", "title": "# \ud83c\udf1f 3D Model to Video: Easy GLB Conversion Tool \ud83c\udf1f", "content_text": "# \ud83c\udf1f 3D Model to Video: Easy GLB Conversion Tool \ud83c\udf1f demo link: ginigen/3D-VIDEO Hello there! Would you like to transform your 3D models into stunning animations? This space can help you! \u2728 ## \ud83d\udd0d What Can It Do? This tool converts your uploaded GLB model into: 1. \ud83c\udfae A transformed GLB file 2. \ud83c\udfac An animated GIF preview 3. \ud83d\udccb A metadata JSON file ## \u2705 Key Features * \ud83d\udda5\ufe0f Works in headless server environments (EGL + pyglet-headless \u2192 pyrender fallback) * \ud83d\udd0d Objects in GIFs appear 3x larger (global scale \u00d73) * \ud83c\udfa8 Clean interface with pastel background ## \ud83c\udfae Animation Types * \ud83d\udd04 Rotate - Object rotates around the Y-axis * \u2b06\ufe0f Float - Object moves smoothly up and down * \ud83d\udca5 Explode - Object moves sideways * \ud83e\udde9 Assemble - Object returns to its original position * \ud83d\udc93 Pulse - Object changes in size * \ud83d\udd04 Swing - Object swings around the Z-axis ## \ud83d\udee0\ufe0f How to Use 1. Upload your GLB model \ud83d\udce4 2. Select your desired animation type \ud83c\udfac 3. Adjust the duration and FPS \u23f1\ufe0f 4. Click the \"Generate Animation\" button \u25b6\ufe0f 5....", "url": "https://huggingface.co/posts/ginipick/766230066345476", "date_published": "2025-05-13T17:21:07.758109"}, {"id": "https://huggingface.co/posts/openfree/538970335354687", "image": "", "title": "\u2728 DreamO Video: From Customized Images to Videos \u2728", "content_text": "\u2728 DreamO Video: From Customized Images to Videos \u2728 Hello, AI creators! Today I'm introducing a truly special project. DreamO Video is an integrated framework that generates customized images based on reference images and transforms them into videos with natural movement. \ud83c\udfac\u2728 openfree/DreamO-video \ud83d\udd0d Key Features Image Reference (IP): Maintain object appearance while applying to new backgrounds and situations ID Preservation: Retain facial features across various environments Style Transfer: Apply unique styles from reference images to other content \ud83c\udf9e\ufe0f Video Generation: Create natural 2-second videos from generated images \ud83d\udca1 How to Use Upload Reference Images: One or two images (people, objects, landscapes, etc.) Select Task Type: Choose between IP (Image Preservation), ID (Face Feature Retention), or Style Enter Prompt: Describe your desired result (e.g., \"a woman playing guitar on a cloud\") Click Generate Image: \u2728 Create customized AI images! Generate Video: Click the \ud83c\udfac button on the...", "url": "https://huggingface.co/posts/openfree/538970335354687", "date_published": "2025-05-13T17:21:07.758761"}, {"id": "https://huggingface.co/posts/blaise-tk/108431169603656", "image": "", "title": "Today we launch Dione.", "content_text": "Today we launch Dione. A few months ago it was just a wild idea I shared with @ bygimenez , now it's real. Dione (Beta) is here, the easiest way to discover and install open-source apps, especially AI ones. Think of it as the Steam of open source. Installing open-source tools is often a mess. Dione fixes that. Beautiful UI and workflow. Soon multi-platform, multilingual & fully open-source. Users can even write and share their own installation scripts. This is just the beginning. \ud83d\ude80 Join our exclusive Beta \u2192 https://getdione.app/beta/join See translation", "url": "https://huggingface.co/posts/blaise-tk/108431169603656", "date_published": "2025-05-13T17:21:07.759090"}, {"id": "https://huggingface.co/posts/smirki/468999292160757", "image": "", "title": "\u2728 We\u2019re live! Introducing TFrameX, the agentic framework for AI builders.", "content_text": "\u2728 We\u2019re live! Introducing TFrameX, the agentic framework for AI builders. After nights of development, we\u2019re finally open-sourcing TFrameX, a powerful AI agent communication and coordination library. TFrameX lets you: \ud83e\udd16 Run agents in dynamic flows \ud83d\udd01 Compose reusable patterns like Sequential, Parallel, Router, and more \ud83e\udde0 Enable agent-to-agent collaboration and delegation \u26a1 Build modular, complex multi-agent systems that just work \ud83d\udc49 GitHub: TFrameX https://github.com/TesslateAI/TFrameX But we didn\u2019t stop there. We also built a sleek visual builder to design, deploy, and debug your agent patterns without writing boilerplate! \ud83e\udde9 Visual Studio for TFrameX: https://github.com/TesslateAI/Studio If you\u2019re building agent frameworks, LLM tools, or agentic apps, TFrameX gives you the tools to move fast and reason deeply. See translation", "url": "https://huggingface.co/posts/smirki/468999292160757", "date_published": "2025-05-13T17:21:07.759486"}, {"id": "https://huggingface.co/posts/Kseniase/849940009274643", "image": "", "title": "11 Alignment and Optimization Algorithms for LLMs", "content_text": "11 Alignment and Optimization Algorithms for LLMs When we need to align models' behavior with the desired objectives, we rely on specialized algorithms that support helpfulness, accuracy, reasoning, safety, and alignment with user preferences. Much of a model\u2019s usefulness comes from post-training optimization methods. Here are the main optimization algorithms (both classic and new) in one place: 1. PPO (Proximal Policy Optimization) -> Proximal Policy Optimization Algorithms (1707.06347) Clips the probability ratio to prevent the new policy from diverging too far from the old one. It helps keep everything stable 2. DPO (Direct Preference Optimization) -> Direct Preference Optimization: Your Language Model is Secretly a Reward Model (2305.18290) It's a non RL method, where an LM is an implicit reward model. It uses a simple loss to boost the preferred answer\u2019s probability over the less preferred one 3. GRPO (Group Relative Policy Optimization) -> DeepSeekMath: Pushing the Limits of...", "url": "https://huggingface.co/posts/Kseniase/849940009274643", "date_published": "2025-05-13T17:21:07.760172"}, {"id": "https://huggingface.co/posts/hesamation/756119536681094", "image": "", "title": "this book actually exists for free, \u201cthe little book of deep learning\u201d. best to refresh your mind about DL basics:", "content_text": "this book actually exists for free, \u201cthe little book of deep learning\u201d. best to refresh your mind about DL basics: > foundations of machine learning > how models train > common layers (dropout, pooling\u2026) > basic intro to LLMs actually optimized for mobile. Book: https://fleuret.org/public/lbdl.pdf See translation", "url": "https://huggingface.co/posts/hesamation/756119536681094", "date_published": "2025-05-13T17:21:07.760433"}, {"id": "https://huggingface.co/posts/as-cle-bert/400981312479742", "image": "", "title": "Let's pipe some \ud835\uddf1\ud835\uddee\ud835\ude01\ud835\uddee \ud835\uddf3\ud835\uddff\ud835\uddfc\ud835\uddfa \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude04\ud835\uddf2\ud835\uddef into our vector database, shall we?\ud83e\udd20", "content_text": "Let's pipe some \ud835\uddf1\ud835\uddee\ud835\ude01\ud835\uddee \ud835\uddf3\ud835\uddff\ud835\uddfc\ud835\uddfa \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude04\ud835\uddf2\ud835\uddef into our vector database, shall we?\ud83e\udd20 With \ud835\udc22\ud835\udc27\ud835\udc20\ud835\udc1e\ud835\udc2c\ud835\udc2d-\ud835\udc1a\ud835\udc27\ud835\udc32\ud835\udc2d\ud835\udc21\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2f\ud835\udfcf.\ud835\udfd1.\ud835\udfce ( https://github.com/AstraBert/ingest-anything ) you can now scrape content simply starting from URLs, extract the text from it, chunk it and put it into your favorite LlamaIndex-compatible database!\ud83d\udd78\ufe0f You can do it thanks to \ud835\uddf0\ud835\uddff\ud835\uddee\ud835\ude04\ud835\uddf9\ud835\uddf2\ud835\uddf2 by Apify, an open-source crawling library for python and javascript that handles all the data flow from the web: ingest-anything then combines it with \ud835\uddd5\ud835\uddf2\ud835\uddee\ud835\ude02\ud835\ude01\ud835\uddf6\ud835\uddf3\ud835\ude02\ud835\uddf9\ud835\udde6\ud835\uddfc\ud835\ude02\ud835\uddfd, \ud835\udde3\ud835\uddf1\ud835\uddf3\ud835\udddc\ud835\ude01\ud835\uddd7\ud835\uddfc\ud835\ude04\ud835\uddfb and \ud835\udde3\ud835\ude06\ud835\udde0\ud835\ude02\ud835\udde3\ud835\uddf1\ud835\uddf3 to scrape HTML files, convert them to PDF and extract the text - hassle-free!\ud83d\ude38 Check the attached code snippet if you're curious of knowing how to get started\ud83c\udfac PS: Don't tell anybody, but this release also has another gem... It supports OpenAI models for agentic chunking, following the new releases of Chonkie\ud83e\udd9b\u2728 If you don't want to miss out on the new features, leave us a little star on GitHub \u27a1\ufe0f https://github.com/AstraBert/ingest-anything And join our discord community!...", "url": "https://huggingface.co/posts/as-cle-bert/400981312479742", "date_published": "2025-05-13T17:21:07.760889"}, {"id": "https://huggingface.co/posts/dhruv3006/692657412350660", "image": "", "title": "The era of local Computer Use AI Agents is here.", "content_text": "The era of local Computer Use AI Agents is here. Meet UI-TARS-1.5-7B-6bit, now running natively on Apple Silicon via MLX. The video is of UI-TARS-1.5-7B-6bit completing the prompt \"draw a line from the red circle to the green circle, then open reddit in a new tab\" running entirely on MacBook. The video is just a replay, during actual usage it took between 15s to 50s per turn with 720p screenshots (on avg its ~30s per turn), this was also with many apps open so it had to fight for memory at times. Built using c/ua : https://github.com/trycua/cua Join us making them here: https://discord.gg/4fuebBsAUj Kudos to the MLX community here on huggingface : mlx-community See translation", "url": "https://huggingface.co/posts/dhruv3006/692657412350660", "date_published": "2025-05-13T17:21:07.761184"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/869555651580897", "image": "", "title": "Transfer Any Clothing Into A New Person & Turn Any Person Into A 3D Figure - ComfyUI Tutorial", "content_text": "Transfer Any Clothing Into A New Person & Turn Any Person Into A 3D Figure - ComfyUI Tutorial ComfyUI is super hard to use but I have literally prepared 1-click way to install and use 2 amazing workflows. First workflow is generating a person wearing any clothing. The second workflow is turning any person image into a 3D toy like figure image. Tutorial Link : https://youtu.be/ZzYnhKeaJBs Video Chapters 0:00:00 Intro: Two One-Click ComfyUI Workflows (Clothing Gen & 3D Figure) 0:00:34 Effort & Goal: Easy Installation & Use of Complex Workflows 0:00:49 Setup Part 1: ComfyUI Prerequisite & Downloading Project Zip File 0:01:06 Setup Part 2: Extracting Zip into ComfyUI Folder (WinRAR 'Extract Here' Tip) 0:01:18 Setup Part 3: Running update_comfyui.bat for Latest ComfyUI Version 0:01:37 Setup Part 4: Running install_clothing_and_3D.bat (Installs Nodes & Requirements) 0:02:03 Model Downloads: Intro to Swarm UI Auto-Installer & Automatic Updater 0:02:28 Using Swarm UI: Launching...", "url": "https://huggingface.co/posts/MonsterMMORPG/869555651580897", "date_published": "2025-05-13T17:21:07.761649"}]}