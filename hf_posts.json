{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/prithivMLmods/223082724733311", "image": "", "title": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea", "content_text": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea \u25cf Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC \u25cf Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \u25cf Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo \u25cf Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- \u25cf FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 \u25cf FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC \u25cf Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC \u25cf Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast \u25cf Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...", "url": "https://huggingface.co/posts/prithivMLmods/223082724733311", "date_published": "2025-12-19T05:27:24.156734"}, {"id": "https://huggingface.co/posts/YatharthS/190514854652270", "image": "", "title": "\ud83e\udd2f \ud83e\udd2f Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! \ud83e\udd2f \ud83e\udd2f", "content_text": "\ud83e\udd2f \ud83e\udd2f Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! \ud83e\udd2f \ud83e\udd2f Github link: https://github.com/ysharma3501/MiraTTS Model link: https://github.com/ysharma3501/MiraTTS Blog explaining llm tts models: https://huggingface.co/blog/YatharthS/llm-tts-models See translation", "url": "https://huggingface.co/posts/YatharthS/190514854652270", "date_published": "2025-12-19T05:27:24.157043"}, {"id": "https://huggingface.co/posts/victor/750233862472141", "image": "", "title": "Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models \ud83d\udd25", "content_text": "Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models \ud83d\udd25 https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe See translation", "url": "https://huggingface.co/posts/victor/750233862472141", "date_published": "2025-12-19T05:27:24.157316"}, {"id": "https://huggingface.co/posts/danielhanchen/963278821580490", "image": "", "title": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25", "content_text": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25 Has 1M context window & best in class performance for SWE-Bench, reasoning & chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF \ud83d\udc9a Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation", "url": "https://huggingface.co/posts/danielhanchen/963278821580490", "date_published": "2025-12-19T05:27:24.157570"}, {"id": "https://huggingface.co/posts/rajkumarrawal/519682431601479", "image": "", "title": "\" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI \". r2r-protocol (Robot2Robot Protocol) is now officially open source! \ud83d\udd13", "content_text": "\" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI \". r2r-protocol (Robot2Robot Protocol) is now officially open source! \ud83d\udd13 \"pip install r2r-protocol\" Whether you're a developer, researcher, or tech enthusiast, we invite you to explore, use, and contribute to the project. \ud83d\udd17 Check it out here: [ https://github.com/Tech-Parivartan/r2r-protocol?tab=readme-ov-file ] Let\u2019s build the future together! \ud83d\udca1 AiParivartanResearchLab techparivartan Documentation of the r2r-protocal : [ https://techparivartanai.notion.site/Robot-to-Robot-r2r-Protocol-1f008f0fb18780439d70e8b9bbbdb869 ] The R2R Protocol enables seamless robot-to-robot interaction across industrial automation, swarm robotics, logistics, and multi-agent systems. It defines structured message formats, negotiation logic, discovery mechanisms, and extensible APIs. #r2r_protocol #robot2robot_protocol #ai...", "url": "https://huggingface.co/posts/rajkumarrawal/519682431601479", "date_published": "2025-12-19T05:27:24.158012"}, {"id": "https://huggingface.co/posts/ronantakizawa/412513789590360", "image": "", "title": "Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on.", "content_text": "Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on. #github #developers ronantakizawa/github-top-developers See translation", "url": "https://huggingface.co/posts/ronantakizawa/412513789590360", "date_published": "2025-12-19T05:27:24.158241"}, {"id": "https://huggingface.co/posts/Reubencf/239576255947718", "image": "", "title": "Great News !", "content_text": "Great News ! Reubencf/Nano_Banana_Editor Now supports black-forest-labs/FLUX.1-Kontext-dev and Qwen/Qwen-Image-Edit-2509 Just log in with Huggingface and try it out See translation", "url": "https://huggingface.co/posts/Reubencf/239576255947718", "date_published": "2025-12-19T05:27:24.158447"}, {"id": "https://huggingface.co/posts/danielhanchen/264398594064230", "image": "", "title": "Google releases FunctionGemma, a new 270M parameter model that runs on just 0.5 GB RAM.\u2728", "content_text": "Google releases FunctionGemma, a new 270M parameter model that runs on just 0.5 GB RAM.\u2728 Built for tool-calling, run locally on your phone at 50+ tokens/s, or fine-tune with Unsloth & deploy to your phone. GGUF: unsloth/functiongemma-270m-it-GGUF Docs + Notebook: https://docs.unsloth.ai/models/functiongemma See translation", "url": "https://huggingface.co/posts/danielhanchen/264398594064230", "date_published": "2025-12-19T05:27:24.158705"}, {"id": "https://huggingface.co/posts/branikita/654655990580208", "image": "", "title": "Update: Our engineer Alan has received a batch of components for the manipulator assemblies \u2014 including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year.", "content_text": "Update: Our engineer Alan has received a batch of components for the manipulator assemblies \u2014 including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year. See translation", "url": "https://huggingface.co/posts/branikita/654655990580208", "date_published": "2025-12-19T05:27:24.158947"}, {"id": "https://huggingface.co/posts/sergiopaniego/463044021249760", "image": "", "title": "Google DeepMind releases FunctionGemma, a 240M model specialized in \ud83d\udd27 tool calling, built for fine-tuning", "content_text": "Google DeepMind releases FunctionGemma, a 240M model specialized in \ud83d\udd27 tool calling, built for fine-tuning TRL has day-0 support. To celebrate, we\u2019re sharing 2 new resources: > Colab guide to fine-tune it for \ud83c\udf10 browser control with BrowserGym OpenEnv > Standalone training script > Colab notebook: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_functiongemma_browsergym_openenv.ipynb > Training script: https://github.com/huggingface/trl/blob/main/examples/scripts/openenv/browsergym_llm.py (command to run it inside the script) > More notebooks in TRL: https://huggingface.co/docs/trl/example_overview#notebooks See translation", "url": "https://huggingface.co/posts/sergiopaniego/463044021249760", "date_published": "2025-12-19T05:27:24.159265"}]}