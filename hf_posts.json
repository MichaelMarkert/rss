{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/YerbaPage/558970453952386", "image": "", "title": "How to compress long code context? \ud83d\udcda", "content_text": "How to compress long code context? \ud83d\udcda Check out our LongCodeZip! Paper just got accepted to ASE 2025. \ud83d\udd25 Code: https://github.com/YerbaPage/LongCodeZip Paper: LongCodeZip: Compress Long Context for Code Language Models (2510.00446) See translation", "url": "https://huggingface.co/posts/YerbaPage/558970453952386", "date_published": "2025-10-03T09:22:53.875532"}, {"id": "https://huggingface.co/posts/AdinaY/926192442043020", "image": "", "title": "GLM-4.6 is here\ud83d\ude80", "content_text": "GLM-4.6 is here\ud83d\ude80 zai-org/GLM-4.6 \u2728 200K context window \u2728 Superior coding & polished UI generation \u2728 Stronger reasoning & tool use \u2728 More capable agents & agent frameworks See translation", "url": "https://huggingface.co/posts/AdinaY/926192442043020", "date_published": "2025-10-03T09:22:53.875779"}, {"id": "https://huggingface.co/posts/giadap/999915316832908", "image": "", "title": "One of the hardest challenges in AI safety is finding the right balance: how do we protect people from harm without undermining their agency? This tension is especially visible in conversational systems, where safeguards can sometimes feel more paternalistic than supportive.", "content_text": "One of the hardest challenges in AI safety is finding the right balance: how do we protect people from harm without undermining their agency? This tension is especially visible in conversational systems, where safeguards can sometimes feel more paternalistic than supportive. In my latest piece for Hugging Face, I argue that open source and community-driven approaches offer a promising (though not exclusive) way forward. \u2728 Transparency can make safety mechanisms into learning opportunities. \u2728 Collaboration with diverse communities makes safeguards more relevant across contexts. \u2728 Iteration in the open lets protections evolve rather than freeze into rigid, one-size-fits-all rules. Of course, this isn\u2019t a silver bullet. Top-down safety measures will still be necessary in some cases. But if we only rely on corporate control, we risk building systems that are safe at the expense of trust and autonomy. Read the blog post here: https://huggingface.co/blog/giadap/preserving-agency See...", "url": "https://huggingface.co/posts/giadap/999915316832908", "date_published": "2025-10-03T09:22:53.876218"}, {"id": "https://huggingface.co/posts/Sri-Vigneshwar-DJ/891594547382960", "image": "", "title": "\ud83d\ude80 Qwen3-Omni for Marketing: A Game-Changer", "content_text": "\ud83d\ude80 Qwen3-Omni for Marketing: A Game-Changer Just wanted to share something exciting I've been exploring\u2014Qwen3-Omni and how it's transforming marketing workflows. What makes it special? At Hawky.ai we are started experimenting with Qwen3 recently for Analysis and Optimization. Unlike traditional tools that look at text, images, or audio separately, Qwen3-Omni analyzes everything together. It handles 119 languages, processes 40-minute audio sequences, and understands both images and videos\u2014all at once. The cool part? It's 2-3x faster than similar models thanks to its MoE architecture. Real applications I'm seeing: Ad Analysis: It scores video ads by combining visual elements, audio tone, and text\u2014giving 25% better CTR predictions than single-mode tools. Campaign Localization: Drop in one ad, get 10 localized versions with native voiceovers in under a minute. Perfect for testing across markets. Market Research: Feed it competitor content, podcasts, or UGC videos. It extracts actionable...", "url": "https://huggingface.co/posts/Sri-Vigneshwar-DJ/891594547382960", "date_published": "2025-10-03T09:22:53.876731"}, {"id": "https://huggingface.co/posts/SelmaNajih001/721687692996128", "image": "", "title": "Introducing", "content_text": "Introducing SelmaNajih001/StockPredictionExplanation , built with GRPO and RAG: -GRPO trains the model to predict and explain stock direction. -RAG grounds explanations in historical financial news and central bank speeches. Together, they create a system that forecasts stock movements and shows the reasoning behind them. Full article: Explainable Financial Predictions \u2014 https://huggingface.co/blog/SelmaNajih001/explainable-financial-predictions Try it here: StockPredictionExplanation Space \u2014 SelmaNajih001/StockPredictionExplanation See translation", "url": "https://huggingface.co/posts/SelmaNajih001/721687692996128", "date_published": "2025-10-03T09:22:53.877051"}, {"id": "https://huggingface.co/posts/Parveshiiii/228189451590505", "image": "", "title": "\ud83d\ude80 Big news from XenArcAI!", "content_text": "\ud83d\ude80 Big news from XenArcAI! We\u2019ve just released our new dataset: **Bhagwat\u2011Gita\u2011Infinity** \ud83c\udf38\ud83d\udcd6 \u2728 What\u2019s inside: - Verse\u2011aligned Sanskrit, Hindi, and English - Clean, structured, and ready for ML/AI projects - Perfect for research, education, and open\u2011source exploration \ud83d\udd17 Hugging Face: XenArcAI/Bhagwat-Gita-Infinity Let\u2019s bring timeless wisdom into modern AI together \ud83d\ude4c See translation", "url": "https://huggingface.co/posts/Parveshiiii/228189451590505", "date_published": "2025-10-03T09:22:53.877332"}, {"id": "https://huggingface.co/posts/andywu-kby/790599686035068", "image": "", "title": "Hello everyone,", "content_text": "Hello everyone, I hope you\u2019re doing well. We\u2019re currently developing a chatbot that can analyze and forecast sales directly from Excel files. Do you think this would be useful? Miragic-AI/Miragic-Sales-Pilot Please share your feedback by \ud83d\udc4d or \ud83d\udc4e this post. Best regards, See translation", "url": "https://huggingface.co/posts/andywu-kby/790599686035068", "date_published": "2025-10-03T09:22:53.877580"}, {"id": "https://huggingface.co/posts/hba123/508032894003486", "image": "", "title": "Hey, amazing, awesome people of the beautiful internet \ud83d\ude0d\ud83e\udd70", "content_text": "Hey, amazing, awesome people of the beautiful internet \ud83d\ude0d\ud83e\udd70 Distillation has been (from my point of view) a main driving factor for the success of hashtag#LLMs - like distilling the knowledge of an amazing big model (say hashtag#DeepSeekv3, or hashtag#GeminiAI) into yours. Probably, you have done it with minimising a KL divergence, and it somehow worked. Well, not that well, right? 1\ufe0f\u20e3 Your model tends to memorise! 2\ufe0f\u20e3 Your model might get the right answer, but its reasoning might be flawed. To fix those problems, we rethink distillation and process a new approach! A method that is based on constrained RL that comes with nice theoretical guarantees and excellent performance! Check it out: Rethinking Large Language Model Distillation: A Constrained Markov Decision Process Perspective (2509.22921) Let us do distillation right! Please upvote if you find it useful! See translation", "url": "https://huggingface.co/posts/hba123/508032894003486", "date_published": "2025-10-03T09:22:53.877991"}, {"id": "https://huggingface.co/posts/prithivMLmods/704561076669428", "image": "", "title": "Try the Hugging Face Space demo for", "content_text": "Try the Hugging Face Space demo for Logics-MLLM/Logics-Parsing , the latest multimodal VLM from the Logics Team at Alibaba Group. It enables end-to-end document parsing with precise content extraction in markdown format, and it also generates a clean HTML representation of the document while preserving its logical structure. \ud83e\udd17\ud83d\udd25 Additionally, I\u2019ve integrated one of my recent works \u2014 prithivMLmods/Gliese-OCR-7B-Post1.0 \u2014 which also excels at document comprehension. \u2b50 Space / App : prithivMLmods/Logics-Parsing-VLM \ud83d\udcc4 Technical Report by the Logics Team, Alibaba Group : Logics-Parsing Technical Report (2509.19760) \u26a1 Collections : prithivMLmods/multimodal-implementations-67c9982ea04b39f0608badb0 Other Pages: \u2794 Multimodal VLMs - July'25 : prithivMLmods/multimodal-vlms-until-july25-688312e6b840e1e156f13027 \u2794 Multimodal VLMs - Aug'25 : prithivMLmods/multimodal-vlms-aug25-68a56aac39fe8084f3c168bd \u2794 VL caption \u2014 < Sep 15 \u201925 : prithivMLmods/vl-caption-sep-15-25-68c7f6d737985c63c13e2391 . . ....", "url": "https://huggingface.co/posts/prithivMLmods/704561076669428", "date_published": "2025-10-03T09:22:53.878434"}, {"id": "https://huggingface.co/posts/sergiopaniego/392040363386800", "image": "", "title": "Want to deploy open models using vLLM as the inference engine?", "content_text": "Want to deploy open models using vLLM as the inference engine? We just released a step-by-step guide on how to do it with @ huggingface Inference Endpoints, now available in the vLLM docs. let the gpus go brrr https://docs.vllm.ai/en/latest/deployment/frameworks/hf_inference_endpoints.html See translation", "url": "https://huggingface.co/posts/sergiopaniego/392040363386800", "date_published": "2025-10-03T09:22:53.878662"}]}