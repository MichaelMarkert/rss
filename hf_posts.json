{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/singhsidhukuldeep/815565847250252", "image": "", "title": "Exciting New Tool for Knowledge Graph Extraction from Plain Text!", "content_text": "Exciting New Tool for Knowledge Graph Extraction from Plain Text! I just came across a groundbreaking new tool called KGGen that's solving a major challenge in the AI world - the scarcity of high-quality knowledge graph data. KGGen is an open-source Python package that leverages language models to extract knowledge graphs (KGs) from plain text. What makes it special is its innovative approach to clustering related entities, which significantly reduces sparsity in the extracted KGs. The technical approach is fascinating: 1. KGGen uses a multi-stage process involving an LLM (GPT-4o in their implementation) to extract entities and relations from source text 2. It aggregates graphs across sources to reduce redundancy 3. Most importantly, it applies iterative LM-based clustering to refine the raw graph The clustering stage is particularly innovative - it identifies which nodes and edges refer to the same underlying entities or concepts. This normalizes variations in tense, plurality,...", "url": "https://huggingface.co/posts/singhsidhukuldeep/815565847250252", "date_published": "2025-03-05T09:23:33.027110"}, {"id": "https://huggingface.co/posts/clem/866977064333227", "image": "", "title": "Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months!", "content_text": "Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months! Nvidia's org: https://huggingface.co/nvidia Enterprise hub: https://huggingface.co/enterprise See translation", "url": "https://huggingface.co/posts/clem/866977064333227", "date_published": "2025-03-05T09:23:33.027414"}, {"id": "https://huggingface.co/posts/AdinaY/776127015570604", "image": "", "title": "Exciting releases from the Chinese community this February\ud83d\udd25", "content_text": "Exciting releases from the Chinese community this February\ud83d\udd25 \ud83d\udc49 zh-ai-community/2025-february-67a35aaa68e97812def5b6ef MLLM: \u2728 Ovis2 by Alibaba AIDC-AI/ovis2-67ab36c7e497429034874464 \u2728 Step Audio Chat by StepFun AI stepfun-ai/step-audio-67b33accf45735bb21131b0b Audio: \u2728 Step Audio TTS by StepFunAI stepfun-ai/Step-Audio-TTS-3B \u2728 InspireMusic by Alibaba https://huggingface.co/FunAudioLLM \u2728 Baichuan Audio by BaichuanAI baichuan-inc/Baichuan-Audio-Instruct Video: \u2728 Wan2.1 by Alibaba_Wan Wan-AI/Wan2.1-T2V-14B \u2728 Stepvideo-T2V by StepFun AI stepfun-ai/stepvideo-t2v \u2728 SkyReels-V1 by Skywork Skywork/skyreels-v1-67b34676ff65b4ec02d16307 \u2728 LLaDA-8B by RenminUniversity GSAI-ML/LLaDA-8B-Instruct MoE: \u2728 Moonlight-16B by MoonshotAI (Kimi) moonshotai/Moonlight-16B-A3B-Instruct Reasoning: \u2728 TinyR1-32B by Qihoo360 qihoo360/TinyR1-32B-Preview Dataset: \u2728 Chinese DeepSeek R1-Distill data -110k Congliu/Chinese-DeepSeek-R1-Distill-data-110k See translation", "url": "https://huggingface.co/posts/AdinaY/776127015570604", "date_published": "2025-03-05T09:23:33.027873"}, {"id": "https://huggingface.co/posts/davidberenstein1957/655300080970392", "image": "", "title": "\ud83e\udd4a Epic Agent Framework Showdown! Available today!", "content_text": "\ud83e\udd4a Epic Agent Framework Showdown! Available today! \ud83d\udd35 In the blue corner, the versatile challenger with a proven track record of knowledge retrieval: LlamaIndex! \ud83d\uded1 In the red corner, the defender, weighing in with lightweight efficiency: Hugging Face smolagents! \ud83d\udd17 URL: https://huggingface.co/agents-course We just published the LlamaIndex unit for the agents course, and it is set to offer a great contrast between the smolagents unit by looking at - What makes llama-index stand-out - How the LlamaHub is used for integrations - Creating QueryEngine components - Using agents and tools - Agentic and multi-agent workflows The team has been working flat-out on this for a few weeks. Supported by Logan Markewich and Laurie Voss over at LlamaIndex. Who won? You decide! See translation", "url": "https://huggingface.co/posts/davidberenstein1957/655300080970392", "date_published": "2025-03-05T09:23:33.028275"}, {"id": "https://huggingface.co/posts/Kseniase/433849056207490", "image": "", "title": "9 types of \"Chain-of-...\" approaches:", "content_text": "9 types of \"Chain-of-...\" approaches: Chain-of-Thought (CoT) prompting enhances reasoning in AI models by breaking down complex problems into step-by-step logical sequences. It continues proving its effectiveness, especially in top-performing reasoning models. However, there are other similar methods, that expand CoT and can be used for different purposes. Here are 9 of them: 1. Chain-of-Action-Thought (COAT) -> Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search (2502.02508) Helps model decide when to keep thinking, double-check their work, or try a different approach, using special guiding tokens. 2. Chain of Draft (CoD) -> Chain of Draft: Thinking Faster by Writing Less (2502.18600) It helps model generate short but meaningful reasoning steps, cutting costs and making processing faster 3. Chain-of-Agents -> Chain of Agents: Large Language Models Collaborating on Long-Context Tasks (2406.02818) Uses multi-agent...", "url": "https://huggingface.co/posts/Kseniase/433849056207490", "date_published": "2025-03-05T09:23:33.028907"}, {"id": "https://huggingface.co/posts/MohamedRashad/233650928001403", "image": "", "title": "I think we have released the best Arabic model under 25B at least based on", "content_text": "I think we have released the best Arabic model under 25B at least based on inceptionai/AraGen-Leaderboard Yehia = ALLaM-AI/ALLaM-7B-Instruct-preview + GRPO and its ranked number one model under the 25B parameter size mark. Now, i said \"i think\" not \"i am sure\" because this model used the same metric of evaluation the AraGen developers use (the 3C3H) as a reward model to improve its responses and this sparks the question. Is this something good for users or is it another type of overfitting that we don't want ? I don't know if this is a good thing or a bad thing but what i know is that you can try it from here: Navid-AI/Yehia-7B-preview or Download it for your personal experiments from here: Navid-AI/Yehia-7B-preview Ramadan Kareem \ud83c\udf19 See translation", "url": "https://huggingface.co/posts/MohamedRashad/233650928001403", "date_published": "2025-03-05T09:23:33.029316"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949", "image": "", "title": "Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!", "content_text": "Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free! duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset Access the full size dataset by creating an EDU account here- https://falcon.duality.ai/secure/documentation/ex3-dataset?sidebarMode=learn Or check it out in the linked HuggingFace dataset! What makes this dataset unique, useful, and capable of bridging the Sim2Real gap? \ud83d\udca0 The digital twins are not generated by AI, but instead crafted by 3D artists to be INDISTINGUISHABLE from the physical-world objects. This allows the training from this data to transfer into real-world applicability \ud83d\udca0 The simulation software, called FalconEditor, can easily create thousands of images with varying lighting, posing, occlusions, backgrounds, camera positions, and more. This enables robust model training. \ud83d\udca0 The labels are created along with the data. This not only saves large amounts of time, but also ensures the...", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949", "date_published": "2025-03-05T09:23:33.029837"}, {"id": "https://huggingface.co/posts/Yehor/619825346186306", "image": "", "title": "Published a stable version of Ukrainian Text-to-Speech library on GitHub and PyPI.", "content_text": "Published a stable version of Ukrainian Text-to-Speech library on GitHub and PyPI. Features: - Multi-speaker model: 2 female (Tetiana, Lada) + 1 male (Mykyta) voices; - Fine-grained control over speech parameters, including duration, fundamental frequency (F0), and energy; - High-fidelity speech generation using the RAD-TTS++ acoustic model; - Fast vocoding using Vocos; - Synthesizes long sentences effectively; - Supports a sampling rate of 44.1 kHz; - Tested on Linux environments and Windows/WSL; - Python API (requires Python 3.9 or later); - CUDA-enabled for GPU acceleration. Repository: https://github.com/egorsmkv/tts_uk See translation", "url": "https://huggingface.co/posts/Yehor/619825346186306", "date_published": "2025-03-05T09:23:33.030158"}, {"id": "https://huggingface.co/posts/davidberenstein1957/915880767531433", "image": "", "title": "\ud83e\udef8 New release to push vector search to the Hub with vicinity and work with any serialisable objects.", "content_text": "\ud83e\udef8 New release to push vector search to the Hub with vicinity and work with any serialisable objects. \ud83e\uddd1\u200d\ud83c\udfeb KNN, HNSW, USEARCH, ANNOY, PYNNDESCENT, FAISS, and VOYAGER. \ud83d\udd17 Example Repo: minishlab/my-vicinity-repo See translation", "url": "https://huggingface.co/posts/davidberenstein1957/915880767531433", "date_published": "2025-03-05T09:23:33.030425"}, {"id": "https://huggingface.co/posts/luigi12345/685788730899562", "image": "", "title": "\ud83e\udd73\ud83e\udd73Just achieved 25m 59s of research with plain ChatGPT \ud83d\udd25 Had it doing a complete internet search in just ONE call visiting 443 websites! Hard to beat huh!", "content_text": "\ud83e\udd73\ud83e\udd73Just achieved 25m 59s of research with plain ChatGPT \ud83d\udd25 Had it doing a complete internet search in just ONE call visiting 443 websites! Hard to beat huh! PROMPT IN COMMENTS See translation", "url": "https://huggingface.co/posts/luigi12345/685788730899562", "date_published": "2025-03-05T09:23:33.030682"}]}