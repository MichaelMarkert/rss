{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/cgeorgiaw/327580602040047", "image": "", "title": "\ud83d\ude80\ud83d\ude80\ud83d\ude80 The largest ever dataset of co-folded 3D protein-ligand structures just dropped on HF!!", "content_text": "\ud83d\ude80\ud83d\ude80\ud83d\ude80 The largest ever dataset of co-folded 3D protein-ligand structures just dropped on HF!! Meet SAIR (Structurally Augmented IC\u2085\u2080 Repository): 5M+ AI-generated complexes with experimentally measured drug potency data from SandboxAQ. \ud83d\ude80\ud83d\ude80\ud83d\ude80 Check it out and explore here: SandboxAQ/SAIR See translation", "url": "https://huggingface.co/posts/cgeorgiaw/327580602040047", "date_published": "2025-09-05T09:23:51.742790"}, {"id": "https://huggingface.co/posts/sergiopaniego/142151327157631", "image": "", "title": "You can now supercharge your TRL training pipelines with kernels", "content_text": "You can now supercharge your TRL training pipelines with kernels \ud83d\udc77 kernels is new library to load optimized compute kernels directly from the Hub Combined with TRL, it makes you developer experience smoother & faster. Check out the new guide to learn more! \ud83d\udd7a Learn \u27a1\ufe0f https://huggingface.co/docs/trl/main/en/kernels_hub See translation", "url": "https://huggingface.co/posts/sergiopaniego/142151327157631", "date_published": "2025-09-05T09:23:51.743091"}, {"id": "https://huggingface.co/posts/prithivMLmods/632863448558657", "image": "", "title": "FastVLMs by Apple are the talk of the week for edge device VLMs and also for consumer-grade VLMs on the Hub. They have some impressive demos available on the Hub for live captioning and inference tasks. Meanwhile, I\u2019m still exploring one of the coolest edge-device multimodal releases\u2014Liquid AI\u2019s LFM2-VL (450M and 1.6B). I\u2019ve also made a live camera video inference demo, which is capable of running on Colab\u2019s free-tier T4 GPU.", "content_text": "FastVLMs by Apple are the talk of the week for edge device VLMs and also for consumer-grade VLMs on the Hub. They have some impressive demos available on the Hub for live captioning and inference tasks. Meanwhile, I\u2019m still exploring one of the coolest edge-device multimodal releases\u2014Liquid AI\u2019s LFM2-VL (450M and 1.6B). I\u2019ve also made a live camera video inference demo, which is capable of running on Colab\u2019s free-tier T4 GPU. \ud83e\udd17Live Captioning Notebooks: \u27a0 LiquidAI LFM2 VL 1.6B Live Cam: https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LiquidAI-LFM2-VL-Live-Cam/LiquidAI_LFM2_VL_1_6B_Live_Cam.ipynb \u27a0 LiquidAI LFM2 VL 450M Live Cam: https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LiquidAI-LFM2-VL-Live-Cam/LiquidAI_LFM2_VL_450M_Live_Cam.ipynb \u2728I also made a demo for the FastVLM Live Captioning Notebook. \u27a0 FastVLM 0.5B Live Cam: https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/Apple-FastVLM-0.5B-Live-...", "url": "https://huggingface.co/posts/prithivMLmods/632863448558657", "date_published": "2025-09-05T09:23:51.743559"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/548344764221698", "image": "", "title": "Qwen Image LoRA trainings Stage 1 results and pre-made configs published - As low as training with 6 GB GPUs - Stage 2 research will hopefully improve quality even more - Images generated with 8-steps lightning LoRA + SECourses Musubi Tuner trained LoRA in 8 steps + 2x Latent Upscale", "content_text": "Qwen Image LoRA trainings Stage 1 results and pre-made configs published - As low as training with 6 GB GPUs - Stage 2 research will hopefully improve quality even more - Images generated with 8-steps lightning LoRA + SECourses Musubi Tuner trained LoRA in 8 steps + 2x Latent Upscale 1-click to install SECourses Musubi Tuner app and pre-made training configs shared here : https://www.patreon.com/posts/137551634 Hopefully a full video tutorial will be made after Stage 2 R&D trainings completed Example training made on the hardest training which is training a person and it works really good. Therefore, it shall work even much better on style training, item training, product training, character training and such Stage 1 took more than 35 unique R&D Qwen LoRA training 1-Click installer currently fully supporting Windows, RunPod (Linux & Cloud) and Massed Compute (Linux & recommend Cloud) training for literally every GPU like RTX 3000, 4000, 5000 series or H100, B200, L40, etc 28 images...", "url": "https://huggingface.co/posts/MonsterMMORPG/548344764221698", "date_published": "2025-09-05T09:23:51.744092"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/955693162356423", "image": "", "title": "We released a new competition!", "content_text": "We released a new competition! https://www.kaggle.com/competitions/grocery-items-multi-class-object-detection/overview Join to: \ud83d\udca1 Learn from others \ud83e\udd14 Develop your Sim2Real skills using simulation \ud83d\udcf8 Generate custom data on the cloud to improve your model \u2728 and more! See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/955693162356423", "date_published": "2025-09-05T09:23:51.744342"}, {"id": "https://huggingface.co/posts/salma-remyx/948973995269090", "image": "", "title": "GitRank", "content_text": "GitRank We built an agent to surface and implement high-potential ideas for your repo, asynchronously generating containers, tests, and PRs so you can evaluate what works and double down on it. Check out the demo: https://youtu.be/frgPsTclc1k Come replicate and specialize a test for your repo! GitRank is live on Remyx. Docs: https://docs.remyx.ai App: https://engine.remyx.ai Example PR here: https://github.com/smellslikeml/experimental-vqasynth/pull/727 See translation", "url": "https://huggingface.co/posts/salma-remyx/948973995269090", "date_published": "2025-09-05T09:23:51.744605"}, {"id": "https://huggingface.co/posts/eliebak/258004860353376", "image": "", "title": "Super excited to announce that our research team at Hugging Face will be doing an AMA on reddit r/LocalLLaMA.", "content_text": "Super excited to announce that our research team at Hugging Face will be doing an AMA on reddit r/LocalLLaMA. Come ask any questions to the team behind SmolLM, FineWeb and more! And who knows, maybe there\u2019ll be a shiny new release to talk about? Thursday 4th September, 8AM-11AM PST \ud83e\udd17 science See translation", "url": "https://huggingface.co/posts/eliebak/258004860353376", "date_published": "2025-09-05T09:23:51.744856"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/683040638338113", "image": "", "title": "I have concluded first 8 traininings of Qwen Image LoRA - we are not at the level of FLUX yet and next 8 trainings starting hopefully - 2656x2656px image generated with 8 steps Fast Qwen LoRA + myself trained LoRA :", "content_text": "I have concluded first 8 traininings of Qwen Image LoRA - we are not at the level of FLUX yet and next 8 trainings starting hopefully - 2656x2656px image generated with 8 steps Fast Qwen LoRA + myself trained LoRA : Grid test results shared here along with App installer : https://www.patreon.com/posts/137551634 See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/683040638338113", "date_published": "2025-09-05T09:23:51.745105"}, {"id": "https://huggingface.co/posts/hesamation/792197182072762", "image": "", "title": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns.", "content_text": "a senior engineer at google just dropped a 400-page free book on docs for review: agentic design patterns. the table of contents looks like everything you need to know about agents + code: > advanced prompt techniques > multi-agent patterns > tool use and MCP > you name it read it here: https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0#heading=h.pxcur8v2qagu you can also pre-order on Amazon (published by Springer) and the royalties goes to Save the Children: https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/ See translation", "url": "https://huggingface.co/posts/hesamation/792197182072762", "date_published": "2025-09-05T09:23:51.745382"}, {"id": "https://huggingface.co/posts/hannayukhymenko/737771230390400", "image": "", "title": "Releasing the Jupyter Agent Dataset! \ud83d\ude80", "content_text": "Releasing the Jupyter Agent Dataset! \ud83d\ude80 Built from 7 TB of real Kaggle datasets + 20k notebooks, creating real code exec traces using Qwen3-Coder and E2B. Training on this data dramatically improves the ability to execute code and analyze data. We ( @ baptistecolle @ hannayukhymenko @ lvwerra ) have created a novel synthetic data generation pipeline with efficient scaffolding, which gives a big performance boost after training your coding agent\ud83d\udd25With the help of real Kaggle notebooks and datasets we generate synthetic notebooks which aim to analyze datasets and answer factual questions about them more efficiently. We simulate a real code execution environment by prompting LLMs or with the help of E2B sandboxes. We have built a dataset of 50k+ high-quality LLM-generated notebooks which can help your agent become better at performing data analysis and question answering. Link: data-agents/jupyter-agent-dataset See translation", "url": "https://huggingface.co/posts/hannayukhymenko/737771230390400", "date_published": "2025-09-05T09:23:51.745779"}]}