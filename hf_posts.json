{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ronantakizawa/356197451153671", "image": "", "title": "Thank you", "content_text": "Thank you @ clem (Co-Founder & CEO of Hugging Face) for sharing my dataset on X / Twitter! ronantakizawa/github-top-developers #github #dataset See translation", "url": "https://huggingface.co/posts/ronantakizawa/356197451153671", "date_published": "2025-12-25T09:28:18.371653"}, {"id": "https://huggingface.co/posts/sergiopaniego/741361727784035", "image": "", "title": "The Christmas holidays are here! \ud83c\udf84", "content_text": "The Christmas holidays are here! \ud83c\udf84 Thinking about learning something new in AI? @ huggingface offers 12 FREE courses covering all the relevant topics, for every level of experience. A great challenge for the holidays (and worth saving for later \ud83d\ude44) Let\u2019s explore them! \ud83e\udde0 \ud835\udddf\ud835\udddf\ud835\udde0 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: large language models with HF tools https://huggingface.co/learn/llm-course \ud83e\udd16 \ud835\uddd4\ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: build and deploy AI agents https://huggingface.co/learn/agents-course \ud83c\udfa8 \ud835\uddd7\ud835\uddf6\ud835\uddf3\ud835\uddf3\ud835\ude02\ud835\ude00\ud835\uddf6\ud835\uddfc\ud835\uddfb \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: diffusion models with \ud83e\udd17 Diffusers https://huggingface.co/learn/diffusion-course \ud83d\udd0a \ud835\uddd4\ud835\ude02\ud835\uddf1\ud835\uddf6\ud835\uddfc \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: transformers for audio tasks https://huggingface.co/learn/audio-course \ud83c\udfae \ud835\uddd7\ud835\uddf2\ud835\uddf2\ud835\uddfd \ud835\udde5\ud835\udddf \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: deep reinforcement learning https://huggingface.co/learn/deep-rl-course \ud83d\udc41\ufe0f \ud835\uddd6\ud835\uddfc\ud835\uddfa\ud835\uddfa\ud835\ude02\ud835\uddfb\ud835\uddf6\ud835\ude01\ud835\ude06 \ud835\uddd6\ud835\uddfc\ud835\uddfa\ud835\uddfd\ud835\ude02\ud835\ude01\ud835\uddf2\ud835\uddff \ud835\udde9\ud835\uddf6\ud835\ude00\ud835\uddf6\ud835\uddfc\ud835\uddfb \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: modern computer vision with HF https://huggingface.co/learn/computer-vision-course \ud83e\uddbe \ud835\udde5\ud835\uddfc\ud835\uddef\ud835\uddfc\ud835\ude01\ud835\uddf6\ud835\uddf0\ud835\ude00 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2 (\ud835\udddf\ud835\uddf2\ud835\udde5\ud835\uddfc\ud835\uddef\ud835\uddfc\ud835\ude01): learning-based robotics https://huggingface.co/learn/robotics-course \ud83e\udde9 \ud835\udde0\ud835\uddd6\ud835\udde3 \ud835\uddd6\ud835\uddfc\ud835\ude02\ud835\uddff\ud835\ude00\ud835\uddf2: Model Context Protocol explained...", "url": "https://huggingface.co/posts/sergiopaniego/741361727784035", "date_published": "2025-12-25T09:28:18.372216"}, {"id": "https://huggingface.co/posts/danielhanchen/419718257011904", "image": "", "title": "You can now run GLM-4.7, the new 355B parameter SOTA model on your local device (128GB RAM).\u2728", "content_text": "You can now run GLM-4.7, the new 355B parameter SOTA model on your local device (128GB RAM).\u2728 The model achieves SOTA performance on coding, agentic and chat benchmarks. GGUF: unsloth/GLM-4.7-GGUF Guide: https://docs.unsloth.ai/models/glm-4.7 See translation", "url": "https://huggingface.co/posts/danielhanchen/419718257011904", "date_published": "2025-12-25T09:28:18.372471"}, {"id": "https://huggingface.co/posts/dhruv3006/662739287947138", "image": "", "title": "OpenAPI specs are a great way to describe APIs in a clear, standard format. They provide a full overview of endpoints, methods, parameters etc. which makes working with APIs easier and more consistent.", "content_text": "OpenAPI specs are a great way to describe APIs in a clear, standard format. They provide a full overview of endpoints, methods, parameters etc. which makes working with APIs easier and more consistent. Voiden lets you turn your OpenAPI spec into organized, ready-to-use API request files. Just import your OpenAPI file, and you can immediately browse your endpoints, grouped by tags, and start testing without any manual setup. The generated requests come pre-configured but fully editable, so you can customize them as you want. If you want to get started with your existing APIs or try out new ones, this can save you quite some time. Read the docs here : https://docs.voiden.md/docs/getting-started-section/getting-started/openapi-imports/ See translation", "url": "https://huggingface.co/posts/dhruv3006/662739287947138", "date_published": "2025-12-25T09:28:18.372789"}, {"id": "https://huggingface.co/posts/Jiaqi-hkust/177996283057314", "image": "", "title": "We have open-sourced Robust-R1 (AAAI 2026 Oral), a new paradigm in the field of anti-degradation and robustness enhancement for multimodal large models.", "content_text": "We have open-sourced Robust-R1 (AAAI 2026 Oral), a new paradigm in the field of anti-degradation and robustness enhancement for multimodal large models. Multimodal Large Language Models struggle to maintain reliable performance under extreme real-world visual degradations, which impede their practical robustness. Existing robust MLLMs predominantly rely on implicit training/adaptation that focuses solely on visual encoder generalization, suffering from limited interpretability and isolated optimization. To overcome these limitations, we propose Robust-R1, a novel framework that explicitly models visual degradations through structured reasoning chains. Our approach integrates: (i) supervised fine-tuning for degradation-aware reasoning foundations, (ii) reward-driven alignment for accurately perceiving degradation parameters, and (iii) dynamic reasoning depth scaling adapted to degradation intensity. To facilitate this approach, we introduce a specialized 11K dataset featuring...", "url": "https://huggingface.co/posts/Jiaqi-hkust/177996283057314", "date_published": "2025-12-25T09:28:18.373282"}, {"id": "https://huggingface.co/posts/nicolay-r/476967281276279", "image": "", "title": "Time-Effective LLM Querying in Information Retrieval Tasks", "content_text": "Time-Effective LLM Querying in Information Retrieval Tasks \ud83c\udfa4 Last week at Research Colloquium in Technische Universit\u00e4t Chemnitz, we presented a framework for time-effective data handling with prompting schemas. The video of the talk is now available \ud83d\udc47\ufe0f \ud83c\udfac\ufe0f Video: https://youtu.be/pa8jGOhHViI \ud83c\udf1f Framework (bulk-chain): https://github.com/nicolay-r/bulk-chain \ud83d\udd11 bulk-chain solves the following problems: \u2705 Effective handling CoT schema with big amount of prompts and parameters they are based on (batching policies) \u2705 Easy-to-apply for data-iterators (datasets handling) See translation", "url": "https://huggingface.co/posts/nicolay-r/476967281276279", "date_published": "2025-12-25T09:28:18.373609"}, {"id": "https://huggingface.co/posts/MikeDoes/649372647638290", "image": "", "title": "How do you protect your prompts without breaking them? You need a smart sanitizer. A new system called Pr\u03f5\u03f5mpt shows how.", "content_text": "How do you protect your prompts without breaking them? You need a smart sanitizer. A new system called Pr\u03f5\u03f5mpt shows how. The first, critical step in their solution is a high-performance Named Entity Recognition (NER) model to find the sensitive data. We're proud to see that these researchers, Amrita Roy Chowdhury, David Glukhov, Divyam Anshumaan, Prasad Chalasani, Nicolas Papernot, Somesh Jha, and Mihir Bellare from the University of Michigan, University of Toronto, University of Wisconsin-Madison, University of California, San Diego - Rady School of Management and Langroid Incorporated fine-tuned their NER model on 10 high-risk categories from the AI4Privacy dataset. This is a perfect win-win. Our open-source data helps provide the foundation for the critical detection engine, which in turn enables the community to build and test better solutions like Pr\u03f5\u03f5mpt's innovative use of encryption and Differential Privacy. \ud83d\udd17 Check out their paper for a deep dive into a formally private,...", "url": "https://huggingface.co/posts/MikeDoes/649372647638290", "date_published": "2025-12-25T09:28:18.374088"}, {"id": "https://huggingface.co/posts/inoculatemedia/435094377049574", "image": "", "title": "I\u2019m opening the waitlist for what I believe to be the most advanced multimodal bridge for A/V professionals. Txt2img, img2video, editing, export to ProRes, apply Luts, Pexels and TouchDesigner integrations,  music and voice gen, multichannel mixing.", "content_text": "I\u2019m opening the waitlist for what I believe to be the most advanced multimodal bridge for A/V professionals. Txt2img, img2video, editing, export to ProRes, apply Luts, Pexels and TouchDesigner integrations, music and voice gen, multichannel mixing. Announcing: Lilikoi by Haawke AI Teaser video made entirely with Lilikoi: https://youtu.be/-O7DH7vFkYg?si=q2t5t6WjQCk2Cp0w Https://Lilikoi.haawke.com Technical brief: https://haawke.com/technical_brief.html See translation", "url": "https://huggingface.co/posts/inoculatemedia/435094377049574", "date_published": "2025-12-25T09:28:18.374383"}, {"id": "https://huggingface.co/posts/ibragim-bad/331533607628990", "image": "", "title": "\ud83c\udf84 67,074 Qwen3-Coder OpenHands trajectories + 2 RFT checkpoints.", "content_text": "\ud83c\udf84 67,074 Qwen3-Coder OpenHands trajectories + 2 RFT checkpoints. We release: 67,000+ trajectories from 3,800 resolved issues in 1,800+ Python repos. About 3x more successful trajectories and 1.5x more repos than our previous dataset. Trajectories are long: on average 64 turns, up to 100 turns and 131k context length. > RFT on this data, SWE-bench Verified: Qwen3-30B-Instruct: 25.7% \u2192 50.3% Pass@1. Qwen3-235B-Instruct: 46.2% \u2192 61.7% Pass@1. Also strong gains on SWE-rebench September. > We also did massive evals. We run OpenHands with 100 and 500 turns. We compare models under both limits. We run on SWE-bench Verified and several months of SWE-rebench. !!! We also check tests written by the models. We measure how often tests are correct. We check how often the final patch passes its own tests. This gives a pool of tests for verifiers and auto graders. > Fully permissive licenses Dataset and models: https://huggingface.co/collections/nebius/openhands-trajectories Blog post:...", "url": "https://huggingface.co/posts/ibragim-bad/331533607628990", "date_published": "2025-12-25T09:28:18.374828"}, {"id": "https://huggingface.co/posts/AbstractPhil/420221970831752", "image": "", "title": "geofractal getting started guide available, bulk ablation for fusion, simple towers, oscillator capacity, and substructure systemic associative capacity.", "content_text": "geofractal getting started guide available, bulk ablation for fusion, simple towers, oscillator capacity, and substructure systemic associative capacity. Many formulas were tested, 92 tests for collectives, oscillation bulk experiments, and more. All of them either coalesce into the correct behavior or the failures are directly visible, which means the system is robust enough to declare some tools functionally valid but not scalable yet. ai-crash course available; https://github.com/AbstractEyes/geofractal/blob/main/ai_helpers/v101_claude_helpers.txt Feed GPT, Claude, or Grokk and they will assist. getting started guide; https://github.com/AbstractEyes/geofractal/blob/main/src/geofractal/router/GETTING_STARTED.md geofractal router architecture is in prototype phases; https://github.com/AbstractEyes/geofractal This is likely one of it's final growing phases before full production capacity is ramped up. The architecture is not for the novice, it's meant for experts to either get...", "url": "https://huggingface.co/posts/AbstractPhil/420221970831752", "date_published": "2025-12-25T09:28:18.375282"}]}