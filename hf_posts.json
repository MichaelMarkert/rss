{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/openfree/652290136793730", "image": "", "title": "\ud83d\ude80 Llama-4 Model-Based Agentic AI System Released!", "content_text": "\ud83d\ude80 Llama-4 Model-Based Agentic AI System Released! \ud83d\udd25 Introducing the Latest Llama-4 Models Hello AI enthusiasts! Today we're excited to introduce our free API service powered by the cutting-edge Llama-4-Maverick-17B and Llama-4-Scout-17B models! These state-of-the-art models will upgrade your AI experience with remarkable stability and speed. Link1: openfree/Llama-4-Maverick-17B-Research Link2: openfree/Llama-4-Scout-17B-Research \ud83e\udde0 The Innovation of Agentic AI: Deep Research Feature The standout feature of our service is the revolutionary \"Deep Research\" functionality! This innovative Agentic AI system includes: \ud83d\udd0d Optimized Keyword Extraction: LLM automatically generates the most effective keywords for searches \ud83c\udf10 Real-time Web Search: Collects the latest information through the SerpHouse API \ud83d\udcca Intelligent Information Analysis: Precise analysis utilizing the LLM's reasoning capabilities based on collected information \ud83d\udcdd Contextualized Response Generation: Provides accurate answers...", "url": "https://huggingface.co/posts/openfree/652290136793730", "date_published": "2025-04-09T09:25:30.126082"}, {"id": "https://huggingface.co/posts/seawolf2357/883323339740165", "image": "", "title": "\ud83c\udfa8 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition \ud83c\udf0f\u2728", "content_text": "\ud83c\udfa8 Ghibli-Style Image Generation with Multilingual Text Integration: FLUX.1 Hugging Face Edition \ud83c\udf0f\u2728 Hello creators! Today I'm introducing a special image generator that combines the beautiful aesthetics of Studio Ghibli with multilingual text integration! \ud83d\ude0d seawolf2357/Ghibli-Multilingual-Text-rendering \u2728 Key Features Ghibli-Style Image Generation - High-quality animation-style images based on FLUX.1 Multilingual Text Rendering - Support for Korean, Japanese, English, and all languages! \ud83c\uddf0\ud83c\uddf7\ud83c\uddef\ud83c\uddf5\ud83c\uddec\ud83c\udde7 Automatic Image Editing with Simple Prompts - Just input your desired text and you're done! Two Stylistic Variations Provided - Get two different results from a single prompt Full Hugging Face Spaces Support - Deploy and share instantly! \ud83d\ude80 How Does It Work? Enter a prompt describing your desired image (e.g., \"a cat sitting by the window\") Input the text you want to add (any language works!) Select the text position, size, and color Two different versions are automatically generated! \ud83d\udcaf...", "url": "https://huggingface.co/posts/seawolf2357/883323339740165", "date_published": "2025-04-09T09:25:30.126768"}, {"id": "https://huggingface.co/posts/openfree/925352420925810", "image": "", "title": "\ud83d\udd25 'Open Meme Studio': Your Creative Meme Factory \ud83c\udfad\u2728", "content_text": "\ud83d\udd25 'Open Meme Studio': Your Creative Meme Factory \ud83c\udfad\u2728 Hello everyone! Today I'm introducing 'Open Meme Studio', an amazing space where you can easily create and transform fun and original meme images. \ud83d\ude80 VIDraft/Open-Meme-Studio \ud83c\udfaf Taking Meme Creation to the Next Level! This application leverages the powerful Kolors model and IP-Adapter-Plus to upgrade your meme-making abilities. Go beyond simple image editing and experience a completely new meme world powered by AI! \ud83d\udee0\ufe0f Features You'll Love \ud83d\udcf8 Transform and reinterpret existing meme templates \ud83c\udfad Freely change expressions and poses \ud83d\udc53 Add props (sunglasses, hats, etc.) \ud83c\udfde\ufe0f Change backgrounds and composite characters \ud83c\udfa8 Apply various artistic styles \ud83d\udcaa Why 'Open Meme Studio' is So Effective Fast Meme Generation: High-quality memes completed in seconds Unlimited Creativity: Completely different results just by changing prompts User-Friendly Interface: Simple prompt input and image upload is all you need Fine-tuned Control: Adjust how much of...", "url": "https://huggingface.co/posts/openfree/925352420925810", "date_published": "2025-04-09T09:25:30.127440"}, {"id": "https://huggingface.co/posts/ginipick/807578740801859", "image": "", "title": "\ud83c\udfef Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! \u2728", "content_text": "\ud83c\udfef Open Ghibli Studio: Transform Your Photos into Ghibli-Style Artwork! \u2728 Hello AI enthusiasts! \ud83d\ude4b\u200d\u2640\ufe0f Today I'm introducing a truly magical project: Open Ghibli Studio \ud83c\udfa8 ginigen/FLUX-Open-Ghibli-Studio \ud83c\udf1f What Can It Do? Upload any regular photo and watch it transform into a beautiful, fantastical image reminiscent of Hayao Miyazaki's Studio Ghibli animations! \ud83c\udfde\ufe0f\u2728 \ud83d\udd27 How Does It Work? \ud83d\udcf8 Upload your photo \ud83e\udd16 Florence-2 AI analyzes the image and generates a description \u270f\ufe0f \"Ghibli style\" is added to the description \ud83c\udfad Magic transformation happens using the FLUX.1 model and Ghibli LoRA! \u2699\ufe0f Customization Options Want more control? Adjust these in the advanced settings: \ud83c\udfb2 Set a seed (for reproducible results) \ud83d\udccf Adjust image dimensions \ud83d\udd0d Guidance scale (prompt adherence) \ud83d\udd04 Number of generation steps \ud83d\udcab Ghibli style intensity \ud83d\ude80 Try It Now! Click the \"Transform to Ghibli Style\" button below to create your own Ghibli world! Ready to meet Totoro, Howl, Sophie, or Chihiro? \ud83c\udf08 \ud83c\udf3f Note: For best results,...", "url": "https://huggingface.co/posts/ginipick/807578740801859", "date_published": "2025-04-09T09:25:30.127949"}, {"id": "https://huggingface.co/posts/aiqtech/202174985893140", "image": "", "title": "\u2728 High-Resolution Ghibli Style Image Generator \u2728", "content_text": "\u2728 High-Resolution Ghibli Style Image Generator \u2728 \ud83c\udf1f Introducing FLUX Ghibli LoRA Hello everyone! Today I'm excited to present a special LoRA model for FLUX Dev.1. This model leverages a LoRA trained on high-resolution Ghibli images for FLUX Dev.1 to easily create beautiful Ghibli-style images with stunning detail! \ud83c\udfa8 space: aiqtech/FLUX-Ghibli-Studio-LoRA model: openfree/flux-chatgpt-ghibli-lora \ud83d\udd2e Key Features Trained on High-Resolution Ghibli Images - Unlike other LoRAs, this one is trained on high-resolution images, delivering sharper and more beautiful results Powered by FLUX Dev.1 - Utilizing the latest FLUX model for faster generation and superior quality User-Friendly Interface - An intuitive UI that allows anyone to create Ghibli-style images with ease Diverse Creative Possibilities - Express various themes in Ghibli style, from futuristic worlds to fantasy elements \ud83d\uddbc\ufe0f Sample Images Include \"Ghibli style\" in your prompts Try combining nature, fantasy elements, futuristic...", "url": "https://huggingface.co/posts/aiqtech/202174985893140", "date_published": "2025-04-09T09:25:30.128521"}, {"id": "https://huggingface.co/posts/danielhanchen/859959880164586", "image": "", "title": "You can now run Llama 4 on your own local device! \ud83e\udd99", "content_text": "You can now run Llama 4 on your own local device! \ud83e\udd99 Run our Dynamic 1.78-bit and 2.71-bit Llama 4 GGUFs: unsloth/Llama-4-Scout-17B-16E-Instruct-GGUF You can run them on llama.cpp and other inference engines. See our guide here: https://docs.unsloth.ai/basics/tutorial-how-to-run-and-fine-tune-llama-4 See translation", "url": "https://huggingface.co/posts/danielhanchen/859959880164586", "date_published": "2025-04-09T09:25:30.128809"}, {"id": "https://huggingface.co/posts/fdaudens/650208950263848", "image": "", "title": "I read the 456-page AI Index report so you don't have to (kidding). The wild part? While AI gets ridiculously more accessible, the power gap is actually widening:", "content_text": "I read the 456-page AI Index report so you don't have to (kidding). The wild part? While AI gets ridiculously more accessible, the power gap is actually widening: 1\ufe0f\u20e3 The democratization of AI capabilities is accelerating rapidly: - The gap between open and closed models is basically closed: difference in benchmarks like MMLU and HumanEval shrunk to just 1.7% in 2024 - The cost to run GPT-3.5-level performance dropped 280x in 2 years - Model size is shrinking while maintaining performance - Phi-3-mini hitting 60%+ MMLU at fraction of parameters of early models like PaLM 2\ufe0f\u20e3 But we're seeing concerning divides deepening: - Geographic: US private investment ($109B) dwarfs everyone else - 12x China's $9.3B - Research concentration: US and China dominate highly-cited papers (50 and 34 respectively in 2023), while next closest is only 7 - Gender: Major gaps in AI skill penetration rates - US shows 2.39 vs 1.71 male/female ratio The tech is getting more accessible but the benefits aren't...", "url": "https://huggingface.co/posts/fdaudens/650208950263848", "date_published": "2025-04-09T09:25:30.129290"}, {"id": "https://huggingface.co/posts/BrigitteTousi/559995441481207", "image": "", "title": "AI agents are transforming how we interact with technology, but how sustainable are they? \ud83c\udf0d", "content_text": "AI agents are transforming how we interact with technology, but how sustainable are they? \ud83c\udf0d Design choices \u2014 like model size and structure \u2014 can massively impact energy use and cost. \u26a1\ud83d\udcb0 The key takeaway: smaller, task-specific models can be far more efficient than large, general-purpose ones. \ud83d\udd11 Open-source models offer greater transparency, allowing us to track energy consumption and make more informed decisions on deployment. \ud83c\udf31 Open-source = more efficient, eco-friendly, and accountable AI. Read our latest, led by @ sasha with assists from myself + @ yjernite \ud83e\udd17 https://huggingface.co/blog/sasha/ai-agent-sustainability See translation", "url": "https://huggingface.co/posts/BrigitteTousi/559995441481207", "date_published": "2025-04-09T09:25:30.129678"}, {"id": "https://huggingface.co/posts/luigi12345/868237953690252", "image": "", "title": "\ud83d\ude80 Meta\u2019s Llama 4 Models Now on Hugging Face!", "content_text": "\ud83d\ude80 Meta\u2019s Llama 4 Models Now on Hugging Face! Meta has released Llama 4 Scout and Llama 4 Maverick, now available on Hugging Face: \u2022 Llama 4 Scout: 17B active parameters, 16-expert Mixture of Experts (MoE) architecture, 10M token context window, fits on a single H100 GPU. \ufffc \u2022 Llama 4 Maverick: 17B active parameters, 128-expert MoE architecture, 1M token context window, optimized for DGX H100 systems. \ufffc \ud83d\udd25 Key Features: \u2022 Native Multimodality: Seamlessly processes text and images. \ufffc \u2022 Extended Context Window: Up to 10 million tokens for handling extensive inputs. \u2022 Multilingual Support: Trained on 200 languages, with fine-tuning support for 12, including Arabic, Spanish, and German. \ufffc \ud83d\udee0\ufe0f Access and Integration: \u2022 Model Checkpoints: Available under the meta-llama organization on the Hugging Face Hub. \u2022 Transformers Compatibility: Fully supported in transformers v4.51.0 for easy loading and fine-tuning. \u2022 Efficient Deployment: Supports tensor-parallelism and automatic device mapping....", "url": "https://huggingface.co/posts/luigi12345/868237953690252", "date_published": "2025-04-09T09:25:30.130139"}, {"id": "https://huggingface.co/posts/jjokah/116151100507837", "image": "", "title": "# Video Tokenization \u2014 for efficient AI video processing", "content_text": "# Video Tokenization \u2014 for efficient AI video processing Meet \ud835\udc15\ud835\udc22\ud835\udc1d\ud835\udc13\ud835\udc28\ud835\udc24, a new open-source video tokenization technique developed by Microsoft Research to address the computational challenges of processing large volumes of video data. The core problem VidTok tackles is the inefficiency caused by redundant information in raw video pixels. VidTok converts complex video footage into compact, structured units called tokens, making it easier and more efficient for AI systems to analyze, understand, and generate video content. Research Paper: https://arxiv.org/abs/2412.13061 VidTok Code: https://github.com/microsoft/VidTok See translation", "url": "https://huggingface.co/posts/jjokah/116151100507837", "date_published": "2025-04-09T09:25:30.130494"}]}