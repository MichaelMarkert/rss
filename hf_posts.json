{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/zc277584121/729228721948980", "image": "", "title": "We've open-sourced a bilingual Semantic Highlighting model that can power multiple production scenarios:", "content_text": "We've open-sourced a bilingual Semantic Highlighting model that can power multiple production scenarios: 1) RAG Answer Highlighting \u2014 Automatically highlight the exact sentences that answer user queries, improving interpretability and helping users quickly locate relevant information. 2) RAG Noise Filtering \u2014 Prune irrelevant context before sending to LLMs, achieving 70-80% token cost reduction while improving answer quality by letting the model focus on what matters. 3) Search System Highlighting \u2014 Add semantic highlighting features to recommendation systems, e-commerce search, or any retrieval system where users need to see why a result is relevant. Try it out: zilliz/semantic-highlight-bilingual-v1 Read our article: https://huggingface.co/blog/zilliz/zilliz-semantic-highlight-model See translation", "url": "https://huggingface.co/posts/zc277584121/729228721948980", "date_published": "2026-01-17T05:25:48.510098"}, {"id": "https://huggingface.co/posts/YatharthS/729508768545264", "image": "", "title": "I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second!", "content_text": "I just released NovaSR, a tiny 52kb audio upsampler that can enhance 3600 seconds of muffled 16khz audio in to clearer 48khz audio in just 1 second! NovaSR can - Enhance TTS model quality. - Restore poor quality datasets. - Work on any device(just 52kb which is smaller than a 3 second audio file!) Model: YatharthS/NovaSR Space to try it: YatharthS/NovaSR Github repo: https://github.com/ysharma3501/NovaSR See translation", "url": "https://huggingface.co/posts/YatharthS/729508768545264", "date_published": "2026-01-17T05:25:48.510415"}, {"id": "https://huggingface.co/posts/danielhanchen/641905091288769", "image": "", "title": "You can now do reinforcement learning training with 7\u00d7 longer context and no accuracy loss, via our new batching algorithms.", "content_text": "You can now do reinforcement learning training with 7\u00d7 longer context and no accuracy loss, via our new batching algorithms. Long reasoning chains in RL are costly, but now we enable you to train gpt-oss with GRPO & reach 380K context on a 192GB GPU. Blog: https://unsloth.ai/docs/new/grpo-long-context See translation", "url": "https://huggingface.co/posts/danielhanchen/641905091288769", "date_published": "2026-01-17T05:25:48.510694"}, {"id": "https://huggingface.co/posts/RakshitAralimatti/271506431516041", "image": "", "title": "I built a crazy ultra\u2013low latency voice assistant agent using Pipecat, NVIDIA Riva, NVIDIA NIM, and an MCP\u2011powered tool stack. It can talk in real time, search the web, and manage your project directory files, document your code and docs hands\u2011free (create, read, summarise, and clean up).", "content_text": "I built a crazy ultra\u2013low latency voice assistant agent using Pipecat, NVIDIA Riva, NVIDIA NIM, and an MCP\u2011powered tool stack. It can talk in real time, search the web, and manage your project directory files, document your code and docs hands\u2011free (create, read, summarise, and clean up). Link - https://github.com/rakshit2020/Voice-Agent-using-Nvidia-Riva-NIM-Pipecat I put everything into a small demo repo with the full architecture diagram and a short demo video so you can see exactly how it works and adapt it to your own projects. Check out the GitHub, play with the agent, and let me know if it\u2019s useful or if you want a breakdown of any part of the setup. See translation", "url": "https://huggingface.co/posts/RakshitAralimatti/271506431516041", "date_published": "2026-01-17T05:25:48.511085"}, {"id": "https://huggingface.co/posts/hypothetical/126420354848703", "image": "", "title": "We thought it would be easier, but finally we have integrated CuDNN Paged Attention to our models!", "content_text": "We thought it would be easier, but finally we have integrated CuDNN Paged Attention to our models! Read article here: https://app.thestage.ai/blog/Integrating-cuDNN-Paged-Attention-to-TheStage-AI-Inference?id=8 Llama-8B with CuDNN paged attention, including B200 support: TheStageAI/Elastic-Llama-3.1-8B-Instruct Mistral-Small-24B with CuDNN paged attention, including B200 support: TheStageAI/Elastic-Mistral-Small-3.1-24B-Instruct-2503 See translation", "url": "https://huggingface.co/posts/hypothetical/126420354848703", "date_published": "2026-01-17T05:25:48.511369"}, {"id": "https://huggingface.co/posts/FreshmanD/375261612088441", "image": "", "title": "\ud83e\udd47 23 Kaggle Gold Medals. One Agent Framework.", "content_text": "\ud83e\udd47 23 Kaggle Gold Medals. One Agent Framework. Introducing LoongFlow: A Thinking & Learning Framework for Expert-Grade AI Agents. Unlike traditional evolve agents(like OpenEvolve-Style), LoongFlow implements the PES (Plan-Execute-Summary) paradigm to learn from mistakes and avoid local optima. \ud83d\ude80 Highlights: * SOTA: Surpassed human mathematicians on 11 geometry/algebra problems. * 23 Kaggle Gold Medals on MLE Bench. * Efficiency: 60% more efficient than current baselines. \ud83d\udd17 Code & Paper: https://github.com/baidu-baige/LoongFlow LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm (2512.24077) #AutoML #Kaggle #Agents #OpenSource #LLM See translation", "url": "https://huggingface.co/posts/FreshmanD/375261612088441", "date_published": "2026-01-17T05:25:48.511728"}, {"id": "https://huggingface.co/posts/wangbuer999/651831586227530", "image": "", "title": "HY-MT1.5-1.8B Lightweight Translation Model  Open-Source Game-Changer", "content_text": "HY-MT1.5-1.8B Lightweight Translation Model Open-Source Game-Changer Tencent raised the bar for lightweight translation! Supports bidirectional translation across 36 languages total\u201433 mainstream languages + 5 ethnic/minority dialects With only 1.8B parameters (less than 1/3 the size of HY-MT1.5-7B), it delivers performance on par with the 7B counterpart and outperforms most commercial translation APIs. \u2705 Quantized versions (FP8/GPTQ-Int4) available for edge device deployment, perfect for real-time translation \u2705 Full support for terminology intervention, context-aware translation, and formatted output \u2705 Ready-to-use prompt templates + seamless integration with Hugging Face Transformers \u2705 Recommended transformers \u2265 4.56.0 (FP8 model requires compressed-tensors 0.11.0) 10+ Hugging Face Spaces already integrated this model! \ud83d\udc49 Model Repo: tencent/HY-MT1.5-1.8B \ud83d\udc49 Technical Report: https://arxiv.org/abs/2512.24092 See translation", "url": "https://huggingface.co/posts/wangbuer999/651831586227530", "date_published": "2026-01-17T05:25:48.512155"}, {"id": "https://huggingface.co/posts/AdinaY/542466498854127", "image": "", "title": "We have a new heatmap live on huggingface now\ud83d\udd25", "content_text": "We have a new heatmap live on huggingface now\ud83d\udd25 woojun-jung/open-source-release-heatmap-ko Korean community built their own version to track labs that actively publish open work, inspired by Chinese open source heat map! This is the open source community at its best \u2665\ufe0f See translation", "url": "https://huggingface.co/posts/AdinaY/542466498854127", "date_published": "2026-01-17T05:25:48.512418"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/524524172408685", "image": "", "title": "Hey Hugging Face! I just wanted to share something I've been working on lately. This is Continuum, an app that started as a regular chat interface but quickly spiraled into much more!", "content_text": "Hey Hugging Face! I just wanted to share something I've been working on lately. This is Continuum, an app that started as a regular chat interface but quickly spiraled into much more! The left panel contains settings, different project workspaces with associated chat sessions, and the model drop down menu. The middle panel is the chat window with engaging color schemes for italics or bold characters. The right panel is the \"Loom\" - a collaborative document workspace for the AI model and the user to work together in markdown with a live preview toggle switch. The Loom supports differential edits allowing the user to reject, approve, or edit each model change/addition. Right now, Continuum will support BYOK, OAI compatible endpoints, and local models served through ollama/llama.cpp It's still very much a work in progress but I'm really happy with how it's coming along so far. I'm excited to share this demo with all of you when it's ready! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/524524172408685", "date_published": "2026-01-17T05:25:48.512772"}, {"id": "https://huggingface.co/posts/mmhamdy/849671126846274", "image": "", "title": "The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable length\ud83d\ude04", "content_text": "The new DeepSeek Engram paper is super fun! It also integrates mHC, and I suspect they're probably releasing all these papers to make the V4 report of reasonable length\ud83d\ude04 Here's a nice short summary from Gemini See translation", "url": "https://huggingface.co/posts/mmhamdy/849671126846274", "date_published": "2026-01-17T05:25:48.513003"}]}