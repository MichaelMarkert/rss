{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Ujjwal-Tyagi/869541950904709", "image": "", "title": "So, Koreans are also doing great progress behind Chinese,", "content_text": "So, Koreans are also doing great progress behind Chinese, Their two open source ai models that are actually good in coding. upstage/Solar-Open-100B skt/A.X-K1 See translation", "url": "https://huggingface.co/posts/Ujjwal-Tyagi/869541950904709", "date_published": "2026-01-21T13:50:04.540560"}, {"id": "https://huggingface.co/posts/marksverdhei/460500590246249", "image": "", "title": "Inspired by the heroes of day zero quants (", "content_text": "Inspired by the heroes of day zero quants ( @ TheBloke @ danielhanchen @ shimmyshimmer @ bartowski ), I decided to join the race by releasing the first FP8 quant of glm-4.7-flash! Not as easy as i expected, but I'm happy i was still able to have it working within a few hours after the original model was released! Interested in feedback if anyone wants to try it out! marksverdhei/GLM-4.7-Flash-FP8 Note: If my PR to vLLM isn't merged yet you might have to use my fork. Cheers! \ud83e\udd17 See translation", "url": "https://huggingface.co/posts/marksverdhei/460500590246249", "date_published": "2026-01-21T13:50:04.540953"}, {"id": "https://huggingface.co/posts/DawnC/976121143006478", "image": "", "title": "VividFlow: Complete AI Image Transformation Platform \ud83c\udfac\ud83c\udfa8\u2728", "content_text": "VividFlow: Complete AI Image Transformation Platform \ud83c\udfac\ud83c\udfa8\u2728 Three powerful creative tools in one streamlined workspace. VividFlow combines professional video generation, intelligent background replacement, and artistic style transfer to transform your images with precision and creativity. \ud83c\udfad Triple Creative Powers - Cinematic Video Generation transforms static images into smooth motion sequences from 0.5 to 5 seconds. Eight curated motion categories cover portraits, products, landscapes, and artistic content with precision-tuned templates. - Intelligent Background Replacement generates photorealistic scenes from 24 professionally crafted presets spanning studios, natural environments, urban settings, and seasonal atmospheres. Advanced edge refinement handles complex subjects, while the built-in Touch Up tool eliminates artifacts through AI-powered inpainting for flawless results. - Artistic Style Transfer converts photographs into stunning interpretations across six distinct styles...", "url": "https://huggingface.co/posts/DawnC/976121143006478", "date_published": "2026-01-21T13:50:04.541623"}, {"id": "https://huggingface.co/posts/danielhanchen/143027024579647", "image": "", "title": "Run GLM-4.7-Flash locally on your device with 24GB RAM!\ud83d\udd25", "content_text": "Run GLM-4.7-Flash locally on your device with 24GB RAM!\ud83d\udd25 It's the best performing 30B model on SWE-Bench and GPQA. With 200K context, it excels at coding, agents, chat & reasoning. GGUF: unsloth/GLM-4.7-Flash-GGUF Guide: https://unsloth.ai/docs/models/glm-4.7-flash See translation", "url": "https://huggingface.co/posts/danielhanchen/143027024579647", "date_published": "2026-01-21T13:50:04.541901"}, {"id": "https://huggingface.co/posts/AdinaY/893023705771972", "image": "", "title": "Z.ai just released a powerful lightweight option of GLM 4.7", "content_text": "Z.ai just released a powerful lightweight option of GLM 4.7 \u2728 30B total/3B active - MoE zai-org/GLM-4.7-Flash See translation", "url": "https://huggingface.co/posts/AdinaY/893023705771972", "date_published": "2026-01-21T13:50:04.542140"}, {"id": "https://huggingface.co/posts/projectlosangeles/732365874551092", "image": "", "title": "Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI!", "content_text": "Check out Orpheus Karaoke! Turn any MIDI into a unique Karaoke MIDI! projectlosangeles/Orpheus-Karaoke See translation", "url": "https://huggingface.co/posts/projectlosangeles/732365874551092", "date_published": "2026-01-21T13:50:04.542350"}, {"id": "https://huggingface.co/posts/efecelik/213200184330880", "image": "", "title": "Interesting paper: PhysRVG", "content_text": "Interesting paper: PhysRVG The core idea: instead of treating physics as a soft condition the model can work around during optimization, enforce it strictly via reinforcement learning. The paper focuses on rigid body dynamics - collisions, pendulums, free fall, rolling. PhysRVG: Physics-Aware Unified Reinforcement Learning for Video Generative Models (2601.11087) See translation", "url": "https://huggingface.co/posts/efecelik/213200184330880", "date_published": "2026-01-21T13:50:04.542602"}, {"id": "https://huggingface.co/posts/ZennyKenny/848353801795401", "image": "", "title": "\ud83d\ude0e My new personal website is live! Check out", "content_text": "\ud83d\ude0e My new personal website is live! Check out https://kennethhamilton.me to chat with an LLM about my professional skills and personal projects. \ud83d\ude48 Think of it like a really, really vain version of ChatGPT. See translation", "url": "https://huggingface.co/posts/ZennyKenny/848353801795401", "date_published": "2026-01-21T13:50:04.542857"}, {"id": "https://huggingface.co/posts/nyuuzyou/331224318760046", "image": "", "title": "\ud83c\udfdb\ufe0f Google Code Archive Dataset -", "content_text": "\ud83c\udfdb\ufe0f Google Code Archive Dataset - nyuuzyou/google-code-archive Expanding beyond the modern code series, this release presents a massive historical snapshot from the Google Code Archive. This dataset captures the open-source landscape from 2006 to 2016, offering a unique time capsule of software development patterns during the era before GitHub's dominance. Key Stats: - 65,825,565 files from 488,618 repositories - 47 GB compressed Parquet storage - 454 programming languages (Heavily featuring Java, PHP, and C++) - Extensive quality filtering (excluding vendor code and build artifacts) - Rich historical metadata: original repo names, file paths, and era-specific licenses This is one of those releases that I'm most interested in getting feedback on. Would you like to see more old code datasets? See translation", "url": "https://huggingface.co/posts/nyuuzyou/331224318760046", "date_published": "2026-01-21T13:50:04.543247"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/422829843470899", "image": "", "title": "NEW MODEL:", "content_text": "NEW MODEL: vanta-research/mox-small-1 Mox-Small-1 has landed on the Hub! Finetuned from the fantastic Olmo3.1 32B architecture by AllenAI, Mox-Small-1 was trained using the same datasets and methodology as Mox-Tiny-1, making this model our second addition to the Mox-1 family of models. Mox-1 is designed to prioritize clarity, honesty, and genuine utility over blind agreement. These models are perfect for when you want to be challenged in a constructive, helpful way. By utilizing Olmo3.1 32B's architecture, Mox-Small-1 brings greater conversational depth and reasoning quality to the Mox-1 model family. Check it out! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/422829843470899", "date_published": "2026-01-21T13:50:04.543540"}]}