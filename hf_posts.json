{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/aiqtech/202174985893140", "image": "", "title": "\u2728 High-Resolution Ghibli Style Image Generator \u2728", "content_text": "\u2728 High-Resolution Ghibli Style Image Generator \u2728 \ud83c\udf1f Introducing FLUX Ghibli LoRA Hello everyone! Today I'm excited to present a special LoRA model for FLUX Dev.1. This model leverages a LoRA trained on high-resolution Ghibli images for FLUX Dev.1 to easily create beautiful Ghibli-style images with stunning detail! \ud83c\udfa8 space: aiqtech/FLUX-Ghibli-Studio-LoRA model: openfree/flux-chatgpt-ghibli-lora \ud83d\udd2e Key Features Trained on High-Resolution Ghibli Images - Unlike other LoRAs, this one is trained on high-resolution images, delivering sharper and more beautiful results Powered by FLUX Dev.1 - Utilizing the latest FLUX model for faster generation and superior quality User-Friendly Interface - An intuitive UI that allows anyone to create Ghibli-style images with ease Diverse Creative Possibilities - Express various themes in Ghibli style, from futuristic worlds to fantasy elements \ud83d\uddbc\ufe0f Sample Images Include \"Ghibli style\" in your prompts Try combining nature, fantasy elements, futuristic...", "url": "https://huggingface.co/posts/aiqtech/202174985893140", "date_published": "2025-04-01T13:32:19.524536"}, {"id": "https://huggingface.co/posts/hanzla/237314499914963", "image": "", "title": "Hi all,", "content_text": "Hi all, Last week, I open sourced Free Search API. It allows sourcing results from top search engines (including google, bing) for free. It uses searxng instances for this purpose. I was overwhelmed by community's response and I am glad for all the support and suggestions. So today, I have pushed several improvements that make this API more stable. These improvements include 1) Parallel scrapping of search results for faster response 2) Markdown formatting of search results 3) Prioritizing SearXNG instances that have faster google response time 4) Update/Get endpoints for searxng instances. Github: https://github.com/HanzlaJavaid/Free-Search/tree/main Try the deployed version: https://freesearch.replit.app/docs I highly appreciate PRs, issues, stars, and any kind of feedback. Let's join hands, and make it real big! See translation", "url": "https://huggingface.co/posts/hanzla/237314499914963", "date_published": "2025-04-01T13:32:19.524912"}, {"id": "https://huggingface.co/posts/danielhanchen/465464088880734", "image": "", "title": "You can now run DeepSeek-V3-0324 on your own local device!", "content_text": "You can now run DeepSeek-V3-0324 on your own local device! Run our Dynamic 2.42 and 2.71-bit DeepSeek GGUFs: unsloth/DeepSeek-V3-0324-GGUF You can run them on llama.cpp and other inference engines. See our guide here: https://docs.unsloth.ai/basics/tutorial-how-to-run-deepseek-v3-0324-locally See translation", "url": "https://huggingface.co/posts/danielhanchen/465464088880734", "date_published": "2025-04-01T13:32:19.525192"}, {"id": "https://huggingface.co/posts/thomwolf/431321353076398", "image": "", "title": "The new DeepSite space is really insane for vibe-coders", "content_text": "The new DeepSite space is really insane for vibe-coders enzostvs/deepsite With the wave of vibe-coding-optimized LLMs like the latest open-source DeepSeek model (version V3-0324), you can basically prompt out-of-the-box and create any app and game in one-shot. It feels so powerful to me, no more complex framework or under-the-hood prompt engineering to have a working text-to-app tool. AI is eating the world and *open-source* AI is eating AI itself! PS: and even more meta is that the DeepSite app and DeepSeek model are both fully open-source code => time to start recursively improve? PPS: you still need some inference hosting unless you're running the 600B param model at home, so check the very nice list of HF Inference Providers for this model: deepseek-ai/DeepSeek-V3-0324 See translation", "url": "https://huggingface.co/posts/thomwolf/431321353076398", "date_published": "2025-04-01T13:32:19.525544"}, {"id": "https://huggingface.co/posts/aiqtech/518766175001571", "image": "", "title": "\ud83e\udd17 Hug Contributors", "content_text": "\ud83e\udd17 Hug Contributors Hugging Face Contributor Dashboard \ud83d\udc68\u200d\ud83d\udcbb\ud83d\udc69\u200d\ud83d\udcbb aiqtech/Contributors-Leaderboard \ud83d\udcca Key Features Contributor Activity Tracking: Visualize yearly and monthly contributions through interactive calendars Top 100 Rankings: Provide rankings based on models, spaces, and dataset contributions Detailed Analysis: Analyze user-specific contribution patterns and influence Visualization: Understand contribution activities at a glance through intuitive charts and graphs \ud83c\udf1f Core Visualization Elements Contribution Calendar: Track activity patterns with GitHub-style heatmaps Radar Chart: Visualize balance between models, spaces, datasets, and activity levels Monthly Activity Graph: Identify most active months and patterns Distribution Pie Chart: Analyze proportion by contribution type \ud83c\udfc6 Ranking System Rankings based on overall contributions, spaces, and models Automatic badges for top 10, 30, and 100 contributors Ranking visualization to understand your position in the community \ud83d\udca1 How...", "url": "https://huggingface.co/posts/aiqtech/518766175001571", "date_published": "2025-04-01T13:32:19.526099"}, {"id": "https://huggingface.co/posts/clem/267300235555885", "image": "", "title": "Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possible\u2014just look at the \u201cT\u201d in ChatGPT, which comes from the Transformer architecture openly shared by Google.", "content_text": "Before 2020, most of the AI field was open and collaborative. For me, that was the key factor that accelerated scientific progress and made the impossible possible\u2014just look at the \u201cT\u201d in ChatGPT, which comes from the Transformer architecture openly shared by Google. Then came the myth that AI was too dangerous to share, and companies started optimizing for short-term revenue. That led many major AI labs and researchers to stop sharing and collaborating. With OAI and sama now saying they're willing to share open weights again, we have a real chance to return to a golden age of AI progress and democratization\u2014powered by openness and collaboration, in the US and around the world. This is incredibly exciting. Let\u2019s go, open science and open-source AI! See translation", "url": "https://huggingface.co/posts/clem/267300235555885", "date_published": "2025-04-01T13:32:19.526501"}, {"id": "https://huggingface.co/posts/zamal/271014113300033", "image": "", "title": "DeepGit: Your GitHub Gold Digger! \ud83d\udcb0\ud83d\ude80", "content_text": "DeepGit: Your GitHub Gold Digger! \ud83d\udcb0\ud83d\ude80 Hey Hugging Face gang! Meet DeepGit\u2014my open-source sidekick that rips through GitHub to snag repos that fit you. Done with dead-end searches? Me too. Built it with LangGraph and some dope tricks: Embeddings grab the good stuff (HF magic, baby!) Re-ranking nails the best picks Snoops docs, code, and buzz in one slick flow Drops a clean list of hidden gems \ud83d\udc8e Unearth that sneaky ML lib or Python gem\u2014run python app.py or langgraph dev and boom! Peek it at https://github.com/zamalali/DeepGit . Fork it, tweak it, love it\u2014Docker\u2019s in, HF vibes are strong. Drop a \ud83c\udf1f or a crazy idea\u2014I\u2019m pumped to jam with you all! \ud83e\ude82 See translation", "url": "https://huggingface.co/posts/zamal/271014113300033", "date_published": "2025-04-01T13:32:19.526884"}, {"id": "https://huggingface.co/posts/openfree/214646053127729", "image": "", "title": "\ud83d\ude80 Gemma3-R1984-27B: Next Generation Agentic AI Platform", "content_text": "\ud83d\ude80 Gemma3-R1984-27B: Next Generation Agentic AI Platform Model Path: VIDraft/Gemma-3-R1984-27B Space: VIDraft/Gemma-3-R1984-27B git clone VIDraft/Gemma-3-R1984-27B \ud83d\udcab A New Frontier in AI Innovation Gemma3-R1984-27B is a powerful agentic AI platform built on Google's Gemma-3-27B model. It integrates state-of-the-art deep research via web search with multimodal file processing capabilities and handles long contexts up to 8,000 tokens. Designed for local deployment on independent servers using NVIDIA A100 GPUs, it provides high security and prevents data leakage. \ud83d\udd13 Uncensored and Unrestricted AI Experience Gemma3-R1984-27B comes with all censorship restrictions removed, allowing users to operate any persona without limitations. The model perfectly implements various roles and characters according to users' creative requests, providing unrestricted responses that transcend the boundaries of conventional AI. This unlimited interaction opens infinite possibilities across research, creative...", "url": "https://huggingface.co/posts/openfree/214646053127729", "date_published": "2025-04-01T13:32:19.527536"}, {"id": "https://huggingface.co/posts/Wauplin/747413191251683", "image": "", "title": "\u203c\ufe0f huggingface_hub's v0.30.0 is out with our biggest update of the past two years!", "content_text": "\u203c\ufe0f huggingface_hub's v0.30.0 is out with our biggest update of the past two years! Full release notes: https://github.com/huggingface/huggingface_hub/releases/tag/v0.30.0 . \ud83d\ude80 Ready. Xet. Go! Xet is a groundbreaking new protocol for storing large objects in Git repositories, designed to replace Git LFS. Unlike LFS, which deduplicates files, Xet operates at the chunk level\u2014making it a game-changer for AI builders collaborating on massive models and datasets. Our Python integration is powered by [xet-core]( https://github.com/huggingface/xet-core ), a Rust-based package that handles all the low-level details. You can start using Xet today by installing the optional dependency: pip install -U huggingface_hub[hf_xet] With that, you can seamlessly download files from Xet-enabled repositories! And don\u2019t worry\u2014everything remains fully backward-compatible if you\u2019re not ready to upgrade yet. Blog post: https://huggingface.co/blog/xet-on-the-hub Docs:...", "url": "https://huggingface.co/posts/Wauplin/747413191251683", "date_published": "2025-04-01T13:32:19.528195"}, {"id": "https://huggingface.co/posts/Yehor/460907086720491", "image": "", "title": "Are you interesting in different runtimes for AI models?", "content_text": "Are you interesting in different runtimes for AI models? Check out IREE (iree.dev), it convert models to MLIR and then execute on different platforms. I have tested it in Rust on CPU and CUDA: https://github.com/egorsmkv/eerie-yolo11 See translation", "url": "https://huggingface.co/posts/Yehor/460907086720491", "date_published": "2025-04-01T13:32:19.528452"}]}