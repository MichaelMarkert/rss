{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/singhsidhukuldeep/815565847250252", "image": "", "title": "Exciting New Tool for Knowledge Graph Extraction from Plain Text!", "content_text": "Exciting New Tool for Knowledge Graph Extraction from Plain Text! I just came across a groundbreaking new tool called KGGen that's solving a major challenge in the AI world - the scarcity of high-quality knowledge graph data. KGGen is an open-source Python package that leverages language models to extract knowledge graphs (KGs) from plain text. What makes it special is its innovative approach to clustering related entities, which significantly reduces sparsity in the extracted KGs. The technical approach is fascinating: 1. KGGen uses a multi-stage process involving an LLM (GPT-4o in their implementation) to extract entities and relations from source text 2. It aggregates graphs across sources to reduce redundancy 3. Most importantly, it applies iterative LM-based clustering to refine the raw graph The clustering stage is particularly innovative - it identifies which nodes and edges refer to the same underlying entities or concepts. This normalizes variations in tense, plurality,...", "url": "https://huggingface.co/posts/singhsidhukuldeep/815565847250252", "date_published": "2025-03-05T17:19:39.061710"}, {"id": "https://huggingface.co/posts/clem/866977064333227", "image": "", "title": "Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months!", "content_text": "Super happy to welcome Nvidia as our latest enterprise hub customer. They have almost 2,000 team members using Hugging Face, and close to 20,000 followers of their org. Can't wait to see what they'll open-source for all of us in the coming months! Nvidia's org: https://huggingface.co/nvidia Enterprise hub: https://huggingface.co/enterprise See translation", "url": "https://huggingface.co/posts/clem/866977064333227", "date_published": "2025-03-05T17:19:39.062061"}, {"id": "https://huggingface.co/posts/davidberenstein1957/655300080970392", "image": "", "title": "\ud83e\udd4a Epic Agent Framework Showdown! Available today!", "content_text": "\ud83e\udd4a Epic Agent Framework Showdown! Available today! \ud83d\udd35 In the blue corner, the versatile challenger with a proven track record of knowledge retrieval: LlamaIndex! \ud83d\uded1 In the red corner, the defender, weighing in with lightweight efficiency: Hugging Face smolagents! \ud83d\udd17 URL: https://huggingface.co/agents-course We just published the LlamaIndex unit for the agents course, and it is set to offer a great contrast between the smolagents unit by looking at - What makes llama-index stand-out - How the LlamaHub is used for integrations - Creating QueryEngine components - Using agents and tools - Agentic and multi-agent workflows The team has been working flat-out on this for a few weeks. Supported by Logan Markewich and Laurie Voss over at LlamaIndex. Who won? You decide! See translation", "url": "https://huggingface.co/posts/davidberenstein1957/655300080970392", "date_published": "2025-03-05T17:19:39.062473"}, {"id": "https://huggingface.co/posts/Undi95/824593315166092", "image": "", "title": "Hi there!", "content_text": "Hi there! If you want to create your own thinking model or do a better MistralThinker, I just uploaded my entire dataset made on Deepseek R1 and the axolotl config. (well I made them public) Axolotl config : Undi95/MistralThinker-v1.1 The dataset : Undi95/R1-RP-ShareGPT3 You can also read all I did on those two discord screenshot from two days ago, I'm a little lazy to rewrite all kek. Hope you will use them! See translation", "url": "https://huggingface.co/posts/Undi95/824593315166092", "date_published": "2025-03-05T17:19:39.062778"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949", "image": "", "title": "Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free!", "content_text": "Duality.ai just released a 1000 image dataset used to train a YOLOv8 model in multiclass object detection -- and it's 100% free! duality-robotics/YOLOv8-Multiclass-Object-Detection-Dataset Access the full size dataset by creating an EDU account here- https://falcon.duality.ai/secure/documentation/ex3-dataset?sidebarMode=learn Or check it out in the linked HuggingFace dataset! What makes this dataset unique, useful, and capable of bridging the Sim2Real gap? \ud83d\udca0 The digital twins are not generated by AI, but instead crafted by 3D artists to be INDISTINGUISHABLE from the physical-world objects. This allows the training from this data to transfer into real-world applicability \ud83d\udca0 The simulation software, called FalconEditor, can easily create thousands of images with varying lighting, posing, occlusions, backgrounds, camera positions, and more. This enables robust model training. \ud83d\udca0 The labels are created along with the data. This not only saves large amounts of time, but also ensures the...", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/775086617889949", "date_published": "2025-03-05T17:19:39.063290"}, {"id": "https://huggingface.co/posts/Yehor/619825346186306", "image": "", "title": "Published a stable version of Ukrainian Text-to-Speech library on GitHub and PyPI.", "content_text": "Published a stable version of Ukrainian Text-to-Speech library on GitHub and PyPI. Features: - Multi-speaker model: 2 female (Tetiana, Lada) + 1 male (Mykyta) voices; - Fine-grained control over speech parameters, including duration, fundamental frequency (F0), and energy; - High-fidelity speech generation using the RAD-TTS++ acoustic model; - Fast vocoding using Vocos; - Synthesizes long sentences effectively; - Supports a sampling rate of 44.1 kHz; - Tested on Linux environments and Windows/WSL; - Python API (requires Python 3.9 or later); - CUDA-enabled for GPU acceleration. Repository: https://github.com/egorsmkv/tts_uk See translation", "url": "https://huggingface.co/posts/Yehor/619825346186306", "date_published": "2025-03-05T17:19:39.063609"}, {"id": "https://huggingface.co/posts/luigi12345/685788730899562", "image": "", "title": "\ud83e\udd73\ud83e\udd73Just achieved 25m 59s of research with plain ChatGPT \ud83d\udd25 Had it doing a complete internet search in just ONE call visiting 443 websites! Hard to beat huh!", "content_text": "\ud83e\udd73\ud83e\udd73Just achieved 25m 59s of research with plain ChatGPT \ud83d\udd25 Had it doing a complete internet search in just ONE call visiting 443 websites! Hard to beat huh! PROMPT IN COMMENTS Check out the Massive Article created by the prompt: https://huggingface.co/blog/luigi12345/automating-lead-generation-with-ai See translation", "url": "https://huggingface.co/posts/luigi12345/685788730899562", "date_published": "2025-03-05T17:19:39.063895"}, {"id": "https://huggingface.co/posts/davidberenstein1957/915880767531433", "image": "", "title": "\ud83e\udef8 New release to push vector search to the Hub with vicinity and work with any serialisable objects.", "content_text": "\ud83e\udef8 New release to push vector search to the Hub with vicinity and work with any serialisable objects. \ud83e\uddd1\u200d\ud83c\udfeb KNN, HNSW, USEARCH, ANNOY, PYNNDESCENT, FAISS, and VOYAGER. \ud83d\udd17 Example Repo: minishlab/my-vicinity-repo See translation", "url": "https://huggingface.co/posts/davidberenstein1957/915880767531433", "date_published": "2025-03-05T17:19:39.064155"}, {"id": "https://huggingface.co/posts/Kseniase/433849056207490", "image": "", "title": "9 types of \"Chain-of-...\" approaches:", "content_text": "9 types of \"Chain-of-...\" approaches: Chain-of-Thought (CoT) prompting enhances reasoning in AI models by breaking down complex problems into step-by-step logical sequences. It continues proving its effectiveness, especially in top-performing reasoning models. However, there are other similar methods, that expand CoT and can be used for different purposes. Here are 9 of them: 1. Chain-of-Action-Thought (COAT) -> Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search (2502.02508) Helps model decide when to keep thinking, double-check their work, or try a different approach, using special guiding tokens. 2. Chain of Draft (CoD) -> Chain of Draft: Thinking Faster by Writing Less (2502.18600) It helps model generate short but meaningful reasoning steps, cutting costs and making processing faster 3. Chain-of-Agents -> Chain of Agents: Large Language Models Collaborating on Long-Context Tasks (2406.02818) Uses multi-agent...", "url": "https://huggingface.co/posts/Kseniase/433849056207490", "date_published": "2025-03-05T17:19:39.064696"}, {"id": "https://huggingface.co/posts/AdinaY/339226274130426", "image": "", "title": "CogView-4 is out\ud83d\udd25\ud83d\ude80 The SoTa OPEN text to image model by ZhipuAI", "content_text": "CogView-4 is out\ud83d\udd25\ud83d\ude80 The SoTa OPEN text to image model by ZhipuAI Model: THUDM/CogView4-6B Demo: THUDM-HF-SPACE/CogView4 \u2728 6B with Apache2.0 \u2728 Supports Chinese & English Prompts by ANY length \u2728 Generate Chinese characters within images \u2728 Creates images at any resolution within a given range See translation", "url": "https://huggingface.co/posts/AdinaY/339226274130426", "date_published": "2025-03-05T17:19:39.064995"}]}