{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Norod78/977626760436669", "image": "", "title": "Multilingual Tokenization Showdown", "content_text": "Multilingual Tokenization Showdown Analyzing 12 LLM Tokenizers Across 204 Languages. First, I've created a dataset with Wikipedia's \"Cat\" article text in 272 languages: Norod78/WikiCat-Multilingual For each language entry with at least 100 words, I tokenized the text using 12 tokenizers and calculated the \"Characters per token\" ratio and \"Word per token\" ratio. The higher this ratio is, the more information each token represents on average for that language (and perhaps allowing the llm to potentially learn more per-parameter if trained on a dataset of that language). You can see a slideshow summary of the results here: https://norod.github.io/wikicat-tokenizer-eval/tokenizer-slideshow.html I hope I interpreted the results correctly, I've made the code available on GitHub so you can re-create the raw results jsonl with this repo: https://github.com/Norod/wikicat-tokenizer-eval Post on X: https://x.com/Norod78/status/1984366900550266999 See translation", "url": "https://huggingface.co/posts/Norod78/977626760436669", "date_published": "2025-11-03T05:24:50.574460"}, {"id": "https://huggingface.co/posts/DavidAU/433692013361833", "image": "", "title": "*** Happy Halloween - Embrace the Horror ! ***", "content_text": "*** Happy Halloween - Embrace the Horror ! *** Unsloth fine tunes using in house horror dataset. Gemma 3 - 1B, 4B, two 12Bs and 27B (uploaded yesterday) Qwen 3 - 1.7B [two] - new today... and , 4B, 6B, 42B ... And 32 MORE horror models: https://huggingface.co/DavidAU/models?search=horror Collection: https://huggingface.co/collections/DavidAU/grand-horror-165b-horror-and-fiction-generation Enjoy ; See translation", "url": "https://huggingface.co/posts/DavidAU/433692013361833", "date_published": "2025-11-03T05:24:50.574725"}, {"id": "https://huggingface.co/posts/nouamanetazi/972464132222376", "image": "", "title": "After training \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25\ud835\udc0b\ud835\udc0c\ud835\udfd1 on \ud835\udfd1\ud835\udfd6\ud835\udfd2 \ud835\udc07\ud835\udfcf\ud835\udfce\ud835\udfce\ud835\udc2c for nearly a month, I've come to realize something most people overlook: \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc26\ud835\udc1a\ud835\udc24\ud835\udc1e-\ud835\udc28\ud835\udc2b-\ud835\udc1b\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc24 \ud835\udc1f\ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc22\ud835\udc27 \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20. \ud83d\udd25", "content_text": "After training \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25\ud835\udc0b\ud835\udc0c\ud835\udfd1 on \ud835\udfd1\ud835\udfd6\ud835\udfd2 \ud835\udc07\ud835\udfcf\ud835\udfce\ud835\udfce\ud835\udc2c for nearly a month, I've come to realize something most people overlook: \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc22\ud835\udc2c \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc26\ud835\udc1a\ud835\udc24\ud835\udc1e-\ud835\udc28\ud835\udc2b-\ud835\udc1b\ud835\udc2b\ud835\udc1e\ud835\udc1a\ud835\udc24 \ud835\udc1f\ud835\udc1a\ud835\udc1c\ud835\udc2d\ud835\udc28\ud835\udc2b \ud835\udc22\ud835\udc27 \ud835\udc0b\ud835\udc0b\ud835\udc0c \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20. \ud83d\udd25 Everyone talks about model architecture and data quality. And yes, those matter immensely. But here's what nobody tells you: when your training run fails at 2 AM because of mysterious \ud835\udc0d\ud835\udc02\ud835\udc02\ud835\udc0b \ud835\udc1e\ud835\udc2b\ud835\udc2b\ud835\udc28\ud835\udc2b\ud835\udc2c, or when your expensive GPU cluster is running at \ud835\udfd4\ud835\udfce% \ud835\udc1e\ud835\udc1f\ud835\udc1f\ud835\udc22\ud835\udc1c\ud835\udc22\ud835\udc1e\ud835\udc27\ud835\udc1c\ud835\udc32, the problem isn't your model. It's most probably a \ud835\udc26\ud835\udc22\ud835\udc2c\ud835\udc2e\ud835\udc2c\ud835\udc1e \ud835\udc28\ud835\udc1f \ud835\udc2d\ud835\udc21\ud835\udc1e \ud835\udc21\ud835\udc1a\ud835\udc2b\ud835\udc1d\ud835\udc30\ud835\udc1a\ud835\udc2b\ud835\udc1e. \ud83d\udee0\ufe0f Questions that seemed simple but had no clear answers: Why is \ud835\udc0c\ud835\udc28\ud835\udc04 \ud835\udc2d\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc2c\ud835\udc25\ud835\udc28\ud835\udc30\ud835\udc1e\ud835\udc2b \ud835\udc2d\ud835\udc21\ud835\udc1a\ud835\udc27 \ud835\udc1d\ud835\udc1e\ud835\udc27\ud835\udc2c\ud835\udc1e \ud835\udc26\ud835\udc28\ud835\udc1d\ud835\udc1e\ud835\udc25\ud835\udc2c? Which \ud835\udc0d\ud835\udc02\ud835\udc02\ud835\udc0b \ud835\udc1f\ud835\udc25\ud835\udc1a\ud835\udc20\ud835\udc2c should we actually set? How often should we checkpoint without killing throughput? That's why we built \ud835\udc13\ud835\udc21\ud835\udc1e \ud835\udc12\ud835\udc26\ud835\udc28\ud835\udc25 \ud835\udc13\ud835\udc2b\ud835\udc1a\ud835\udc22\ud835\udc27\ud835\udc22\ud835\udc27\ud835\udc20 \ud835\udc0f\ud835\udc25\ud835\udc1a\ud835\udc32\ud835\udc1b\ud835\udc28\ud835\udc28\ud835\udc24 \ud83d\udcd6: a complete guide covering everything from model architecture and data curation to the SmolLM3 training marathon, post-training techniques, and crucially, the \ud835\udc22\ud835\udc27\ud835\udc1f\ud835\udc2b\ud835\udc1a\ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc2e\ud835\udc1c\ud835\udc2d\ud835\udc2e\ud835\udc2b\ud835\udc1e \ud835\udc25\ud835\udc1a\ud835\udc32\ud835\udc1e\ud835\udc2b that most teams get wrong. We validated real vs...", "url": "https://huggingface.co/posts/nouamanetazi/972464132222376", "date_published": "2025-11-03T05:24:50.575320"}, {"id": "https://huggingface.co/posts/Shivansh000/941986646578616", "image": "", "title": "I am dedicating this weekend to practicing/reading the latest b(ook)log from hugging face. It is meant to be a guide for anyone trying to go from \u201cwe have a great dataset and GPUs\u201d to \u201cwe built a really strong model.\u201d Will share thoughts upon completion.", "content_text": "I am dedicating this weekend to practicing/reading the latest b(ook)log from hugging face. It is meant to be a guide for anyone trying to go from \u201cwe have a great dataset and GPUs\u201d to \u201cwe built a really strong model.\u201d Will share thoughts upon completion. Thanks for the treat @ eliebak @ ThomasWolf and HF team! HuggingFaceTB/smol-training-playbook See translation", "url": "https://huggingface.co/posts/Shivansh000/941986646578616", "date_published": "2025-11-03T05:24:50.575600"}, {"id": "https://huggingface.co/posts/sergiopaniego/207791817757812", "image": "", "title": "Sharing the slides from yesterday's talk about \"Fine Tuning with TRL\" from the", "content_text": "Sharing the slides from yesterday's talk about \"Fine Tuning with TRL\" from the @ TogetherAgent x @ huggingface workshop we hosted in our Paris office \ud83c\udf83! Link: https://github.com/sergiopaniego/talks/blob/main/fine_tuning_with_trl/Fine%20tuning%20with%20TRL%20(Oct%2025).pdf See translation", "url": "https://huggingface.co/posts/sergiopaniego/207791817757812", "date_published": "2025-11-03T05:24:50.575844"}, {"id": "https://huggingface.co/posts/Kseniase/468043722468280", "image": "", "title": "11 Fascinating new Policy Optimization techniques", "content_text": "11 Fascinating new Policy Optimization techniques Policy optimization (PO) algorithms are central to training AI models with preference-based feedback. In recent weeks, numerous new PO methods have emerged that build on or replace the popular PPO and GRPO, solving their issues. Here are 11 of them: 1. BAlanced Policy Optimization (BAPO) \u2192 BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping (2510.18927) Dynamically adjusting the clipping bounds in PPO-style updates to balance positive and negative gradients and prevent entropy collapse 2. Training-Free GRPO \u2192 Training-Free Group Relative Policy Optimization (2510.08191) Instead of using numeric rewards, it compares rollouts semantically to distill useful knowledge as a token prior, which is then applied during inference to guide the model\u2019s behavior 3. Asymmetric Importance Sampling Policy Optimization (ASPO) \u2192 ASPO: Asymmetric Importance Sampling Policy Optimization...", "url": "https://huggingface.co/posts/Kseniase/468043722468280", "date_published": "2025-11-03T05:24:50.576519"}, {"id": "https://huggingface.co/posts/ronantakizawa/591564562942305", "image": "", "title": "Introducing the Medical-o1-Reasoning-SFT-Japanese dataset \ud83c\udf89", "content_text": "Introducing the Medical-o1-Reasoning-SFT-Japanese dataset \ud83c\udf89 This dataset is a Japanese dataset consisting questions, reasoning, and answer results for complex medical topics. #japanese #medical #dataset ronantakizawa/Medical-o1-Reasoning-SFT-Japanese See translation", "url": "https://huggingface.co/posts/ronantakizawa/591564562942305", "date_published": "2025-11-03T05:24:50.576759"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/973176037226952", "image": "", "title": "New Datasets Published:", "content_text": "New Datasets Published: vanta-research/poetic-imagery-small vanta-research/excitement-small We are open sourcing two of our datasets today, which were used in the training of Apollo Astralis 8B and 4B. The first dataset, poetic-imagery-small is designed to give the model's responses a bit of \"depth\" to them in order to encourage curiosity and thought from the user. Additionally, the excitement-small dataset is designed to teach the model how to use \"excited\" language conversationally. This dataset was used on both Apollo Astralis models, which effectively demonstrate general excitement during user interaction. VANTA Research is an AI safety project which aims to research and develop language models aligned for all types of thinking. These datasets were created aligned with that mission, in addition to rigorous AI safety standards. See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/973176037226952", "date_published": "2025-11-03T05:24:50.577121"}, {"id": "https://huggingface.co/posts/DmitryRyumin/744756733617336", "image": "", "title": "\ud83d\ude80\ud83d\udc4c\ud83c\udf1f New Research Alert - ICCV 2025 (Oral)! \ud83c\udf1f\ud83e\udd0c\ud83d\ude80", "content_text": "\ud83d\ude80\ud83d\udc4c\ud83c\udf1f New Research Alert - ICCV 2025 (Oral)! \ud83c\udf1f\ud83e\udd0c\ud83d\ude80 \ud83d\udcc4 Title: Understanding Co-speech Gestures in-the-wild \ud83d\udd1d \ud83d\udcdd Description: JEGAL is a tri-modal model that learns from gestures, speech and text simultaneously, enabling devices to interpret co-speech gestures in the wild. \ud83d\udc65 Authors: @ sindhuhegde , K R Prajwal, Taein Kwon, and Andrew Zisserman \ud83d\udcc5 Conference: ICCV, 19 \u2013 23 Oct, 2025 | Honolulu, Hawai'i, USA \ud83c\uddfa\ud83c\uddf8 \ud83d\udcc4 Paper: Understanding Co-speech Gestures in-the-wild (2503.22668) \ud83c\udf10 Web Page: https://www.robots.ox.ac.uk/~vgg/research/jegal \ud83d\udcc1 Repository: https://github.com/Sindhu-Hegde/jegal \ud83d\udcfa Video: https://www.youtube.com/watch?v=TYFOLKfM-rM \ud83d\ude80 ICCV-2023-25-Papers: https://github.com/DmitryRyumin/ICCV-2023-25-Papers \ud83d\ude80 Added to the Human Modeling Section: https://github.com/DmitryRyumin/ICCV-2023-25-Papers/blob/main/sections/2025/main/human-modeling.md \ud83d\udcda More Papers: more cutting-edge research presented at other conferences in the DmitryRyumin/NewEraAI-Papers curated by @ DmitryRyumin \ud83d\udd0d Keywords:...", "url": "https://huggingface.co/posts/DmitryRyumin/744756733617336", "date_published": "2025-11-03T05:24:50.577584"}, {"id": "https://huggingface.co/posts/prithivMLmods/710644146568512", "image": "", "title": "A small blog post titled - Hall of Multimodal OCR VLMs and Demonstrations has been published on \u2197\ufe0f", "content_text": "A small blog post titled - Hall of Multimodal OCR VLMs and Demonstrations has been published on \u2197\ufe0f https://huggingface.co/blog/prithivMLmods/multimodal-ocr-vlms on behalf of strangervisionhf It discusses the latest trends in OCR models, the multilingual support offered by modern OCR systems, their unique capabilities, OCR benchmark model comparisons, transformer-based implementations, and strategies for streamlining transformers compatibility. See translation", "url": "https://huggingface.co/posts/prithivMLmods/710644146568512", "date_published": "2025-11-03T05:24:50.577866"}]}