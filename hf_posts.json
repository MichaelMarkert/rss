{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/Ujjwal-Tyagi/924115096887729", "image": "", "title": "For more better details and analysis, you can read the article here:", "content_text": "For more better details and analysis, you can read the article here: https://huggingface.co/blog/Ujjwal-Tyagi/steering-not-censoring , We are sleepwalking into a crisis. I am deeply concerned about AI model safety right now because, as the community rushes to roll out increasingly powerful open-source models, we are completely neglecting the most critical aspect: safety. It seems that nobody is seriously thinking about the potential consequences of unregulated model outputs or the necessity of robust guardrails. We are essentially planting the seeds for our own destruction if we prioritize raw performance over security. This negligence is terrifyingly evident when you look at the current landscape. Take Qwen Image 2512, for example; while it delivers undeniably strong performance, it has incredibly weak guardrails that make it dangerous to deploy. In stark contrast, Z Image might not get as much hype for its power, but it has much better safety guardrails than Qwen Image 2512. It is...", "url": "https://huggingface.co/posts/Ujjwal-Tyagi/924115096887729", "date_published": "2026-01-11T17:21:57.877973"}, {"id": "https://huggingface.co/posts/DawnC/872062429240283", "image": "", "title": "VividFlow: AI Image Enhancement & Video Generation \ud83c\udfac\ud83c\udfa8", "content_text": "VividFlow: AI Image Enhancement & Video Generation \ud83c\udfac\ud83c\udfa8 Bring your images to life with cinematic motion AND create stunning AI backgrounds! VividFlow combines professional-grade video generation with intelligent background replacement in one streamlined platform. \ud83c\udfad Dual Creative Powers Transform any static image into high-quality dynamic videos with smooth, natural motion ranging from 0.5 to 5 seconds. Choose from curated motion templates across 8 categories designed for portraits, products, landscapes, and artistic content. Create photorealistic backgrounds by selecting from 24 professionally crafted scene presets spanning studios, natural environments, urban settings, and artistic atmospheres...etc. \u26a1 Optimized Performance Video generation currently completes in 4-5 minutes with active optimization underway to dramatically reduce processing time. Background replacement finishes in 30-40 seconds after initial loading. The independent dual-tab design ensures smooth workflow without...", "url": "https://huggingface.co/posts/DawnC/872062429240283", "date_published": "2026-01-11T17:21:57.878630"}, {"id": "https://huggingface.co/posts/sergiopaniego/609901844144152", "image": "", "title": "New GRPO + TRL free Colab notebook out! \ud83d\udd25", "content_text": "New GRPO + TRL free Colab notebook out! \ud83d\udd25 Fine-tune 7B+ models on T4 GPUs thanks to a ton of memory optimizations for GRPO 7B model uses only 9.2 GB VRAM (~7\u00d7 reduction) \ud83e\udd2f Try the notebook here \ud83d\udc49 https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_trl_lora_qlora.ipynb See translation", "url": "https://huggingface.co/posts/sergiopaniego/609901844144152", "date_published": "2026-01-11T17:21:57.878921"}, {"id": "https://huggingface.co/posts/hypothetical/242547767593660", "image": "", "title": "We have updated our transcription model:", "content_text": "We have updated our transcription model: TheStageAI/thewhisper-large-v3-turbo \u2013 6.00 WER on the English Open ASR Leaderboard \u2013 4.74 WER on the Multilingual Open ASR Leaderboard \u2013 Beats NVIDIA Parakeet (6.34 WER) and Whisper-large-v3-turbo (7.8 WER) \u2013 Strong improvements in Arabic, Hindi, Chinese \u2013 Maintains quality with background and environmental noise \u2013 Optimized inference engines for NVIDIA and Apple \u2013 Hugging Face Transformers interface for easy use \u2013 Best-in-class speed on NVIDIA GPUs and power efficiency on Apple devices \u2013 NVIDIA Jetson Thor support See translation", "url": "https://huggingface.co/posts/hypothetical/242547767593660", "date_published": "2026-01-11T17:21:57.879278"}, {"id": "https://huggingface.co/posts/Reality123b/635291729211142", "image": "", "title": "Happy birthday to me!!!", "content_text": "Happy birthday to me!!! See translation", "url": "https://huggingface.co/posts/Reality123b/635291729211142", "date_published": "2026-01-11T17:21:57.879467"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/111185407753079", "image": "", "title": "Atom-80B is out!:", "content_text": "Atom-80B is out!: vanta-research/atom-80b I'm excited to share the new Atom-80B from VANTA Research! A few days ago we released the largest model-to-date from our portfolio, which was Atom-27B. We've quickly scaled up to the new Qwen3 Next 80B architecture, bringing our friendly, curious, and collaborative Atom persona to cutting edge lightweight, high parameter inference. Atom is designed to work and think alongside you through curious exploration. Using Atom collaboratively in your work can help spark your own creativity or curiosity. Give it a try! See translation", "url": "https://huggingface.co/posts/unmodeled-tyler/111185407753079", "date_published": "2026-01-11T17:21:57.879781"}, {"id": "https://huggingface.co/posts/prithivMLmods/771186692524026", "image": "", "title": "LTX-2 Camera-Control LoRA demo with dolly-in/out and dolly-left/right is now available on Hugging Face, paired with ltx-2-19b-distilled-lora for fast inference. It also includes dynamic GPU duration adjustments for long video generations. Click the related Space links below.", "content_text": "LTX-2 Camera-Control LoRA demo with dolly-in/out and dolly-left/right is now available on Hugging Face, paired with ltx-2-19b-distilled-lora for fast inference. It also includes dynamic GPU duration adjustments for long video generations. Click the related Space links below. \ud83e\udd17Try it now on : prithivMLmods/LTX-2-LoRAs-Camera-Control-Dolly \u2b50Github: https://github.com/PRITHIVSAKTHIUR/LTX-2-LoRAs-Camera-Control-Dolly \ud83d\udd79\ufe0fCollection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection To learn more, visit the app page or the respective model pages. See translation", "url": "https://huggingface.co/posts/prithivMLmods/771186692524026", "date_published": "2026-01-11T17:21:57.880121"}, {"id": "https://huggingface.co/posts/branikita/526284345540053", "image": "", "title": "Our engineer Alan from", "content_text": "Our engineer Alan from https://robonine.com team has assembled the mechanical frame of our 6-DoF manipulator prototype - without servo motors for now. At this stage we are evaluating how easy the structure is to assemble, checking for any mechanical play, and validating the kinematics. Good news: the structure feels solid and Alan reports no detectable backlash so far. See translation", "url": "https://huggingface.co/posts/branikita/526284345540053", "date_published": "2026-01-11T17:21:57.880371"}, {"id": "https://huggingface.co/posts/de-Rodrigo/941101663333132", "image": "", "title": "We are happy to share the VERSE Methodology paper via arXiv! \ud83d\udcc3\ud83d\udcab", "content_text": "We are happy to share the VERSE Methodology paper via arXiv! \ud83d\udcc3\ud83d\udcab VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding (2601.05125) We usually train VLMs on visual synthetic data that we (as humans) label as photorealistic. We argue that this is an anthropocentric perspective imposed to a model that might not synthetize visual information as we do. VERSE helps to visualize latent space and overlay visual features to detect poor-performance regions and take action to include better-suited training sets to boost model performance. Resources: - Code: https://github.com/nachoDRT/VrDU-Doctor - Hugging Face Space: de-Rodrigo/Embeddings Want to collaborate? Do you have any feedback? \ud83e\uddd0 PD: As always, we are grateful to Hugging Face \ud83e\udd17 for providing the fantastic tools and resources we find on the platform! See translation", "url": "https://huggingface.co/posts/de-Rodrigo/941101663333132", "date_published": "2026-01-11T17:21:57.880787"}, {"id": "https://huggingface.co/posts/AdinaY/745173620987102", "image": "", "title": "Wechat AI is shipping!", "content_text": "Wechat AI is shipping! WeDLM \ud83d\udd25 A new language model that generates tokens in parallel, making it faster than standard LLMs , with the same Transformer setup! https://huggingface.co/collections/tencent/wedlm \u2728 7B/8B - Base & Instruct \u2728 Apache 2.0 See translation", "url": "https://huggingface.co/posts/AdinaY/745173620987102", "date_published": "2026-01-11T17:21:57.881029"}]}