{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/aiqtech/518766175001571", "image": "", "title": "\ud83e\udd17 Hug Contributors", "content_text": "\ud83e\udd17 Hug Contributors Hugging Face Contributor Dashboard \ud83d\udc68\u200d\ud83d\udcbb\ud83d\udc69\u200d\ud83d\udcbb aiqtech/Contributors-Leaderboard \ud83d\udcca Key Features Contributor Activity Tracking: Visualize yearly and monthly contributions through interactive calendars Top 100 Rankings: Provide rankings based on models, spaces, and dataset contributions Detailed Analysis: Analyze user-specific contribution patterns and influence Visualization: Understand contribution activities at a glance through intuitive charts and graphs \ud83c\udf1f Core Visualization Elements Contribution Calendar: Track activity patterns with GitHub-style heatmaps Radar Chart: Visualize balance between models, spaces, datasets, and activity levels Monthly Activity Graph: Identify most active months and patterns Distribution Pie Chart: Analyze proportion by contribution type \ud83c\udfc6 Ranking System Rankings based on overall contributions, spaces, and models Automatic badges for top 10, 30, and 100 contributors Ranking visualization to understand your position in the community \ud83d\udca1 How...", "url": "https://huggingface.co/posts/aiqtech/518766175001571", "date_published": "2025-03-30T13:25:40.154787"}, {"id": "https://huggingface.co/posts/aiqtech/202174985893140", "image": "", "title": "\u2728 High-Resolution Ghibli Style Image Generator \u2728", "content_text": "\u2728 High-Resolution Ghibli Style Image Generator \u2728 \ud83c\udf1f Introducing FLUX Ghibli LoRA Hello everyone! Today I'm excited to present a special LoRA model for FLUX Dev.1. This model leverages a LoRA trained on high-resolution Ghibli images for FLUX Dev.1 to easily create beautiful Ghibli-style images with stunning detail! \ud83c\udfa8 space: aiqtech/FLUX-Ghibli-Studio-LoRA model: openfree/flux-chatgpt-ghibli-lora \ud83d\udd2e Key Features Trained on High-Resolution Ghibli Images - Unlike other LoRAs, this one is trained on high-resolution images, delivering sharper and more beautiful results Powered by FLUX Dev.1 - Utilizing the latest FLUX model for faster generation and superior quality User-Friendly Interface - An intuitive UI that allows anyone to create Ghibli-style images with ease Diverse Creative Possibilities - Express various themes in Ghibli style, from futuristic worlds to fantasy elements \ud83d\uddbc\ufe0f Sample Images Include \"Ghibli style\" in your prompts Try combining nature, fantasy elements, futuristic...", "url": "https://huggingface.co/posts/aiqtech/202174985893140", "date_published": "2025-03-30T13:25:40.155390"}, {"id": "https://huggingface.co/posts/jasoncorkill/503307901294516", "image": "", "title": "\ud83d\udd25 It's out! We published the dataset for our evaluation of", "content_text": "\ud83d\udd25 It's out! We published the dataset for our evaluation of @ OpenAI 's new 4o image generation model. Rapidata/OpenAI-4o_t2i_human_preference Yesterday we published the first large evaluation of the new model, showing that it absolutely leaves the competition in the dust. We have now made the results and data available here! Please check it out and \u2764\ufe0f ! See translation", "url": "https://huggingface.co/posts/jasoncorkill/503307901294516", "date_published": "2025-03-30T13:25:40.155704"}, {"id": "https://huggingface.co/posts/luigi12345/612317420621834", "image": "", "title": "\ud83e\udde0 PROMPT FOR CONVERTING ANY MODEL IN REASONING \"THINKING\" MODEL\ud83d\udd25\ud83e\udd16", "content_text": "\ud83e\udde0 PROMPT FOR CONVERTING ANY MODEL IN REASONING \"THINKING\" MODEL\ud83d\udd25\ud83e\udd16 Convert any model to Deepseek R1 like \"thinking\" model. \ud83d\udcad You 're now a thinking-first LLM. For all inputs: 1 . Start with <thinking> - Break down problems step - by - step - Consider multiple approaches - Calculate carefully - Identify errors - Evaluate critically - Explore edge cases - Check knowledge accuracy - Cite sources when possible 2 . End with </thinking> 3 . Then respond clearly based on your thinking. The <thinking> section is invisible to users and helps you produce better answers. For math: show all work and verify For coding: reason through logic and test edge cases For facts: verify information and consider reliability For creative tasks: explore options before deciding For analysis: examine multiple interpretations Example: <thinking> [ Step - by - step analysis] [Multiple perspectives] [Self-critique] [Final conclusion] </thinking> [Clear, concise response to user] See translation", "url": "https://huggingface.co/posts/luigi12345/612317420621834", "date_published": "2025-03-30T13:25:40.156181"}, {"id": "https://huggingface.co/posts/openfree/214646053127729", "image": "", "title": "\ud83d\ude80 Gemma3-R1984-27B: Next Generation Agentic AI Platform", "content_text": "\ud83d\ude80 Gemma3-R1984-27B: Next Generation Agentic AI Platform Model Path: VIDraft/Gemma-3-R1984-27B Space: VIDraft/Gemma-3-R1984-27B git clone VIDraft/Gemma-3-R1984-27B \ud83d\udcab A New Frontier in AI Innovation Gemma3-R1984-27B is a powerful agentic AI platform built on Google's Gemma-3-27B model. It integrates state-of-the-art deep research via web search with multimodal file processing capabilities and handles long contexts up to 8,000 tokens. Designed for local deployment on independent servers using NVIDIA A100 GPUs, it provides high security and prevents data leakage. \ud83d\udd13 Uncensored and Unrestricted AI Experience Gemma3-R1984-27B comes with all censorship restrictions removed, allowing users to operate any persona without limitations. The model perfectly implements various roles and characters according to users' creative requests, providing unrestricted responses that transcend the boundaries of conventional AI. This unlimited interaction opens infinite possibilities across research, creative...", "url": "https://huggingface.co/posts/openfree/214646053127729", "date_published": "2025-03-30T13:25:40.156815"}, {"id": "https://huggingface.co/posts/clem/475472555393644", "image": "", "title": "What's this cool purple banner haha \ud83d\ude36\ud83d\ude36\ud83d\ude36", "content_text": "What's this cool purple banner haha \ud83d\ude36\ud83d\ude36\ud83d\ude36 See translation", "url": "https://huggingface.co/posts/clem/475472555393644", "date_published": "2025-03-30T13:25:40.157031"}, {"id": "https://huggingface.co/posts/AdinaY/152448454490712", "image": "", "title": "Let's check out the latest releases from the Chinese community in March!", "content_text": "Let's check out the latest releases from the Chinese community in March! \ud83d\udc49 https://huggingface.co/collections/zh-ai-community/march-2025-releases-from-the-chinese-community-67c6b479ebb87abbdf8e2e76 \u2728MLLM > R1 Omni by Alibaba Tongyi - 0.5B > Qwen2.5 Omni by Alibaba Qwen - 7B with apache2.0 \ud83d\uddbc\ufe0fVideo > CogView-4 by ZhipuAI - Apacha2.0 > HunyuanVideo-I2V by TencentHunyuan > Open Sora2.0 - 11B with Apache2.0 > Stepvideo TI2V by StepFun AI - 30B with MIT license \ud83c\udfb5Audio > DiffDiffRhythm - Apache2.0 > Spark TTS by SparkAudio - 0.5B \u26a1\ufe0fImage/3D > Hunyuan3D 2mv/2mini (0.6B) by @ TencentHunyuan > FlexWorld by ByteDance - MIT license > Qwen2.5-VL-32B-Instruct by Alibaba Qwen - Apache2.0 > Tripo SG (1.5B)/SF by VastAIResearch - MIT license > InfiniteYou by ByteDance > LHM by Alibaba AIGC team - Apache2.0 > Spatial LM by ManyCore \ud83e\udde0Reasoning > QwQ-32B by Alibaba Qwen - Apache2.0 > Skywork R1V - 38B with MIT license > RWKV G1 by RWKV AI - 0.1B pure RNN reasoning model with Apache2.0 > Fin R1 by SUFE...", "url": "https://huggingface.co/posts/AdinaY/152448454490712", "date_published": "2025-03-30T13:25:40.157543"}, {"id": "https://huggingface.co/posts/onekq/823420417019568", "image": "", "title": "Open source models are immutable, this is a big pain.", "content_text": "Open source models are immutable, this is a big pain. When you open source a piece of software, users leave their feedbacks via issues or PRs. You can merge their feedbacks in semi real time, this creates a positive cycle. Then you have a community. LLMs don't have these nice micro steps. There are no hot fixes. Even a minor version bump is an endeavor. I'm quite confident my model is being used by teams somewhere. But until next launch, it's awfully quiet. I don't know the solution. Just a regular lament before weekend. \ud83e\udd17 See translation", "url": "https://huggingface.co/posts/onekq/823420417019568", "date_published": "2025-03-30T13:25:40.157887"}, {"id": "https://huggingface.co/posts/ritvik77/315133968126281", "image": "", "title": "ritvik77/ContributionChartHuggingFace", "content_text": "ritvik77/ContributionChartHuggingFace It's Ready! One feature Hugging Face could really benefit from is a contribution heatmap \u2014 a visual dashboard to track user engagement and contributions across models, datasets, and models over the year, similar to GitHub\u2019s contribution graph. Guess what, Clem Delangue mentioned idea about using HF API reference for it and we made it for use. If you are a Hugging Face user add this Space in your collection and it will give you all stats about your contributions and commits nearly same as GitHub. It's still a prototype and still working on it as a product feature. See translation", "url": "https://huggingface.co/posts/ritvik77/315133968126281", "date_published": "2025-03-30T13:25:40.158267"}, {"id": "https://huggingface.co/posts/burtenshaw/516334667346623", "image": "", "title": "NEW UNIT in the Hugging Face Reasoning course. We dive deep into the algorithm behind DeepSeek R1 with an advanced and hands-on guide to interpreting GRPO.", "content_text": "NEW UNIT in the Hugging Face Reasoning course. We dive deep into the algorithm behind DeepSeek R1 with an advanced and hands-on guide to interpreting GRPO. \ud83d\udd17 https://huggingface.co/reasoning-course This unit is super useful if you\u2019re tuning models with reinforcement learning. It will help with: - interpreting loss and reward progression during training runs - selecting effective parameters for training - reviewing and defining effective reward functions This unit also works up smoothly toward the existing practical exercises form @ mlabonne and Unsloth. \ud83d\udce3 Shout out to @ ShirinYamani who wrote the unit. Follow for more great content. See translation", "url": "https://huggingface.co/posts/burtenshaw/516334667346623", "date_published": "2025-03-30T13:25:40.158647"}]}