{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/merve/482686790570915", "image": "", "title": "ByteDance released Tar 1.5B and 7B: image-text in image-text out models, fully open-source \ud83d\udc4f", "content_text": "ByteDance released Tar 1.5B and 7B: image-text in image-text out models, fully open-source \ud83d\udc4f ByteDance-Seed/tar-6864cf0d9fe59a3b91cc4260 They have an image tokenizer unified with text, and they de-tokenize using either of two models (LLM and diffusion) The model is actually a full LLM (Qwen2), the tokenizer converts image tokens \ud83e\udd2f See translation", "url": "https://huggingface.co/posts/merve/482686790570915", "date_published": "2025-07-10T09:28:13.059660"}, {"id": "https://huggingface.co/posts/a-r-r-o-w/278025275110164", "image": "", "title": "Caching is an essential technique used in diffusion inference serving for speeding up image/video generations. Diffusers just added support for another caching method: First Block Cache - a technique developed by", "content_text": "Caching is an essential technique used in diffusion inference serving for speeding up image/video generations. Diffusers just added support for another caching method: First Block Cache - a technique developed by @ chengzeyi building upon the ideas of TeaCache. The idea in short is: if the model predictions do not vary much over successive inference steps, we can skip certain steps where the prediction difference is small. To figure out whether an inference step will make a significant improvement to the overall velocity/noise prediction, we calculate the relative difference of the output of the first transformer block at timestep $t$ with $t-1$, and compare it against a selected threshold. If the difference is lower than the threshold, we skip the step. A higher threshold will lead to more steps being skipped. However, skipping many steps is bad because it can throw off the model predictions, and so we need to test and select the threshold based on level of quality-speed tradeoff...", "url": "https://huggingface.co/posts/a-r-r-o-w/278025275110164", "date_published": "2025-07-10T09:28:13.060189"}, {"id": "https://huggingface.co/posts/YerbaPage/789674491872223", "image": "", "title": "How to achieve 100% Pass Rate on HumanEval ? \ud83d\udd25", "content_text": "How to achieve 100% Pass Rate on HumanEval ? \ud83d\udd25 Meet MGDebugger if you are tired of LLMs failing on complex bugs \ud83e\udd14 Our MGDebugger, just hit 100% accuracy on HumanEval using the DeepSeek-R1 model. \ud83d\ude80 \u2728 Demo: learnmlf/MGDebugger \ud83d\udcdd Paper: From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging (2410.01215) \ud83d\udcbb Code: https://github.com/YerbaPage/MGDebugger HumanEval may be retired, we're ready for the next challenge In more complex scenarios! You may also take look at this repo for a collection of awesome repo-level coding tasks! \ud83d\udda5\ufe0f https://github.com/YerbaPage/Awesome-Repo-Level-Code-Generation See translation", "url": "https://huggingface.co/posts/YerbaPage/789674491872223", "date_published": "2025-07-10T09:28:13.060539"}, {"id": "https://huggingface.co/posts/merve/713910696313243", "image": "", "title": "GitHub refuses to render notebooks for a long time now \ud83d\udc94", "content_text": "GitHub refuses to render notebooks for a long time now \ud83d\udc94 so smol-vision now lives in Hugging Face model repository \ud83e\udd17 merve/smol-vision See translation", "url": "https://huggingface.co/posts/merve/713910696313243", "date_published": "2025-07-10T09:28:13.060756"}, {"id": "https://huggingface.co/posts/giadap/958744591263435", "image": "", "title": "I've been posting bits and pieces about this research, but now I can finally say: new paper alert \ud83d\udea8", "content_text": "I've been posting bits and pieces about this research, but now I can finally say: new paper alert \ud83d\udea8 My colleague @ brunatrevelin and I just shared a paper exploring why traditional consent frameworks are breaking down in AI contexts (forthcoming chapter in a collective book). The current model places impossible burdens on users to manage countless consent decisions. Meanwhile, AI systems learn to mimic our voices and writing styles from data we unknowingly provided years ago. What's next? We need to shift from individual responsibility to collective accountability. This means: - Organizations designing systems that respect human agency by default - Developers building ethics into models from the start - Policymakers creating frameworks beyond minimal compliance Blog post: https://huggingface.co/blog/giadap/consentful-ai Paper: Can AI be Consentful? (2507.01051) See translation", "url": "https://huggingface.co/posts/giadap/958744591263435", "date_published": "2025-07-10T09:28:13.061159"}, {"id": "https://huggingface.co/posts/louisbrulenaudet/165456039014439", "image": "", "title": "Because hackathons are often the starting point for many AI projects, I've created a Python-backend template incorporating my feedback to streamline collaboration and urgent deployments \ud83c\udfce\ufe0f", "content_text": "Because hackathons are often the starting point for many AI projects, I've created a Python-backend template incorporating my feedback to streamline collaboration and urgent deployments \ud83c\udfce\ufe0f Within a year, I had the opportunity to participate in hackathons organized by Mistral, OpenAI, and DeepMind and this GitHub template is structured around several fundamental building blocks and recommendations I offer developers eager to participate in their first hackathon, whether as part of a team or individually. Its emphasis is on rapid setup and deployment through: - uv as a package manager, simplifying usage via a series of pre-configured make commands. - FastAPI for API management, structured in a modular architecture designed to minimize branch conflicts during merges to main branches (using minimal health-check and ping routes to verify Docker\u2019s proper execution and backend accessibility on the local network). - Pydantic for validation and type handling, which simplifies debugging and...", "url": "https://huggingface.co/posts/louisbrulenaudet/165456039014439", "date_published": "2025-07-10T09:28:13.061768"}, {"id": "https://huggingface.co/posts/ProCreations/258072359756545", "image": "", "title": "33 followers AGAIN in another day is insane.... Thank you guys!", "content_text": "33 followers AGAIN in another day is insane.... Thank you guys! trying to get to the #1 trending community article. upvote my article to help out! https://huggingface.co/blog/ProCreations/transformers-are-getting-old Also, I made a ZeroGPU space that lets you try out smollm3 with no setup needed: Check it out! ProCreations/smollm3 See translation", "url": "https://huggingface.co/posts/ProCreations/258072359756545", "date_published": "2025-07-10T09:28:13.062029"}, {"id": "https://huggingface.co/posts/m-ric/129069007859083", "image": "", "title": "Diffusion LLMs are coming for autoregressive LLMs \u26a1\ufe0f\u26a1\ufe0f Inception Labs' new diffusion model demolishes all leading LLMs on generation speed, with equal quality !", "content_text": "Diffusion LLMs are coming for autoregressive LLMs \u26a1\ufe0f\u26a1\ufe0f Inception Labs' new diffusion model demolishes all leading LLMs on generation speed, with equal quality ! Inception Labs was founded a few months ago, and they're not sleeping: after dropping a code model, they just published Mercury chat, a diffusion-based chat model that reaches 1000 tokens / second on H100, i.e. 10x more than models of equivalent performance on the same hardware! What's the breakthrough? Well instead, of generating tokens left-to-right like the more common autoregressive LLMs, diffusion models generate their blocks of text all at once, and successive steps refine the whole text. Diffusion models being really fast at isn't new, we have had some promising results on this by Google already back in May with Gemini Diffusion, and Mercury themselves had already published their coding model a few months ago But being that good quality is new - and now Inception Labs just proved that their models work well in chat...", "url": "https://huggingface.co/posts/m-ric/129069007859083", "date_published": "2025-07-10T09:28:13.062496"}, {"id": "https://huggingface.co/posts/nicolay-r/221275408085007", "image": "", "title": "\ud83d\ude80 For those who interested in summarization of the long textual reports in medical domain  \ud83d\udcdd\ud83e\ude7a,", "content_text": "\ud83d\ude80 For those who interested in summarization of the long textual reports in medical domain \ud83d\udcdd\ud83e\ude7a, @ Xiaolihai and I delighted to share that we experiment with distillation tuning adaptation for Qwen-2.5 0.5B. We use reports from the MultiClinSum dataset and pass it through 72B version to retrieve report explanations in order to initiate ditillation tuning for 0.5B model. We experiment with passages written in English, French, Portuguese, and Spanish. \ud83d\udd11 We find that using distil-technique results in 2-4% performance increment on fine-tuning and similar improvements for reports in English (non-official and official evaluation). For the other it results in systems that perform similar to the convential tuning (standard) (see result below). Dataset: https://zenodo.org/records/15459174 Competition: https://participants-area.bioasq.org/general_information/MultiClinSum/ Github: https://github.com/nicolay-r/distil-tuning-llm model: nicolay-r/qwen25-05b-multiclinsum-distil See translation", "url": "https://huggingface.co/posts/nicolay-r/221275408085007", "date_published": "2025-07-10T09:28:13.062911"}, {"id": "https://huggingface.co/posts/Parveshiiii/143893358011969", "image": "", "title": "\ud83e\udde0 Glimpses of AGI \u2014 A Vision for All Humanity", "content_text": "\ud83e\udde0 Glimpses of AGI \u2014 A Vision for All Humanity What if AGI wasn\u2019t just a distant dream\u2014but a blueprint already unfolding? I\u2019ve just published a deep dive called Glimpses of AGI, exploring how scalable intelligence, synthetic reasoning, and alignment strategies are paving a new path forward. This isn\u2019t your average tech commentary\u2014it\u2019s a bold vision for conscious AI systems that reason, align, and adapt beyond narrow tasks. \ud83d\udd0d Read it, upvote it if it sparks something, and let\u2019s ignite a collective conversation about the future of AGI. https://huggingface.co/blog/Parveshiiii/glimpses-of-agi See translation", "url": "https://huggingface.co/posts/Parveshiiii/143893358011969", "date_published": "2025-07-10T09:28:13.063235"}]}