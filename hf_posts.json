{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/giadap/164607097500775", "image": "", "title": "\ud83d\udcac From Replika to everyday chatbots, millions of people are forming emotional bonds with AI, sometimes seeking comfort, sometimes seeking intimacy. But what happens when an AI tells you \"I understand how you feel\" and you actually believe it?", "content_text": "\ud83d\udcac From Replika to everyday chatbots, millions of people are forming emotional bonds with AI, sometimes seeking comfort, sometimes seeking intimacy. But what happens when an AI tells you \"I understand how you feel\" and you actually believe it? At Hugging Face, together with @ frimelle and @ yjernite , we dug into something we felt wasn't getting enough attention: the need to evaluate AI companionship behaviors. These are the subtle ways AI systems validate us, engage with us, and sometimes manipulate our emotional lives. Here's what we found: \ud83d\udc49 Existing benchmarks (accuracy, helpfulness, safety) completely miss this emotional dimension. \ud83d\udc49 We mapped how leading AI systems actually respond to vulnerable prompts. \ud83d\udc49 We built the Interactions and Machine Attachment Benchmark (INTIMA): a first attempt at evaluating how models handle emotional dependency, boundaries, and attachment (with a full paper coming soon). Check out the blog post: https://huggingface.co/blog/giadap/evaluating-...", "url": "https://huggingface.co/posts/giadap/164607097500775", "date_published": "2025-07-31T05:31:31.275426"}, {"id": "https://huggingface.co/posts/sergiopaniego/236970560808195", "image": "", "title": "We just released TRL v0.20 with major multimodal upgrades!", "content_text": "We just released TRL v0.20 with major multimodal upgrades! \ud83d\udc41\ufe0f VLM support for GRPO (highly requested by the community!) \ud83c\udf9e\ufe0f New GSPO trainer (from @ Qwen , released last week, VLM-ready) \ud83d\udc19 New MPO trainer (multimodal by design, as in the paper) \ud83d\udcdd Full release notes here: https://github.com/huggingface/trl/releases/tag/v0.20.0 See translation", "url": "https://huggingface.co/posts/sergiopaniego/236970560808195", "date_published": "2025-07-31T05:31:31.275709"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/147929225613950", "image": "", "title": "When you're looking for data, what's your focus (use the reactions below to vote):", "content_text": "When you're looking for data, what's your focus (use the reactions below to vote): \ud83d\ude80 Getting as many images as you can \ud83e\udd2f Getting the right type of images (framing, domain, lighting, etc) I know both are very important, but I'm curious what people would put as #1 See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/147929225613950", "date_published": "2025-07-31T05:31:31.275959"}, {"id": "https://huggingface.co/posts/YerbaPage/459269562265928", "image": "", "title": "How to achieve 100% Pass Rate on HumanEval ? \ud83d\udd25", "content_text": "How to achieve 100% Pass Rate on HumanEval ? \ud83d\udd25 Meet MGDebugger if you are tired of LLMs failing on complex bugs \ud83e\udd14 Our MGDebugger, just hit 100% accuracy on HumanEval using the DeepSeek-R1 model. \ud83d\ude80 \u2728 Demo: learnmlf/MGDebugger \ud83d\udcdd Paper: From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging (2410.01215) \ud83d\udcbb Code: https://github.com/YerbaPage/MGDebugger HumanEval may be retired, we're ready for the next challenge In more complex scenarios! You may also take look at this repo for a collection of awesome repo-level coding tasks! \ud83d\udda5\ufe0f https://github.com/YerbaPage/Awesome-Repo-Level-Code-Generation See translation", "url": "https://huggingface.co/posts/YerbaPage/459269562265928", "date_published": "2025-07-31T05:31:31.276310"}, {"id": "https://huggingface.co/posts/sequelbox/481535699199098", "image": "", "title": "NEW EXPERIMENTAL RELEASE: DAG Reasoning is here!", "content_text": "NEW EXPERIMENTAL RELEASE: DAG Reasoning is here! - Our first Experimental Reasoning Modality release: create structured, analytical Directed Acyclic Graphs to provide insight into your queries and situations! - Multi-step analysis identifies causal relationships, produces confidence measurements, and forms a single structured graph object. - DAG Reasoning Format provides clear, readable JSON containing structured, useful information; easy to use for creating visualizations, doing analysis, or further conversation with your assistant. - Trained in a variety of subjects for flexible analysis: programming, science, business, economics, finance, law, logistics, management, and more! Our first DAG Reasoning release is Qwen 3, starting off with 8B and 14B! Get 8B: sequelbox/Qwen3-8B-DAG-Reasoning Get 14B: sequelbox/Qwen3-14B-DAG-Reasoning You can also get the DAG Reasoning dataset, to train your own models to use DAG Reasoning Format: sequelbox/DAG-Reasoning-DeepSeek-R1-0528 Support our...", "url": "https://huggingface.co/posts/sequelbox/481535699199098", "date_published": "2025-07-31T05:31:31.276685"}, {"id": "https://huggingface.co/posts/ImranzamanML/854877876171123", "image": "", "title": "Hugging Face just made life easier with the new hf CLI!", "content_text": "Hugging Face just made life easier with the new hf CLI! huggingface-cli to hf With renaming the CLI, there are new features added like hf jobs. We can now run any script or Docker image on dedicated Hugging Face infrastructure with a simple command. It's a good addition for running experiments and jobs on the fly. To get started, just run: pip install -U huggingface_hub List of hf CLI Commands Main Commands hf auth: Manage authentication (login, logout, etc.). hf cache: Manage the local cache directory. hf download: Download files from the Hub. hf jobs: Run and manage Jobs on the Hub. hf repo: Manage repos on the Hub. hf upload: Upload a file or a folder to the Hub. hf version: Print information about the hf version. hf env: Print information about the environment. Authentication Subcommands (hf auth) login: Log in using a Hugging Face token. logout: Log out of your account. whoami: See which account you are logged in as. switch: Switch between different stored access...", "url": "https://huggingface.co/posts/ImranzamanML/854877876171123", "date_published": "2025-07-31T05:31:31.277135"}, {"id": "https://huggingface.co/posts/smirki/773357866668514", "image": "", "title": "Just dropped!", "content_text": "Just dropped! Tesslate/UIGEN-X-32B-0727 Runs Locally and Crushes It. Reasoning for UI, Mobile, Software and Frontend design. Specifically trained for modern web and mobile development across frameworks like React (Next.js, Remix, Gatsby, Vite), Vue (Nuxt, Quasar), Angular (Angular CLI, Ionic), and SvelteKit, along with Solid.js, Qwik, Astro, and static site tools like 11ty and Hugo. Styling options include Tailwind CSS, CSS-in-JS (Styled Components, Emotion), and full design systems like Carbon and Material UI. We cover UI libraries for every framework React (shadcn/ui, Chakra, Ant Design), Vue (Vuetify, PrimeVue), Angular, and Svelte plus headless solutions like Radix UI. State management spans Redux, Zustand, Pinia, Vuex, NgRx, and universal tools like MobX and XState. For animation, we support Framer Motion, GSAP, and Lottie, with icons from Lucide, Heroicons, and more. Beyond web, we enable React Native, Flutter, and Ionic for mobile, and Electron, Tauri, and Flutter Desktop for...", "url": "https://huggingface.co/posts/smirki/773357866668514", "date_published": "2025-07-31T05:31:31.277524"}, {"id": "https://huggingface.co/posts/MikeDoes/228428153197540", "image": "", "title": "\ud83d\udee1\ufe0f At Ai4Privacy, our goal is to empower researchers to build a safer AI ecosystem. Today, we're highlighting crucial research that does just that by exposing a new vulnerability.", "content_text": "\ud83d\udee1\ufe0f At Ai4Privacy, our goal is to empower researchers to build a safer AI ecosystem. Today, we're highlighting crucial research that does just that by exposing a new vulnerability. The paper \"Forget to Flourish\" details a new model poisoning technique. It's a reminder that as we fine-tune LLMs, our anonymization and privacy strategies must evolve to counter increasingly sophisticated threats. We're proud that the Ai4Privacy dataset was instrumental in this study. It served two key purposes: Provided a Realistic Testbed: It gave the researchers access to a diverse set of synthetic and realistic PII samples in a safe, controlled environment. Enabled Impactful Benchmarking: It allowed them to measure the actual effectiveness of their data extraction attack, proving it could compromise specific, high-value information. This work reinforces our belief that progress in AI security is a community effort. By providing robust tools for benchmarking, we can collectively identify weaknesses and...", "url": "https://huggingface.co/posts/MikeDoes/228428153197540", "date_published": "2025-07-31T05:31:31.278005"}, {"id": "https://huggingface.co/posts/AdinaY/263963364371914", "image": "", "title": "Qwen3-30B-A3B-Thinking-2507 \ud83d\udd25 latest step in scaling thinking capabilities from  Alibaba Qwen team.", "content_text": "Qwen3-30B-A3B-Thinking-2507 \ud83d\udd25 latest step in scaling thinking capabilities from Alibaba Qwen team. Qwen/Qwen3-30B-A3B-Thinking-2507-FP8 \u2728 30B total / 3B active - Apache 2.0 \u2728 Native 256K context \u2728 SOTA coding, alignment, agentic reasoning See translation", "url": "https://huggingface.co/posts/AdinaY/263963364371914", "date_published": "2025-07-31T05:31:31.278255"}, {"id": "https://huggingface.co/posts/merve/514822650680483", "image": "", "title": "past week in open AI was insane \ud83d\udd25 here's some of picks, find more here", "content_text": "past week in open AI was insane \ud83d\udd25 here's some of picks, find more here merve/releases-july-25-688768ca47fe3693407e02d1 \ud83d\udcac LLMs & VLMs > Qwen/Qwen3-235B-A22B-Thinking-2507 had a new update (OS) > Qwen/Qwen3-Coder-480B-A35B-Instruct is out with 480B total 35B active params \ud83e\udd2f (OS) > AllenAI dropped an update to allenai/olmOCR-7B-0725 \ud83d\udcdd > InternLM released internlm/Intern-S1 - 235B Qwen3 MoE + 6B InternViT encoder (OS) > OmniSVG/OmniSVG is a new SVG generation VLM (OS) \ud83d\uddbc\ufe0f image/video/3D generation > WanAI released Wan2.2 series - both T2V and I2V 14B models for high-quality video generation (OS) multimodalart/wan-22-688767e313337b434ed55112 > Tencent dropped tencent/HunyuanWorld-1 - image-to-3D scene generation model See translation", "url": "https://huggingface.co/posts/merve/514822650680483", "date_published": "2025-07-31T05:31:31.278621"}]}