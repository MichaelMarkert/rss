{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/hba123/904232449612527", "image": "", "title": "Hello, amazing robotics people \ud83d\ude0d \ud83d\ude0d \ud83d\ude0d We have FINALLY delivered on your major request! Ark just got a major upgrade:", "content_text": "Hello, amazing robotics people \ud83d\ude0d \ud83d\ude0d \ud83d\ude0d We have FINALLY delivered on your major request! Ark just got a major upgrade: We\u2019ve now integrated Vision-Language-Action Models (VLAs) into Ark \ud83c\udf89 VLAs = models that connect vision + language \u2192 robot actions (see image) What does this mean? \ud83d\udde3\ufe0f Give robots natural language instructions \u2192 they act \ud83d\udc40 Combine perception + language for real-world control \ud83e\uddbe Powered by pi0 pretrained models for fast prototyping \u26a1 Supports easy data collection and fine-tuning within Ark within a couple of lines of code Next, we plan to go into the world of designing worlds \ud83d\ude09 Who knows, maybe those video models are actually zero-shot learners and reasoners? Check it out here \ud83d\udc49 https://github.com/Robotics-Ark/ark_framework Check out the tutorial \ud83d\udc49 https://arkrobotics.notion.site/VLA-Pi0-with-Ark-279e053d9c6f800ab0a2d498835dd96b \u2b50 Star the repo, try it with your robots, and let us together make robots great (again?)! See translation", "url": "https://huggingface.co/posts/hba123/904232449612527", "date_published": "2025-09-27T09:19:59.039685"}, {"id": "https://huggingface.co/posts/tsungyi/865184416328763", "image": "", "title": "We\u2019re excited to share that Cosmos Reason has surpassed 1 million downloads on Hugging Face!", "content_text": "We\u2019re excited to share that Cosmos Reason has surpassed 1 million downloads on Hugging Face! Cosmos Reason is an open, customizable, commercial-ready 7B-parameter reasoning vision language model (VLM) designed for physical AI. By combining physics understanding, prior knowledge, and common sense reasoning, Cosmos Reason empowers AI agents and robots to operate intelligently in real-world environments. Key applications already unlocked include: \u2705 Automating large-scale dataset curation and annotation \ud83e\udd16 Powering robot planning and vision-language action (VLA) decision-making \ud83d\udcca Driving advanced video analytics and actionable insight generation We\u2019re proud to see a global community of developers using Cosmos Reason to teach robots to think like humans\u2014and we\u2019re just getting started. \u26a1 Get started with Cosmos Reason 1 NIM, an easy-to-use microservice for AI model deployment: https://catalog.ngc.nvidia.com/orgs/nim/teams/nvidia/containers/cosmos-reason1-7b?version=1 \ud83d\udcc8 See the leaderboard:...", "url": "https://huggingface.co/posts/tsungyi/865184416328763", "date_published": "2025-09-27T09:19:59.040133"}, {"id": "https://huggingface.co/posts/yeonseok-zeticai/752870941871415", "image": "", "title": "\ud83c\udfaf RetinaFace On-Device Deployment Study: NPU Acceleration Breakthrough!", "content_text": "\ud83c\udfaf RetinaFace On-Device Deployment Study: NPU Acceleration Breakthrough! (Check details at :https://mlange.zetic.ai/p/Steve/RetinaFace) TL;DR: Successfully deployed RetinaFace with ZETIC.MLange achieving 1.43ms inference on mobile NPU! \ud83d\udd0d Complete Performance Analysis: Latency Comparison: - NPU: 1.43ms (Winner! \ud83c\udfc6) - GPU: 3.75ms - CPU: 21.42ms Accuracy Metrics - SNR: - FP16: 56.98 dB - Integer Quantized: 48.03 dB (Precision-Performance: Excellent trade-off maintained) Memory Footprint: - Model Size: 2.00 MB (highly compressed) - Runtime Memory: 14.58 MB peak - Deployment Ready: \u2705 Production optimized \ud83d\udee0 Technical Implementation: (Runnable with Copy & Paste at the MLange link!) \ud83d\udcca Device Compatibility Matrix: Tested on 50+ devices including Samsung Galaxy series, Google Pixel lineup, and Xiaomi devices, iPhones and iPads. Consistent sub-5ms performance across the board! \ud83d\ude80 Applications Unlocked: - Real-time AR/VR face tracking - Privacy-preserving edge authentication - Live video...", "url": "https://huggingface.co/posts/yeonseok-zeticai/752870941871415", "date_published": "2025-09-27T09:19:59.040652"}, {"id": "https://huggingface.co/posts/sergiopaniego/566597314485869", "image": "", "title": "\ud83d\udca5 Tons of new material just landed in the smol-course! \ud83e\uddd1\u200d\ud83d\udcbb", "content_text": "\ud83d\udca5 Tons of new material just landed in the smol-course! \ud83e\uddd1\u200d\ud83d\udcbb > evaluation > alignment > VLMs > quizzes > assignments! > certificates!\ud83d\udc69\u200d\ud83c\udf93 go learn! \ud83d\udc49 https://huggingface.co/learn/smol-course/unit0/1 See translation", "url": "https://huggingface.co/posts/sergiopaniego/566597314485869", "date_published": "2025-09-27T09:19:59.040895"}, {"id": "https://huggingface.co/posts/yeonseok-zeticai/603791080422979", "image": "", "title": "\u26a1 RexBERT Complete On-device Study: Comprehensive Performance Analysis Across Mobile Devices", "content_text": "\u26a1 RexBERT Complete On-device Study: Comprehensive Performance Analysis Across Mobile Devices (Check details at https://mlange.zetic.ai/p/Steve/RexBERT ) TL;DR: Transformer models are now practical for real-time mobile applications. The cloud-to-edge AI migration is complete. - Original model from @ thebajajra \ud83c\udfaf Study Overview: - Model: RexBERT (ModernBERT for E-commerce) - Focus: Real-world deployment viability and performance analysis \ud83d\udcca Key Performance Metrics: Latency Results: - NPU (Best): 4.74ms average - GPU: 12.56ms average - CPU: 35.16ms average NPU Advantage: 16.98x speedup over CPU Memory Efficiency: - Model Size: 568.96 MB (compressed for mobile) - Runtime Memory: 299.01 MB peak consumption - Load Memory Range: 285 MB - 1,072 MB across devices Accuracy Preservation: - FP16 Precision: 63.72 dB - Quantized Mode: Available with minimal accuracy loss - Inference Quality: Production-grade maintained \ud83d\udee0 Technical Implementation: (Runnable with Copy & Paste at the ZETIC.MLange...", "url": "https://huggingface.co/posts/yeonseok-zeticai/603791080422979", "date_published": "2025-09-27T09:19:59.041539"}, {"id": "https://huggingface.co/posts/Parveshiiii/762902765406270", "image": "", "title": "\ud83d\ude80 New Release from XenArcAI", "content_text": "\ud83d\ude80 New Release from XenArcAI We\u2019re excited to introduce AIRealNet \u2014 our SwinV2\u2011based image classifier built to distinguish between artificial and real images. \u2728 Highlights: - Backbone: SwinV2 - Input size: 256\u00d7256 - Labels: artificial vs. real - Performance: Accuracy 0.999 | F1 0.999 | Val Loss 0.0063 This model is now live on Hugging Face: \ud83d\udc49 XenArcAI/AIRealNet We built AIRealNet to push forward open\u2011source tools for authenticity detection, and we can\u2019t wait to see how the community uses it. See translation", "url": "https://huggingface.co/posts/Parveshiiii/762902765406270", "date_published": "2025-09-27T09:19:59.041858"}, {"id": "https://huggingface.co/posts/salma-remyx/152672163606512", "image": "", "title": "Thanks again to", "content_text": "Thanks again to @ ag2 for hosting us at their Community Talks! @ terry-remyx walked us through a technical deep dive into GitRank, our automated pipeline that converts research papers with code into containerized, executable environments and generates specialized tests tailored to users' specific codebases. In case you missed it... Full recording: https://www.youtube.com/watch?v=N_FNfZ71s2I Deck: https://docs.google.com/presentation/d/1S0q-wGCu2dliVWb9ykGKFz61jZKZI4ipxWBv73HOFBo/edit?usp=sharing See translation", "url": "https://huggingface.co/posts/salma-remyx/152672163606512", "date_published": "2025-09-27T09:19:59.042133"}, {"id": "https://huggingface.co/posts/AnSungJae3489/522189375080147", "image": "", "title": "ShareGPT? How about ShareGPT-X?", "content_text": "ShareGPT? How about ShareGPT-X? We release **92K** Human with LLM conversations as a refresh and update over the original ShareGPT Dataset. DSULT-Core/ShareGPT-X See translation", "url": "https://huggingface.co/posts/AnSungJae3489/522189375080147", "date_published": "2025-09-27T09:19:59.042362"}, {"id": "https://huggingface.co/posts/omarkamali/930832276115275", "image": "", "title": "**Wikipedia Monthly's September edition is now live \ud83c\udf89**", "content_text": "**Wikipedia Monthly's September edition is now live \ud83c\udf89** Highlights of this edition: \u00b7 \ud83d\udde3\ufe0f 341 languages \u00b7 \ud83d\udcda 63.1M articles \u00b7 \ud83d\udce6 86.5GB of data This update also solves upload issues in the August edition where some languages had missing parts. Happy data engineering! omarkamali/wikipedia-monthly See translation", "url": "https://huggingface.co/posts/omarkamali/930832276115275", "date_published": "2025-09-27T09:19:59.042636"}, {"id": "https://huggingface.co/posts/ZennyKenny/883175347255342", "image": "", "title": "\ud83d\udd12 Like a lot of other AI builders, I have some anxiety about the emerging surveillance-capitalist paradigm emerging in the AI space.", "content_text": "\ud83d\udd12 Like a lot of other AI builders, I have some anxiety about the emerging surveillance-capitalist paradigm emerging in the AI space. \ud83d\udc49 Of course-- this kind of thing isn't completely new and has been going on for decades, but the difference is the stronger immersion of AI tools into our daily lives (compared to something like a search engine or social network). \u2755 That's why I was really excited to come across Lumo: https://lumo.proton.me/u/1/ \u2755 Lumo is created by ProtonPrivacy and offers privacy-first features that make sure that what you do with you AI assistant is your business. \u2755 I already trust Proton with my other business apps and I've never been disappointed, plus the Lumo architecture is really fantastic, dynamically routing each query to the most appropriate model for the request. \ud83d\udd25 Really awesome stuff Proton, thank you as always. See translation", "url": "https://huggingface.co/posts/ZennyKenny/883175347255342", "date_published": "2025-09-27T09:19:59.043028"}]}