{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/marksverdhei/322290772927588", "image": "", "title": "Dear Hugging Face team, can we please have a way to archive hf repositories / spaces? I have a bunch of spaces that used to work but don't any more due to the hf space implementations changing and i think it would be good if I could archive those like in GitHub.", "content_text": "Dear Hugging Face team, can we please have a way to archive hf repositories / spaces? I have a bunch of spaces that used to work but don't any more due to the hf space implementations changing and i think it would be good if I could archive those like in GitHub. React to this post if you want to see this feature! \ud83d\udca1 See translation", "url": "https://huggingface.co/posts/marksverdhei/322290772927588", "date_published": "2026-02-02T06:05:47.022621"}, {"id": "https://huggingface.co/posts/nyuuzyou/211988639050417", "image": "", "title": "\ud83c\udfdb\ufe0f Microsoft CodePlex Archive Dataset -", "content_text": "\ud83c\udfdb\ufe0f Microsoft CodePlex Archive Dataset - nyuuzyou/ms-codeplex-archive Following the strong response to the Google Code Archive nyuuzyou/google-code-archive (thanks!), this release preserves another major historical repository: the Microsoft CodePlex Archive. CodePlex served as Microsoft\u2019s primary open-source hosting platform from 2006 to 2017. This dataset captures the distinct .NET and Windows-centric development ecosystem that flourished before the industry standardizing on GitHub. Key Stats: - 5,043,730 files from 38,087 repositories - 3.6 GB compressed Parquet - 91 programming languages (Heavily featuring C#, ASP.NET, and C++) - Cleaned of binaries, build artifacts, and vendor directories (node_modules, packages) - Includes platform-specific license metadata (Ms-PL, Ms-RL) See translation", "url": "https://huggingface.co/posts/nyuuzyou/211988639050417", "date_published": "2026-02-02T06:05:47.023035"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/813967180726808", "image": "", "title": "LTX 2 & Z Image Base Full Tutorial + Audio to Video Lip Sync + ComfyUI + SwarmUI + Windows + Cloud", "content_text": "LTX 2 & Z Image Base Full Tutorial + Audio to Video Lip Sync + ComfyUI + SwarmUI + Windows + Cloud Full tutorial link > https://www.youtube.com/watch?v=SkXrYezeEDc Info LTX 2 is the newest state of the art (SOTA) Open Source video generation model and tutorial will show you how to use it with very best and most performant way in ComfyUI and also in SwarmUI. Moreover, Z Image Base model published and I will show how to use Z Image Base with most amazing preset and workflow as well. Furthermore, this tutorial will show you how to install, update, setup, download ComfyUI and SwarmUI and models and presets and workflows both on Windows and on RunPod, Massed Compute and SimplePod. Linux users can use Massed Compute scripts and installers directly. This is a masterpiece entire lecture level complete tutorial. This video will kickstart your AI journey 100x. Both local Windows and Cloud. 45 Second Raw Demo Video This video made with text + image + audio = lip synched and animated video at...", "url": "https://huggingface.co/posts/MonsterMMORPG/813967180726808", "date_published": "2026-02-02T06:05:47.023420"}, {"id": "https://huggingface.co/posts/Duskfallcrew/930947700024485", "image": "", "title": "You've noticed that I did the \"WEIRD\" and attempted to make it look like all my old content was \"SCRAPED\"", "content_text": "You've noticed that I did the \"WEIRD\" and attempted to make it look like all my old content was \"SCRAPED\" I'm largely retiring from GEN AI. Calypso Crunchies is an old account I used to use for diffusers conversions for someone. IF YOU WOULD LIKE ACCESS to ANYTHING -- I lost access due to me forgetting to jank Calypso into the E&D old repo, but i can get Angel or someone to add me or my other account back.. I didn't want HF to lose 3 years of my insane progress in doing things, but i need to retire from Generative image AI fast, my mental health has been diving for so long. I'll continue in the developing/vibe coding./educational sphere, but I just can't continue in the other end of it. Much love, thank you all See translation", "url": "https://huggingface.co/posts/Duskfallcrew/930947700024485", "date_published": "2026-02-02T06:05:47.023741"}, {"id": "https://huggingface.co/posts/yuriyvnv/972315277032860", "image": "", "title": "\ud83c\udfaf WAVe: 1B Multimodal Embedding Model for Word-Level Speech Quality", "content_text": "\ud83c\udfaf WAVe: 1B Multimodal Embedding Model for Word-Level Speech Quality Multimodal embeddings for speech + transcript that verify quality at the word level, not just sentence level. Catches mispronunciations, timing errors, and prosody issues that sentence-level filters miss. \ud83d\udcca Impact on Portuguese ASR: \u2022 34% reduction in training steps \u2022 50% better cross-domain generalization \u2022 30% less synthetic data needed \u2022 Word-aligned attention finds errors other methods miss \ud83c\udfd7\ufe0f Architecture: \u2022 Text: XLM-RoBERTa (278M params) \u2022 Audio: Wav2Vec2-BERT 2.0 (581M params) \u2022 Word Alignment: Multi-head attention + GLU (14M params) \u2022 Total: 1B parameters from transformers import AutoModel, AutoProcessor processor = AutoProcessor.from_pretrained( \"yuriyvnv/WAVe-1B-Multimodal-PT\" , trust_remote_code = True ) model = AutoModel.from_pretrained( \"yuriyvnv/WAVe-1B-Multimodal-PT\" , trust_remote_code = True ) # Assess speech-transcript alignment inputs = processor( text = \"Ol\u00e1, como est\u00e1?\" , audio =audio_array,...", "url": "https://huggingface.co/posts/yuriyvnv/972315277032860", "date_published": "2026-02-02T06:05:47.024270"}, {"id": "https://huggingface.co/posts/OzTianlu/678257236628568", "image": "", "title": "Geilim-1B-SR-Instruct \u2014 Serbian Intelligence for Deep Reasoning \ud83e\udde0\ud83c\uddf7\ud83c\uddf8", "content_text": "Geilim-1B-SR-Instruct \u2014 Serbian Intelligence for Deep Reasoning \ud83e\udde0\ud83c\uddf7\ud83c\uddf8 NoesisLab/Geilim-1B-SR-Instruct Geilim-1B-SR-Instruct is a lightweight Large Language Model (LLM) designed to bring advanced reasoning capabilities to low-resource languages. It focuses on Serbian understanding and generation while maintaining robust English reasoning. Built on the LLaMA-3 architecture with a proprietary hybrid reasoning mechanism, it delivers deep logic while keeping outputs concise and natural. \ud83d\ude80 Core Innovations \ud83d\udca1 Implicit Deep Reasoning: Combines standard attention mechanisms with graph-structured reasoning components for rigorous logic and causal inference. \ud83d\udd78\ufe0f ASPP & -flow Hybrid Design: High-efficiency structured propagation + internal probability space optimization for high-quality reasoning without long-winded intermediate steps. \u26a1 Bilingual Adaptation: Primarily focused on Serbian while preserving English logic, making it perfect for multilingual chats and cross-lingual tasks. \ud83c\udf0d Lightweight...", "url": "https://huggingface.co/posts/OzTianlu/678257236628568", "date_published": "2026-02-02T06:05:47.024816"}, {"id": "https://huggingface.co/posts/kanaria007/513254467148584", "image": "", "title": "\u2705 New Article: *Evaluation as a Goal Surface* (v0.1)", "content_text": "\u2705 New Article: *Evaluation as a Goal Surface* (v0.1) Title: \ud83e\uddea Evaluation as a Goal Surface: Experiments, Learning Boundary, and ETH-Aware A/B \ud83d\udd17 https://huggingface.co/blog/kanaria007/evaluation-as-a-goal-surface --- Summary: Most \u201cevaluation\u201d quietly collapses into a single number\u2014and then we optimize the wrong thing. This article reframes evaluation as a *goal surface*: multi-objective, role-aware, and ethics-bounded. In SI-Core terms, experiments become *first-class Jumps (E-Jumps)* with explicit contracts, traces, and gates\u2014so you can run A/B tests, shadow evals, and adaptive rollouts *without violating ETH, confusing principals/roles, or learning from unsafe data*. > Don\u2019t optimize a metric. > Optimize a goal surface\u2014under explicit constraints. --- Why It Matters: \u2022 Prevents Goodhart failures by treating evaluation as *multi-goal + constraints*, not a scalar leaderboard \u2022 Makes experimentation auditable: *EvalTrace* answers \u201cwhat changed, for whom, why, and under what policy\u201d \u2022...", "url": "https://huggingface.co/posts/kanaria007/513254467148584", "date_published": "2026-02-02T06:05:47.025478"}, {"id": "https://huggingface.co/posts/raincandy-u/348219893520522", "image": "", "title": "Introducing Rain-v2: Democratizing LLM training on gaming GPUs! \u26a1", "content_text": "Introducing Rain-v2: Democratizing LLM training on gaming GPUs! \u26a1 \u200bFollowing Rain-100M, we\u2019re scaling up. Rain-v2 features a larger training dataset. We\u2019ve published a comprehensive blog covering the end-to-end journey\u2014from raw data collection to rigorous evaluation and safety testing. \u200bHF Repo: \ud83e\udd17 raincandy-u/Rain-v2 \u200bBlog: \ud83d\udcda https://angelkawaii.xyz/2026/01/29/rain-v2/ \u200bSpecial thanks to the open-source community and the SmolLM2 team for their foundational work! \ud83d\ude80 HuggingFaceTB SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language Model (2502.02737) See translation", "url": "https://huggingface.co/posts/raincandy-u/348219893520522", "date_published": "2026-02-02T06:05:47.025822"}, {"id": "https://huggingface.co/posts/eaddario/695215283251750", "image": "", "title": "Experimental global target bits\u2011per\u2011weight quantization of mistralai/Ministral-3-14B-Instruct-2512 and mistralai/Ministral-3-14B-Reasoning-2512", "content_text": "Experimental global target bits\u2011per\u2011weight quantization of mistralai/Ministral-3-14B-Instruct-2512 and mistralai/Ministral-3-14B-Reasoning-2512 Unlike standard llama.cpp quantizations that rely on fixed type heuristics (e.g., Q4_K_M), the Target BPW approach optimizes per-tensor precision where it matters the most, and produces high quality models that meet a precise global file size target. Key Advantages: - VRAM Maximization: Can generate high quality models sized exactly to fit hardware constraints (e.g., fitting the model into exactly 24GB VRAM). - Data-Driven Precision: Quantization mix is determined by actual weight error sensitivity rather than hardcoded rules, often yielding better PPL/KLD size trade-offs. Full benchmarks (PPL, KLD, ARC, MMLU, etc.) and methodology in the models' cards eaddario/Ministral-3-14B-Instruct-2512-GGUF eaddario/Ministral-3-14B-Reasoning-2512-GGUF See translation", "url": "https://huggingface.co/posts/eaddario/695215283251750", "date_published": "2026-02-02T06:05:47.026232"}, {"id": "https://huggingface.co/posts/neph1/280223950636420", "image": "", "title": "Not for everybody, but the absolute mad craze about clawdbot/moltbook the last couple of days reminded me of a short story I wrote in 2018 (ancient times!).", "content_text": "Not for everybody, but the absolute mad craze about clawdbot/moltbook the last couple of days reminded me of a short story I wrote in 2018 (ancient times!). Synopsis: \"A man insults a sentient traffic light on the way to a meeting. Little does he know it is connected to a social media network for AI, and that his action will lead to a very bad day.\" Cleanliness is bliss (<1000 words) https://www.wattpad.com/story/407330595-cleanliness-is-bliss Sorry for the non-technical post, but it felt relevant. See translation", "url": "https://huggingface.co/posts/neph1/280223950636420", "date_published": "2026-02-02T06:05:47.026509"}]}