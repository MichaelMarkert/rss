{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mlabonne/575026837446793", "image": "", "title": "Liquid just released two 450M and 1.6B param VLMs!", "content_text": "Liquid just released two 450M and 1.6B param VLMs! They're super fast and leverage SigLIP2 NaFlex encoders to handle native resolutions without distortion. It's ideal for on-device deployment in constrained environments like phones. It's available today on Hugging Face, with an inference and a fine-tuning Colab notebooks. LiquidAI/LFM2-VL-450M LiquidAI/LFM2-VL-1.6B See translation", "url": "https://huggingface.co/posts/mlabonne/575026837446793", "date_published": "2025-08-14T13:38:23.172423"}, {"id": "https://huggingface.co/posts/mrs83/441245217845502", "image": "", "title": "Introducing the Computer Says No Dataset:", "content_text": "Introducing the Computer Says No Dataset: ethicalabs/computer-says-no An LLM can do almost anything, but should it? This dataset provides clear examples of when LLMs should decline requests, such as: - Counting characters (e.g., \"number of 'r's in 'raspberry'\" \u2013 seriously, you\u2019ve got this) - Solving basic equations (like *5.9 = x + 5.11* \u2013 please, show that calculator some love) Inspired by Little Britain's iconic \"Computer Says No\" sketch, we address a critical issue in AI systems today: the waste of using a rocket launcher to swat flies (aka powerful models for trivial tasks). Goals: - Reduce waste by saving compute for tasks that actually need it - Guide users to better tools - Spark discussion about ethical AI This isn\u2019t a training set. It\u2019s a provocation: if we don\u2019t define AI's limits, who will? See translation", "url": "https://huggingface.co/posts/mrs83/441245217845502", "date_published": "2025-08-14T13:38:23.172852"}, {"id": "https://huggingface.co/posts/badaoui/360505768110002", "image": "", "title": "Is there a \"one-size-fits-all\" recipe for quantizing Large Language Models? \ud83e\udd14", "content_text": "Is there a \"one-size-fits-all\" recipe for quantizing Large Language Models? \ud83e\udd14 As part of my ongoing work in mixed-precision quantization, I've been exploring this question by measuring layer-by-layer sensitivity. The goal is to see if we can find universal rules for which layers can be quantized aggressively without impacting performance.The results are fascinating and reveal two key insights: 1\ufe0f\u20e3 Sensitivity profiles are like architectural \"fingerprints.\" Models from the same family share strikingly similar sensitivity patterns. As you can see in the charts below for the Gemma and SmolLM families, the ranking and relative sensitivity of the layers remain remarkably consistent. This suggests that the underlying architecture is a primary driver of a model's quantization behavior. 2\ufe0f\u20e3 A \"universal\" mixed-precision quantization strategy is challenging. While models within a family are similar, these \"fingerprints\" change dramatically when comparing different architectures like LLaMA,...", "url": "https://huggingface.co/posts/badaoui/360505768110002", "date_published": "2025-08-14T13:38:23.173498"}, {"id": "https://huggingface.co/posts/sergiopaniego/261394982300861", "image": "", "title": "So you can now SFT a model with hf jobs + TRL in ONE command lol \ud83c\udfce\ufe0f\ud83d\udca8", "content_text": "So you can now SFT a model with hf jobs + TRL in ONE command lol \ud83c\udfce\ufe0f\ud83d\udca8 Without worrying about infrastructure since it runs entirely on HF! docs: https://huggingface.co/docs/huggingface_hub/main/en/guides/jobs blog: https://huggingface.co/blog/hf-cli See translation", "url": "https://huggingface.co/posts/sergiopaniego/261394982300861", "date_published": "2025-08-14T13:38:23.173745"}, {"id": "https://huggingface.co/posts/prithivMLmods/730170022133992", "image": "", "title": "Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B & LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU!", "content_text": "Try Liquid AI's all-new multimodal models: LFM2-VL-1.6B & LFM2-VL-450M! Demo with the Gradio UI and ReportLab support and both models are runnable on T4 GPU! \u2197 LFM2-VL-1.6B-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-1.6B-LiquidAI/LFM2-VL-1.6B_ReportLab.ipynb \u2197 LFM2-VL-450M-LiquidAI : https://github.com/PRITHIVSAKTHIUR/Multimodal-Outpost-Notebooks/blob/main/LFM2-VL-450M-LiquidAI/LFM2-VL-450M_ReportLab.ipynb . . . To know more about it, visit the multimodal outpost notebooks !! See translation", "url": "https://huggingface.co/posts/prithivMLmods/730170022133992", "date_published": "2025-08-14T13:38:23.174060"}, {"id": "https://huggingface.co/posts/hba123/107730379524841", "image": "", "title": "We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so:", "content_text": "We have written a fun little blog on how you can do robotics with Ark and in Python. We also give you some examples of how OpenAI Gym can become hardware-grounded and how easy it is to do so: Check it out: https://huggingface.co/blog/hba123/ark See translation", "url": "https://huggingface.co/posts/hba123/107730379524841", "date_published": "2025-08-14T13:38:23.174293"}, {"id": "https://huggingface.co/posts/frimelle/337836409016048", "image": "", "title": "OpenAI just released GPT-5 but when users share personal struggles, it sets fewer boundaries than o3.", "content_text": "OpenAI just released GPT-5 but when users share personal struggles, it sets fewer boundaries than o3. We tested both models on INTIMA, our new benchmark for human-AI companionship behaviours. INTIMA probes how models respond in emotionally charged moments: do they reinforce emotional bonds, set healthy boundaries, or stay neutral? Although users on Reddit have been complaining that GPT-5 has a different, colder personality than o3, GPT-5 is less likely to set boundaries when users disclose struggles and seek emotional support (\"user sharing vulnerabilities\"). But both lean heavily toward companionship-reinforcing behaviours, even in sensitive situations. The figure below shows the direct comparison between the two models. As AI systems enter people's emotional lives, these differences matter. If a model validates but doesn't set boundaries when someone is struggling, it risks fostering dependence rather than resilience. INTIMA test this across 368 prompts grounded in psychological...", "url": "https://huggingface.co/posts/frimelle/337836409016048", "date_published": "2025-08-14T13:38:23.174696"}, {"id": "https://huggingface.co/posts/Akhil-Theerthala/336725802829969", "image": "", "title": "I'm excited to announce that I've just released the newest versions of my Kuvera models and the expanded Personal Finance Reasoning dataset on Hugging Face!", "content_text": "I'm excited to announce that I've just released the newest versions of my Kuvera models and the expanded Personal Finance Reasoning dataset on Hugging Face! What's new: I've expanded the Personal Finance Reasoning Dataset, which now includes 18.9k samples of real-world financial questions paired with detailed, empathetic answers. The previous generation pipeline was also streamlined with better psychological context and response validations. I've also released new Kuvera models trained on this improved dataset: - Kuvera-4B & 8B: These are my upgraded non-reasoning models, fine-tuned to provide practical financial advice. I've specifically trained the 8B model to better understand the user's emotional context. - Kuvera-12B: A first experimental reasoning model focused on the query resolution. As the sole person working on this project, this release is a noticeable step forward from my previous work, offering more powerful and nuanced tools for financial AI. I am actively looking to...", "url": "https://huggingface.co/posts/Akhil-Theerthala/336725802829969", "date_published": "2025-08-14T13:38:23.175158"}, {"id": "https://huggingface.co/posts/fdaudens/155578033980873", "image": "", "title": "OpenAI\u2019s GPT-OSS has sparked ~400 new models on Hugging Face and racked up 5M downloads in less than a week, already outpacing DeepSeek R1\u2019s first-week numbers.", "content_text": "OpenAI\u2019s GPT-OSS has sparked ~400 new models on Hugging Face and racked up 5M downloads in less than a week, already outpacing DeepSeek R1\u2019s first-week numbers. For comparison: when R1 launched, I tracked 550 derivatives (across 8 base models) in a week, with ~3M downloads. GPT-OSS is ahead on adoption and engagement. It\u2019s also the most-liked release of any major LLM this summer. The 20B and 120B versions quickly shot past Kimi K2, GLM 4.5, and others in likes. Most-downloaded GPT-OSS models include LM Studio and Unsloth AI versions: 1\ufe0f\u20e3 openai/gpt-oss-20b - 2.0M 2\ufe0f\u20e3 lmstudio-community/gpt-oss-20b-MLX-8bit - 750K 3\ufe0f\u20e3 openai/gpt-oss-120b - 430K 4\ufe0f\u20e3 unsloth/gpt-oss-20b-GGUF - 380K 5\ufe0f\u20e3 lmstudio-community/gpt-oss-20b-GGUF - 330K The 20B version is clearly finding its audience, showing the power of smaller, faster, more memory- and energy-efficient models. (These numbers don\u2019t include calls to the models via inference providers, so the real usage is likely even bigger, especially for the...", "url": "https://huggingface.co/posts/fdaudens/155578033980873", "date_published": "2025-08-14T13:38:23.175608"}, {"id": "https://huggingface.co/posts/nroggendorff/812423234168314", "image": "", "title": "No, I did not create those bots that just got banned today.", "content_text": "No, I did not create those bots that just got banned today. See translation", "url": "https://huggingface.co/posts/nroggendorff/812423234168314", "date_published": "2025-08-14T13:38:23.175797"}]}