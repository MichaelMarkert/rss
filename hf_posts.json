{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/prithivMLmods/771186692524026", "image": "", "title": "LTX-2 Camera-Control LoRA demo with dolly-in/out and dolly-left/right is now available on Hugging Face, paired with ltx-2-19b-distilled-lora for fast inference. It also includes dynamic GPU duration adjustments for long video generations. Click the related Space links below.", "content_text": "LTX-2 Camera-Control LoRA demo with dolly-in/out and dolly-left/right is now available on Hugging Face, paired with ltx-2-19b-distilled-lora for fast inference. It also includes dynamic GPU duration adjustments for long video generations. Click the related Space links below. \ud83e\udd17Try it now on : prithivMLmods/LTX-2-LoRAs-Camera-Control-Dolly \u2b50Github: https://github.com/PRITHIVSAKTHIUR/LTX-2-LoRAs-Camera-Control-Dolly \ud83d\udd79\ufe0fCollection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection To learn more, visit the app page or the respective model pages. See translation", "url": "https://huggingface.co/posts/prithivMLmods/771186692524026", "date_published": "2026-01-13T17:30:58.710404"}, {"id": "https://huggingface.co/posts/AdinaY/646030921039082", "image": "", "title": "AgentCPM-Explore\ud83d\udd25 on device agent foundation model released by OpenBMB", "content_text": "AgentCPM-Explore\ud83d\udd25 on device agent foundation model released by OpenBMB openbmb/AgentCPM-Explore \u2728 4B - Apache2.0 \u2728 Supports 100+ multi-turn environment interactions with search + verification \u2728 Full training/inference stack is openly shared as well See translation", "url": "https://huggingface.co/posts/AdinaY/646030921039082", "date_published": "2026-01-13T17:30:58.710682"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/671443723641634", "image": "", "title": "NVFP4 With CUDA 13 Full Tutorial, 100%+ Speed Gain + Quality Comparison & New Cheap Cloud SimplePod", "content_text": "NVFP4 With CUDA 13 Full Tutorial, 100%+ Speed Gain + Quality Comparison & New Cheap Cloud SimplePod Full tutorial: https://www.youtube.com/watch?v=yOj9PYq3XYM Finally NVFP4 models has arrived to ComfyUI thus SwarmUI with CUDA 13. NVFP4 models are literally 100%+ faster with minimal impact on quality. I have done grid quality comparison to show you the difference on FLUX 2, Z Image Turbo and FLUX 1 of NVFP4 versions. To make CUDA 13 work, I have compiled Flash Attention, Sage Attention & xFormers for both Windows and Linux with all of the CUDA archs to support literally all GPUs starting from GTX 1650 series, RTX 2000, 3000, 4000, 5000 series and more. In this full tutorial, I will show you how to upgrade your ComfyUI and thus SwarmUI to use latest CUDA 13 with latest libraries and Torch 2.9.1. Moreover, our compiled libraries such as Sage Attention works with all models on all GPUs without generating black images or videos such as Qwen Image or Wan 2.2 models. Hopefully LTX 2...", "url": "https://huggingface.co/posts/MonsterMMORPG/671443723641634", "date_published": "2026-01-13T17:30:58.711351"}, {"id": "https://huggingface.co/posts/mindchain/535995505101203", "image": "", "title": "Claude Code Self & Continual Learning", "content_text": "Claude Code Self & Continual Learning Hey everyone! \ud83d\udc4b 30 GitHub Stars in 4 Days - Thank You! I'm really grateful for the positive response to the Claude Reflect System. In just 4 days, 30 developers have shown interest by starring the project. Thank you so much! What Is Claude Reflect? Correct once, never again. Claude Reflect helps Claude Code remember your corrections and preferences across sessions. Instead of repeating the same feedback, the system learns and applies it automatically. Main Features: \ud83e\udde0 Learning System - Detects corrections and preferences from conversations - Stores them permanently in skill files - Applies learnings in future sessions \ud83d\udd12 Safety First - Automatic backups before changes - YAML validation - Git version control \u26a1 Two Modes - Manual: Run /reflect when you want - Auto: Reflects automatically at session end How It Works If you correct Claude to use pytest instead of unittest, this preference gets saved. Next time, Claude will remember and use pytest...", "url": "https://huggingface.co/posts/mindchain/535995505101203", "date_published": "2026-01-13T17:30:58.711985"}, {"id": "https://huggingface.co/posts/AdinaY/528053481951824", "image": "", "title": "Based on 2025 Chinese AI Timeline, here are some interesting takeaways:", "content_text": "Based on 2025 Chinese AI Timeline, here are some interesting takeaways: \u2728 DeepSeek cadence: They shipped almost every month! (except Feb 2025) \u2728 Qwen trajectory: Not a single \u201chit\u201d model, but an expanding product line. VL/Math/Coder/Reranker/Embedding/Omni/Next/Image \u2728 Multimodal trend: Steadily rising share, shifting from generation to editing + tooling. \u2728 Reasoning as a main track: more engineered, system-level reasoning. \u2728 From foundation to components: growth in infra models (embeddings, rerankers, OCR, speech) signals a move toward deployable stacks. \u2728 Ecosystem broadening: more players beyond the top labs. Follow for more updates\ud83d\udc49 zh-ai-community See translation", "url": "https://huggingface.co/posts/AdinaY/528053481951824", "date_published": "2026-01-13T17:30:58.712354"}, {"id": "https://huggingface.co/posts/MikeDoes/151930847327570", "image": "", "title": "Building powerful multilingual AI shouldn't mean sacrificing user privacy.", "content_text": "Building powerful multilingual AI shouldn't mean sacrificing user privacy. We're highlighting a solution-oriented report from researchers Sahana Naganandh, Vaibhav V, and Thenmozhi M at Vellore Institute of Technology that investigates this exact challenge. The direct connection to our mission is clear: the paper showcases the PII43K dataset as a privacy-preserving alternative to high-risk, raw multilingual data The report notes that our dataset, with its structured anonymization, is a \"useful option for privacy-centric AI applications.\" It's always a delight when academic research independently validates our data-first approach to solving real-world privacy problems. This is how we build a safer AI future together. \ud83d\udd17 Read the full report here to learn more: https://assets.cureusjournals.com/artifacts/upload/technical_report/pdf/3689/20250724-59151-93w9ar.pdf \ud83d\ude80 Stay updated on the latest in privacy-preserving AI\u2014follow us on LinkedIn:...", "url": "https://huggingface.co/posts/MikeDoes/151930847327570", "date_published": "2026-01-13T17:30:58.712829"}, {"id": "https://huggingface.co/posts/unmodeled-tyler/815553899913449", "image": "", "title": "NEW MODEL:", "content_text": "NEW MODEL: vanta-research/mox-8b Hey everyone! I changed up my approach with this one a bit. Mox was designed with the following characteristics: - self coherence - direct opinions - epistemic confidence - grounded meta-awareness - reasoned refusals I've been thinking a lot about what \"helpfulness\" means lately. Commonly in AI, that looks like fulfilling user requests as closely as possible as long as the request isn't unsafe. But I wanted to know what it was like to build a model that might be helpful in the same way a human would be. For example, if you ask Mox to write a 10 page paper on the cultural significance of staplers, Mox will probably refuse, tell you that wouldn't be useful or helpful to ANYBODY and recommend a different, but more useful approach. Mox is still very much a work in progress, but I think that this is a good starting point! I'm already generating more datasets to add more elements to Mox's persona in future versions, which you should see on the hub soon!...", "url": "https://huggingface.co/posts/unmodeled-tyler/815553899913449", "date_published": "2026-01-13T17:30:58.713221"}, {"id": "https://huggingface.co/posts/branikita/526284345540053", "image": "", "title": "Our engineer Alan from", "content_text": "Our engineer Alan from https://robonine.com team has assembled the mechanical frame of our 6-DoF manipulator prototype - without servo motors for now. At this stage we are evaluating how easy the structure is to assemble, checking for any mechanical play, and validating the kinematics. Good news: the structure feels solid and Alan reports no detectable backlash so far. See translation", "url": "https://huggingface.co/posts/branikita/526284345540053", "date_published": "2026-01-13T17:30:58.713472"}, {"id": "https://huggingface.co/posts/Ujjwal-Tyagi/141864984025794", "image": "", "title": "I\u2019m looking for AI engineers and researchers to join my company as part of the core team. We\u2019ll be working on cutting-edge research and hands-on implementation across LLMs and related systems. I\u2019m especially interested in founding engineers for my ai startup, who want to build from the ground up and shape both the product and the research direction. If this sounds interesting to you, reply to this post and message me on Discord \u2014 my username is \"ujjwal_tyagi.shirova\", Please also attach your Resume and Details of your open source projects (if any related to LLMs) on discord, avoid sharing here as a reply to this post.", "content_text": "I\u2019m looking for AI engineers and researchers to join my company as part of the core team. We\u2019ll be working on cutting-edge research and hands-on implementation across LLMs and related systems. I\u2019m especially interested in founding engineers for my ai startup, who want to build from the ground up and shape both the product and the research direction. If this sounds interesting to you, reply to this post and message me on Discord \u2014 my username is \"ujjwal_tyagi.shirova\", Please also attach your Resume and Details of your open source projects (if any related to LLMs) on discord, avoid sharing here as a reply to this post. See translation", "url": "https://huggingface.co/posts/Ujjwal-Tyagi/141864984025794", "date_published": "2026-01-13T17:30:58.713823"}, {"id": "https://huggingface.co/posts/kanaria007/479061057773185", "image": "", "title": "\u2705 New Article: *Designing, Safeguarding, and Evaluating Learning Companions* (v0.1)", "content_text": "\u2705 New Article: *Designing, Safeguarding, and Evaluating Learning Companions* (v0.1) Title: \ud83d\udee1\ufe0f Designing, Safeguarding, and Evaluating SI-Core Learning Companions \ud83d\udd17 https://huggingface.co/blog/kanaria007/designing-safeguarding-and-evaluating --- Summary: Most \u201cAI tutoring\u201d talks about prompts, content, and engagement graphs. But real learning companions\u2014especially for children / ND learners\u2014fail in quieter ways: *the system \u201cworks\u201d while stress rises, agency drops, or fairness erodes.* This article is a practical playbook for building SI-Core\u2013wrapped learning companions that are *goal-aware (GCS surfaces), safety-bounded (ETH guardrails), and honestly evaluated (PoC \u2192 real-world studies)*\u2014without collapsing everything into a single score. > Mastery is important, but not the only axis. > *Wellbeing, autonomy, and fairness must be first-class.* --- Why It Matters: \u2022 Replaces \u201cone number\u201d optimization with *goal surfaces* (and explicit anti-goals) \u2022 Treats *child/ND safety* as a runtime...", "url": "https://huggingface.co/posts/kanaria007/479061057773185", "date_published": "2026-01-13T17:30:58.714468"}]}