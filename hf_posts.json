{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/446160279272944", "image": "", "title": "Run OpenAI's new gpt-oss models locally with Unsloth GGUFs! \ud83d\udd25\ud83e\udda5", "content_text": "Run OpenAI's new gpt-oss models locally with Unsloth GGUFs! \ud83d\udd25\ud83e\udda5 20b GGUF: unsloth/gpt-oss-20b-GGUF 120b GGUF: unsloth/gpt-oss-120b-GGUF Model will run on 14GB RAM for 20b and 66GB for 120b. See translation", "url": "https://huggingface.co/posts/danielhanchen/446160279272944", "date_published": "2025-08-07T05:32:44.131128"}, {"id": "https://huggingface.co/posts/ImranzamanML/667361724381561", "image": "", "title": "Finaly OpenAI is open to share open-source models after GPT2-2019.", "content_text": "Finaly OpenAI is open to share open-source models after GPT2-2019. gpt-oss-120b gpt-oss-20b openai/gpt-oss-120b #AI #GPT #LLM #Openai See translation", "url": "https://huggingface.co/posts/ImranzamanML/667361724381561", "date_published": "2025-08-07T05:32:44.131356"}, {"id": "https://huggingface.co/posts/prithivMLmods/372876915549424", "image": "", "title": "Qwen Image \u2013 The Latest Image Generation Model\ud83d\udd25", "content_text": "Qwen Image \u2013 The Latest Image Generation Model\ud83d\udd25 Below are some samples generated using the Qwen Image Diffusion Model. Qwen-Image, a 20B MMDiT model for next-generation text-to-image generation, preserves typographic details, layout coherence, and contextual harmony with stunning accuracy. It is especially strong at creating stunning graphic posters with native text. The model is now open-source. [ \ud835\ude80\ud835\udea0\ud835\ude8e\ud835\ude97-\ud835\ude78\ud835\ude96\ud835\ude8a\ud835\ude90\ud835\ude8e : Qwen/Qwen-Image ] \u2937 Try the Qwen Image demo here: prithivMLmods/Qwen-Image-Diffusion , Qwen/Qwen-Image & more ... \u2937 Qwen-Image Technical Report : Qwen-Image Technical Report (2508.02324) \u2937 Qwen Image [GitHub] : https://github.com/QwenLM/Qwen-Image Even more impressively, it demonstrates a strong ability to understand images. The model supports a wide range of vision-related tasks such as object detection, semantic segmentation, depth and edge (Canny) estimation, novel view synthesis, and image super-resolution. While each task is technically distinct, they can all be viewed...", "url": "https://huggingface.co/posts/prithivMLmods/372876915549424", "date_published": "2025-08-07T05:32:44.131927"}, {"id": "https://huggingface.co/posts/mitkox/378542221866585", "image": "", "title": "I run Claude Code with Qwen3 Coder Flash locally on my MacBook Air. It works offline, zero cloud, zero internet, zero EU AI Act anxiety. No limit with all tokens on the house.", "content_text": "I run Claude Code with Qwen3 Coder Flash locally on my MacBook Air. It works offline, zero cloud, zero internet, zero EU AI Act anxiety. No limit with all tokens on the house. It\u2019s not great, not terrible- adequate performance for an on device AI agent chewing through code on a 1.24 kg laptop. I wrote an interpreter to broker peace between Claude Code and my local AI runtime. Make sure you own your AI. AI in the cloud is not aligned with you; it\u2019s aligned with the company that owns it. See translation", "url": "https://huggingface.co/posts/mitkox/378542221866585", "date_published": "2025-08-07T05:32:44.132245"}, {"id": "https://huggingface.co/posts/openfree/275314685023370", "image": "", "title": "\ud83d\ude80 GPT-OSS 120B & 20B - Use Both Models in One Space!", "content_text": "\ud83d\ude80 GPT-OSS 120B & 20B - Use Both Models in One Space! openfree/OpenAI-gpt-oss VIDraft/gpt-oss-RAG \ud83c\udfaf Two Models, One Space! GPT-OSS hit #1 on HF just 2 hours after release! \ud83c\udfc6 Now you can use both models conveniently in a single space. \ud83d\udccb Model Selection Made Easy! Just pick from the dropdown \u2705 \u251c\u2500\u2500 GPT-OSS-120B (Complex tasks) \u2514\u2500\u2500 GPT-OSS-20B (Quick chats) \ud83d\udcab How to Use (Takes 30 seconds!) Sign in \u2192 With your HF account \ud83d\udd10 Select model \u2192 Choose what you need \ud83d\udccc Apply \u2192 Click! \u26a1 Start chatting \u2192 That's it! \ud83d\udcac \ud83c\udf08 Perfect For: 120B \u2192 Deep analysis, professional work \ud83e\udde0 20B \u2192 Fast responses, casual conversations \u26a1 No installation needed - just use it in your browser! \ud83c\udf10 \u2728 Special Features \ud83c\udfa8 Beautiful gradient UI \ud83c\udf19 Dark mode support \ud83d\udd04 Real-time model switching \ud83c\udd93 Completely free! \ud83d\udc49 Try it now! It's really that simple! #GPT-OSS #HuggingFace #FreeAI #EasyToUse See translation", "url": "https://huggingface.co/posts/openfree/275314685023370", "date_published": "2025-08-07T05:32:44.132683"}, {"id": "https://huggingface.co/posts/neph1/202844482773668", "image": "", "title": "I'm building a mmo-ish RPG with LLM agents that can (hopefully) complete player tasks, as an experiment. I've started documenting my progress here:", "content_text": "I'm building a mmo-ish RPG with LLM agents that can (hopefully) complete player tasks, as an experiment. I've started documenting my progress here: https://huggingface.co/blog/neph1/rpg-llm-agents Let me know if you want to see more of it. See translation", "url": "https://huggingface.co/posts/neph1/202844482773668", "date_published": "2025-08-07T05:32:44.132930"}, {"id": "https://huggingface.co/posts/tomaarsen/619466658423382", "image": "", "title": "\ud83d\ude0e I just published Sentence Transformers v5.1.0, and it's a big one. 2x-3x speedups of SparseEncoder models via ONNX and/or OpenVINO backends, easier distillation data preparation with hard negatives mining, and more:", "content_text": "\ud83d\ude0e I just published Sentence Transformers v5.1.0, and it's a big one. 2x-3x speedups of SparseEncoder models via ONNX and/or OpenVINO backends, easier distillation data preparation with hard negatives mining, and more: 1\ufe0f\u20e3 Faster ONNX and OpenVINO backends for SparseEncoder models Usage is as simple as backend=\"onnx\" or backend=\"openvino\" when initializing a SparseEncoder to get started, but I also included utility functions for optimization, dynamic quantization, and static quantization, plus benchmarks. 2\ufe0f\u20e3 New n-tuple-scores output format from mine_hard_negatives This new output format is immediately compatible with the MarginMSELoss and SparseMarginMSELoss for training SentenceTransformer, CrossEncoder, and SparseEncoder losses. 3\ufe0f\u20e3 Gathering across devices When doing multi-GPU training using a loss that has in-batch negatives (e.g. MultipleNegativesRankingLoss), you can now use gather_across_devices=True to load in-batch negatives from the other devices too! Essentially a free...", "url": "https://huggingface.co/posts/tomaarsen/619466658423382", "date_published": "2025-08-07T05:32:44.133535"}, {"id": "https://huggingface.co/posts/fdaudens/331415397781817", "image": "", "title": "Well, it took just 2 hours for", "content_text": "Well, it took just 2 hours for openai/gpt-oss-120b to hit #1 on Hugging Face. Don\u2019t remember seeing anything rise that fast! See translation", "url": "https://huggingface.co/posts/fdaudens/331415397781817", "date_published": "2025-08-07T05:32:44.133771"}, {"id": "https://huggingface.co/posts/JingzeShi/527939367728783", "image": "", "title": "Trainable selective sampling and sparse attention kernels are indispensable in the era of context engineering. We hope our work will be helpful to everyone! \ud83e\udd17", "content_text": "Trainable selective sampling and sparse attention kernels are indispensable in the era of context engineering. We hope our work will be helpful to everyone! \ud83e\udd17 Trainable Dynamic Mask Sparse Attention (2508.02124) See translation", "url": "https://huggingface.co/posts/JingzeShi/527939367728783", "date_published": "2025-08-07T05:32:44.134000"}, {"id": "https://huggingface.co/posts/ginipick/461357732375110", "image": "", "title": "\ud83d\ude80 FLUXllama gpt-oss: 4-bit Quantization + GPT-OSS-120B = Perfect AI Image Generation", "content_text": "\ud83d\ude80 FLUXllama gpt-oss: 4-bit Quantization + GPT-OSS-120B = Perfect AI Image Generation \ud83c\udfaf One-Line Summary \"Maximum Images with Minimal Memory!\" - The perfect fusion of 4-bit quantization and GPT-OSS-120B prompt enhancement ginipick/FLUXllama \ud83e\udde0 Core Innovation: Prompt Enhancement System \ud83d\udcdd What You Type: \"cat\" \u2728 What GPT-OSS-120B Transforms: \"Majestic tabby cat with emerald eyes in golden afternoon light, soft bokeh, cinematic lighting, 8K photorealistic\" \ud83d\udca1 Result: Beginners create professional-grade images instantly! \u26a1 The Magic of 4-bit Quantization \ud83d\udd25 Before (Standard Model) \ud83d\udce6 Memory: 24GB VRAM required \u23f1\ufe0f Loading: 45 seconds \ud83d\udcb0 Cost: RTX 4090 essential ($2000+) \ud83c\udf89 After (FLUXllama gpt-oss 4-bit) \ud83d\udce6 Memory: 6GB VRAM (75% reduction!) \u23f1\ufe0f Loading: 12 seconds (73% faster!) \ud83d\udcb0 Cost: RTX 3060 works great! ($400) Same quality, 4x efficiency! \ud83c\udf8a \ud83d\udd27 Simple Model Swapping python# Switch to any LLM in 1 second! pipe = pipeline(\"text-generation\", model=\"your-model\") \u2705 GPT-OSS-120B (Premium quality) \u2705...", "url": "https://huggingface.co/posts/ginipick/461357732375110", "date_published": "2025-08-07T05:32:44.134560"}]}