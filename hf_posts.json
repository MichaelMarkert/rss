{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/lysandre/966361810633890", "image": "", "title": "SmolVLM-2 and SigLIP-2 are now part of", "content_text": "SmolVLM-2 and SigLIP-2 are now part of transformers in dedicated releases! They're added on top of the v4.49.0 release, and can be installed from the following tags: v4.49.0-SmolVLM-2 and v4.49.0-SigLIP-2 . This marks a new beginning for the release process of transformers. For the past five years, we've been doing monthly releases featuring many models (v4.49.0, the latest release, features 9 new architectures). Starting with SmolVLM-2 & SigLIP2, we'll now additionally release tags supporting new models on a stable branch. These models are therefore directly available for use by installing from the tag itself. These tags will continue to be updated with fixes applied to these models. Going forward, continue expecting software releases following semantic versioning: v4.50.0 will have ~10 new architectures compared to v4.49.0, as well as a myriad of new features, improvements and bug fixes. Accompanying these software releases, we'll release tags offering brand new models as fast as...", "url": "https://huggingface.co/posts/lysandre/966361810633890", "date_published": "2025-02-22T05:18:55.198911"}, {"id": "https://huggingface.co/posts/DmitryRyumin/189065722993769", "image": "", "title": "\ud83d\ude80\ud83c\udfad\ud83c\udf1f New Research Alert - WACV 2025 (Avatars Collection)! \ud83c\udf1f\ud83c\udfad\ud83d\ude80", "content_text": "\ud83d\ude80\ud83c\udfad\ud83c\udf1f New Research Alert - WACV 2025 (Avatars Collection)! \ud83c\udf1f\ud83c\udfad\ud83d\ude80 \ud83d\udcc4 Title: EmoVOCA: Speech-Driven Emotional 3D Talking Heads \ud83d\udd1d \ud83d\udcdd Description: EmoVOCA is a data-driven method for generating emotional 3D talking heads by combining speech-driven lip movements with expressive facial dynamics. This method has been developed to overcome the limitations of corpora and to achieve state-of-the-art animation quality. \ud83d\udc65 Authors: @ FedeNoce , Claudio Ferrari, and Stefano Berretti \ud83d\udcc5 Conference: WACV, 28 Feb \u2013 4 Mar, 2025 | Arizona, USA \ud83c\uddfa\ud83c\uddf8 \ud83d\udcc4 Paper: https://arxiv.org/abs/2403.12886 \ud83c\udf10 Github Page: https://fedenoce.github.io/emovoca/ \ud83d\udcc1 Repository: https://github.com/miccunifi/EmoVOCA \ud83d\ude80 CVPR-2023-24-Papers: https://github.com/DmitryRyumin/CVPR-2023-24-Papers \ud83d\ude80 WACV-2024-Papers: https://github.com/DmitryRyumin/WACV-2024-Papers \ud83d\ude80 ICCV-2023-Papers: https://github.com/DmitryRyumin/ICCV-2023-Papers \ud83d\udcda More Papers: more cutting-edge research presented at other conferences in the DmitryRyumin/NewEraAI-Papers...", "url": "https://huggingface.co/posts/DmitryRyumin/189065722993769", "date_published": "2025-02-22T05:18:55.199453"}, {"id": "https://huggingface.co/posts/merve/467807900895850", "image": "", "title": "Google just released PaliGemma 2 Mix: new versatile instruction vision language models \ud83d\udd25", "content_text": "Google just released PaliGemma 2 Mix: new versatile instruction vision language models \ud83d\udd25 > Three new models: 3B, 10B, 28B with res 224, 448 \ud83d\udc99 > Can do vision language tasks with open-ended prompts, understand documents, and segment or detect anything \ud83e\udd2f Read more https://huggingface.co/blog/paligemma2mix Try the demo google/paligemma2-10b-mix All models are here google/paligemma-2-mix-67ac6a251aaf3ee73679dcc4 See translation", "url": "https://huggingface.co/posts/merve/467807900895850", "date_published": "2025-02-22T05:18:55.199763"}, {"id": "https://huggingface.co/posts/burtenshaw/189514834246661", "image": "", "title": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts:", "content_text": "AGENTS + FINETUNING! This week Hugging Face learn has a whole pathway on finetuning for agentic applications. You can follow these two courses to get knowledge on levelling up your agent game beyond prompts: 1\ufe0f\u20e3 New Supervised Fine-tuning unit in the NLP Course https://huggingface.co/learn/nlp-course/en/chapter11/1 2\ufe0f\u20e3New Finetuning for agents bonus module in the Agents Course https://huggingface.co/learn/agents-course/bonus-unit1/introduction Fine-tuning will squeeze everything out of your model for how you\u2019re using it, more than any prompt. See translation", "url": "https://huggingface.co/posts/burtenshaw/189514834246661", "date_published": "2025-02-22T05:18:55.200089"}, {"id": "https://huggingface.co/posts/jsulz/911431940353906", "image": "", "title": "Time flies!", "content_text": "Time flies! Six months after joining Hugging Face the Xet team is kicking off the first migrations from LFS to our storage for a number of repositories on the Hub. More on the nitty gritty details behind the migration soon, but here are the big takeaways: \ud83e\udd16 We've successfully completed the first migrations from LFS -> Xet to test the infrastructure and prepare for a wider release \u2705 No action on your part needed - you can work with a Xet-backed repo like any other repo on the Hub (for now - major improvements on their way!) \ud83d\udc40 Keep an eye out for the Xet logo to see if a repo you know is on our infra! See the screenshots below to spot the difference \ud83d\udc47 \u23e9 \u23e9 \u23e9 Blazing uploads and downloads coming soon. W\u2019re gearing up for a full integration with the Hub's Python library that will make building on the Hub faster than ever - special thanks to @ celinah and @ Wauplin for their assistance. \ud83c\udf89 Want Early Access? If you\u2019re curious and want to test it out the bleeding edge that will power the...", "url": "https://huggingface.co/posts/jsulz/911431940353906", "date_published": "2025-02-22T05:18:55.200650"}, {"id": "https://huggingface.co/posts/smirki/311150694603392", "image": "", "title": "UIGEN for Tailwind v4 is coming soon!", "content_text": "UIGEN for Tailwind v4 is coming soon! See translation", "url": "https://huggingface.co/posts/smirki/311150694603392", "date_published": "2025-02-22T05:18:55.200866"}, {"id": "https://huggingface.co/posts/JingzeShi/354750943862398", "image": "", "title": "\ud83e\udd17Welcome to the Doge Edge Device Small language Model.", "content_text": "\ud83e\udd17Welcome to the Doge Edge Device Small language Model. SmallDoge/Doge-160M-Instruct See translation", "url": "https://huggingface.co/posts/JingzeShi/354750943862398", "date_published": "2025-02-22T05:18:55.201078"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/561059857144028", "image": "", "title": "IDM VTON : Virtual Try On APP Automatic Installers for Windows, RunPod, Massed Compute and a free Kaggle Account notebook Published - Can transfer objects too", "content_text": "IDM VTON : Virtual Try On APP Automatic Installers for Windows, RunPod, Massed Compute and a free Kaggle Account notebook Published - Can transfer objects too Installers & APP 1-Click installers for Windows, RunPod, Massed Compute and a free Kaggle account notebook in below link: https://www.patreon.com/posts/122718239 Features Seamlessly install on Windows, RunPod, Massed Compute and on Kaggle with just 1-click into a Python 3.10 VENV Our APP has so many extra features Can perfectly handle any resolution and aspect ratio images You can perfectly manually mask via latest version of Gradio and properly working image editor Supports 4-bit, 8-bit quantization + CPU offloading for lower VRAM GPUs All generated images are also automatically saved You can also generate more than 1 image like 10 images as batch generation with order Official repo : https://idm-vton.github.io/ See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/561059857144028", "date_published": "2025-02-22T05:18:55.201443"}, {"id": "https://huggingface.co/posts/jasoncorkill/138106605710984", "image": "", "title": "Integrating human feedback is vital for evolving AI models. Boost quality, scalability, and cost-effectiveness with our crowdsourcing tool!", "content_text": "Integrating human feedback is vital for evolving AI models. Boost quality, scalability, and cost-effectiveness with our crowdsourcing tool! ..Or run A/B tests and gather thousands of responses in minutes. Upload two images, ask a question, and watch the insights roll in! Check it out here and let us know your feedback: https://app.rapidata.ai/compare See translation", "url": "https://huggingface.co/posts/jasoncorkill/138106605710984", "date_published": "2025-02-22T05:18:55.201703"}, {"id": "https://huggingface.co/posts/fdaudens/121352437859372", "image": "", "title": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses.", "content_text": "\ud83c\udfaf Perplexity drops their FIRST open-weight model on Hugging Face: A decensored DeepSeek-R1 with full reasoning capabilities. Tested on 1000+ examples for unbiased responses. Check it out: perplexity-ai/r1-1776 Blog post: https://perplexity.ai/hub/blog/open-sourcing-r1-1776 See translation", "url": "https://huggingface.co/posts/fdaudens/121352437859372", "date_published": "2025-02-22T05:18:55.201960"}]}