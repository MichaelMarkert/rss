{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/jasoncorkill/653065305581211", "image": "", "title": "\ud83d\ude80 Building Better Evaluations: 32K Image Annotations Now Available", "content_text": "\ud83d\ude80 Building Better Evaluations: 32K Image Annotations Now Available Today, we're releasing an expanded version: 32K images annotated with 3.7M responses from over 300K individuals which was completed in under two weeks using the Rapidata Python API. Rapidata/text-2-image-Rich-Human-Feedback-32k A few months ago, we published one of our most liked dataset with 13K images based on the @ data-is-better-together 's dataset, following Google's research on \"Rich Human Feedback for Text-to-Image Generation\" ( https://arxiv.org/abs/2312.10240 ). It collected over 1.5M responses from 150K+ participants. Rapidata/text-2-image-Rich-Human-Feedback In the examples below, users highlighted words from prompts that were not correctly depicted in the generated images. Higher word scores indicate more frequent issues. If an image captured the prompt accurately, users could select [No_mistakes]. We're continuing to work on large-scale human feedback and model evaluation. If you're working on related...", "url": "https://huggingface.co/posts/jasoncorkill/653065305581211", "date_published": "2025-04-30T09:24:57.600293"}, {"id": "https://huggingface.co/posts/merterbak/337137510653930", "image": "", "title": "Qwen 3 models released\ud83d\udd25", "content_text": "Qwen 3 models released\ud83d\udd25 It offers 2 MoE and 6 dense models with following parameter sizes: 0.6B, 1.7B, 4B, 8B, 14B, 30B(MoE), 32B, and 235B(MoE). Models: Qwen/qwen3-67dd247413f0e2e4f653967f Blog: https://qwenlm.github.io/blog/qwen3/ Demo: Qwen/Qwen3-Demo GitHub: https://github.com/QwenLM/Qwen3 \u2705 Pre-trained 119 languages(36 trillion tokens) and dialects with strong translation and instruction following abilities. (Qwen2.5 was pre-trained on 18 trillion tokens.) \u2705Qwen3 dense models match the performance of larger Qwen2.5 models. For example, Qwen3-1.7B/4B/8B/14B/32B perform like Qwen2.5-3B/7B/14B/32B/72B. \u2705 Three stage done while pretraining: \u2022 Stage 1: General language learning and knowledge building. \u2022 Stage 2: Reasoning boost with STEM, coding, and logic skills. \u2022 Stage 3: Long context training \u2705 It supports MCP in the model \u2705 Strong agent skills \u2705 Supports seamless between thinking mode (for hard tasks like math and coding) and non-thinking mode (for fast chatting) inside chat...", "url": "https://huggingface.co/posts/merterbak/337137510653930", "date_published": "2025-04-30T09:24:57.600781"}, {"id": "https://huggingface.co/posts/Xenova/886388075601859", "image": "", "title": "Introducing the ONNX model explorer: Browse, search, and visualize neural networks directly in your browser. \ud83e\udd2f A great tool for anyone studying Machine Learning! We're also releasing the entire dataset of graphs so you can use them in your own projects! \ud83e\udd17", "content_text": "Introducing the ONNX model explorer: Browse, search, and visualize neural networks directly in your browser. \ud83e\udd2f A great tool for anyone studying Machine Learning! We're also releasing the entire dataset of graphs so you can use them in your own projects! \ud83e\udd17 Check it out! \ud83d\udc47 Demo: onnx-community/model-explorer Dataset: onnx-community/model-explorer Source code: https://github.com/xenova/model-explorer See translation", "url": "https://huggingface.co/posts/Xenova/886388075601859", "date_published": "2025-04-30T09:24:57.601068"}, {"id": "https://huggingface.co/posts/ginipick/433098376713304", "image": "", "title": "# \u2728 Dream of IKEA: The Future of AI Interior Design \u2728", "content_text": "# \u2728 Dream of IKEA: The Future of AI Interior Design \u2728 Hello, AI interior design enthusiasts! \ud83c\udfe0 Today I'm thrilled to introduce you to **\"Dream of IKEA\"** - an amazing project that will completely transform your living spaces! ## \ud83c\udf1f What Can It Do? **Dream of IKEA** is a magical tool that uses artificial intelligence to transform your ordinary spaces into the interior design of your dreams! \ud83e\ude84 - \ud83d\udcf8 Simply upload a photo of your room - \ud83d\udcad Describe your desired style or concept - \ud83c\udfa8 The AI will redesign your space with stunning results! ## \ud83c\udfc6 Key Features - **Diverse Style Selection** - Over 20 design styles including Minimalist, Bohemian, Japanese, Scandinavian, and more - **User-Friendly Interface** - Beautiful, intuitive UI that anyone can use - **High-Quality Image Generation** - Amazing quality powered by ControlNet and Stable Diffusion - **Customizable Prompts** - Create completely personalized designs with your own prompts ## \ud83d\udee0\ufe0f Technical Highlights This project utilizes cutting-edge...", "url": "https://huggingface.co/posts/ginipick/433098376713304", "date_published": "2025-04-30T09:24:57.601731"}, {"id": "https://huggingface.co/posts/Kseniase/484268922176188", "image": "", "title": "6 Free resources on Reinforcement Learning (RL)", "content_text": "6 Free resources on Reinforcement Learning (RL) RL now is where the real action is, it's the engine behind autonomous tech, robots, and the next wave of AI that thinks, moves and solves problems on its own. To stay up to date with what\u2019s happening in RL, we offer some fresh materials on it: 1. \"Reinforcement Learning from Human Feedback\" by Nathan Lambert -> https://rlhfbook.com/ It's a short introduction to RLHF, explaining instruction tuning, reward modeling, alignment methods, synthetic data, evaluation, and more 2. \"A Course in Reinforcement Learning (2nd Edition)\" by Dimitri P. Bertsekas -> https://www.mit.edu/~dimitrib/RLbook.html Explains dynamic programming (DP) and RL, diving into rollout algorithms, neural networks, policy learning, etc. It\u2019s packed with solved exercises and real-world examples 3. \"Mathematical Foundations of Reinforcement Learning\" video course by Shiyu Zhao -> https://www.youtube.com/playlist?list=PLEhdbSEZZbDaFWPX4gehhwB9vJZJ1DNm8 Offers a mathematical...", "url": "https://huggingface.co/posts/Kseniase/484268922176188", "date_published": "2025-04-30T09:24:57.602386"}, {"id": "https://huggingface.co/posts/nyuuzyou/112237159992701", "image": "", "title": "\ud83d\uddbc\ufe0f SVGFind Icons Dataset -", "content_text": "\ud83d\uddbc\ufe0f SVGFind Icons Dataset - nyuuzyou/svgfind Collection of 3,655,810 Scalable Vector Graphics (SVG) icons featuring: - Sourced from SVGFind across diverse categories & styles - Includes metadata: unique ID, title, tags, data pack, and license information - Contains minified SVG markup for direct use or processing - Organized into splits based on license type (Creative Commons: 3,645,444 icons, Public Domain: 10,366 icons) With over 3.6 million icons, this appears to be the largest SVG dataset on Hugging Face to date. If you're aware of a larger SVG collection, please let me know and I'll update this post with a reference to the largest dataset. See translation", "url": "https://huggingface.co/posts/nyuuzyou/112237159992701", "date_published": "2025-04-30T09:24:57.602740"}, {"id": "https://huggingface.co/posts/AdinaY/658134534684379", "image": "", "title": "Kimi-Audio \ud83d\ude80\ud83c\udfa7 an OPEN audio foundation model released by Moonshot AI", "content_text": "Kimi-Audio \ud83d\ude80\ud83c\udfa7 an OPEN audio foundation model released by Moonshot AI moonshotai/Kimi-Audio-7B-Instruct \u2728 7B \u2728 13M+ hours of pretraining data \u2728 Novel hybrid input architecture \u2728 Universal audio capabilities (ASR, AQA, AAC, SER, SEC/ASC, end-to-end conversation) See translation", "url": "https://huggingface.co/posts/AdinaY/658134534684379", "date_published": "2025-04-30T09:24:57.603004"}, {"id": "https://huggingface.co/posts/Jaward/748880241075570", "image": "", "title": "Finally my first solo preprint is here:) a love letter to the field. Nothing much lol, this is just me trying to finetune my understanding of research behind the recent breakthroughs in reasoning models. It\u2019s a preprint targeting beginners in the field -  will eventually make necessary changes later. In the meantime have fun with it:)", "content_text": "Finally my first solo preprint is here:) a love letter to the field. Nothing much lol, this is just me trying to finetune my understanding of research behind the recent breakthroughs in reasoning models. It\u2019s a preprint targeting beginners in the field - will eventually make necessary changes later. In the meantime have fun with it:) Download: https://github.com/Jaykef/Jaykef/blob/main/papers/The-Dawn-of-Thinking-Machines.pdf See translation", "url": "https://huggingface.co/posts/Jaward/748880241075570", "date_published": "2025-04-30T09:24:57.603297"}, {"id": "https://huggingface.co/posts/anakin87/692858936883406", "image": "", "title": "\ud835\udddc \ud835\ude01\ud835\uddff\ud835\uddee\ud835\uddf6\ud835\uddfb\ud835\uddf2\ud835\uddf1 \ud835\uddee \ud835\udddf\ud835\uddee\ud835\uddfb\ud835\uddf4\ud835\ude02\ud835\uddee\ud835\uddf4\ud835\uddf2 \ud835\udde0\ud835\uddfc\ud835\uddf1\ud835\uddf2\ud835\uddf9 \ud835\ude01\ud835\uddfc \ud835\ude00\ud835\uddf0\ud835\uddf5\ud835\uddf2\ud835\uddf1\ud835\ude02\ud835\uddf9\ud835\uddf2 \ud835\uddf2\ud835\ude03\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00 \ud835\ude04\ud835\uddf6\ud835\ude01\ud835\uddf5 \ud835\uddda\ud835\udde5\ud835\udde3\ud835\udde2! \ud83d\udc51 \ud83d\uddd3\ufe0f", "content_text": "\ud835\udddc \ud835\ude01\ud835\uddff\ud835\uddee\ud835\uddf6\ud835\uddfb\ud835\uddf2\ud835\uddf1 \ud835\uddee \ud835\udddf\ud835\uddee\ud835\uddfb\ud835\uddf4\ud835\ude02\ud835\uddee\ud835\uddf4\ud835\uddf2 \ud835\udde0\ud835\uddfc\ud835\uddf1\ud835\uddf2\ud835\uddf9 \ud835\ude01\ud835\uddfc \ud835\ude00\ud835\uddf0\ud835\uddf5\ud835\uddf2\ud835\uddf1\ud835\ude02\ud835\uddf9\ud835\uddf2 \ud835\uddf2\ud835\ude03\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00 \ud835\ude04\ud835\uddf6\ud835\ude01\ud835\uddf5 \ud835\uddda\ud835\udde5\ud835\udde3\ud835\udde2! \ud83d\udc51 \ud83d\uddd3\ufe0f \u270d\ufe0f Blog post: https://huggingface.co/blog/anakin87/qwen-scheduler-grpo I experimented with GRPO lately. I am fascinated by models learning from prompts and rewards - no example answers needed like in Supervised Fine-Tuning. After the DeepSeek boom, everyone is trying GRPO with GSM8K or the Countdown Game... I wanted a different challenge, like \ud835\ude01\ud835\uddf2\ud835\uddee\ud835\uddf0\ud835\uddf5\ud835\uddf6\ud835\uddfb\ud835\uddf4 \ud835\uddee \ud835\uddfa\ud835\uddfc\ud835\uddf1\ud835\uddf2\ud835\uddf9 \ud835\ude01\ud835\uddfc \ud835\uddf0\ud835\uddff\ud835\uddf2\ud835\uddee\ud835\ude01\ud835\uddf2 \ud835\uddee \ud835\ude00\ud835\uddf0\ud835\uddf5\ud835\uddf2\ud835\uddf1\ud835\ude02\ud835\uddf9\ud835\uddf2 \ud835\uddf3\ud835\uddff\ud835\uddfc\ud835\uddfa \ud835\uddee \ud835\uddf9\ud835\uddf6\ud835\ude00\ud835\ude01 \ud835\uddfc\ud835\uddf3 \ud835\uddf2\ud835\ude03\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00 \ud835\uddee\ud835\uddfb\ud835\uddf1 \ud835\uddfd\ud835\uddff\ud835\uddf6\ud835\uddfc\ud835\uddff\ud835\uddf6\ud835\ude01\ud835\uddf6\ud835\uddf2\ud835\ude00. Choosing an original problem forced me to: \ud83e\udd14 Think about the problem setting \ud83e\uddec Generate data \ud83e\udd0f Choose the right base model \ud83c\udfc6 Design reward functions (and experiencing reward hacking) \ud83d\udd04 Run multiple rounds of training, hoping that my model would learn something. A fun and rewarding \ud83d\ude04 experience. I learned a lot of things, that I want to share with you. \ud83d\udc47 \u270d\ufe0f Blog post: https://huggingface.co/blog/anakin87/qwen-scheduler-grpo \ud83d\udcbb Code: https://github.com/anakin87/qwen-scheduler-grpo \ud83e\udd17 Hugging Face collection...", "url": "https://huggingface.co/posts/anakin87/692858936883406", "date_published": "2025-04-30T09:24:57.603756"}, {"id": "https://huggingface.co/posts/ZennyKenny/876840490309462", "image": "", "title": "I've created a new dataset using the Algorithm of Thoughts architecture proposed by Sel et al. (2023) in a reasoning context. (paper:", "content_text": "I've created a new dataset using the Algorithm of Thoughts architecture proposed by Sel et al. (2023) in a reasoning context. (paper: https://arxiv.org/pdf/2308.10379 ) The dataset simulates the discovery phase of a fictitious VC firm called Reasoned Capital and, once expanded, can be used to create models which are able to make complex, subjective financial decisions based on different criteria. The generation process encourages recursive problem-solving in increasingly complex prompts to encourage models to assess and reevaluate the conclusions and generated opinions of upstream models. Pretty neat stuff, and I'm not aware of this architecture being used in a reasoning context anywhere else. Check it out: ZennyKenny/synthetic_vc_financial_decisions_reasoning_dataset See translation", "url": "https://huggingface.co/posts/ZennyKenny/876840490309462", "date_published": "2025-04-30T09:24:57.604063"}]}