{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/mitkox/390180686171042", "image": "", "title": "Say hello to my little friends! I just unboxed this trio of HP Z2 G1a!", "content_text": "Say hello to my little friends! I just unboxed this trio of HP Z2 G1a! Three is always better than one! 3x AMD Ryzen AI Max+ Pro 395 384GB RAM 24TB of RAID storage Ubuntu 24.04 ROCm 7.0.2 llama cpp, vLLM and Aibrix Small, cheap GPUs are about to become the Raspberry Pi of edge AI inference. Sprinkle some kubectl fairy dust on top, and suddenly it's a high-availability, self-healing, cloud-native, enterprise-grade AI cluster camping in a closet. Make sure you own your AI. AI in the cloud is not aligned with you; it\u2019s aligned with the company that owns it. See translation", "url": "https://huggingface.co/posts/mitkox/390180686171042", "date_published": "2025-10-25T05:21:51.135591"}, {"id": "https://huggingface.co/posts/tomaarsen/527498981313495", "image": "", "title": "\ud83e\udd17 Sentence Transformers is joining Hugging Face! \ud83e\udd17 This formalizes the existing maintenance structure, as I've personally led the project for the past two years on behalf of Hugging Face! Details:", "content_text": "\ud83e\udd17 Sentence Transformers is joining Hugging Face! \ud83e\udd17 This formalizes the existing maintenance structure, as I've personally led the project for the past two years on behalf of Hugging Face! Details: Today, the Ubiquitous Knowledge Processing (UKP) Lab is transferring the project to Hugging Face. Sentence Transformers will remain a community-driven, open-source project, with the same open-source license (Apache 2.0) as before. Contributions from researchers, developers, and enthusiasts are welcome and encouraged. The project will continue to prioritize transparency, collaboration, and broad accessibility. Read our full announcement for more details and quotes from UKP and Hugging Face leadership: https://huggingface.co/blog/sentence-transformers-joins-hf We see an increasing wish from companies to move from large LLM APIs to local models for better control and privacy, reflected in the library's growth: in just the last 30 days, Sentence Transformer models have been downloaded >270...", "url": "https://huggingface.co/posts/tomaarsen/527498981313495", "date_published": "2025-10-25T05:21:51.136194"}, {"id": "https://huggingface.co/posts/salma-remyx/787120125285076", "image": "", "title": "We've built over 10K containerized reproductions of papers from arXiv!", "content_text": "We've built over 10K containerized reproductions of papers from arXiv! Instead of spending all day trying to build an environment to test that new idea, just pull the Docker container from the Remyx registry. And with Remyx, you can start experimenting faster by generating a test PR in your codebase based on the ideas found in your paper of choice. Hub: https://hub.docker.com/u/remyxai Remyx docs: https://docs.remyx.ai/resources/ideate Coming soon, explore reproduced papers with AG2 + Remyx: https://github.com/ag2ai/ag2/pull/2141 See translation", "url": "https://huggingface.co/posts/salma-remyx/787120125285076", "date_published": "2025-10-25T05:21:51.136482"}, {"id": "https://huggingface.co/posts/SelmaNajih001/829546518885653", "image": "", "title": "Which is the best model to use as a signal for investment?", "content_text": "Which is the best model to use as a signal for investment? Here who is gaining the most: SelmaNajih001/InvestmentStrategyBasedOnSentiment The Space uses titles from this dataset: \ud83d\udcca SelmaNajih001/Cnbc_MultiCompany Given a news title, it calculates a sentiment score : if the score crosses a certain threshold, the strategy decides to buy or sell. Each trade lasts one day, and the strategy then computes the daily return. For Tesla the best model seems to be the regression \ud83d\udc40 Just a quick note: the model uses the closing price as the buy price, meaning it already reflects the impact of the news. See translation", "url": "https://huggingface.co/posts/SelmaNajih001/829546518885653", "date_published": "2025-10-25T05:21:51.136835"}, {"id": "https://huggingface.co/posts/sondhiArm/743734106671454", "image": "", "title": "Hello from PyTorch Conference 2025! \ud83d\udc4b", "content_text": "Hello from PyTorch Conference 2025! \ud83d\udc4b The energy is high, and we\u2019re excited to connect with the community to showcase how developers can build high-performance GenAI applications across cloud, mobile, and edge using PyTorch and ExecuTorch. Visit us at Booth #P1 to explore hands-on demos, join a one-on-one workshop, or catch one of our insightful sessions throughout the day. https://developer.arm.com/developer-partners/pytorch See translation", "url": "https://huggingface.co/posts/sondhiArm/743734106671454", "date_published": "2025-10-25T05:21:51.137125"}, {"id": "https://huggingface.co/posts/sergiopaniego/527159223589050", "image": "", "title": "Meet OpenEnv \ud83d\udc4b, an open ecosystem of environments for intelligent agents. Build, share, and test agents safely and consistently.", "content_text": "Meet OpenEnv \ud83d\udc4b, an open ecosystem of environments for intelligent agents. Build, share, and test agents safely and consistently. Ideal for training with TRL (we include examples\ud83e\udd13), deployment, and community collaboration via the HF Hub Blog: https://huggingface.co/blog/openenv Hub for Environments: openenv OpenEnv repo: https://github.com/meta-pytorch/OpenEnv Try it out using TRL: https://huggingface.co/docs/trl/main/en/openenv See translation", "url": "https://huggingface.co/posts/sergiopaniego/527159223589050", "date_published": "2025-10-25T05:21:51.137405"}, {"id": "https://huggingface.co/posts/branikita/215658672762252", "image": "", "title": "We\u2019re preparing an in-depth review of the Feetech STS-3250 servo motor \u2014 exploring its performance, features. One of the top serial bus servo for hobby robotics compatible with SO-ARM 100 manipulator.", "content_text": "We\u2019re preparing an in-depth review of the Feetech STS-3250 servo motor \u2014 exploring its performance, features. One of the top serial bus servo for hobby robotics compatible with SO-ARM 100 manipulator. See translation", "url": "https://huggingface.co/posts/branikita/215658672762252", "date_published": "2025-10-25T05:21:51.137633"}, {"id": "https://huggingface.co/posts/AdinaY/459235610615805", "image": "", "title": "HunyuanWorld Mirror\ud83d\udd25a versatile feed forward model for universal 3D world reconstruction by Tencent", "content_text": "HunyuanWorld Mirror\ud83d\udd25a versatile feed forward model for universal 3D world reconstruction by Tencent tencent/HunyuanWorld-Mirror \u2728 Any prior in \u2192 3D world out \u2728 Mix camera, intrinsics, depth as priors \u2728 Predict point clouds, normals, Gaussians & more in one pass \u2728 Unified architecture for all 3D task See translation", "url": "https://huggingface.co/posts/AdinaY/459235610615805", "date_published": "2025-10-25T05:21:51.137911"}, {"id": "https://huggingface.co/posts/SelmaNajih001/973945902491280", "image": "", "title": "How Financial News Can Be Used to Train Good Financial Models \ud83d\udcf0", "content_text": "How Financial News Can Be Used to Train Good Financial Models \ud83d\udcf0 Numbers tell you what happened, but news tells you why. I\u2019ve written an article explaining how news can be used to train AI models for sentiment analysis and better forecasting. Hope you find it interesting! Read it here: https://huggingface.co/blog/SelmaNajih001/llms-applied-to-finance I would love to read your opinions! I\u2019m open to suggestions on how to improve the methodology and the training See translation", "url": "https://huggingface.co/posts/SelmaNajih001/973945902491280", "date_published": "2025-10-25T05:21:51.138200"}, {"id": "https://huggingface.co/posts/piercus/153431503429656", "image": "", "title": "\ud83d\udea7 Reproducing LBM-Eraser\u2026 in the open [1] !", "content_text": "\ud83d\udea7 Reproducing LBM-Eraser\u2026 in the open [1] ! Today we have trained a LBM [2] promptless inpainter using Re-LAION-Caption19M [3]. We use a subset of 1.25M images with aesthetic_score > 5.6 and pwatermark < 0.2 and LaMa [2] mask generation. 2 takeaways : \ud83d\uddbc Inpainting is better compared to our RORD experiments [5] \ud83e\uddb6 \"4 steps\" outperforms single-step [1] Finegrain LBM Fork : https://github.com/finegrain-ai/LBM [2] LBM: Latent Bridge Matching for Fast Image-to-Image Translation (2503.07535) [3] supermodelresearch/Re-LAION-Caption19M [4] Resolution-robust Large Mask Inpainting with Fourier Convolutions (2109.07161) [5] https://huggingface.co/posts/piercus/778833977889788 cc @ supermodelresearch @ presencesw See translation", "url": "https://huggingface.co/posts/piercus/153431503429656", "date_published": "2025-10-25T05:21:51.138558"}]}