{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/tomaarsen/619466658423382", "image": "", "title": "\ud83d\ude0e I just published Sentence Transformers v5.1.0, and it's a big one. 2x-3x speedups of SparseEncoder models via ONNX and/or OpenVINO backends, easier distillation data preparation with hard negatives mining, and more:", "content_text": "\ud83d\ude0e I just published Sentence Transformers v5.1.0, and it's a big one. 2x-3x speedups of SparseEncoder models via ONNX and/or OpenVINO backends, easier distillation data preparation with hard negatives mining, and more: 1\ufe0f\u20e3 Faster ONNX and OpenVINO backends for SparseEncoder models Usage is as simple as backend=\"onnx\" or backend=\"openvino\" when initializing a SparseEncoder to get started, but I also included utility functions for optimization, dynamic quantization, and static quantization, plus benchmarks. 2\ufe0f\u20e3 New n-tuple-scores output format from mine_hard_negatives This new output format is immediately compatible with the MarginMSELoss and SparseMarginMSELoss for training SentenceTransformer, CrossEncoder, and SparseEncoder losses. 3\ufe0f\u20e3 Gathering across devices When doing multi-GPU training using a loss that has in-batch negatives (e.g. MultipleNegativesRankingLoss), you can now use gather_across_devices=True to load in-batch negatives from the other devices too! Essentially a free...", "url": "https://huggingface.co/posts/tomaarsen/619466658423382", "date_published": "2025-08-08T09:32:20.380239"}, {"id": "https://huggingface.co/posts/danielhanchen/446160279272944", "image": "", "title": "Run OpenAI's new gpt-oss models locally with Unsloth GGUFs! \ud83d\udd25\ud83e\udda5", "content_text": "Run OpenAI's new gpt-oss models locally with Unsloth GGUFs! \ud83d\udd25\ud83e\udda5 20b GGUF: unsloth/gpt-oss-20b-GGUF 120b GGUF: unsloth/gpt-oss-120b-GGUF Model will run on 14GB RAM for 20b and 66GB for 120b. See translation", "url": "https://huggingface.co/posts/danielhanchen/446160279272944", "date_published": "2025-08-08T09:32:20.380546"}, {"id": "https://huggingface.co/posts/clem/743374424636682", "image": "", "title": "Thread to gossip during the", "content_text": "Thread to gossip during the openai GPT-5 livestream: https://www.youtube.com/watch?v=0Uu_VJeVVfo . Feel free to post your impressions below! See translation", "url": "https://huggingface.co/posts/clem/743374424636682", "date_published": "2025-08-08T09:32:20.380777"}, {"id": "https://huggingface.co/posts/sweatSmile/255574652175478", "image": "", "title": "Qwen3 is the latest version of the Qwen language models. It's smarter, faster, and now understands 119 languages instead of just 29.", "content_text": "Qwen3 is the latest version of the Qwen language models. It's smarter, faster, and now understands 119 languages instead of just 29. It can do both deep reasoning and quick answers using a single model, depending on what you need. The models range in size from small (0.6B) to huge (235B), with smart ways to save compute. It's trained on 36 trillion tokens and fine-tuned in four steps to boost performance. Qwen3 performs as well as or better than many top models, including some from big companies. It\u2019s fully open-source under licence. Amazing!!! https://github.com/QwenLM/Qwen3/blob/main/Qwen3_Technical_Report.pdf See translation", "url": "https://huggingface.co/posts/sweatSmile/255574652175478", "date_published": "2025-08-08T09:32:20.381139"}, {"id": "https://huggingface.co/posts/georgewritescode/981174566402338", "image": "", "title": "Announcing Artificial Analysis Long Context Reasoning (AA-LCR), a new benchmark to evaluate long context performance through testing reasoning capabilities across multiple long documents (~100k tokens)", "content_text": "Announcing Artificial Analysis Long Context Reasoning (AA-LCR), a new benchmark to evaluate long context performance through testing reasoning capabilities across multiple long documents (~100k tokens) The focus of AA-LCR is to replicate real knowledge work and reasoning tasks, testing capability critical to modern AI applications spanning document analysis, codebase understanding, and complex multi-step workflows. AA-LCR is 100 hard text-based questions that require reasoning across multiple real-world documents that represent ~100k input tokens. Questions are designed so answers cannot be directly found but must be reasoned from multiple information sources, with human testing verifying that each question requires genuine inference rather than retrieval. Key takeaways: \u27a4 Today\u2019s leading models achieve ~70% accuracy: the top three places go to OpenAI o3 (69%), xAI Grok 4 (68%) and Qwen3 235B 2507 Thinking (67%) \u27a4\ud83d\udc40 We also already have gpt-oss results! 120B performs close to o4-mini...", "url": "https://huggingface.co/posts/georgewritescode/981174566402338", "date_published": "2025-08-08T09:32:20.381752"}, {"id": "https://huggingface.co/posts/openfree/275314685023370", "image": "", "title": "\ud83d\ude80 GPT-OSS 120B & 20B - Use Both Models in One Space!", "content_text": "\ud83d\ude80 GPT-OSS 120B & 20B - Use Both Models in One Space! openfree/OpenAI-gpt-oss VIDraft/gpt-oss-RAG \ud83c\udfaf Two Models, One Space! GPT-OSS hit #1 on HF just 2 hours after release! \ud83c\udfc6 Now you can use both models conveniently in a single space. \ud83d\udccb Model Selection Made Easy! Just pick from the dropdown \u2705 \u251c\u2500\u2500 GPT-OSS-120B (Complex tasks) \u2514\u2500\u2500 GPT-OSS-20B (Quick chats) \ud83d\udcab How to Use (Takes 30 seconds!) Sign in \u2192 With your HF account \ud83d\udd10 Select model \u2192 Choose what you need \ud83d\udccc Apply \u2192 Click! \u26a1 Start chatting \u2192 That's it! \ud83d\udcac \ud83c\udf08 Perfect For: 120B \u2192 Deep analysis, professional work \ud83e\udde0 20B \u2192 Fast responses, casual conversations \u26a1 No installation needed - just use it in your browser! \ud83c\udf10 \u2728 Special Features \ud83c\udfa8 Beautiful gradient UI \ud83c\udf19 Dark mode support \ud83d\udd04 Real-time model switching \ud83c\udd93 Completely free! \ud83d\udc49 Try it now! It's really that simple! #GPT-OSS #HuggingFace #FreeAI #EasyToUse See translation", "url": "https://huggingface.co/posts/openfree/275314685023370", "date_published": "2025-08-08T09:32:20.382253"}, {"id": "https://huggingface.co/posts/ImranzamanML/667361724381561", "image": "", "title": "Finaly OpenAI is open to share open-source models after GPT2-2019.", "content_text": "Finaly OpenAI is open to share open-source models after GPT2-2019. gpt-oss-120b gpt-oss-20b openai/gpt-oss-120b #AI #GPT #LLM #Openai See translation", "url": "https://huggingface.co/posts/ImranzamanML/667361724381561", "date_published": "2025-08-08T09:32:20.382494"}, {"id": "https://huggingface.co/posts/fdaudens/331415397781817", "image": "", "title": "Well, it took just 2 hours for", "content_text": "Well, it took just 2 hours for openai/gpt-oss-120b to hit #1 on Hugging Face. Don\u2019t remember seeing anything rise that fast! See translation", "url": "https://huggingface.co/posts/fdaudens/331415397781817", "date_published": "2025-08-08T09:32:20.382736"}, {"id": "https://huggingface.co/posts/neph1/202844482773668", "image": "", "title": "I'm building a mmo-ish RPG with LLM agents that can (hopefully) complete player tasks, as an experiment. I've started documenting my progress here:", "content_text": "I'm building a mmo-ish RPG with LLM agents that can (hopefully) complete player tasks, as an experiment. I've started documenting my progress here: https://huggingface.co/blog/neph1/rpg-llm-agents Let me know if you want to see more of it. See translation", "url": "https://huggingface.co/posts/neph1/202844482773668", "date_published": "2025-08-08T09:32:20.382979"}, {"id": "https://huggingface.co/posts/sergiopaniego/625485045816019", "image": "", "title": "OpenAI's open models are out! \ud83d\udc83", "content_text": "OpenAI's open models are out! \ud83d\udc83 Try: https://www.gpt-oss.com/ Learn: https://huggingface.co/blog/welcome-openai-gpt-oss See translation", "url": "https://huggingface.co/posts/sergiopaniego/625485045816019", "date_published": "2025-08-08T09:32:20.383202"}]}