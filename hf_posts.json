{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/victor/750233862472141", "image": "", "title": "Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models \ud83d\udd25", "content_text": "Nvidia is on a roll lately. Nemotron 3 Nano is my new fav local model, but here's the real flex: they published the entire evaluation setup. Configs, prompts, logs, all of it. This is how you do open models \ud83d\udd25 https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe See translation", "url": "https://huggingface.co/posts/victor/750233862472141", "date_published": "2025-12-19T17:22:14.704447"}, {"id": "https://huggingface.co/posts/YatharthS/190514854652270", "image": "", "title": "\ud83e\udd2f \ud83e\udd2f Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! \ud83e\udd2f \ud83e\udd2f", "content_text": "\ud83e\udd2f \ud83e\udd2f Released a high quality finetuned LLM based TTS model that can generate realistic and clear 48khz audio at over 100x realtime speed! \ud83e\udd2f \ud83e\udd2f Github link: https://github.com/ysharma3501/MiraTTS Model link: https://github.com/ysharma3501/MiraTTS Blog explaining llm tts models: https://huggingface.co/blog/YatharthS/llm-tts-models See translation", "url": "https://huggingface.co/posts/YatharthS/190514854652270", "date_published": "2025-12-19T17:22:14.704805"}, {"id": "https://huggingface.co/posts/prithivMLmods/223082724733311", "image": "", "title": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea", "content_text": "Introducing the Z Image Turbo LoRA DLC App, a gallery space for plug-and-play Z-Image-Turbo LoRAs. It features a curated collection of impressive LoRAs for generating high-quality images. By default, it runs on the base model. Simply choose a LoRA, type your prompt, and generate images. You can find the app and more details below. \ud83e\udd17\ud83e\uddea \u25cf Space [Demo]: prithivMLmods/Z-Image-Turbo-LoRA-DLC \u25cf Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection \u25cf Check the list of Z-Image LoRA's: https://huggingface.co/models?other=base_model:adapter:Tongyi-MAI/Z-Image-Turbo \u25cf Github: https://github.com/PRITHIVSAKTHIUR/Z-Image-Turbo-LoRA-DLC Other related image gen spaces:- \u25cf FLUX-LoRA-DLC2: prithivMLmods/FLUX-LoRA-DLC2 \u25cf FLUX-LoRA-DLC: prithivMLmods/FLUX-LoRA-DLC \u25cf Qwen-Image-LoRA-DLC: prithivMLmods/Qwen-Image-LoRA-DLC \u25cf Qwen-Image-Edit-2509-LoRAs-Fast: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast \u25cf Qwen-Image-Edit-2509-LoRAs-Fast-Fusion: prithivMLmods/Qwen-...", "url": "https://huggingface.co/posts/prithivMLmods/223082724733311", "date_published": "2025-12-19T17:22:14.705314"}, {"id": "https://huggingface.co/posts/sergiopaniego/463044021249760", "image": "", "title": "Google DeepMind releases FunctionGemma, a 240M model specialized in \ud83d\udd27 tool calling, built for fine-tuning", "content_text": "Google DeepMind releases FunctionGemma, a 240M model specialized in \ud83d\udd27 tool calling, built for fine-tuning TRL has day-0 support. To celebrate, we\u2019re sharing 2 new resources: > Colab guide to fine-tune it for \ud83c\udf10 browser control with BrowserGym OpenEnv > Standalone training script > Colab notebook: https://colab.research.google.com/github/huggingface/trl/blob/main/examples/notebooks/grpo_functiongemma_browsergym_openenv.ipynb > Training script: https://github.com/huggingface/trl/blob/main/examples/scripts/openenv/browsergym_llm.py (command to run it inside the script) > More notebooks in TRL: https://huggingface.co/docs/trl/example_overview#notebooks See translation", "url": "https://huggingface.co/posts/sergiopaniego/463044021249760", "date_published": "2025-12-19T17:22:14.705653"}, {"id": "https://huggingface.co/posts/rajkumarrawal/519682431601479", "image": "", "title": "\" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI \". r2r-protocol (Robot2Robot Protocol) is now officially open source! \ud83d\udd13", "content_text": "\" An open standardized protocol enabling communication for autonomous robots to exchange data, coordinate tasks, and collaborate in real-time environments in the age of AI \". r2r-protocol (Robot2Robot Protocol) is now officially open source! \ud83d\udd13 \"pip install r2r-protocol\" Whether you're a developer, researcher, or tech enthusiast, we invite you to explore, use, and contribute to the project. \ud83d\udd17 Check it out here: [ https://github.com/Tech-Parivartan/r2r-protocol?tab=readme-ov-file ] Let\u2019s build the future together! \ud83d\udca1 AiParivartanResearchLab techparivartan Documentation of the r2r-protocal : [ https://techparivartanai.notion.site/Robot-to-Robot-r2r-Protocol-1f008f0fb18780439d70e8b9bbbdb869 ] The R2R Protocol enables seamless robot-to-robot interaction across industrial automation, swarm robotics, logistics, and multi-agent systems. It defines structured message formats, negotiation logic, discovery mechanisms, and extensible APIs. #r2r_protocol #robot2robot_protocol #ai...", "url": "https://huggingface.co/posts/rajkumarrawal/519682431601479", "date_published": "2025-12-19T17:22:14.706101"}, {"id": "https://huggingface.co/posts/branikita/654655990580208", "image": "", "title": "Update: Our engineer Alan has received a batch of components for the manipulator assemblies \u2014 including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year.", "content_text": "Update: Our engineer Alan has received a batch of components for the manipulator assemblies \u2014 including clamps and metal bracket parts. Prototype assembly is planned for the beginning of next year. See translation", "url": "https://huggingface.co/posts/branikita/654655990580208", "date_published": "2025-12-19T17:22:14.706336"}, {"id": "https://huggingface.co/posts/ZennyKenny/672558817086708", "image": "", "title": "\ud83c\udf53 One of the coolest parts about being an early Strawberry user has been the opportunity to build on the app at the ground floor.", "content_text": "\ud83c\udf53 One of the coolest parts about being an early Strawberry user has been the opportunity to build on the app at the ground floor. The platform already has a ton of great integrations that let you interact with your external apps directly with tools, but I wanted to add the ability to do stuff in Slack as well. \ud83d\udcaa So I took the base Anthropic Slack MCP server, added a whole bunch of new tools, and generalized it as an HTTP-based SSE-server and deployed it in like 2 minutes with Railway so that Strawberry could make use of it (as can Claude or any other MCP client). Now, you can Chat with your Strawberry Companion (or Claude, or whatever) and do things like: \u27a1\ufe0f Get caught up across all of your Slack channels after a long weekend or noisy incident without having to read 20 threads in 10 different channels \u27a1\ufe0f Create, read, and edit Canvases, Messages, and Channels \u27a1\ufe0f Take any resources or content that you're using in your Chat and inject it directly into Slack without copy / paste \ud83d\ude0e I'm...", "url": "https://huggingface.co/posts/ZennyKenny/672558817086708", "date_published": "2025-12-19T17:22:14.706845"}, {"id": "https://huggingface.co/posts/prithivMLmods/594063489793001", "image": "", "title": "Demo for Molmo2 on Hugging Face is live now, including Single/Multi-Image VQA, Visual Pointing/Grounding, Video VQA, and Video Point Tracking. Find the demo and related collections below. \ud83d\udd25\ud83e\udd17", "content_text": "Demo for Molmo2 on Hugging Face is live now, including Single/Multi-Image VQA, Visual Pointing/Grounding, Video VQA, and Video Point Tracking. Find the demo and related collections below. \ud83d\udd25\ud83e\udd17 \u25cf Molmo2 HF Demo\ud83d\udda5\ufe0f: prithivMLmods/Molmo2-HF-Demo \u25cf Model Collection: https://huggingface.co/collections/allenai/molmo2 \u25cf Related Multimodal Space Collection: https://huggingface.co/collections/prithivMLmods/multimodal-implementations To know more about it, visit the app page or the respective model page! See translation", "url": "https://huggingface.co/posts/prithivMLmods/594063489793001", "date_published": "2025-12-19T17:22:14.707166"}, {"id": "https://huggingface.co/posts/ronantakizawa/412513789590360", "image": "", "title": "Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on.", "content_text": "Introducing the github-top-developers dataset: A comprehensive dataset of the top 8000 developers on GitHub (2020-2025). This dataset captures the evolution of GitHub's trending developers repositories over time and the projects they work on. #github #developers ronantakizawa/github-top-developers See translation", "url": "https://huggingface.co/posts/ronantakizawa/412513789590360", "date_published": "2025-12-19T17:22:14.707397"}, {"id": "https://huggingface.co/posts/danielhanchen/963278821580490", "image": "", "title": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25", "content_text": "NVIDIA releases Nemotron 3 Nano, a new 30B hybrid reasoning model! \ud83d\udd25 Has 1M context window & best in class performance for SWE-Bench, reasoning & chat. Run the MoE model locally with 24GB RAM. GGUF: unsloth/Nemotron-3-Nano-30B-A3B-GGUF \ud83d\udc9a Step-by-step Guide: https://docs.unsloth.ai/models/nemotron-3 See translation", "url": "https://huggingface.co/posts/danielhanchen/963278821580490", "date_published": "2025-12-19T17:22:14.707649"}]}