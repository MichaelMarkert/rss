{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/danielhanchen/579968620456275", "image": "", "title": "You can now fine-tune embedding models in our free Unsloth notebook! \ud83e\udd17", "content_text": "You can now fine-tune embedding models in our free Unsloth notebook! \ud83e\udd17 Fine-tuning embedding models improves retrieval & RAG by aligning vectors to your domain-specific notion of similarity, improving search, clustering, and recommendations on your data. \u2b50 Blog + Notebooks: https://unsloth.ai/docs/new/embedding-finetuning Unsloth trains embedding models 1.8-3.3x faster with 20% less VRAM, 2x longer context & no accuracy loss vs. FA2 setups. We'd like to thank Hugging Face and Unsloth contributor: electroglyph for making this possible! See translation", "url": "https://huggingface.co/posts/danielhanchen/579968620456275", "date_published": "2026-01-23T13:47:00.940715"}, {"id": "https://huggingface.co/posts/IlyasMoutawwakil/703555138750194", "image": "", "title": "After 2 months of refinement, I'm happy to announce that a lot of Transformers' modeling code is now significantly more torch-compile & export-friendly \ud83d\udd25", "content_text": "After 2 months of refinement, I'm happy to announce that a lot of Transformers' modeling code is now significantly more torch-compile & export-friendly \ud83d\udd25 Why it had to be done \ud83d\udc47 PyTorch's Dynamo compiler is increasingly becoming the default interoperability layer for ML systems. Anything that relies on torch.export or torch.compile, from model optimization to cross-framework integrations, benefits directly when models can be captured as a single dynamo-traced graph ! Transformers models are now easier to: \u2699\ufe0f Compile end-to-end with torch.compile backends \ud83d\udce6 Export reliably via torch.export and torch.onnx.export \ud83d\ude80 Deploy to ONNX / ONNX Runtime, Intel Corporation's OpenVINO, NVIDIA AutoDeploy (TRT-LLM), AMD's Quark, Meta's Executorch and more hardware-specific runtimes. This work aims at unblocking entire TorchDynamo-based toolchains that rely on exporting Transformers across runtimes and accelerators. We are doubling down on Transformers commitment to be a first-class citizen of the...", "url": "https://huggingface.co/posts/IlyasMoutawwakil/703555138750194", "date_published": "2026-01-23T13:47:00.941260"}, {"id": "https://huggingface.co/posts/hassenhamdi/338157395556750", "image": "", "title": "Google published the paper. I shipped the code. \ud83d\ude80", "content_text": "Google published the paper. I shipped the code. \ud83d\ude80 DeepMind just released PACEvolve (Progress-Aware Consistent Evolution), a massive overhaul of the AlphaEvolve framework. It solves the critical issues of \"Context Pollution\" and \"Mode Collapse\" that have historically crippled evolutionary coding agents. But there was no public implementation. So I built one. Introducing OpenPACEvolve: A fully open-source, production-grade implementation of the PACEvolve framework. \ud83d\udee0 I engineered this framework solo, but I wasn't working alone. I orchestrated a custom coding agents powered by Claude Opus 4.5 as Engineer and Gemini Pro 3 Preview ensuring fiedelity and quallty. By leveraging these SOTA models, I was able to translate complex theoretical research into functional, modular Python architecture in record time. This is what the future of AI engineering looks like: Human architectural oversight + AI velocity. \ud83e\udde0 What OpenPACEvolve Solves: Unlike standard agents that get \"stuck\" in loops, this...", "url": "https://huggingface.co/posts/hassenhamdi/338157395556750", "date_published": "2026-01-23T13:47:00.941858"}, {"id": "https://huggingface.co/posts/mitkox/833172754531021", "image": "", "title": "GLM-4.7-Flash is fast, good and cheap.", "content_text": "GLM-4.7-Flash is fast, good and cheap. 3,074 tokens/sec peak at 200k tokens context window on my desktop PC. Works with Claude Code and opencode for hours. No errors, drop-in replacement of the Anthropic cloud AI. MIT licensed, open weights, free for commercial use and modifications. Supports speculative decoding using MTP, which is highly effective in mitigating latency. Great for on device AI coding as AWQ 4bit at 18.5 GB. Hybrid inference on a single consumer GPU + CPU RAM. See translation", "url": "https://huggingface.co/posts/mitkox/833172754531021", "date_published": "2026-01-23T13:47:00.942140"}, {"id": "https://huggingface.co/posts/Ujjwal-Tyagi/827993286487533", "image": "", "title": "There is a new open-source music generation model called HeartMuLa. It offers strong, competitive performance compared to Suno and supports English, Chinese, Japanese, Korean, and Spanish. It is optimized to run easily on RTX GPUs and other consumer-grade hardware.", "content_text": "There is a new open-source music generation model called HeartMuLa. It offers strong, competitive performance compared to Suno and supports English, Chinese, Japanese, Korean, and Spanish. It is optimized to run easily on RTX GPUs and other consumer-grade hardware. HeartMuLa/HeartMuLa-oss-3B https://github.com/HeartMuLa/heartlib See translation", "url": "https://huggingface.co/posts/Ujjwal-Tyagi/827993286487533", "date_published": "2026-01-23T13:47:00.942377"}, {"id": "https://huggingface.co/posts/Reubencf/519964840142107", "image": "", "title": "Now Live: The", "content_text": "Now Live: The Reubencf/Nano_Banana_Editor now includes 10 free requests/day! \ud83c\udf4c I'm personally sponsoring these credits to help make open AI accessible to all. (Note: Limits are subject to change based on funding). Enjoy ! See translation", "url": "https://huggingface.co/posts/Reubencf/519964840142107", "date_published": "2026-01-23T13:47:00.942629"}, {"id": "https://huggingface.co/posts/branikita/663180639810394", "image": "", "title": "Our engineer Alan from", "content_text": "Our engineer Alan from https://robonine.com/ (Educational Robotics) integrated Feetech STS3250 and STS3215 servo motors into the prototype and completed the first test run of a 6-DOF semi-SCARA manipulator. During motion, the structure demonstrates high stiffness with no visible backlash or mechanical play. The kinematic chain remains stable throughout the test trajectory, confirming the rigidity of the mechanical design and joint assembly. The next stage includes full assembly with all actuators operating in backlash compensation mode, followed by quantitative measurement of positioning accuracy and repeatability. See translation", "url": "https://huggingface.co/posts/branikita/663180639810394", "date_published": "2026-01-23T13:47:00.942909"}, {"id": "https://huggingface.co/posts/danielhanchen/143027024579647", "image": "", "title": "Run GLM-4.7-Flash locally on your device with 24GB RAM!\ud83d\udd25", "content_text": "Run GLM-4.7-Flash locally on your device with 24GB RAM!\ud83d\udd25 It's the best performing 30B model on SWE-Bench and GPQA. With 200K context, it excels at coding, agents, chat & reasoning. GGUF: unsloth/GLM-4.7-Flash-GGUF Guide: https://unsloth.ai/docs/models/glm-4.7-flash See translation", "url": "https://huggingface.co/posts/danielhanchen/143027024579647", "date_published": "2026-01-23T13:47:00.943163"}, {"id": "https://huggingface.co/posts/Juanxi/706096090265682", "image": "", "title": "Recent Updates on ScalingOpt | Your Stars are Appreciated", "content_text": "Recent Updates on ScalingOpt | Your Stars are Appreciated We are pleased to announce several key updates to the ScalingOpt project: Pyramid Visualization Structure Following a suggestion from Yufei, we have introduced a pyramid-based visualization framework to systematically outline the layered architecture of Foundation Models\u2014from foundational principles to infrastructure-level details. This addition is designed to assist teams in organizing and presenting related materials more clearly. Integration of Optimizer Summaries by Yifeng We extend a warm welcome to Yifeng (author of MARS), who has joined the project. He has contributed a comprehensive summary of over 100 optimizers, now available in ScalingOpt. This resource can be accessed via the \u201cOptimization Summary Sheet\u201d on the homepage or under the Optimizers page, featuring a reader-friendly interface that supports easy viewing, downloading, and citation. Growing Community of Members We continue to update and expand the list of...", "url": "https://huggingface.co/posts/Juanxi/706096090265682", "date_published": "2026-01-23T13:47:00.943703"}, {"id": "https://huggingface.co/posts/mahimairaja/326779707036352", "image": "", "title": "My Favorite Open Source Models for Jan 2026", "content_text": "My Favorite Open Source Models for Jan 2026 1. General Use - deepseek-ai/DeepSeek-V3.2 2. Reasoning - deepseek-ai/DeepSeek-V3.2-Speciale 3. Coding - Qwen/Qwen3-Coder-30B-A3B-Instruct 4. OCR - Qwen/Qwen3-VL-8B-Instruct 5. Image Generation - black-forest-labs/FLUX.2-dev 6. Image Editing - Qwen/Qwen-Image-Edit-2509 What model do you use regularly? See translation", "url": "https://huggingface.co/posts/mahimairaja/326779707036352", "date_published": "2026-01-23T13:47:00.943958"}]}