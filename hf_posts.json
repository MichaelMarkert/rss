{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/anakin87/201202681111752", "image": "", "title": "LLMs can leak their post-training data (RL included) \ud83d\udca7", "content_text": "LLMs can leak their post-training data (RL included) \ud83d\udca7 New interesting paper on this topic from Google DeepMind: Extracting alignment data in open models (2510.18554) It's known that Language Models memorize data that can be extracted via prompting. In this paper, the authors investigate this aspect: - using open models, where prompting can be fully customized by the user, including special tokens. - focusing on open-source models like Olmo, where full training data is available. \ud83d\udce4 How do they extract data? During post-training (like SFT), new tokens such as <|user|> are introduced. The authors hypothesize prompting the model with these tokens can make it output its alignment data (remember Magpie?). For example, for SFT, their extraction prompt is <|endoftext|><|user|>. \ud83d\udccf Evaluating memorization The authors compare each sampled example with the original data using vector search with embedding similarity. They find that many outputs are semantically very similar to the original...", "url": "https://huggingface.co/posts/anakin87/201202681111752", "date_published": "2025-11-15T13:27:36.703980"}, {"id": "https://huggingface.co/posts/ronantakizawa/435117440357729", "image": "", "title": "Reached 1000+ total downloads across my models and datasets! \ud83c\udf89", "content_text": "Reached 1000+ total downloads across my models and datasets! \ud83c\udf89 Follow me for more @ ronantakizawa See translation", "url": "https://huggingface.co/posts/ronantakizawa/435117440357729", "date_published": "2025-11-15T13:27:36.704222"}, {"id": "https://huggingface.co/posts/alibidaran/312503029386627", "image": "", "title": "This shared notebook comprises the MMLU benchmark evaluating task for my latest reasoning model for the sociology field. The results show that using Few-shot prompting in the system prompt can significantly improve the model's performance at answering questions.", "content_text": "This shared notebook comprises the MMLU benchmark evaluating task for my latest reasoning model for the sociology field. The results show that using Few-shot prompting in the system prompt can significantly improve the model's performance at answering questions. Model's link: alibidaran/GRPO_LLAMA3-instructive_reasoning1 Notebook evaluation: https://www.kaggle.com/code/alibidaran/mmlu-socialogy-thinking-evals?scriptVersionId=277240033 See translation", "url": "https://huggingface.co/posts/alibidaran/312503029386627", "date_published": "2025-11-15T13:27:36.704477"}, {"id": "https://huggingface.co/posts/evalstate/865812476358807", "image": "", "title": "Hugging Face MCP Server v0.2.45", "content_text": "Hugging Face MCP Server v0.2.45 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ - New! Experimental dynamic_space tool. - Default Image Generator changed to Qwen-Image-Fast See translation", "url": "https://huggingface.co/posts/evalstate/865812476358807", "date_published": "2025-11-15T13:27:36.704702"}, {"id": "https://huggingface.co/posts/codelion/349113167339666", "image": "", "title": "\ud83c\udfaf Introducing Chayan: A Calibrated 4-Model LLM Router Achieving 69% Accuracy on RouterArena", "content_text": "\ud83c\udfaf Introducing Chayan: A Calibrated 4-Model LLM Router Achieving 69% Accuracy on RouterArena We're excited to share Chayan, a cost-efficient LLM router that intelligently routes queries between 4 models to maximize accuracy while minimizing cost. Chayan just submitted to the RouterArena leaderboard and achieved 69.05% accuracy on the benchmark! \ud83d\udd17 Model: adaptive-classifier/chayan \ud83d\udd17 Dataset: RouteWorks/RouterArena \ud83d\udcca Performance Highlights Chayan achieves impressive results on the RouterArena benchmark: \u2022 69.05% accuracy (would rank #1 on current leaderboard) \u2022 $0.333 per 1K queries \u2022 +12.07pp improvement over all-mini baseline (56.98%) \u2022 99% of perfect 2-model oracle performance at 57% lower cost Compared to our previous 2-model router (61.43% accuracy), Chayan delivers +7.62pp improvement through smarter 4-model routing. \ud83e\udde0 How It Works Chayan uses an Adaptive K-NN classifier with prototype memory to route between 4 models: \u2022 openai/gpt-4o-mini (fast & cheap) \u2022...", "url": "https://huggingface.co/posts/codelion/349113167339666", "date_published": "2025-11-15T13:27:36.705260"}, {"id": "https://huggingface.co/posts/nroggendorff/877752190149689", "image": "", "title": "Developing with ZeroGPU without a PRO account is painful. They give you so many requests at once, but then have like a 24 hour cooldown. I vote less requests in a batch, but then a shorter cooldown.", "content_text": "Developing with ZeroGPU without a PRO account is painful. They give you so many requests at once, but then have like a 24 hour cooldown. I vote less requests in a batch, but then a shorter cooldown. or just less of a cooldown, but i understand if that is not allowed See translation", "url": "https://huggingface.co/posts/nroggendorff/877752190149689", "date_published": "2025-11-15T13:27:36.705492"}, {"id": "https://huggingface.co/posts/onekq/566639652632782", "image": "", "title": "The reaction on the QAT post is beyond expectations so below is my optimizer post as promised. But I found that I had lots of explanation to do about optimizer itself. So this post is actually a historical recount. The Muon optimizer  (used by Kimi) post (coming very soon) can only continue after this.", "content_text": "The reaction on the QAT post is beyond expectations so below is my optimizer post as promised. But I found that I had lots of explanation to do about optimizer itself. So this post is actually a historical recount. The Muon optimizer (used by Kimi) post (coming very soon) can only continue after this. https://huggingface.co/blog/onekq/adam-optimizer If you know Adam(W) optimizer already, you can just skip and sorry for the wait. Otherwise, it should be a useful read. See translation", "url": "https://huggingface.co/posts/onekq/566639652632782", "date_published": "2025-11-15T13:27:36.705768"}, {"id": "https://huggingface.co/posts/ronantakizawa/135864739980663", "image": "", "title": "Introducing the Japanese honorifics dataset: a dataset with 137 sentences covering the three main keigo forms: \u5c0a\u656c\u8a9e (Sonkeigo), \u8b19\u8b72\u8a9e (Kenj\u014dgo), and \u4e01\u5be7\u8a9e (Teineigo). Each entry includes the base form, all three honorific transformations, and English translations for essential phrases in Japanese. This dataset is perfect for training and evaluating the Japanese skill level of LLMs.", "content_text": "Introducing the Japanese honorifics dataset: a dataset with 137 sentences covering the three main keigo forms: \u5c0a\u656c\u8a9e (Sonkeigo), \u8b19\u8b72\u8a9e (Kenj\u014dgo), and \u4e01\u5be7\u8a9e (Teineigo). Each entry includes the base form, all three honorific transformations, and English translations for essential phrases in Japanese. This dataset is perfect for training and evaluating the Japanese skill level of LLMs. #japanese #japanesedataset ronantakizawa/japanese-honorifics See translation", "url": "https://huggingface.co/posts/ronantakizawa/135864739980663", "date_published": "2025-11-15T13:27:36.706059"}, {"id": "https://huggingface.co/posts/prithivMLmods/809040430953807", "image": "", "title": "Try the all-new trending Qwen-Image-Edit specialized adapter demos, including Photo-to-Anime, Light Restoration, Multi-Angle Edits, Relighting, and more \u2014 all in a single Hugging Face Space. Below is the demo link. \ud83e\udd17\ud83c\udf20", "content_text": "Try the all-new trending Qwen-Image-Edit specialized adapter demos, including Photo-to-Anime, Light Restoration, Multi-Angle Edits, Relighting, and more \u2014 all in a single Hugging Face Space. Below is the demo link. \ud83e\udd17\ud83c\udf20 \u2b9e Demo-Space: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast \u2b9e How-to-Use: prithivMLmods/Qwen-Image-Edit-2509-LoRAs-Fast#2 \u2b9e Collection: https://huggingface.co/collections/prithivMLmods/image-generation-apps-collection To know more about it, visit the app page or the respective model page! See translation", "url": "https://huggingface.co/posts/prithivMLmods/809040430953807", "date_published": "2025-11-15T13:27:36.706360"}, {"id": "https://huggingface.co/posts/evalstate/966306150906160", "image": "", "title": "Hugging Face MCP Server v0.2.46", "content_text": "Hugging Face MCP Server v0.2.46 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ - Add \"discover\" to Dynamic Space tool. Recommend deselecting \"space_search\" if using dynamic spaces. See translation", "url": "https://huggingface.co/posts/evalstate/966306150906160", "date_published": "2025-11-15T13:27:36.706575"}]}