{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/ginipick/539440985640088", "image": "", "title": "Gini's AI Spaces: Everything You Need for Visual Content Creation!", "content_text": "Gini's AI Spaces: Everything You Need for Visual Content Creation! Hello! \u2728 Let me introduce Gini\u2019s 5 AI Spaces that effortlessly generate various styles of visual content. Each Space leverages Diffusers and Gradio, so you can create stunning images in just a few clicks! 1) Flowchart Features: Hand-drawn style flowcharts for workflows or business processes Use Cases: Software release pipelines, data pipelines, corporate workflows Benefits: Clear stage-by-stage structure, simple icon usage ginigen/Flowchart 2) Infographic Features: Visually appealing infographics that communicate data or statistics Use Cases: Global energy charts, startup growth metrics, health tips and more Benefits: Eye-catching icons and layouts, perfect for storytelling at a glance ginigen/Infographic 3) Mockup Features: Sketch-style wireframes or UX mockups for apps/websites Use Cases: Mobile login flows, dashboards, e-commerce site layouts Benefits: Rapid prototyping of early design ideas, perfect for...", "url": "https://huggingface.co/posts/ginipick/539440985640088", "date_published": "2025-02-17T09:23:39.228805"}, {"id": "https://huggingface.co/posts/tianchez/384417618281589", "image": "", "title": "Introducing VLM-R1!", "content_text": "Introducing VLM-R1! GRPO has helped DeepSeek R1 to learn reasoning. Can it also help VLMs perform stronger for general computer vision tasks? The answer is YES and it generalizes better than SFT. We trained Qwen 2.5 VL 3B on RefCOCO (a visual grounding task) and eval on RefCOCO Val and RefGTA (an OOD task). https://github.com/om-ai-lab/VLM-R1 See translation", "url": "https://huggingface.co/posts/tianchez/384417618281589", "date_published": "2025-02-17T09:23:39.229097"}, {"id": "https://huggingface.co/posts/prithivMLmods/804280933500371", "image": "", "title": "The last week of Impression Craft Arts and sketches from strangerzonehf\ud83c\udfa8\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa8", "content_text": "The last week of Impression Craft Arts and sketches from strangerzonehf\ud83c\udfa8\ud83e\uddd1\ud83c\udffb\u200d\ud83c\udfa8 - Collection : strangerzonehf/Flux-Ultimate-LoRA-Collection Adapters: + Ld-Art : strangerzonehf/Ld-Art + Animeopix-Flux : strangerzonehf/Animeopix-Flux + Flux-Super-Paint-LoRA : strangerzonehf/Flux-Super-Paint-LoRA + CinematicShot-Pics-Flux : strangerzonehf/cinematicShot-Pics-Flux + Oil-Wall-Art-Flux : strangerzonehf/Oil-Wall-Art-Flux + Pixelo-Flux : strangerzonehf/Pixelo-Flux + Abstract-Shattered : strangerzonehf/Abstract-Shattered + Neon-Impressionism-Flux : strangerzonehf/Neon-Impressionism-Flux + NewG-Art : strangerzonehf/NewG-Art \ud83e\udea7Demo : prithivMLmods/FLUX-LoRA-DLC \ud83e\udd17Page : https://huggingface.co/strangerzonehf See translation", "url": "https://huggingface.co/posts/prithivMLmods/804280933500371", "date_published": "2025-02-17T09:23:39.229479"}, {"id": "https://huggingface.co/posts/Reality123b/533143502736808", "image": "", "title": "I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it?", "content_text": "I'm working on a groundbreaking AI technology that's kind of like openai's deep research but better. I'm not disclosing everything now. should I open source it? See translation", "url": "https://huggingface.co/posts/Reality123b/533143502736808", "date_published": "2025-02-17T09:23:39.229725"}, {"id": "https://huggingface.co/posts/fffiloni/806803691807876", "image": "", "title": "I was thinking i need to step up my game on training Flux LoRas models, time to have some fun ! \u2600\ufe0f", "content_text": "I was thinking i need to step up my game on training Flux LoRas models, time to have some fun ! \u2600\ufe0f Expect a new drop per week on aesthetics that catched my attention, here are 3 of them that worked really well ! fffiloni/cute-comic-800 fffiloni/carbo-800 fffiloni/oniric-750 See translation", "url": "https://huggingface.co/posts/fffiloni/806803691807876", "date_published": "2025-02-17T09:23:39.230003"}, {"id": "https://huggingface.co/posts/merve/171433424068357", "image": "", "title": "Your weekly recap of open AI is here, and it's packed with models!", "content_text": "Your weekly recap of open AI is here, and it's packed with models! merve/feb-14-releases-67af876b404cc27c6d837767 \ud83d\udc40 Multimodal > OpenGVLab released InternVideo 2.5 Chat models, new video LMs with long context > AIDC released Ovis2 model family along with Ovis dataset, new vision LMs in different sizes (1B, 2B, 4B, 8B, 16B, 34B), with video and OCR support > ColQwenStella-2b is a multilingual visual retrieval model that is sota in it's size > Hoags-2B-Exp is a new multilingual vision LM with contextual reasoning, long context video understanding \ud83d\udcac LLMs A lot of math models! > Open-R1 team released OpenR1-Math-220k large scale math reasoning dataset, along with Qwen2.5-220K-Math fine-tuned on the dataset, OpenR1-Qwen-7B > Nomic AI released new Nomic Embed multilingual retrieval model, a MoE with 500 params with 305M active params, outperforming other models > DeepScaleR-1.5B-Preview is a new DeepSeek-R1-Distill fine-tune using distributed RL on math > LIMO is a new fine-tune of...", "url": "https://huggingface.co/posts/merve/171433424068357", "date_published": "2025-02-17T09:23:39.230523"}, {"id": "https://huggingface.co/posts/Kseniase/134685305854108", "image": "", "title": "8 New Applications of Test-Time Scaling", "content_text": "8 New Applications of Test-Time Scaling We've noticed a huge interest in test-time scaling (TTS), so we decided to explore this concept further. Test-time compute (TTC) refers to the amount of computational power used by an AI model when generating a response. Many researchers are now focused on scaling TTC, as it enables slow, deep \"thinking\" and step-by-step reasoning, which improves overall models' performance. Here are 8 fresh studies on test-time scaling: 1. Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach (2502.05171) Introduces an LM that scales TTC by reasoning in latent space instead of generating more tokens with no special training. Here, a recurrent block to processes information iteratively. 2. Generating Symbolic World Models via Test-time Scaling of Large Language Models (2502.04728) Shows how TTS is applied to enhance model's Planning Domain Definition Language (PDDL) reasoning capabilities, which can be used to generate a symbolic world...", "url": "https://huggingface.co/posts/Kseniase/134685305854108", "date_published": "2025-02-17T09:23:39.231108"}, {"id": "https://huggingface.co/posts/nroggendorff/464265972064174", "image": "", "title": "hello, dev mode explorers!", "content_text": "hello, dev mode explorers! See translation", "url": "https://huggingface.co/posts/nroggendorff/464265972064174", "date_published": "2025-02-17T09:23:39.231316"}, {"id": "https://huggingface.co/posts/benhaotang/322538825901593", "image": "", "title": "Try out my updated implementation of forked OpenDeepResearcher(link below) as an OpenAI compatible endpoint, but with full control, can be deployed completely free with Gemini api or completely locally with ollama, or pay-as-you-go in BYOK format, the AI agents will think dynamically based on the difficulties of given research, compatible with any OpenAI compatible configurable clients(Msty, Chatbox, even vscode AI Toolkit playground).", "content_text": "Try out my updated implementation of forked OpenDeepResearcher(link below) as an OpenAI compatible endpoint, but with full control, can be deployed completely free with Gemini api or completely locally with ollama, or pay-as-you-go in BYOK format, the AI agents will think dynamically based on the difficulties of given research, compatible with any OpenAI compatible configurable clients(Msty, Chatbox, even vscode AI Toolkit playground). If you don't want to pay OpenAI $200 to use or want to take control of your deep research, check out here: \ud83d\udc49 https://github.com/benhaotang/OpenDeepResearcher-via-searxng **Personal take** Based on my testing against Perplexity's and Gemini's implementation with some Physics domain questions, mine is comparable and very competent at finding even the most rare articles or methods. Also a funny benchmark of mine to test all these searching models, is to trouble shot a WSL2 hanging issue I experienced last year, with prompt: > wsl2 in windows hangs in...", "url": "https://huggingface.co/posts/benhaotang/322538825901593", "date_published": "2025-02-17T09:23:39.231985"}, {"id": "https://huggingface.co/posts/davanstrien/966932095656116", "image": "", "title": "How do you make 1M+ Hugging Face models & datasets more discoverable?", "content_text": "How do you make 1M+ Hugging Face models & datasets more discoverable? davanstrien/Smol-Hub-tldr ! I fine-tuned HuggingFaceTB/SmolLM2-360M to generate one-line summaries from a model or dataset README. Its own self-description? \"A model for generating concise summaries of model & dataset cards from the Hugging Face Hub\" The goal? Make it easier to find the right models and datasets for your specific needs. It's already powering a semantic search for datasets Space. It's still a WIP but thanks to @ loubnabnl , @ anton-l , @ eliebak et al, for cooking such a nice base model for fine-tuning small, efficient models for specific domains and tasks. \ud83d\ude4f See translation", "url": "https://huggingface.co/posts/davanstrien/966932095656116", "date_published": "2025-02-17T09:23:39.232374"}]}